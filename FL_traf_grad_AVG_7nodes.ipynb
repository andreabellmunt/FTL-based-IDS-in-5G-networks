{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Federated Learning for attack detection: 7 nodes sharing gradients: FedAVG**\n",
    "\n",
    "IDs from this file = **id8xy** (x = 0 if experiment with dataset, x = 1 if epochs & iterations, y being integer equal or greater than 0)\n",
    "\n",
    "In this file, experiments with different datasets, and number of epochs & iterations are done. The experiments are divided into sections, based on the elements being changed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static elements for all experiments (execute first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Disable warns\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data): \n",
    "\n",
    "    # Select the 'proto' and 'state' values that I want\n",
    "    data = data.loc[(data['proto'] == 'tcp') | (data['proto'] =='udp') | (data['proto'] =='icmp') | (data['proto'] =='arp') | (data['proto'] =='ipv6-icmp') | (data['proto'] =='igmp') | (data['proto'] =='rarp'), :]\n",
    "    data = data.loc[(data['state'] == 'RST') | (data['state'] =='REQ') | (data['state'] =='INT') | (data['state'] =='FIN') | (data['state'] =='CON') | (data['state'] =='ECO') | (data['state'] =='ACC') | (data['state'] == 'PAR'), :]\n",
    "\n",
    "    # Extracting labels \n",
    "    data_labels = data[['label']]\n",
    "\n",
    "    # Drop the invalid features and select interested data features\n",
    "    data_features=data[['proto','srcip','sport','dstip','dsport','spkts','dpkts','sbytes','dbytes','state','stime','ltime','dur']]\n",
    "\n",
    "    \"\"\"PREPROCESSING\"\"\"\n",
    "\n",
    "\n",
    "    # Preprocess IP and ports features\n",
    "    # IP Source Address\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "\n",
    "    # IP Destination Address\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "    # Ports\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "\n",
    "    # Convert all ports with 0 decimal, and HEX to DEC\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    # Convert field to int format\n",
    "    data_features['srcip'] = data_features['srcip'].astype(int)\n",
    "    data_features['sport'] = data_features['sport'].astype(int)\n",
    "    data_features['dstip'] = data_features['dstip'].astype(int)\n",
    "    data_features['dsport'] = data_features['dsport'].astype(int)\n",
    "\n",
    "    # Convert some fields to logarithmic\n",
    "    log1p_col = ['dur', 'sbytes', 'dbytes', 'spkts']\n",
    "\n",
    "    for col in log1p_col:\n",
    "        data_features[col] = data_features[col].apply(np.log1p)\n",
    "\n",
    "    # Create a complementary field of attack & Transform to One hot encoding - LABELS\n",
    "    normal=data_labels['label']\n",
    "    normal=normal.replace(1,2)\n",
    "    normal=normal.replace(0,1)\n",
    "    normal=normal.replace(2,0)\n",
    "\n",
    "    # Insert the new column in data labels\n",
    "    data_labels.insert(1, 'normal', normal)\n",
    "    data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "    data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "    # Transform to One hot encoding - FEATURES\n",
    "    data_features=pd.get_dummies(data_features)\n",
    "\n",
    "    # Value given for the missing columns\n",
    "    auxCol=0\n",
    "\n",
    "    # As we are using different datasets that might not have all representations, we are going to detect and add the missing columns \n",
    "    # The columns that can have types are: proto and state: need to check if all representations are done \n",
    "    state_cols = [col for col in data_features if col.startswith('state_')]\n",
    "    proto_cols = [col for col in data_features if col.startswith('proto_')]\n",
    "    \n",
    "    # Check if all columns are present\n",
    "    if 'state_PAR' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_PAR', auxCol, True)\n",
    "    if 'state_ACC' not in state_cols: \n",
    "        data_features.insert(data_features.shape[1], 'state_ACC', auxCol, True)\n",
    "    if 'state_ECO' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_ECO', auxCol, True)\n",
    "    if 'state_CON' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_CON', auxCol, True)\n",
    "    if 'state_FIN' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_FIN', auxCol, True)\n",
    "    if 'state_INT' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_INT', auxCol, True)\n",
    "    if 'state_REQ' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_REQ', auxCol, True)\n",
    "    if 'state_RST' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_RST', auxCol, True)\n",
    "    if 'proto_igmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_igmp', auxCol, True)\n",
    "    if 'proto_arp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_arp', auxCol, True)\n",
    "    if 'proto_icmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_icmp', auxCol, True)\n",
    "    if 'proto_udp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_udp', auxCol, True)\n",
    "    if 'proto_tcp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_tcp', auxCol, True)\n",
    "\n",
    "    # Normalize all data features\n",
    "    data_features = StandardScaler().fit_transform(data_features)\n",
    "\n",
    "    #Add dimension to data features\n",
    "    data_features = np.expand_dims(data_features, axis=2)\n",
    "    data_features = np.expand_dims(data_features, axis=3)\n",
    "\n",
    "    x = data_features\n",
    "    y = data_labels.to_numpy()\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building and definition\n",
    "def build_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(filters=32,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(1, 1), padding='same'))\n",
    "    model.add(layers.Conv2D(filters=64,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(1, 1), padding='same'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(Dense(444, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns values of loss, accuracy, f1, precision and recall of model evaluating with test dataset \n",
    "def evaluation(model, x, y): \n",
    "    loss, accuracy = model.evaluate(x, y)\n",
    "    y_pred = model.predict(x)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y = np.argmax(y, axis=1)\n",
    "    report = classification_report(y, y_pred, target_names=['normal', 'attack'], output_dict=True)\n",
    "    # Obtain f1, precision and recall from the report\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    return loss, accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_18580/3836997398.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n"
     ]
    }
   ],
   "source": [
    "test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n",
    "test_plus = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test+.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments with datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 7A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-7A-Part1.csv', low_memory=False)\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-7A-Part2.csv', low_memory=False)\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-7A-Part3.csv', low_memory=False)\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-7A-Part4.csv', low_memory=False)\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-7A-Part5.csv', low_memory=False)\n",
    "training6 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-7A-Part6.csv', low_memory=False)\n",
    "training7 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-7A-Part7.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 7\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'id800.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    # Calculate mean gradient for each layer\n",
    "    mean_grad = [tf.reduce_mean(layer_grads, axis=0) for layer_grads in zip(*grad_list)]\n",
    "    \n",
    "    return mean_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)\n",
    "x6, y6 = preprocessing(training6)\n",
    "x7, y7 = preprocessing(training7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 180ms/step - loss: 0.4786 - accuracy: 0.9559 - val_loss: 1.1013 - val_accuracy: 0.6185\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 167ms/step - loss: 0.1121 - accuracy: 0.9893 - val_loss: 2.1094 - val_accuracy: 0.6187\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 165ms/step - loss: 0.0499 - accuracy: 0.9915 - val_loss: 0.9106 - val_accuracy: 0.6191\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 168ms/step - loss: 0.0309 - accuracy: 0.9918 - val_loss: 0.5823 - val_accuracy: 0.6495\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 175ms/step - loss: 0.0279 - accuracy: 0.9921 - val_loss: 0.6174 - val_accuracy: 0.6454\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 175ms/step - loss: 0.0270 - accuracy: 0.9917 - val_loss: 0.5414 - val_accuracy: 0.6688\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 178ms/step - loss: 0.0244 - accuracy: 0.9919 - val_loss: 0.3880 - val_accuracy: 0.7462\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 170ms/step - loss: 0.0227 - accuracy: 0.9918 - val_loss: 0.4887 - val_accuracy: 0.6665\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 185ms/step - loss: 0.0207 - accuracy: 0.9930 - val_loss: 0.5096 - val_accuracy: 0.6646\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 179ms/step - loss: 0.0194 - accuracy: 0.9935 - val_loss: 0.4207 - val_accuracy: 0.7172\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 3s 153ms/step - loss: 0.0329 - accuracy: 0.9904 - val_loss: 0.4663 - val_accuracy: 0.6735\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 3s 153ms/step - loss: 0.0194 - accuracy: 0.9932 - val_loss: 0.3519 - val_accuracy: 0.7600\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 3s 154ms/step - loss: 0.0184 - accuracy: 0.9939 - val_loss: 0.3241 - val_accuracy: 0.7851\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 164ms/step - loss: 0.0178 - accuracy: 0.9941 - val_loss: 0.3817 - val_accuracy: 0.7536\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 3s 152ms/step - loss: 0.0172 - accuracy: 0.9943 - val_loss: 0.4540 - val_accuracy: 0.7311\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 3s 155ms/step - loss: 0.0179 - accuracy: 0.9938 - val_loss: 0.4284 - val_accuracy: 0.7518\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 3s 159ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 0.3531 - val_accuracy: 0.7975\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 3s 151ms/step - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.3428 - val_accuracy: 0.8101\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 168ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.4168 - val_accuracy: 0.7945\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 3s 150ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.2900 - val_accuracy: 0.8398\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 3s 154ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.5422 - val_accuracy: 0.7676\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 164ms/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 0.3358 - val_accuracy: 0.8277\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 170ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.4626 - val_accuracy: 0.7919\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 173ms/step - loss: 0.0147 - accuracy: 0.9955 - val_loss: 0.4491 - val_accuracy: 0.7993\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 163ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.3042 - val_accuracy: 0.8440\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 183ms/step - loss: 0.0161 - accuracy: 0.9948 - val_loss: 0.4427 - val_accuracy: 0.8026\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 172ms/step - loss: 0.0130 - accuracy: 0.9962 - val_loss: 0.4593 - val_accuracy: 0.8031\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 171ms/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 0.3154 - val_accuracy: 0.8449\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 165ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.4192 - val_accuracy: 0.8231\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 176ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.4301 - val_accuracy: 0.8235\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 174ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.2170 - val_accuracy: 0.8760\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 164ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.4915 - val_accuracy: 0.8087\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 168ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.4486 - val_accuracy: 0.8190\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 161ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 0.6127 - val_accuracy: 0.7766\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 167ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 0.3351 - val_accuracy: 0.8504\n",
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.0519 - accuracy: 0.9741\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.2220 - accuracy: 0.9038\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 177ms/step - loss: 0.0159 - accuracy: 0.9954 - val_loss: 0.5574 - val_accuracy: 0.7811\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 182ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.5813 - val_accuracy: 0.7778\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 165ms/step - loss: 0.0139 - accuracy: 0.9959 - val_loss: 0.5909 - val_accuracy: 0.7740\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 162ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 0.3216 - val_accuracy: 0.8508\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 5s 206ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.4182 - val_accuracy: 0.8233\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 187ms/step - loss: 0.0144 - accuracy: 0.9958 - val_loss: 0.3442 - val_accuracy: 0.8463\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 161ms/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 0.4838 - val_accuracy: 0.7988\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 180ms/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.4999 - val_accuracy: 0.7981\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 185ms/step - loss: 0.0134 - accuracy: 0.9961 - val_loss: 0.4817 - val_accuracy: 0.8078\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 3s 151ms/step - loss: 0.0139 - accuracy: 0.9962 - val_loss: 0.4556 - val_accuracy: 0.8175\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 184ms/step - loss: 0.0144 - accuracy: 0.9959 - val_loss: 0.6186 - val_accuracy: 0.7784\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 160ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.4008 - val_accuracy: 0.8402\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 3s 156ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.4246 - val_accuracy: 0.8373\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 176ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.4129 - val_accuracy: 0.8383\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 171ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 0.4236 - val_accuracy: 0.8398\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 5s 217ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 0.5074 - val_accuracy: 0.8148\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 167ms/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.5339 - val_accuracy: 0.8063\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 178ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 0.4081 - val_accuracy: 0.8458\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 167ms/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 0.6208 - val_accuracy: 0.7897\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 3s 157ms/step - loss: 0.0125 - accuracy: 0.9964 - val_loss: 0.4488 - val_accuracy: 0.8345\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 162ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.3938 - val_accuracy: 0.8371\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 163ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.3475 - val_accuracy: 0.8509\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 3s 158ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.5860 - val_accuracy: 0.7999\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 166ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.3210 - val_accuracy: 0.8575\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 165ms/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.6110 - val_accuracy: 0.7957\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 165ms/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 0.3073 - val_accuracy: 0.8666\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 3s 157ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.4960 - val_accuracy: 0.8355\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 3s 158ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.4198 - val_accuracy: 0.8496\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 166ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.4317 - val_accuracy: 0.8472\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 186ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.4512 - val_accuracy: 0.8477\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 3s 159ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.6035 - val_accuracy: 0.8171\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 3s 155ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 0.7045 - val_accuracy: 0.7883\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 185ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.5205 - val_accuracy: 0.8312\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 164ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.4132 - val_accuracy: 0.8528\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 171ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 0.4926 - val_accuracy: 0.8357\n",
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.0702 - accuracy: 0.9720\n",
      "1721/1721 [==============================] - 4s 3ms/step - loss: 0.4188 - accuracy: 0.8064\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 166ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 0.5265 - val_accuracy: 0.8162\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 172ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.4520 - val_accuracy: 0.8374\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 161ms/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.4059 - val_accuracy: 0.8465\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 3s 155ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.4798 - val_accuracy: 0.8288\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 166ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.4648 - val_accuracy: 0.8326\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 164ms/step - loss: 0.0126 - accuracy: 0.9965 - val_loss: 0.4885 - val_accuracy: 0.8183\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 3s 155ms/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.3645 - val_accuracy: 0.8511\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 170ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.4627 - val_accuracy: 0.8283\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 3s 158ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.4564 - val_accuracy: 0.8292\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 173ms/step - loss: 0.0117 - accuracy: 0.9971 - val_loss: 0.5245 - val_accuracy: 0.8150\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 167ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.4217 - val_accuracy: 0.8373\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 159ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 0.5043 - val_accuracy: 0.8297\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 161ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.5538 - val_accuracy: 0.8217\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 164ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 0.5059 - val_accuracy: 0.8310\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 161ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.4234 - val_accuracy: 0.8469\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 3s 153ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.6006 - val_accuracy: 0.8218\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 164ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.5343 - val_accuracy: 0.8337\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 167ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.5059 - val_accuracy: 0.8362\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 169ms/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.5795 - val_accuracy: 0.8240\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 166ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.4502 - val_accuracy: 0.8451\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 168ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 0.4726 - val_accuracy: 0.8349\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 171ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.3513 - val_accuracy: 0.8605\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 165ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.5281 - val_accuracy: 0.8249\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 187ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 0.5003 - val_accuracy: 0.8335\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 184ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 0.4816 - val_accuracy: 0.8398\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 180ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.5154 - val_accuracy: 0.8373\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 184ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.4112 - val_accuracy: 0.8555\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 160ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.6331 - val_accuracy: 0.8172\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 170ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.5070 - val_accuracy: 0.8399\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 177ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.5847 - val_accuracy: 0.8287\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 181ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.6187 - val_accuracy: 0.8234\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 177ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.5372 - val_accuracy: 0.8394\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 178ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.6043 - val_accuracy: 0.8242\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 180ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.6757 - val_accuracy: 0.8051\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 178ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.5039 - val_accuracy: 0.8403\n",
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.0698 - accuracy: 0.9754\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.3980 - accuracy: 0.8158\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        elif node == 4: \n",
    "            x, y = x5, y5\n",
    "        elif node == 5:\n",
    "            x, y = x6, y6\n",
    "        elif node == 6:\n",
    "            x, y = x7, y7\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/id800.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.05185585841536522, 0.22198174893856049], [0.07023578882217407, 0.4187829792499542], [0.0698380097746849, 0.3980315923690796]]\n",
      "Accuracy for iterations:  [[0.9740716814994812, 0.9038363695144653], [0.9720485806465149, 0.8064193725585938], [0.9754082560539246, 0.81581050157547]]\n",
      "F1 for iterations:  [[0.9740397749331544, 0.9022309916842483], [0.9720038590077885, 0.794770736312494], [0.975379422934498, 0.8056475489028748]]\n",
      "Precision for iterations:  [[0.9745438223826113, 0.9129364335975925], [0.9727745762291028, 0.8476057364886238], [0.9758466743376849, 0.8536176953832524]]\n",
      "Recall for iterations:  [[0.974071693593152, 0.9038363728838189], [0.9720485553185895, 0.8064193853084357], [0.9754082795290543, 0.8158105064302841]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-7B-Part1.csv', low_memory=False)\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-7B-Part2.csv', low_memory=False)\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-7B-Part3.csv', low_memory=False)\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-7B-Part4.csv', low_memory=False)\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-7B-Part5.csv', low_memory=False)\n",
    "training6 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-7B-Part6.csv', low_memory=False)\n",
    "training7 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-7B-Part7.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 7\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'id801.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    # Calculate mean gradient for each layer\n",
    "    mean_grad = [tf.reduce_mean(layer_grads, axis=0) for layer_grads in zip(*grad_list)]\n",
    "    \n",
    "    return mean_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)\n",
    "x6, y6 = preprocessing(training6)\n",
    "x7, y7 = preprocessing(training7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 180ms/step - loss: 0.4743 - accuracy: 0.9491 - val_loss: 0.4989 - val_accuracy: 0.8740\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 180ms/step - loss: 0.1137 - accuracy: 0.9793 - val_loss: 0.6969 - val_accuracy: 0.8742\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 174ms/step - loss: 0.0515 - accuracy: 0.9914 - val_loss: 0.2355 - val_accuracy: 0.8751\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 195ms/step - loss: 0.0305 - accuracy: 0.9914 - val_loss: 0.1829 - val_accuracy: 0.8836\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 5s 205ms/step - loss: 0.0264 - accuracy: 0.9920 - val_loss: 0.1898 - val_accuracy: 0.8813\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.0252 - accuracy: 0.9909 - val_loss: 0.3168 - val_accuracy: 0.8259\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 197ms/step - loss: 0.0225 - accuracy: 0.9912 - val_loss: 0.4866 - val_accuracy: 0.6810\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 184ms/step - loss: 0.0205 - accuracy: 0.9917 - val_loss: 0.4363 - val_accuracy: 0.6973\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 181ms/step - loss: 0.0193 - accuracy: 0.9924 - val_loss: 0.2153 - val_accuracy: 0.8938\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 176ms/step - loss: 0.0180 - accuracy: 0.9932 - val_loss: 0.3115 - val_accuracy: 0.7906\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 185ms/step - loss: 0.0219 - accuracy: 0.9923 - val_loss: 0.3806 - val_accuracy: 0.7433\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 199ms/step - loss: 0.0184 - accuracy: 0.9938 - val_loss: 0.3856 - val_accuracy: 0.7404\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 172ms/step - loss: 0.0177 - accuracy: 0.9942 - val_loss: 0.3825 - val_accuracy: 0.7476\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 177ms/step - loss: 0.0173 - accuracy: 0.9945 - val_loss: 0.2546 - val_accuracy: 0.8330\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 183ms/step - loss: 0.0169 - accuracy: 0.9948 - val_loss: 0.3930 - val_accuracy: 0.7575\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 170ms/step - loss: 0.0154 - accuracy: 0.9945 - val_loss: 0.2068 - val_accuracy: 0.8729\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 181ms/step - loss: 0.0145 - accuracy: 0.9948 - val_loss: 0.4342 - val_accuracy: 0.7595\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 189ms/step - loss: 0.0137 - accuracy: 0.9955 - val_loss: 0.3136 - val_accuracy: 0.8199\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 172ms/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 0.3716 - val_accuracy: 0.8019\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 184ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.3452 - val_accuracy: 0.8159\n",
      "Epoch 1/5\n",
      "13/13 [==============================] - 2s 172ms/step - loss: 4.8638 - accuracy: 0.4897 - val_loss: 1.6492 - val_accuracy: 0.7838\n",
      "Epoch 2/5\n",
      "13/13 [==============================] - 2s 176ms/step - loss: 1.1944 - accuracy: 0.8260 - val_loss: 0.1582 - val_accuracy: 0.9616\n",
      "Epoch 3/5\n",
      "13/13 [==============================] - 2s 176ms/step - loss: 0.0353 - accuracy: 0.9793 - val_loss: 0.0146 - val_accuracy: 0.9948\n",
      "Epoch 4/5\n",
      "13/13 [==============================] - 2s 167ms/step - loss: 4.3073e-05 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9983\n",
      "Epoch 5/5\n",
      "13/13 [==============================] - 2s 178ms/step - loss: 1.2230e-05 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9985\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 194ms/step - loss: 4.9813 - accuracy: 0.5242 - val_loss: 0.6821 - val_accuracy: 0.7498\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 191ms/step - loss: 0.0360 - accuracy: 0.9921 - val_loss: 0.9216 - val_accuracy: 0.7286\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 191ms/step - loss: 0.0199 - accuracy: 0.9941 - val_loss: 0.6231 - val_accuracy: 0.7546\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 173ms/step - loss: 0.0190 - accuracy: 0.9942 - val_loss: 0.5704 - val_accuracy: 0.7607\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 179ms/step - loss: 0.0182 - accuracy: 0.9943 - val_loss: 0.5416 - val_accuracy: 0.7638\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 3s 156ms/step - loss: 0.1715 - accuracy: 0.9333 - val_loss: 3.8044 - val_accuracy: 0.5052\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 161ms/step - loss: 5.7046e-05 - accuracy: 1.0000 - val_loss: 5.2408 - val_accuracy: 0.5052\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 165ms/step - loss: 1.4390e-05 - accuracy: 1.0000 - val_loss: 5.4412 - val_accuracy: 0.5052\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 180ms/step - loss: 1.2020e-05 - accuracy: 1.0000 - val_loss: 5.4784 - val_accuracy: 0.5052\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 3s 153ms/step - loss: 1.1483e-05 - accuracy: 1.0000 - val_loss: 5.4972 - val_accuracy: 0.5052\n",
      "4279/4279 [==============================] - 10s 2ms/step - loss: 5.4712 - accuracy: 0.5288\n",
      "   1/1721 [..............................] - ETA: 0s - loss: 14.6691 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1721/1721 [==============================] - 5s 3ms/step - loss: 6.3833 - accuracy: 0.5608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 174ms/step - loss: 0.8329 - accuracy: 0.8259 - val_loss: 0.0394 - val_accuracy: 0.9966\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 162ms/step - loss: 0.0265 - accuracy: 0.9916 - val_loss: 0.1742 - val_accuracy: 0.9227\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 168ms/step - loss: 0.0212 - accuracy: 0.9937 - val_loss: 0.1303 - val_accuracy: 0.9323\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 173ms/step - loss: 0.0192 - accuracy: 0.9935 - val_loss: 0.1402 - val_accuracy: 0.9122\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 182ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.1216 - val_accuracy: 0.9188\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 189ms/step - loss: 0.0170 - accuracy: 0.9943 - val_loss: 0.2280 - val_accuracy: 0.8723\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 177ms/step - loss: 0.0148 - accuracy: 0.9948 - val_loss: 0.2571 - val_accuracy: 0.8537\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 170ms/step - loss: 0.0142 - accuracy: 0.9953 - val_loss: 0.2871 - val_accuracy: 0.8368\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 179ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.1582 - val_accuracy: 0.9210\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 180ms/step - loss: 0.0136 - accuracy: 0.9955 - val_loss: 0.2395 - val_accuracy: 0.8788\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 181ms/step - loss: 0.0891 - accuracy: 0.9565 - val_loss: 0.5700 - val_accuracy: 0.7133\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 179ms/step - loss: 0.0220 - accuracy: 0.9942 - val_loss: 0.2866 - val_accuracy: 0.8332\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 182ms/step - loss: 0.0195 - accuracy: 0.9947 - val_loss: 0.3790 - val_accuracy: 0.7958\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 201ms/step - loss: 0.0169 - accuracy: 0.9950 - val_loss: 0.3678 - val_accuracy: 0.8019\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 200ms/step - loss: 0.0159 - accuracy: 0.9953 - val_loss: 0.3933 - val_accuracy: 0.7949\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 190ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 0.4350 - val_accuracy: 0.7798\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 178ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.2574 - val_accuracy: 0.8485\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 180ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.3095 - val_accuracy: 0.8338\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 176ms/step - loss: 0.0127 - accuracy: 0.9955 - val_loss: 0.5099 - val_accuracy: 0.7655\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 181ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.4390 - val_accuracy: 0.7938\n",
      "Epoch 1/5\n",
      "13/13 [==============================] - 2s 181ms/step - loss: 5.1776 - accuracy: 0.4995 - val_loss: 1.9149 - val_accuracy: 0.7848\n",
      "Epoch 2/5\n",
      "13/13 [==============================] - 2s 165ms/step - loss: 1.5991 - accuracy: 0.8211 - val_loss: 0.2356 - val_accuracy: 0.9552\n",
      "Epoch 3/5\n",
      "13/13 [==============================] - 2s 186ms/step - loss: 0.0806 - accuracy: 0.9649 - val_loss: 0.0168 - val_accuracy: 0.9946\n",
      "Epoch 4/5\n",
      "13/13 [==============================] - 2s 173ms/step - loss: 1.9225e-05 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9982\n",
      "Epoch 5/5\n",
      "13/13 [==============================] - 2s 185ms/step - loss: 2.4255e-06 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9991\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 180ms/step - loss: 4.5931 - accuracy: 0.6063 - val_loss: 0.5364 - val_accuracy: 0.7756\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 176ms/step - loss: 0.0279 - accuracy: 0.9944 - val_loss: 0.8455 - val_accuracy: 0.7469\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 198ms/step - loss: 0.0192 - accuracy: 0.9943 - val_loss: 0.6201 - val_accuracy: 0.7636\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 197ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.5445 - val_accuracy: 0.7697\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 0.0172 - accuracy: 0.9948 - val_loss: 0.5006 - val_accuracy: 0.7753\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 170ms/step - loss: 0.4028 - accuracy: 0.8757 - val_loss: 1.1328 - val_accuracy: 0.7049\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 161ms/step - loss: 0.0041 - accuracy: 0.9982 - val_loss: 2.6696 - val_accuracy: 0.5065\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 4s 187ms/step - loss: 6.1566e-04 - accuracy: 1.0000 - val_loss: 3.1474 - val_accuracy: 0.5054\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 3.3532e-04 - accuracy: 1.0000 - val_loss: 3.3523 - val_accuracy: 0.5053\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 179ms/step - loss: 2.3903e-04 - accuracy: 1.0000 - val_loss: 3.4972 - val_accuracy: 0.5053\n",
      "4279/4279 [==============================] - 22s 5ms/step - loss: 4.7094 - accuracy: 0.5288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   9/1721 [..............................] - ETA: 10s - loss: 11.0885 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1721/1721 [==============================] - 13s 8ms/step - loss: 5.0264 - accuracy: 0.5608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "22/22 [==============================] - 7s 321ms/step - loss: 0.4322 - accuracy: 0.8757 - val_loss: 0.0492 - val_accuracy: 0.9888\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 4s 190ms/step - loss: 0.0193 - accuracy: 0.9933 - val_loss: 0.1926 - val_accuracy: 0.8968\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 5s 222ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.1429 - val_accuracy: 0.9072\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 5s 245ms/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.1771 - val_accuracy: 0.8980\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 5s 232ms/step - loss: 0.0150 - accuracy: 0.9958 - val_loss: 0.1849 - val_accuracy: 0.8983\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 6s 284ms/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.2551 - val_accuracy: 0.8687\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 6s 252ms/step - loss: 0.0139 - accuracy: 0.9954 - val_loss: 0.1720 - val_accuracy: 0.9168\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 5s 245ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.4061 - val_accuracy: 0.7961\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 5s 249ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.2570 - val_accuracy: 0.8743\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 5s 247ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.1714 - val_accuracy: 0.9170\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 6s 264ms/step - loss: 0.1148 - accuracy: 0.9475 - val_loss: 0.2173 - val_accuracy: 0.8952\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.0221 - accuracy: 0.9943 - val_loss: 0.4164 - val_accuracy: 0.8013\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 5s 248ms/step - loss: 0.0198 - accuracy: 0.9947 - val_loss: 0.5075 - val_accuracy: 0.7724\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 5s 234ms/step - loss: 0.0183 - accuracy: 0.9952 - val_loss: 0.3493 - val_accuracy: 0.8172\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 4s 181ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 0.4684 - val_accuracy: 0.7845\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 7s 339ms/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.3945 - val_accuracy: 0.8123\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.4366 - val_accuracy: 0.8007\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 6s 251ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 0.2742 - val_accuracy: 0.8514\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 6s 280ms/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 0.4021 - val_accuracy: 0.8206\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 7s 327ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.3898 - val_accuracy: 0.8221\n",
      "Epoch 1/5\n",
      "13/13 [==============================] - 4s 277ms/step - loss: 4.4837 - accuracy: 0.5339 - val_loss: 1.4173 - val_accuracy: 0.8100\n",
      "Epoch 2/5\n",
      "13/13 [==============================] - 3s 228ms/step - loss: 0.7606 - accuracy: 0.8580 - val_loss: 0.1023 - val_accuracy: 0.9785\n",
      "Epoch 3/5\n",
      "13/13 [==============================] - 2s 175ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9949\n",
      "Epoch 4/5\n",
      "13/13 [==============================] - 3s 224ms/step - loss: 2.3814e-05 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9974\n",
      "Epoch 5/5\n",
      "13/13 [==============================] - 3s 239ms/step - loss: 1.0380e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9980\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 273ms/step - loss: 2.2883 - accuracy: 0.7352 - val_loss: 0.5590 - val_accuracy: 0.7656\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 256ms/step - loss: 0.0211 - accuracy: 0.9948 - val_loss: 0.7444 - val_accuracy: 0.7508\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 228ms/step - loss: 0.0181 - accuracy: 0.9946 - val_loss: 0.5883 - val_accuracy: 0.7608\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 268ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.5009 - val_accuracy: 0.7666\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 301ms/step - loss: 0.0163 - accuracy: 0.9948 - val_loss: 0.4429 - val_accuracy: 0.7726\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 5s 224ms/step - loss: 0.5627 - accuracy: 0.8248 - val_loss: 0.7641 - val_accuracy: 0.7272\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 5s 226ms/step - loss: 0.0051 - accuracy: 0.9979 - val_loss: 1.9570 - val_accuracy: 0.5083\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 5s 229ms/step - loss: 9.5664e-04 - accuracy: 1.0000 - val_loss: 2.3326 - val_accuracy: 0.5055\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 5s 240ms/step - loss: 5.7498e-04 - accuracy: 1.0000 - val_loss: 2.5045 - val_accuracy: 0.5055\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 5s 245ms/step - loss: 4.2444e-04 - accuracy: 1.0000 - val_loss: 2.6314 - val_accuracy: 0.5053\n",
      "4279/4279 [==============================] - 26s 6ms/step - loss: 4.2497 - accuracy: 0.5288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1721/1721 [==============================] - 10s 6ms/step - loss: 4.4292 - accuracy: 0.5608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        elif node == 4:\n",
    "            x, y = x5, y5\n",
    "        elif node == 5:\n",
    "            x, y = x6, y6\n",
    "        elif node == 6:\n",
    "            x, y = x7, y7\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/id801.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[5.471231460571289, 6.383303642272949], [4.70941162109375, 5.026413440704346], [4.249748706817627, 4.4292378425598145]]\n",
      "Accuracy for iterations:  [[0.5287913680076599, 0.5607607364654541], [0.5287913680076599, 0.5607607364654541], [0.5287913680076599, 0.5607607364654541]]\n",
      "F1 for iterations:  [[0.36580572534487127, 0.4029478640083462], [0.36580572534487127, 0.4029478640083462], [0.36580572534487127, 0.4029478640083462]]\n",
      "Precision for iterations:  [[0.2796203190506846, 0.31445260225958305], [0.2796203190506846, 0.31445260225958305], [0.2796203190506846, 0.31445260225958305]]\n",
      "Recall for iterations:  [[0.5287913757340267, 0.5607607353048027], [0.5287913757340267, 0.5607607353048027], [0.5287913757340267, 0.5607607353048027]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 7C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-7C-Part1.csv', low_memory=False)\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-7C-Part2.csv', low_memory=False)\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-7C-Part3.csv', low_memory=False)\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-7C-Part4.csv', low_memory=False)\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-7C-Part5.csv', low_memory=False)\n",
    "training6 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-7C-Part6.csv', low_memory=False)\n",
    "training7 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-7C-Part7.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 7\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'id802.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    # Calculate mean gradient for each layer\n",
    "    mean_grad = [tf.reduce_mean(layer_grads, axis=0) for layer_grads in zip(*grad_list)]\n",
    "    \n",
    "    return mean_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)\n",
    "x6, y6 = preprocessing(training6)\n",
    "x7, y7 = preprocessing(training7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 197ms/step - loss: 0.5271 - accuracy: 0.9335 - val_loss: 0.5175 - val_accuracy: 0.8267\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 198ms/step - loss: 0.1387 - accuracy: 0.9837 - val_loss: 0.3878 - val_accuracy: 0.8273\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 0.0488 - accuracy: 0.9881 - val_loss: 0.1423 - val_accuracy: 0.9334\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 0.0355 - accuracy: 0.9892 - val_loss: 0.1701 - val_accuracy: 0.9141\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 0.0300 - accuracy: 0.9894 - val_loss: 0.1579 - val_accuracy: 0.9194\n",
      "Epoch 1/5\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 0.1104 - accuracy: 0.9695 - val_loss: 0.8676 - val_accuracy: 0.7491\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 6s 192ms/step - loss: 0.0313 - accuracy: 0.9939 - val_loss: 0.8984 - val_accuracy: 0.7480\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 6s 197ms/step - loss: 0.0278 - accuracy: 0.9937 - val_loss: 0.7491 - val_accuracy: 0.7492\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 7s 207ms/step - loss: 0.0260 - accuracy: 0.9935 - val_loss: 0.6527 - val_accuracy: 0.7513\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 6s 203ms/step - loss: 0.0250 - accuracy: 0.9937 - val_loss: 0.6476 - val_accuracy: 0.7515\n",
      "Epoch 1/5\n",
      "21/21 [==============================] - 4s 197ms/step - loss: 0.0814 - accuracy: 0.9760 - val_loss: 0.7263 - val_accuracy: 0.6630\n",
      "Epoch 2/5\n",
      "21/21 [==============================] - 4s 192ms/step - loss: 0.0300 - accuracy: 0.9891 - val_loss: 0.4926 - val_accuracy: 0.7904\n",
      "Epoch 3/5\n",
      "21/21 [==============================] - 4s 189ms/step - loss: 0.0255 - accuracy: 0.9900 - val_loss: 0.5939 - val_accuracy: 0.6995\n",
      "Epoch 4/5\n",
      "21/21 [==============================] - 4s 188ms/step - loss: 0.0240 - accuracy: 0.9903 - val_loss: 0.4593 - val_accuracy: 0.7702\n",
      "Epoch 5/5\n",
      "21/21 [==============================] - 4s 184ms/step - loss: 0.0230 - accuracy: 0.9908 - val_loss: 0.3704 - val_accuracy: 0.8359\n",
      "Epoch 1/5\n",
      "13/13 [==============================] - 3s 198ms/step - loss: 0.2031 - accuracy: 0.9122 - val_loss: 0.1007 - val_accuracy: 0.9751\n",
      "Epoch 2/5\n",
      "13/13 [==============================] - 3s 235ms/step - loss: 9.6835e-04 - accuracy: 0.9999 - val_loss: 0.0191 - val_accuracy: 0.9981\n",
      "Epoch 3/5\n",
      "13/13 [==============================] - 2s 171ms/step - loss: 2.4916e-04 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9998\n",
      "Epoch 4/5\n",
      "13/13 [==============================] - 2s 184ms/step - loss: 1.7828e-04 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9998\n",
      "Epoch 5/5\n",
      "13/13 [==============================] - 3s 259ms/step - loss: 1.5656e-04 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9998\n",
      "Epoch 1/5\n",
      "43/43 [==============================] - 11s 247ms/step - loss: 1.1748 - accuracy: 0.7677 - val_loss: 0.9759 - val_accuracy: 0.7479\n",
      "Epoch 2/5\n",
      "43/43 [==============================] - 11s 252ms/step - loss: 0.0245 - accuracy: 0.9947 - val_loss: 0.6817 - val_accuracy: 0.7492\n",
      "Epoch 3/5\n",
      "43/43 [==============================] - 10s 227ms/step - loss: 0.0218 - accuracy: 0.9947 - val_loss: 0.7328 - val_accuracy: 0.7492\n",
      "Epoch 4/5\n",
      "43/43 [==============================] - 9s 209ms/step - loss: 0.0213 - accuracy: 0.9947 - val_loss: 0.6868 - val_accuracy: 0.7492\n",
      "Epoch 5/5\n",
      "43/43 [==============================] - 9s 208ms/step - loss: 0.0208 - accuracy: 0.9947 - val_loss: 0.6882 - val_accuracy: 0.7492\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 5s 229ms/step - loss: 0.0329 - accuracy: 0.9905 - val_loss: 0.6451 - val_accuracy: 0.6287\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 5s 206ms/step - loss: 0.0228 - accuracy: 0.9916 - val_loss: 0.4116 - val_accuracy: 0.6852\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 5s 222ms/step - loss: 0.0196 - accuracy: 0.9923 - val_loss: 0.4207 - val_accuracy: 0.6783\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 5s 219ms/step - loss: 0.0187 - accuracy: 0.9928 - val_loss: 0.4049 - val_accuracy: 0.6910\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 6s 246ms/step - loss: 0.0179 - accuracy: 0.9934 - val_loss: 0.2649 - val_accuracy: 0.8237\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 1s 186ms/step - loss: 0.0846 - accuracy: 0.9836 - val_loss: 0.1253 - val_accuracy: 0.9903\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 1s 155ms/step - loss: 0.0671 - accuracy: 0.9835 - val_loss: 0.1057 - val_accuracy: 0.9909\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 1s 181ms/step - loss: 0.0598 - accuracy: 0.9836 - val_loss: 0.1015 - val_accuracy: 0.9919\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 1s 156ms/step - loss: 0.0551 - accuracy: 0.9846 - val_loss: 0.0810 - val_accuracy: 0.9964\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 1s 143ms/step - loss: 0.0520 - accuracy: 0.9858 - val_loss: 0.0945 - val_accuracy: 0.9977\n",
      "4279/4279 [==============================] - 19s 4ms/step - loss: 0.0489 - accuracy: 0.9911\n",
      "1721/1721 [==============================] - 7s 4ms/step - loss: 0.0597 - accuracy: 0.9902\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.0678 - accuracy: 0.9765 - val_loss: 0.1127 - val_accuracy: 0.9527\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 177ms/step - loss: 0.0203 - accuracy: 0.9934 - val_loss: 0.1068 - val_accuracy: 0.9529\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 161ms/step - loss: 0.0185 - accuracy: 0.9940 - val_loss: 0.1102 - val_accuracy: 0.9440\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 0.0178 - accuracy: 0.9940 - val_loss: 0.1126 - val_accuracy: 0.9397\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.1268 - val_accuracy: 0.9349\n",
      "Epoch 1/5\n",
      "32/32 [==============================] - 8s 240ms/step - loss: 0.0448 - accuracy: 0.9869 - val_loss: 0.5290 - val_accuracy: 0.7489\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 8s 258ms/step - loss: 0.0202 - accuracy: 0.9939 - val_loss: 0.3737 - val_accuracy: 0.7524\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 9s 271ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.3647 - val_accuracy: 0.7571\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 7s 211ms/step - loss: 0.0181 - accuracy: 0.9943 - val_loss: 0.3833 - val_accuracy: 0.7590\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 7s 212ms/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.3259 - val_accuracy: 0.7782\n",
      "Epoch 1/5\n",
      "21/21 [==============================] - 4s 190ms/step - loss: 0.0203 - accuracy: 0.9928 - val_loss: 0.4980 - val_accuracy: 0.6519\n",
      "Epoch 2/5\n",
      "21/21 [==============================] - 4s 202ms/step - loss: 0.0172 - accuracy: 0.9935 - val_loss: 0.2996 - val_accuracy: 0.8152\n",
      "Epoch 3/5\n",
      "21/21 [==============================] - 4s 213ms/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 0.2431 - val_accuracy: 0.8657\n",
      "Epoch 4/5\n",
      "21/21 [==============================] - 5s 258ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.2610 - val_accuracy: 0.8287\n",
      "Epoch 5/5\n",
      "21/21 [==============================] - 4s 207ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.4298 - val_accuracy: 0.7400\n",
      "Epoch 1/5\n",
      "13/13 [==============================] - 3s 235ms/step - loss: 2.6460 - accuracy: 0.6230 - val_loss: 1.2880 - val_accuracy: 0.7296\n",
      "Epoch 2/5\n",
      "13/13 [==============================] - 3s 223ms/step - loss: 0.4764 - accuracy: 0.8587 - val_loss: 0.1087 - val_accuracy: 0.9670\n",
      "Epoch 3/5\n",
      "13/13 [==============================] - 3s 232ms/step - loss: 0.0107 - accuracy: 0.9999 - val_loss: 0.0243 - val_accuracy: 0.9930\n",
      "Epoch 4/5\n",
      "13/13 [==============================] - 3s 203ms/step - loss: 4.8884e-04 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 0.9972\n",
      "Epoch 5/5\n",
      "13/13 [==============================] - 2s 192ms/step - loss: 2.2697e-04 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9975\n",
      "Epoch 1/5\n",
      "43/43 [==============================] - 11s 245ms/step - loss: 1.8342 - accuracy: 0.6653 - val_loss: 0.5360 - val_accuracy: 0.7507\n",
      "Epoch 2/5\n",
      "43/43 [==============================] - 9s 202ms/step - loss: 0.0195 - accuracy: 0.9954 - val_loss: 0.5949 - val_accuracy: 0.7482\n",
      "Epoch 3/5\n",
      "43/43 [==============================] - 8s 191ms/step - loss: 0.0179 - accuracy: 0.9949 - val_loss: 0.5709 - val_accuracy: 0.7486\n",
      "Epoch 4/5\n",
      "43/43 [==============================] - 8s 187ms/step - loss: 0.0176 - accuracy: 0.9949 - val_loss: 0.5687 - val_accuracy: 0.7486\n",
      "Epoch 5/5\n",
      "43/43 [==============================] - 8s 196ms/step - loss: 0.0174 - accuracy: 0.9949 - val_loss: 0.5771 - val_accuracy: 0.7486\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 4s 170ms/step - loss: 0.0170 - accuracy: 0.9940 - val_loss: 0.2599 - val_accuracy: 0.8318\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 4s 168ms/step - loss: 0.0142 - accuracy: 0.9952 - val_loss: 0.2956 - val_accuracy: 0.8303\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 4s 164ms/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.3642 - val_accuracy: 0.8155\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 4s 171ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.3269 - val_accuracy: 0.8358\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 4s 166ms/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 0.2415 - val_accuracy: 0.8599\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 1s 150ms/step - loss: 0.0960 - accuracy: 0.9711 - val_loss: 0.1230 - val_accuracy: 0.9897\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 1s 133ms/step - loss: 0.0701 - accuracy: 0.9826 - val_loss: 0.1272 - val_accuracy: 0.9903\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 1s 149ms/step - loss: 0.0632 - accuracy: 0.9840 - val_loss: 0.1161 - val_accuracy: 0.9916\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 1s 143ms/step - loss: 0.0563 - accuracy: 0.9835 - val_loss: 0.1114 - val_accuracy: 0.9935\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 1s 132ms/step - loss: 0.0515 - accuracy: 0.9857 - val_loss: 0.1041 - val_accuracy: 0.9955\n",
      "4279/4279 [==============================] - 14s 3ms/step - loss: 0.0387 - accuracy: 0.9917\n",
      "1721/1721 [==============================] - 6s 3ms/step - loss: 0.0771 - accuracy: 0.9881\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.0869 - accuracy: 0.9715 - val_loss: 0.1671 - val_accuracy: 0.9367\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 162ms/step - loss: 0.0176 - accuracy: 0.9948 - val_loss: 0.1774 - val_accuracy: 0.9274\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 2s 155ms/step - loss: 0.0168 - accuracy: 0.9949 - val_loss: 0.1563 - val_accuracy: 0.9304\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 158ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.2110 - val_accuracy: 0.8888\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 162ms/step - loss: 0.0151 - accuracy: 0.9954 - val_loss: 0.1543 - val_accuracy: 0.9255\n",
      "Epoch 1/5\n",
      "32/32 [==============================] - 5s 169ms/step - loss: 0.0342 - accuracy: 0.9898 - val_loss: 0.4530 - val_accuracy: 0.7913\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 6s 172ms/step - loss: 0.0160 - accuracy: 0.9952 - val_loss: 0.3060 - val_accuracy: 0.8185\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 5s 172ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.2603 - val_accuracy: 0.8443\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 5s 171ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 0.3187 - val_accuracy: 0.8257\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 5s 164ms/step - loss: 0.0144 - accuracy: 0.9958 - val_loss: 0.2664 - val_accuracy: 0.8549\n",
      "Epoch 1/5\n",
      "21/21 [==============================] - 4s 171ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 0.2491 - val_accuracy: 0.8524\n",
      "Epoch 2/5\n",
      "21/21 [==============================] - 4s 168ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.3279 - val_accuracy: 0.8143\n",
      "Epoch 3/5\n",
      "21/21 [==============================] - 3s 161ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 0.3276 - val_accuracy: 0.8210\n",
      "Epoch 4/5\n",
      "21/21 [==============================] - 3s 166ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 0.3536 - val_accuracy: 0.8142\n",
      "Epoch 5/5\n",
      "21/21 [==============================] - 3s 159ms/step - loss: 0.0125 - accuracy: 0.9964 - val_loss: 0.4343 - val_accuracy: 0.7978\n",
      "Epoch 1/5\n",
      "13/13 [==============================] - 2s 165ms/step - loss: 4.2162 - accuracy: 0.5554 - val_loss: 1.5632 - val_accuracy: 0.7464\n",
      "Epoch 2/5\n",
      "13/13 [==============================] - 2s 175ms/step - loss: 0.8718 - accuracy: 0.8325 - val_loss: 0.1033 - val_accuracy: 0.9767\n",
      "Epoch 3/5\n",
      "13/13 [==============================] - 2s 160ms/step - loss: 0.0096 - accuracy: 0.9999 - val_loss: 0.0207 - val_accuracy: 0.9984\n",
      "Epoch 4/5\n",
      "13/13 [==============================] - 2s 158ms/step - loss: 6.0976e-05 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 0.9998\n",
      "Epoch 5/5\n",
      "13/13 [==============================] - 2s 164ms/step - loss: 1.8951e-05 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 0.9998\n",
      "Epoch 1/5\n",
      "43/43 [==============================] - 7s 170ms/step - loss: 1.8142 - accuracy: 0.7288 - val_loss: 0.7770 - val_accuracy: 0.7510\n",
      "Epoch 2/5\n",
      "43/43 [==============================] - 7s 168ms/step - loss: 0.0185 - accuracy: 0.9957 - val_loss: 0.8317 - val_accuracy: 0.7469\n",
      "Epoch 3/5\n",
      "43/43 [==============================] - 7s 169ms/step - loss: 0.0177 - accuracy: 0.9957 - val_loss: 0.7216 - val_accuracy: 0.7529\n",
      "Epoch 4/5\n",
      "43/43 [==============================] - 7s 168ms/step - loss: 0.0173 - accuracy: 0.9958 - val_loss: 0.7017 - val_accuracy: 0.7541\n",
      "Epoch 5/5\n",
      "43/43 [==============================] - 7s 169ms/step - loss: 0.0170 - accuracy: 0.9958 - val_loss: 0.6742 - val_accuracy: 0.7558\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 4s 172ms/step - loss: 0.0141 - accuracy: 0.9948 - val_loss: 0.4300 - val_accuracy: 0.7794\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 4s 166ms/step - loss: 0.0123 - accuracy: 0.9956 - val_loss: 0.4683 - val_accuracy: 0.7916\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 4s 166ms/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 0.4762 - val_accuracy: 0.8002\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 4s 164ms/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 0.4003 - val_accuracy: 0.8316\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 4s 171ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.3534 - val_accuracy: 0.8449\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 1s 144ms/step - loss: 0.1673 - accuracy: 0.9374 - val_loss: 0.2397 - val_accuracy: 0.9298\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 1s 133ms/step - loss: 0.0874 - accuracy: 0.9743 - val_loss: 0.1110 - val_accuracy: 0.9932\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 1s 133ms/step - loss: 0.0741 - accuracy: 0.9821 - val_loss: 0.1113 - val_accuracy: 0.9932\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 1s 138ms/step - loss: 0.0658 - accuracy: 0.9833 - val_loss: 0.1491 - val_accuracy: 0.9913\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 1s 127ms/step - loss: 0.0607 - accuracy: 0.9827 - val_loss: 0.1459 - val_accuracy: 0.9926\n",
      "4279/4279 [==============================] - 14s 3ms/step - loss: 0.0927 - accuracy: 0.9609\n",
      "1721/1721 [==============================] - 6s 3ms/step - loss: 0.3096 - accuracy: 0.8319\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        elif node == 4: \n",
    "            x, y = x5, y5\n",
    "        elif node == 5:\n",
    "            x, y = x6, y6\n",
    "        elif node == 6:\n",
    "            x, y = x7, y7\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/id802.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.048929013311862946, 0.05968993902206421], [0.038720790296792984, 0.0770510658621788], [0.09274330735206604, 0.30963996052742004]]\n",
      "Accuracy for iterations:  [[0.9910821318626404, 0.9902274012565613], [0.9916810393333435, 0.9880840182304382], [0.9608519077301025, 0.831868052482605]]\n",
      "F1 for iterations:  [[0.9910852850645745, 0.9902372314709055], [0.9916839000686489, 0.9880921646613824], [0.9607299641024801, 0.8239361419268945]]\n",
      "Precision for iterations:  [[0.9911854671535346, 0.9904017524130945], [0.9917778611019462, 0.9881687462082935], [0.9628368207667298, 0.8640875336071753]]\n",
      "Recall for iterations:  [[0.991082123345701, 0.9902274213470901], [0.9916810307049578, 0.9880839933154109], [0.9608519091998013, 0.8318680520235414]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
