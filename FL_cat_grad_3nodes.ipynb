{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Federated Learning for attack classification: 3 nodes sharing gradients**\n",
    "\n",
    "IDs from this file = **id0xy** (x = 0 if experiment with dataset, x = 1 if epochs & iterations, y being integer equal or greater than 0)\n",
    "\n",
    "In this file, experiments with different datasets, and number of epochs & iterations are done. The experiments are divided into sections, based on the elements being changed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static elements for all experiments (execute first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Disable warns\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for test and training datasets (to be able to train and make predictions to evaluate)\n",
    "def preprocessing(data): \n",
    "\n",
    "    # Select the 'proto' and 'state' values that I want\n",
    "    data = data.loc[(data['proto'] == 'tcp') | (data['proto'] =='udp') | (data['proto'] =='icmp') | (data['proto'] =='arp') | (data['proto'] =='ipv6-icmp') | (data['proto'] =='igmp') | (data['proto'] =='rarp'), :]\n",
    "    data = data.loc[(data['state'] == 'RST') | (data['state'] =='REQ') | (data['state'] =='INT') | (data['state'] =='FIN') | (data['state'] =='CON') | (data['state'] =='ECO') | (data['state'] =='ACC') | (data['state'] == 'PAR'), :]\n",
    "\n",
    "    # Creating categories dataframe\n",
    "    data_labels = pd.DataFrame()\n",
    "\n",
    "    # Drop the invalid features and select interested data features\n",
    "    data_features=data[['proto','srcip','sport','dstip','dsport','spkts','dpkts','sbytes','dbytes','state','stime','ltime','dur']]\n",
    "\n",
    "    \"\"\"PREPROCESSING\"\"\"\n",
    "\n",
    "\n",
    "    # Preprocess IP and ports features\n",
    "    # IP Source Address\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "\n",
    "    # IP Destination Address\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "    # Ports\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "\n",
    "    # Convert all ports with 0 decimal, and HEX to DEC\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    # Convert field to int format\n",
    "    data_features['srcip'] = data_features['srcip'].astype(int)\n",
    "    data_features['sport'] = data_features['sport'].astype(int)\n",
    "    data_features['dstip'] = data_features['dstip'].astype(int)\n",
    "    data_features['dsport'] = data_features['dsport'].astype(int)\n",
    "\n",
    "    # Convert some fields to logarithmic\n",
    "    log1p_col = ['dur', 'sbytes', 'dbytes', 'spkts']\n",
    "\n",
    "    for col in log1p_col:\n",
    "        data_features[col] = data_features[col].apply(np.log1p)\n",
    "        \n",
    "    # Transform to One Hot Encoding the Categories - normal, dos, reconnaissance, generic, exploits, worms, fuzzers, analysis, backdoor, shellcode\n",
    "    data_labels.insert(0, 'normal', data['attack_cat'].replace('normal', 1).replace(['dos', 'reconnaissance', 'generic', 'exploits', 'worms', 'fuzzers', 'analysis', 'backdoor', 'shellcode'], 0))\n",
    "    data_labels.insert(1, 'dos', data['attack_cat'].replace('dos', 1).replace(['normal', 'reconnaissance', 'generic', 'exploits', 'worms', 'fuzzers', 'analysis', 'backdoor', 'shellcode'], 0))\n",
    "    data_labels.insert(2, 'reconnaissance', data['attack_cat'].replace('reconnaissance', 1).replace(['normal', 'dos', 'generic', 'exploits', 'worms', 'fuzzers', 'analysis', 'backdoor', 'shellcode'], 0))\n",
    "    data_labels.insert(3, 'generic', data['attack_cat'].replace('generic', 1).replace(['normal', 'dos', 'reconnaissance', 'exploits', 'worms', 'fuzzers', 'analysis', 'backdoor', 'shellcode'], 0))\n",
    "    data_labels.insert(4, 'exploits', data['attack_cat'].replace('exploits', 1).replace(['normal', 'dos', 'reconnaissance', 'generic', 'worms', 'fuzzers', 'analysis', 'backdoor', 'shellcode'], 0))\n",
    "    data_labels.insert(5, 'worms', data['attack_cat'].replace('worms', 1).replace(['normal', 'dos', 'reconnaissance', 'generic', 'exploits', 'fuzzers', 'analysis', 'backdoor', 'shellcode'], 0))\n",
    "    data_labels.insert(6, 'fuzzers', data['attack_cat'].replace('fuzzers', 1).replace(['normal', 'dos', 'reconnaissance', 'generic', 'exploits', 'worms', 'analysis', 'backdoor', 'shellcode'], 0))\n",
    "    data_labels.insert(7, 'analysis', data['attack_cat'].replace('analysis', 1).replace(['normal', 'dos', 'reconnaissance', 'generic', 'exploits', 'worms', 'fuzzers', 'backdoor', 'shellcode'], 0))\n",
    "    data_labels.insert(8, 'backdoor', data['attack_cat'].replace('backdoor', 1).replace(['normal', 'dos', 'reconnaissance', 'generic', 'exploits', 'worms', 'fuzzers', 'analysis', 'shellcode'], 0))\n",
    "    data_labels.insert(9, 'shellcode', data['attack_cat'].replace('shellcode', 1).replace(['normal', 'dos', 'reconnaissance', 'generic', 'exploits', 'worms', 'fuzzers', 'analysis', 'backdoor'], 0))\n",
    "\n",
    "    data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "    # Transform to One hot encoding - FEATURES\n",
    "    data_features=pd.get_dummies(data_features)\n",
    "\n",
    "    # Generate 2 new columns to fit with training\n",
    "    auxCol=data_features['sbytes']\n",
    "    auxCol=0\n",
    "\n",
    "      # As we are using different datasets that might not have all representations, we are going to detect and add the missing columns \n",
    "    # The columns that can have types are: proto and state: need to check if all representations are done \n",
    "    state_cols = [col for col in data_features if col.startswith('state_')]\n",
    "    proto_cols = [col for col in data_features if col.startswith('proto_')]\n",
    "    \n",
    "    # Check if all columns are present\n",
    "    if 'state_PAR' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_PAR', auxCol, True)\n",
    "    if 'state_ACC' not in state_cols: \n",
    "        data_features.insert(data_features.shape[1], 'state_ACC', auxCol, True)\n",
    "    if 'state_ECO' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_ECO', auxCol, True)\n",
    "    if 'state_CON' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_CON', auxCol, True)\n",
    "    if 'state_FIN' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_FIN', auxCol, True)\n",
    "    if 'state_INT' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_INT', auxCol, True)\n",
    "    if 'state_REQ' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_REQ', auxCol, True)\n",
    "    if 'state_RST' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_RST', auxCol, True)\n",
    "    if 'proto_igmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_igmp', auxCol, True)\n",
    "    if 'proto_arp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_arp', auxCol, True)\n",
    "    if 'proto_icmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_icmp', auxCol, True)\n",
    "    if 'proto_udp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_udp', auxCol, True)\n",
    "    if 'proto_tcp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_tcp', auxCol, True)\n",
    "\n",
    "    # Normalize all data features\n",
    "    data_features = StandardScaler().fit_transform(data_features)\n",
    "\n",
    "    #Add dimension to data features\n",
    "    data_features = np.expand_dims(data_features, axis=2)\n",
    "    data_features = np.expand_dims(data_features, axis=3)\n",
    "\n",
    "    x = data_features\n",
    "    y = data_labels.to_numpy()\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building and definition\n",
    "def build_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(filters=32,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(1, 1), padding='same'))\n",
    "    model.add(layers.Conv2D(filters=64,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(1, 1), padding='same'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(Dense(444, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns values of loss, accuracy, f1, precision and recall of model evaluating with test dataset \n",
    "def evaluation(model, x, y): \n",
    "    loss, accuracy = model.evaluate(x, y)\n",
    "    y_pred = model.predict(x)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y = np.argmax(y, axis=1)\n",
    "    report = classification_report(y, y_pred, labels = [i for i in range(10)], target_names=['normal', 'dos', 'reconnaissance', 'generic', 'exploits', 'worms', 'fuzzers', 'analysis', 'backdoor', 'shellcode'], output_dict=True)\n",
    "    # Obtain f1, precision and recall from the report\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    return loss, accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments with datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 3A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3268/797642493.py:2: DtypeWarning: Columns (2,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3A-Part1.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3268/797642493.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3A-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3268/797642493.py:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3A-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3268/797642493.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3A-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3A-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3A-Part3.csv')\n",
    "test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n",
    "test_plus = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test+.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "node_datasets = [training1, training2, training3]\n",
    "num_nodes = 3\n",
    "global_updates = 10\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'id000.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    avg_grad = np.mean(grad_list, axis=0)\n",
    "    return avg_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 23s 418ms/step - loss: 0.7425 - accuracy: 0.9000 - val_loss: 7.6566 - val_accuracy: 0.3314\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 29s 544ms/step - loss: 0.0514 - accuracy: 0.9920 - val_loss: 8.1478 - val_accuracy: 0.3315\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 27s 509ms/step - loss: 0.0302 - accuracy: 0.9926 - val_loss: 8.4146 - val_accuracy: 0.3317\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 27s 505ms/step - loss: 0.0274 - accuracy: 0.9925 - val_loss: 8.5737 - val_accuracy: 0.3317\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 33s 612ms/step - loss: 0.0259 - accuracy: 0.9926 - val_loss: 8.6774 - val_accuracy: 0.3317\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 32s 602ms/step - loss: 0.0247 - accuracy: 0.9927 - val_loss: 8.7664 - val_accuracy: 0.3317\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 39s 716ms/step - loss: 0.0234 - accuracy: 0.9927 - val_loss: 8.8369 - val_accuracy: 0.3324\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 40s 750ms/step - loss: 0.0220 - accuracy: 0.9930 - val_loss: 8.9577 - val_accuracy: 0.3325\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 51s 938ms/step - loss: 0.0206 - accuracy: 0.9935 - val_loss: 9.0606 - val_accuracy: 0.3333\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 9.2253 - val_accuracy: 0.3344\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 67s 1s/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 9.3541 - val_accuracy: 0.3332\n",
      "Epoch 1/15\n",
      "53/53 [==============================] - 72s 1s/step - loss: 0.0167 - accuracy: 0.9948 - val_loss: 1.9544 - val_accuracy: 0.8865\n",
      "Epoch 2/15\n",
      "53/53 [==============================] - 67s 1s/step - loss: 0.0155 - accuracy: 0.9952 - val_loss: 2.1447 - val_accuracy: 0.8854\n",
      "Epoch 3/15\n",
      "53/53 [==============================] - 63s 1s/step - loss: 0.0149 - accuracy: 0.9955 - val_loss: 2.2567 - val_accuracy: 0.8848\n",
      "Epoch 4/15\n",
      "53/53 [==============================] - 60s 1s/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 2.1197 - val_accuracy: 0.8869\n",
      "Epoch 5/15\n",
      "53/53 [==============================] - 57s 1s/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 2.1885 - val_accuracy: 0.8860\n",
      "Epoch 6/15\n",
      "53/53 [==============================] - 62s 1s/step - loss: 0.0144 - accuracy: 0.9956 - val_loss: 2.1701 - val_accuracy: 0.8886\n",
      "Epoch 7/15\n",
      "53/53 [==============================] - 65s 1s/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 2.2161 - val_accuracy: 0.8872\n",
      "Epoch 8/15\n",
      "53/53 [==============================] - 64s 1s/step - loss: 0.0140 - accuracy: 0.9960 - val_loss: 2.2283 - val_accuracy: 0.8872\n",
      "Epoch 9/15\n",
      "53/53 [==============================] - 62s 1s/step - loss: 0.0139 - accuracy: 0.9961 - val_loss: 2.2359 - val_accuracy: 0.8874\n",
      "Epoch 10/15\n",
      "53/53 [==============================] - 59s 1s/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 2.2614 - val_accuracy: 0.8872\n",
      "Epoch 11/15\n",
      "53/53 [==============================] - 54s 1s/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 2.2365 - val_accuracy: 0.8886\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 70s 1s/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 8.7537 - val_accuracy: 0.5620\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 8.9502 - val_accuracy: 0.5622\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 8.8896 - val_accuracy: 0.5608\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 70s 1s/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 8.7373 - val_accuracy: 0.5627\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 8.4949 - val_accuracy: 0.5604\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 8.5827 - val_accuracy: 0.5611\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 8.5681 - val_accuracy: 0.5622\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 66s 1s/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 8.3135 - val_accuracy: 0.5619\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 8.3697 - val_accuracy: 0.5617\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0121 - accuracy: 0.9965 - val_loss: 8.8794 - val_accuracy: 0.5630\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 67s 1s/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 8.6208 - val_accuracy: 0.5617\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0119 - accuracy: 0.9966 - val_loss: 8.8434 - val_accuracy: 0.5617\n",
      "Epoch 13/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 9.0030 - val_accuracy: 0.5615\n",
      "Epoch 14/15\n",
      "54/54 [==============================] - 55s 1s/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 9.0171 - val_accuracy: 0.5629\n",
      "Epoch 15/15\n",
      "54/54 [==============================] - 54s 992ms/step - loss: 0.0119 - accuracy: 0.9965 - val_loss: 8.9074 - val_accuracy: 0.5616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279/4279 [==============================] - 89s 21ms/step - loss: 1.7159 - accuracy: 0.90100s - loss: 1.7166 - accuracy: 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2/1721 [..............................] - ETA: 1:02 - loss: 13.6738 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0725s vs `on_test_batch_end` time: 0.2160s). Check your callbacks.\n",
      "1721/1721 [==============================] - 32s 19ms/step - loss: 7.0446 - accuracy: 0.5554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0132 - accuracy: 0.9965 - val_loss: 11.2388 - val_accuracy: 0.3354\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0126 - accuracy: 0.9967 - val_loss: 11.5578 - val_accuracy: 0.3352\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 55s 1s/step - loss: 0.0133 - accuracy: 0.9964 - val_loss: 11.3091 - val_accuracy: 0.3353\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0125 - accuracy: 0.9965 - val_loss: 11.5496 - val_accuracy: 0.3355\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 66s 1s/step - loss: 0.0130 - accuracy: 0.9964 - val_loss: 11.3087 - val_accuracy: 0.3354\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0122 - accuracy: 0.9968 - val_loss: 11.9370 - val_accuracy: 0.3347\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 53s 986ms/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 12.0610 - val_accuracy: 0.3350\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 53s 989ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 12.4712 - val_accuracy: 0.3354\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 57s 1s/step - loss: 0.0118 - accuracy: 0.9970 - val_loss: 12.9920 - val_accuracy: 0.3353\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 52s 959ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 13.0300 - val_accuracy: 0.3350\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 53s 989ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 13.5046 - val_accuracy: 0.3353\n",
      "Epoch 1/15\n",
      "53/53 [==============================] - 67s 1s/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 2.6414 - val_accuracy: 0.8890\n",
      "Epoch 2/15\n",
      "53/53 [==============================] - 58s 1s/step - loss: 0.0101 - accuracy: 0.9971 - val_loss: 2.7373 - val_accuracy: 0.8882\n",
      "Epoch 3/15\n",
      "53/53 [==============================] - 60s 1s/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 2.7749 - val_accuracy: 0.8883\n",
      "Epoch 4/15\n",
      "53/53 [==============================] - 63s 1s/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 2.7777 - val_accuracy: 0.8884\n",
      "Epoch 5/15\n",
      "53/53 [==============================] - 59s 1s/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 2.8260 - val_accuracy: 0.8881\n",
      "Epoch 6/15\n",
      "53/53 [==============================] - 62s 1s/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 2.9320 - val_accuracy: 0.8883\n",
      "Epoch 7/15\n",
      "53/53 [==============================] - 62s 1s/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 2.9346 - val_accuracy: 0.8884\n",
      "Epoch 8/15\n",
      "53/53 [==============================] - 64s 1s/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 2.9861 - val_accuracy: 0.8889\n",
      "Epoch 9/15\n",
      "53/53 [==============================] - 59s 1s/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 2.9545 - val_accuracy: 0.8882\n",
      "Epoch 10/15\n",
      "53/53 [==============================] - 62s 1s/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 2.9244 - val_accuracy: 0.8875\n",
      "Epoch 11/15\n",
      "53/53 [==============================] - 62s 1s/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 3.0059 - val_accuracy: 0.8896\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 68s 1s/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 11.2013 - val_accuracy: 0.5627\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 65s 1s/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 10.8926 - val_accuracy: 0.5612\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 67s 1s/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 11.1608 - val_accuracy: 0.5620\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 11.2567 - val_accuracy: 0.5614\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 11.0096 - val_accuracy: 0.5621\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 11.1109 - val_accuracy: 0.5618\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 11.0773 - val_accuracy: 0.5617\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 11.2930 - val_accuracy: 0.5615\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 66s 1s/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 11.6505 - val_accuracy: 0.5627\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 11.5191 - val_accuracy: 0.5619\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 11.3557 - val_accuracy: 0.5617\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 57s 1s/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 11.4714 - val_accuracy: 0.5623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279/4279 [==============================] - 82s 19ms/step - loss: 2.1919 - accuracy: 0.9165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1721/1721 [==============================] - 30s 17ms/step - loss: 9.1639 - accuracy: 0.5583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 14.6432 - val_accuracy: 0.3353\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 14.8719 - val_accuracy: 0.3357\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 14.6012 - val_accuracy: 0.3355\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0084 - accuracy: 0.9978 - val_loss: 14.7512 - val_accuracy: 0.3352\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 14.8159 - val_accuracy: 0.3351\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 55s 1s/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 14.9478 - val_accuracy: 0.3357\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 55s 1s/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 15.0541 - val_accuracy: 0.3356\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0083 - accuracy: 0.9980 - val_loss: 15.2334 - val_accuracy: 0.3357\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 54s 1s/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 15.1363 - val_accuracy: 0.3355\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0082 - accuracy: 0.9978 - val_loss: 14.9268 - val_accuracy: 0.3352\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 15.1301 - val_accuracy: 0.3359\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 14.7111 - val_accuracy: 0.3350\n",
      "Epoch 13/15\n",
      "54/54 [==============================] - 57s 1s/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 15.0278 - val_accuracy: 0.3357\n",
      "Epoch 1/15\n",
      "53/53 [==============================] - 66s 1s/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 2.8995 - val_accuracy: 0.8883\n",
      "Epoch 2/15\n",
      "53/53 [==============================] - 59s 1s/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 2.9074 - val_accuracy: 0.8884\n",
      "Epoch 3/15\n",
      "53/53 [==============================] - 59s 1s/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 2.8914 - val_accuracy: 0.8876\n",
      "Epoch 4/15\n",
      "53/53 [==============================] - 58s 1s/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 2.9448 - val_accuracy: 0.8898\n",
      "Epoch 5/15\n",
      "53/53 [==============================] - 61s 1s/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 2.8562 - val_accuracy: 0.8891\n",
      "Epoch 6/15\n",
      "53/53 [==============================] - 58s 1s/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 2.8740 - val_accuracy: 0.8887\n",
      "Epoch 7/15\n",
      "53/53 [==============================] - 55s 1s/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 2.8605 - val_accuracy: 0.8894\n",
      "Epoch 8/15\n",
      "53/53 [==============================] - 58s 1s/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 2.8699 - val_accuracy: 0.8889\n",
      "Epoch 9/15\n",
      "53/53 [==============================] - 63s 1s/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 2.9184 - val_accuracy: 0.8894\n",
      "Epoch 10/15\n",
      "53/53 [==============================] - 61s 1s/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 2.9293 - val_accuracy: 0.8891\n",
      "Epoch 11/15\n",
      "53/53 [==============================] - 58s 1s/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 2.9442 - val_accuracy: 0.8896\n",
      "Epoch 12/15\n",
      "53/53 [==============================] - 64s 1s/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 2.8953 - val_accuracy: 0.8891\n",
      "Epoch 13/15\n",
      "53/53 [==============================] - 63s 1s/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 2.9104 - val_accuracy: 0.8892\n",
      "Epoch 14/15\n",
      "53/53 [==============================] - 63s 1s/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 2.8628 - val_accuracy: 0.8881\n",
      "Epoch 15/15\n",
      "53/53 [==============================] - 64s 1s/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 2.9172 - val_accuracy: 0.8890\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 69s 1s/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 10.0010 - val_accuracy: 0.5616\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 66s 1s/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 10.0721 - val_accuracy: 0.5622\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 65s 1s/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 10.5737 - val_accuracy: 0.5630\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 10.3022 - val_accuracy: 0.5618\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 10.4006 - val_accuracy: 0.5622\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 10.4143 - val_accuracy: 0.5623\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 54s 991ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 10.5764 - val_accuracy: 0.5626\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 10.5386 - val_accuracy: 0.5628\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 10.4465 - val_accuracy: 0.5623\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 56s 1s/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 10.6944 - val_accuracy: 0.5626\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 10.6381 - val_accuracy: 0.5624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279/4279 [==============================] - 84s 20ms/step - loss: 2.3710 - accuracy: 0.6898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1721/1721 [==============================] - 39s 23ms/step - loss: 8.6432 - accuracy: 0.5582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "54/54 [==============================] - 71s 1s/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 13.6544 - val_accuracy: 0.3356\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 65s 1s/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 13.5712 - val_accuracy: 0.3354\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 67s 1s/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 13.6652 - val_accuracy: 0.3352\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 54s 999ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 14.0182 - val_accuracy: 0.3356\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 13.8774 - val_accuracy: 0.3359\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 52s 967ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 13.9242 - val_accuracy: 0.3358\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 49s 912ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 13.8619 - val_accuracy: 0.3355\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 13.8076 - val_accuracy: 0.3353\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 14.1126 - val_accuracy: 0.3356\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 67s 1s/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 14.0665 - val_accuracy: 0.3352\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 13.8441 - val_accuracy: 0.3355\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 14.1400 - val_accuracy: 0.3355\n",
      "Epoch 1/15\n",
      "53/53 [==============================] - 63s 1s/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 2.7076 - val_accuracy: 0.8879\n",
      "Epoch 2/15\n",
      "53/53 [==============================] - 60s 1s/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 2.7607 - val_accuracy: 0.8893\n",
      "Epoch 3/15\n",
      "53/53 [==============================] - 58s 1s/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 2.7590 - val_accuracy: 0.8893\n",
      "Epoch 4/15\n",
      "53/53 [==============================] - 59s 1s/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 2.6804 - val_accuracy: 0.8878\n",
      "Epoch 5/15\n",
      "53/53 [==============================] - 64s 1s/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 2.6846 - val_accuracy: 0.8887\n",
      "Epoch 6/15\n",
      "53/53 [==============================] - 64s 1s/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 2.7028 - val_accuracy: 0.8893\n",
      "Epoch 7/15\n",
      "53/53 [==============================] - 62s 1s/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 2.6748 - val_accuracy: 0.8891\n",
      "Epoch 8/15\n",
      "53/53 [==============================] - 64s 1s/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 2.7120 - val_accuracy: 0.8891\n",
      "Epoch 9/15\n",
      "53/53 [==============================] - 57s 1s/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 2.6823 - val_accuracy: 0.8873\n",
      "Epoch 10/15\n",
      "53/53 [==============================] - 56s 1s/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 2.7558 - val_accuracy: 0.8891\n",
      "Epoch 11/15\n",
      "53/53 [==============================] - 54s 1s/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 2.7591 - val_accuracy: 0.8888\n",
      "Epoch 12/15\n",
      "53/53 [==============================] - 59s 1s/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 2.7817 - val_accuracy: 0.8890\n",
      "Epoch 13/15\n",
      "53/53 [==============================] - 57s 1s/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 2.6780 - val_accuracy: 0.8886\n",
      "Epoch 14/15\n",
      "53/53 [==============================] - 61s 1s/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 2.6754 - val_accuracy: 0.8889\n",
      "Epoch 15/15\n",
      "53/53 [==============================] - 60s 1s/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 2.6957 - val_accuracy: 0.8886\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 65s 1s/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 10.1515 - val_accuracy: 0.5624\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 10.0628 - val_accuracy: 0.5620\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 10.2753 - val_accuracy: 0.5624\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 10.1942 - val_accuracy: 0.5623\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 10.6414 - val_accuracy: 0.5627\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 10.2130 - val_accuracy: 0.5618\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 10.0772 - val_accuracy: 0.5619\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 10.3327 - val_accuracy: 0.5620\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 52s 959ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 10.3560 - val_accuracy: 0.5620\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 10.6399 - val_accuracy: 0.5630\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 10.5693 - val_accuracy: 0.5622\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 10.7964 - val_accuracy: 0.5624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279/4279 [==============================] - 91s 21ms/step - loss: 2.8661 - accuracy: 0.5299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1721/1721 [==============================] - 38s 22ms/step - loss: 9.4559 - accuracy: 0.5577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "54/54 [==============================] - 75s 1s/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 13.3637 - val_accuracy: 0.3353\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 13.4767 - val_accuracy: 0.3353\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 13.3983 - val_accuracy: 0.3357\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 13.6081 - val_accuracy: 0.3359\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 55s 1s/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 13.4490 - val_accuracy: 0.3358\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 52s 968ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 13.4976 - val_accuracy: 0.3358\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 56s 1s/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 13.6669 - val_accuracy: 0.3359\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 13.3691 - val_accuracy: 0.3355\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 13.5379 - val_accuracy: 0.3358\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 13.6318 - val_accuracy: 0.3355\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 56s 1s/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 13.7279 - val_accuracy: 0.3357\n",
      "Epoch 1/15\n",
      "53/53 [==============================] - 69s 1s/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 2.5711 - val_accuracy: 0.8893\n",
      "Epoch 2/15\n",
      "53/53 [==============================] - 60s 1s/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 2.5777 - val_accuracy: 0.8895\n",
      "Epoch 3/15\n",
      "53/53 [==============================] - 60s 1s/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 2.4808 - val_accuracy: 0.8884\n",
      "Epoch 4/15\n",
      "53/53 [==============================] - 59s 1s/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 2.6017 - val_accuracy: 0.8891\n",
      "Epoch 5/15\n",
      "53/53 [==============================] - 67s 1s/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 2.5486 - val_accuracy: 0.8900\n",
      "Epoch 6/15\n",
      "53/53 [==============================] - 61s 1s/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 2.5599 - val_accuracy: 0.8894\n",
      "Epoch 7/15\n",
      "53/53 [==============================] - 60s 1s/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 2.5758 - val_accuracy: 0.8889\n",
      "Epoch 8/15\n",
      "53/53 [==============================] - 60s 1s/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 2.5706 - val_accuracy: 0.8894\n",
      "Epoch 9/15\n",
      "53/53 [==============================] - 61s 1s/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 2.5517 - val_accuracy: 0.8884\n",
      "Epoch 10/15\n",
      "53/53 [==============================] - 61s 1s/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 2.6274 - val_accuracy: 0.8896\n",
      "Epoch 11/15\n",
      "53/53 [==============================] - 64s 1s/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 2.6391 - val_accuracy: 0.8892\n",
      "Epoch 12/15\n",
      "53/53 [==============================] - 60s 1s/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 2.6317 - val_accuracy: 0.8893\n",
      "Epoch 13/15\n",
      "53/53 [==============================] - 59s 1s/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 2.6142 - val_accuracy: 0.8891\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 81s 1s/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 9.7543 - val_accuracy: 0.5620\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0055 - accuracy: 0.9980 - val_loss: 10.1688 - val_accuracy: 0.5628\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 9.5896 - val_accuracy: 0.5622\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 9.8342 - val_accuracy: 0.5624\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 66s 1s/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 10.1673 - val_accuracy: 0.5626\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 10.1160 - val_accuracy: 0.5623\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 56s 1s/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 10.2542 - val_accuracy: 0.5623\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 65s 1s/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 10.2631 - val_accuracy: 0.5624\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 10.3642 - val_accuracy: 0.5626\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 10.4922 - val_accuracy: 0.5628\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 65s 1s/step - loss: 0.0047 - accuracy: 0.9983 - val_loss: 10.5529 - val_accuracy: 0.5625\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 10.8333 - val_accuracy: 0.5627\n",
      "Epoch 13/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 10.5111 - val_accuracy: 0.5627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279/4279 [==============================] - 77s 18ms/step - loss: 3.0080 - accuracy: 0.5295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1721/1721 [==============================] - 43s 25ms/step - loss: 10.1454 - accuracy: 0.5561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "54/54 [==============================] - 71s 1s/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 13.7080 - val_accuracy: 0.3358\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 65s 1s/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 13.5470 - val_accuracy: 0.3356\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 13.3641 - val_accuracy: 0.3355\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 13.5424 - val_accuracy: 0.3357\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 13.5274 - val_accuracy: 0.3356\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 13.9166 - val_accuracy: 0.3358\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 54s 1s/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 13.7013 - val_accuracy: 0.3355\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 13.7398 - val_accuracy: 0.3357\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 13.7892 - val_accuracy: 0.3356\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 13.6645 - val_accuracy: 0.3352\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 13.5503 - val_accuracy: 0.3353\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 14.3736 - val_accuracy: 0.3358\n",
      "Epoch 13/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 13.9892 - val_accuracy: 0.3354\n",
      "Epoch 1/15\n",
      "53/53 [==============================] - 67s 1s/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 2.5675 - val_accuracy: 0.8890\n",
      "Epoch 2/15\n",
      "53/53 [==============================] - 58s 1s/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 2.5691 - val_accuracy: 0.8894\n",
      "Epoch 3/15\n",
      "53/53 [==============================] - 62s 1s/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 2.5391 - val_accuracy: 0.8893\n",
      "Epoch 4/15\n",
      "53/53 [==============================] - 59s 1s/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 2.5535 - val_accuracy: 0.8892\n",
      "Epoch 5/15\n",
      "53/53 [==============================] - 60s 1s/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 2.5980 - val_accuracy: 0.8901\n",
      "Epoch 6/15\n",
      "53/53 [==============================] - 60s 1s/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 2.5304 - val_accuracy: 0.8895\n",
      "Epoch 7/15\n",
      "53/53 [==============================] - 62s 1s/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 2.5810 - val_accuracy: 0.8893\n",
      "Epoch 8/15\n",
      "53/53 [==============================] - 63s 1s/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 2.5703 - val_accuracy: 0.8890\n",
      "Epoch 9/15\n",
      "53/53 [==============================] - 64s 1s/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 2.5880 - val_accuracy: 0.8892\n",
      "Epoch 10/15\n",
      "53/53 [==============================] - 64s 1s/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 2.6509 - val_accuracy: 0.8892\n",
      "Epoch 11/15\n",
      "53/53 [==============================] - 63s 1s/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 2.6562 - val_accuracy: 0.8899\n",
      "Epoch 12/15\n",
      "53/53 [==============================] - 63s 1s/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 2.6126 - val_accuracy: 0.8894\n",
      "Epoch 13/15\n",
      "53/53 [==============================] - 56s 1s/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 2.6620 - val_accuracy: 0.8899\n",
      "Epoch 14/15\n",
      "53/53 [==============================] - 57s 1s/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 2.6265 - val_accuracy: 0.8893\n",
      "Epoch 15/15\n",
      "53/53 [==============================] - 55s 1s/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 2.6370 - val_accuracy: 0.8891\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 10.4669 - val_accuracy: 0.5629\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0047 - accuracy: 0.9983 - val_loss: 10.1635 - val_accuracy: 0.5624\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0044 - accuracy: 0.9983 - val_loss: 10.3077 - val_accuracy: 0.5629\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 67s 1s/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 10.4082 - val_accuracy: 0.5627\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 9.8939 - val_accuracy: 0.5626\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 65s 1s/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 10.2984 - val_accuracy: 0.5630\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 67s 1s/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 10.1851 - val_accuracy: 0.5624\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 9.7621 - val_accuracy: 0.5620\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 65s 1s/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 10.3261 - val_accuracy: 0.5624\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 10.1325 - val_accuracy: 0.5623\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 10.1834 - val_accuracy: 0.5623\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 10.1605 - val_accuracy: 0.5624\n",
      "Epoch 13/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0039 - accuracy: 0.9985 - val_loss: 10.7185 - val_accuracy: 0.5629\n",
      "Epoch 14/15\n",
      "54/54 [==============================] - 57s 1s/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 10.4797 - val_accuracy: 0.5624\n",
      "Epoch 15/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 10.7867 - val_accuracy: 0.5628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279/4279 [==============================] - 81s 19ms/step - loss: 2.9826 - accuracy: 0.54171s - loss: - ETA: 0s - los\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1721/1721 [==============================] - 30s 17ms/step - loss: 11.7583 - accuracy: 0.5544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "54/54 [==============================] - 70s 1s/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 13.5490 - val_accuracy: 0.3357\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 65s 1s/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 13.5826 - val_accuracy: 0.3356\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 13.2607 - val_accuracy: 0.3352\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 13.5015 - val_accuracy: 0.3357\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 13.3080 - val_accuracy: 0.3356\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 13.3493 - val_accuracy: 0.3355\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 13.8606 - val_accuracy: 0.3357\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 13.7025 - val_accuracy: 0.3357\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 13.8061 - val_accuracy: 0.3358\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 13.6300 - val_accuracy: 0.3356\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 13.8523 - val_accuracy: 0.3358\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 56s 1s/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 13.7971 - val_accuracy: 0.3357\n",
      "Epoch 13/15\n",
      "54/54 [==============================] - 57s 1s/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 13.7784 - val_accuracy: 0.3356\n",
      "Epoch 1/15\n",
      "53/53 [==============================] - 64s 1s/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 2.5049 - val_accuracy: 0.8897\n",
      "Epoch 2/15\n",
      "53/53 [==============================] - 60s 1s/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 2.4200 - val_accuracy: 0.8896\n",
      "Epoch 3/15\n",
      "53/53 [==============================] - 66s 1s/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 2.5054 - val_accuracy: 0.8901\n",
      "Epoch 4/15\n",
      "53/53 [==============================] - 65s 1s/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 2.4439 - val_accuracy: 0.8893\n",
      "Epoch 5/15\n",
      "53/53 [==============================] - 62s 1s/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 2.3755 - val_accuracy: 0.8888\n",
      "Epoch 6/15\n",
      "53/53 [==============================] - 62s 1s/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 2.4625 - val_accuracy: 0.8896\n",
      "Epoch 7/15\n",
      "53/53 [==============================] - 62s 1s/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 2.3974 - val_accuracy: 0.8887\n",
      "Epoch 8/15\n",
      "53/53 [==============================] - 57s 1s/step - loss: 0.0039 - accuracy: 0.9985 - val_loss: 2.4269 - val_accuracy: 0.8891\n",
      "Epoch 9/15\n",
      "53/53 [==============================] - 60s 1s/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 2.5137 - val_accuracy: 0.8902\n",
      "Epoch 10/15\n",
      "53/53 [==============================] - 60s 1s/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 2.4475 - val_accuracy: 0.8894\n",
      "Epoch 11/15\n",
      "53/53 [==============================] - 59s 1s/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 2.5623 - val_accuracy: 0.8903\n",
      "Epoch 12/15\n",
      "53/53 [==============================] - 60s 1s/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 2.5705 - val_accuracy: 0.8902\n",
      "Epoch 13/15\n",
      "53/53 [==============================] - 56s 1s/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 2.4955 - val_accuracy: 0.8892\n",
      "Epoch 14/15\n",
      "53/53 [==============================] - 49s 919ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 2.5367 - val_accuracy: 0.8896\n",
      "Epoch 15/15\n",
      "53/53 [==============================] - 57s 1s/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 2.4692 - val_accuracy: 0.8890\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 76s 1s/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 9.8806 - val_accuracy: 0.5627\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 10.0150 - val_accuracy: 0.5630\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 68s 1s/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 10.0114 - val_accuracy: 0.5627\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 9.7093 - val_accuracy: 0.5624\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 10.0690 - val_accuracy: 0.5627\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 9.9416 - val_accuracy: 0.5626\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 66s 1s/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 10.0057 - val_accuracy: 0.5626\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 9.9842 - val_accuracy: 0.5627\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 10.0759 - val_accuracy: 0.5628\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 55s 1s/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 9.9338 - val_accuracy: 0.5624\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 52s 954ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 10.1622 - val_accuracy: 0.5624\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 49s 914ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 10.2217 - val_accuracy: 0.5626\n",
      "Epoch 13/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 10.5212 - val_accuracy: 0.5630\n",
      "Epoch 14/15\n",
      "54/54 [==============================] - 66s 1s/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 10.1976 - val_accuracy: 0.5628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279/4279 [==============================] - 97s 23ms/step - loss: 2.9654 - accuracy: 0.5782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1721/1721 [==============================] - 35s 20ms/step - loss: 13.1615 - accuracy: 0.5530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 13.7580 - val_accuracy: 0.3357\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 13.3265 - val_accuracy: 0.3355\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 13.5474 - val_accuracy: 0.3357\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 13.7093 - val_accuracy: 0.3357\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 65s 1s/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 13.7158 - val_accuracy: 0.3358\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 13.4736 - val_accuracy: 0.3356\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 13.7913 - val_accuracy: 0.3358\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 13.9916 - val_accuracy: 0.3358\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 57s 1s/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 13.8254 - val_accuracy: 0.3357\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 13.8856 - val_accuracy: 0.3357\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 13.9744 - val_accuracy: 0.3358\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 14.1661 - val_accuracy: 0.3358\n",
      "Epoch 1/15\n",
      "53/53 [==============================] - 71s 1s/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 2.5706 - val_accuracy: 0.8905\n",
      "Epoch 2/15\n",
      "53/53 [==============================] - 64s 1s/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 2.4996 - val_accuracy: 0.8897\n",
      "Epoch 3/15\n",
      "53/53 [==============================] - 63s 1s/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 2.5224 - val_accuracy: 0.8902\n",
      "Epoch 4/15\n",
      "53/53 [==============================] - 67s 1s/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 2.3401 - val_accuracy: 0.8884\n",
      "Epoch 5/15\n",
      "53/53 [==============================] - 63s 1s/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 2.3922 - val_accuracy: 0.8894\n",
      "Epoch 6/15\n",
      "53/53 [==============================] - 60s 1s/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 2.4163 - val_accuracy: 0.8891\n",
      "Epoch 7/15\n",
      "53/53 [==============================] - 61s 1s/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 2.4760 - val_accuracy: 0.8899\n",
      "Epoch 8/15\n",
      "53/53 [==============================] - 61s 1s/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 2.4746 - val_accuracy: 0.8893\n",
      "Epoch 9/15\n",
      "53/53 [==============================] - 56s 1s/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 2.4598 - val_accuracy: 0.8893\n",
      "Epoch 10/15\n",
      "53/53 [==============================] - 64s 1s/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 2.4732 - val_accuracy: 0.8895\n",
      "Epoch 11/15\n",
      "53/53 [==============================] - 58s 1s/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 2.4051 - val_accuracy: 0.8892\n",
      "Epoch 12/15\n",
      "53/53 [==============================] - 56s 1s/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 2.5250 - val_accuracy: 0.8894\n",
      "Epoch 13/15\n",
      "53/53 [==============================] - 56s 1s/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 2.5092 - val_accuracy: 0.8894\n",
      "Epoch 14/15\n",
      "53/53 [==============================] - 62s 1s/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 2.5238 - val_accuracy: 0.8895\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 69s 1s/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 9.9446 - val_accuracy: 0.5630\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 71s 1s/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 10.1403 - val_accuracy: 0.5630\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 65s 1s/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 9.7457 - val_accuracy: 0.5626\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 68s 1s/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 10.0594 - val_accuracy: 0.5631\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 68s 1s/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 10.2094 - val_accuracy: 0.5633\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 9.9526 - val_accuracy: 0.5625\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 10.1461 - val_accuracy: 0.5627\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 10.1950 - val_accuracy: 0.5631\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 55s 1s/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 10.1729 - val_accuracy: 0.5628\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 10.7363 - val_accuracy: 0.5634\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 56s 1s/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 10.6883 - val_accuracy: 0.5635\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 56s 1s/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 10.2797 - val_accuracy: 0.5628\n",
      "Epoch 13/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 10.5123 - val_accuracy: 0.5630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279/4279 [==============================] - 102s 24ms/step - loss: 2.6688 - accuracy: 0.6938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1721/1721 [==============================] - 33s 19ms/step - loss: 14.4467 - accuracy: 0.5524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "54/54 [==============================] - 67s 1s/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 13.3184 - val_accuracy: 0.3355\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 55s 1s/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 13.5683 - val_accuracy: 0.3358\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 13.5205 - val_accuracy: 0.3357\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 57s 1s/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 13.3019 - val_accuracy: 0.3356\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 13.4431 - val_accuracy: 0.3356\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 57s 1s/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 13.6095 - val_accuracy: 0.3356\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 13.9425 - val_accuracy: 0.3359\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 53s 976ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 13.8322 - val_accuracy: 0.3359\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 13.8434 - val_accuracy: 0.3357\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 13.8786 - val_accuracy: 0.3357\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 52s 954ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 13.7546 - val_accuracy: 0.3355\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 53s 981ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 13.9659 - val_accuracy: 0.3357\n",
      "Epoch 13/15\n",
      "54/54 [==============================] - 53s 984ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 14.1461 - val_accuracy: 0.3357\n",
      "Epoch 14/15\n",
      "54/54 [==============================] - 55s 1s/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 14.0966 - val_accuracy: 0.3357\n",
      "Epoch 1/15\n",
      "53/53 [==============================] - 82s 2s/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 2.6145 - val_accuracy: 0.8900\n",
      "Epoch 2/15\n",
      "53/53 [==============================] - 59s 1s/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 2.5535 - val_accuracy: 0.8896\n",
      "Epoch 3/15\n",
      "53/53 [==============================] - 55s 1s/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 2.6050 - val_accuracy: 0.8901\n",
      "Epoch 4/15\n",
      "53/53 [==============================] - 60s 1s/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 2.5202 - val_accuracy: 0.8892\n",
      "Epoch 5/15\n",
      "53/53 [==============================] - 52s 985ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 2.5817 - val_accuracy: 0.8900\n",
      "Epoch 6/15\n",
      "53/53 [==============================] - 56s 1s/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 2.5306 - val_accuracy: 0.8891\n",
      "Epoch 7/15\n",
      "53/53 [==============================] - 53s 1s/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 2.5677 - val_accuracy: 0.8897\n",
      "Epoch 8/15\n",
      "53/53 [==============================] - 53s 992ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 2.5824 - val_accuracy: 0.8897\n",
      "Epoch 9/15\n",
      "53/53 [==============================] - 51s 958ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 2.5592 - val_accuracy: 0.8896\n",
      "Epoch 10/15\n",
      "53/53 [==============================] - 49s 923ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 2.6243 - val_accuracy: 0.8899\n",
      "Epoch 11/15\n",
      "53/53 [==============================] - 45s 846ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 2.6552 - val_accuracy: 0.8899\n",
      "Epoch 12/15\n",
      "53/53 [==============================] - 48s 906ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 2.6363 - val_accuracy: 0.8900\n",
      "Epoch 13/15\n",
      "53/53 [==============================] - 51s 955ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 2.6093 - val_accuracy: 0.8898\n",
      "Epoch 14/15\n",
      "53/53 [==============================] - 51s 963ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 2.6348 - val_accuracy: 0.8896\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 55s 1s/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 10.7629 - val_accuracy: 0.5636\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 10.2070 - val_accuracy: 0.5623\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 10.6465 - val_accuracy: 0.5631\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 10.4665 - val_accuracy: 0.5628\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 55s 1s/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 10.4292 - val_accuracy: 0.5629\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 57s 1s/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 10.6217 - val_accuracy: 0.5631\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 52s 968ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 10.8379 - val_accuracy: 0.5634\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 50s 934ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 10.8435 - val_accuracy: 0.5633\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 52s 961ms/step - loss: 0.0025 - accuracy: 0.9990 - val_loss: 10.7397 - val_accuracy: 0.5631\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 54s 1s/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 10.8509 - val_accuracy: 0.5631\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 55s 1s/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 11.2190 - val_accuracy: 0.5636\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0025 - accuracy: 0.9990 - val_loss: 10.9784 - val_accuracy: 0.5630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279/4279 [==============================] - 82s 19ms/step - loss: 3.2159 - accuracy: 0.5346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1721/1721 [==============================] - 35s 20ms/step - loss: 15.6192 - accuracy: 0.5508 2s - loss: 16.9448 - accuracy: 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 14.1302 - val_accuracy: 0.3359\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 14.0938 - val_accuracy: 0.3357\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 14.0292 - val_accuracy: 0.3358\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 13.9694 - val_accuracy: 0.3358\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 14.0255 - val_accuracy: 0.3359\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 13.6506 - val_accuracy: 0.3357\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 54s 1000ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 13.6142 - val_accuracy: 0.3357\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 54s 1s/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 14.2169 - val_accuracy: 0.3359\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 52s 965ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 13.8474 - val_accuracy: 0.3357\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 47s 863ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 14.0181 - val_accuracy: 0.3358\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 52s 968ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 14.2204 - val_accuracy: 0.3358\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 54s 1s/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 13.8623 - val_accuracy: 0.3356\n",
      "Epoch 13/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 13.9132 - val_accuracy: 0.3357\n",
      "Epoch 14/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 14.1586 - val_accuracy: 0.3357\n",
      "Epoch 15/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 14.3455 - val_accuracy: 0.3358\n",
      "Epoch 1/15\n",
      "53/53 [==============================] - 59s 1s/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 2.5956 - val_accuracy: 0.8901\n",
      "Epoch 2/15\n",
      "53/53 [==============================] - 59s 1s/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 2.4862 - val_accuracy: 0.8887\n",
      "Epoch 3/15\n",
      "53/53 [==============================] - 59s 1s/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 2.5415 - val_accuracy: 0.8899\n",
      "Epoch 4/15\n",
      "53/53 [==============================] - 59s 1s/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 2.5299 - val_accuracy: 0.8898\n",
      "Epoch 5/15\n",
      "53/53 [==============================] - 52s 987ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 2.5989 - val_accuracy: 0.8902\n",
      "Epoch 6/15\n",
      "53/53 [==============================] - 46s 876ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 2.5875 - val_accuracy: 0.8896\n",
      "Epoch 7/15\n",
      "53/53 [==============================] - 49s 930ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 2.6654 - val_accuracy: 0.8904\n",
      "Epoch 8/15\n",
      "53/53 [==============================] - 46s 868ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 2.5929 - val_accuracy: 0.8893\n",
      "Epoch 9/15\n",
      "53/53 [==============================] - 36s 686ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 2.6355 - val_accuracy: 0.8899\n",
      "Epoch 10/15\n",
      "53/53 [==============================] - 36s 674ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 2.6979 - val_accuracy: 0.8900\n",
      "Epoch 11/15\n",
      "53/53 [==============================] - 44s 833ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 2.7181 - val_accuracy: 0.8900\n",
      "Epoch 12/15\n",
      "53/53 [==============================] - 40s 752ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 2.7032 - val_accuracy: 0.8898\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 47s 879ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 10.5450 - val_accuracy: 0.5630\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 42s 778ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 10.9067 - val_accuracy: 0.5631\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 42s 780ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 10.9963 - val_accuracy: 0.5631\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 40s 735ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 10.9462 - val_accuracy: 0.5629\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 32s 586ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 10.9907 - val_accuracy: 0.5631\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 35s 652ms/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 11.0772 - val_accuracy: 0.5632\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 39s 714ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 11.0254 - val_accuracy: 0.5628\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 39s 721ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 11.2568 - val_accuracy: 0.5632\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 37s 687ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 10.9989 - val_accuracy: 0.5629\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 35s 644ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 11.1777 - val_accuracy: 0.5628\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 35s 652ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 11.2041 - val_accuracy: 0.5634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279/4279 [==============================] - 53s 12ms/step - loss: 3.0947 - accuracy: 0.5345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1721/1721 [==============================] - 17s 10ms/step - loss: 16.6600 - accuracy: 0.5501 1s \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        else:\n",
    "            x, y = x3, y3\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(y, predictions)\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/id000.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[1.7159273624420166, 7.04463529586792], [2.1918957233428955, 9.16387939453125], [2.3710083961486816, 8.643190383911133], [2.8661272525787354, 9.455855369567871], [3.008028268814087, 10.14539623260498], [2.9826226234436035, 11.758312225341797], [2.965424060821533, 13.161545753479004], [2.6688168048858643, 14.4466552734375], [3.215939998626709, 15.619219779968262], [3.094697952270508, 16.659975051879883]]\n",
      "Accuracy for iterations:  [[0.9010415077209473, 0.5553658604621887], [0.9164524078369141, 0.558344841003418], [0.6898463368415833, 0.5581995248794556], [0.5299088358879089, 0.5576727390289307], [0.5295217633247375, 0.5561469197273254], [0.5416678786277771, 0.5544031262397766], [0.5781574249267578, 0.5529862642288208], [0.6938195824623108, 0.5523686408996582], [0.5346197485923767, 0.5508065223693848], [0.534459114074707, 0.5500617623329163]]\n",
      "F1 for iterations:  [[0.8644252689061761, 0.45439290560040924], [0.879090638864813, 0.42621753868101747], [0.6356918065866827, 0.434673024818802], [0.39148001449744196, 0.4475037127860661], [0.39198449444862254, 0.4648700042733946], [0.4163055138405205, 0.4932199363766483], [0.47935626140661325, 0.5030421695215732], [0.641687560615615, 0.5121234105139727], [0.4046532934848111, 0.5182866305976449], [0.4047460175609475, 0.5187163131825344]]\n",
      "Precision for iterations:  [[0.8311930037559874, 0.384487872467741], [0.8454035522955787, 0.344657444998081], [0.640851693476874, 0.3559117127438005], [0.3328066292102794, 0.3736822585703099], [0.3328319695894054, 0.39933040500598094], [0.3856092161491118, 0.4441987646570954], [0.483810840241881, 0.4613723700679471], [0.6367753689794386, 0.4773443775686182], [0.35732601790977625, 0.48939265438617163], [0.357046022553487, 0.49075072500144606]]\n",
      "Recall for iterations:  [[0.9010415145052441, 0.5553658359369323], [0.9164524233836805, 0.5583448376080796], [0.6898463291361127, 0.5581995204533895], [0.5299088492214205, 0.5576727457676379], [0.5295217505623886, 0.5561469156433917], [0.5416678839580473, 0.5544031097871104], [0.5781574103830086, 0.5529862675288818], [0.6938195682024014, 0.5523686696214488], [0.5346197668643548, 0.5508065102085301], [0.5344590844021152, 0.5500617597907433]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 3B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3268/1167559547.py:2: DtypeWarning: Columns (2,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3B-Part1.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3268/1167559547.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3B-Part2.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3B-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3B-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3B-Part3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "node_datasets = [training1, training2, training3]\n",
    "num_nodes = 3\n",
    "global_updates = 10\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'id001.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    avg_grad = np.mean(grad_list, axis=0)\n",
    "    return avg_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "12/57 [=====>........................] - ETA: 13s - loss: 1.9652 - accuracy: 0.9167"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3268/3582129653.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mlocal_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_val_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_val_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_local_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlocal_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3268/4157577176.py\u001b[0m in \u001b[0;36mtrain_local_model\u001b[1;34m(model, node, x_train, y_train)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5e-4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss_fct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocal_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2048\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\UX430\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\UX430\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1091\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1092\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1093\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1094\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1095\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\UX430\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\UX430\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\UX430\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\UX430\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32mc:\\Users\\UX430\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\Users\\UX430\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\UX430\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        else:\n",
    "            x, y = x3, y3\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(y, predictions)\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/id001.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 3C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3C-Part3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "node_datasets = [training1, training2, training3]\n",
    "num_nodes = 3\n",
    "global_updates = 10\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'id002.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    avg_grad = np.mean(grad_list, axis=0)\n",
    "    return avg_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        else:\n",
    "            x, y = x3, y3\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(y, predictions)\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/id002.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3D-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3D-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3D-Part3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "node_datasets = [training1, training2, training3]\n",
    "num_nodes = 3\n",
    "global_updates = 10\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'id003.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    avg_grad = np.mean(grad_list, axis=0)\n",
    "    return avg_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        else:\n",
    "            x, y = x3, y3\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(y, predictions)\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/id003.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATASET 3E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3E-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3E-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3E-Part3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "node_datasets = [training1, training2, training3]\n",
    "num_nodes = 3\n",
    "global_updates = 10\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'id004.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    avg_grad = np.mean(grad_list, axis=0)\n",
    "    return avg_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        else:\n",
    "            x, y = x3, y3\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(y, predictions)\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/id004.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATASET 3F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3F-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3F-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3F-Part3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "node_datasets = [training1, training2, training3]\n",
    "num_nodes = 3\n",
    "global_updates = 10\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'id005.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    avg_grad = np.mean(grad_list, axis=0)\n",
    "    return avg_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        else:\n",
    "            x, y = x3, y3\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(y, predictions)\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/id005.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATASET 3G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3G-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3G-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3G-Part3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "node_datasets = [training1, training2, training3]\n",
    "num_nodes = 3\n",
    "global_updates = 10\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'id006.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    avg_grad = np.mean(grad_list, axis=0)\n",
    "    return avg_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        else:\n",
    "            x, y = x3, y3\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(y, predictions)\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/id006.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with epochs and iterations \n",
    "\n",
    "Use of dataset 3C, considering it contains an equal partition of the data between the 3 nodes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #Epochs = 10, #Iterations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3C-Part3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "node_datasets = [training1, training2, training3]\n",
    "num_nodes = 3\n",
    "global_updates = 10\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'id010.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    avg_grad = np.mean(grad_list, axis=0)\n",
    "    return avg_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        else:\n",
    "            x, y = x3, y3\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(y, predictions)\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/id010.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #Epochs = 5, #Iterations = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3C-Part3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "node_datasets = [training1, training2, training3]\n",
    "num_nodes = 3\n",
    "global_updates = 5\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'id011.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    avg_grad = np.mean(grad_list, axis=0)\n",
    "    return avg_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        else:\n",
    "            x, y = x3, y3\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(y, predictions)\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/id011.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
