{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated Learning with one corrupted node: krum\n",
    "Using one balanced and one unbalanced dataset with one corrupted node (5%, 25% and 50% corrupted samples) to test different aggregation functions and determine the more robust one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Disable warns\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data): \n",
    "\n",
    "    # Select the 'proto' and 'state' values that I want\n",
    "    data = data.loc[(data['proto'] == 'tcp') | (data['proto'] =='udp') | (data['proto'] =='icmp') | (data['proto'] =='arp') | (data['proto'] =='ipv6-icmp') | (data['proto'] =='igmp') | (data['proto'] =='rarp'), :]\n",
    "    data = data.loc[(data['state'] == 'RST') | (data['state'] =='REQ') | (data['state'] =='INT') | (data['state'] =='FIN') | (data['state'] =='CON') | (data['state'] =='ECO') | (data['state'] =='ACC') | (data['state'] == 'PAR'), :]\n",
    "\n",
    "    # Extracting labels \n",
    "    data_labels = data[['label']]\n",
    "\n",
    "    # Drop the invalid features and select interested data features\n",
    "    data_features=data[['proto','srcip','sport','dstip','dsport','spkts','dpkts','sbytes','dbytes','state','stime','ltime','dur']]\n",
    "\n",
    "    \"\"\"PREPROCESSING\"\"\"\n",
    "\n",
    "\n",
    "    # Preprocess IP and ports features\n",
    "    # IP Source Address\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "\n",
    "    # IP Destination Address\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "    # Ports\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "\n",
    "    # Convert all ports with 0 decimal, and HEX to DEC\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    # Convert field to int format\n",
    "    data_features['srcip'] = data_features['srcip'].astype(int)\n",
    "    data_features['sport'] = data_features['sport'].astype(int)\n",
    "    data_features['dstip'] = data_features['dstip'].astype(int)\n",
    "    data_features['dsport'] = data_features['dsport'].astype(int)\n",
    "\n",
    "    # Convert some fields to logarithmic\n",
    "    log1p_col = ['dur', 'sbytes', 'dbytes', 'spkts']\n",
    "\n",
    "    for col in log1p_col:\n",
    "        data_features[col] = data_features[col].apply(np.log1p)\n",
    "\n",
    "    # Create a complementary field of attack & Transform to One hot encoding - LABELS\n",
    "    normal=data_labels['label']\n",
    "    normal=normal.replace(1,2)\n",
    "    normal=normal.replace(0,1)\n",
    "    normal=normal.replace(2,0)\n",
    "\n",
    "    # Insert the new column in data labels\n",
    "    data_labels.insert(1, 'normal', normal)\n",
    "    data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "    data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "    # Transform to One hot encoding - FEATURES\n",
    "    data_features=pd.get_dummies(data_features)\n",
    "\n",
    "    # Value given for the missing columns\n",
    "    auxCol=0\n",
    "\n",
    "    # As we are using different datasets that might not have all representations, we are going to detect and add the missing columns \n",
    "    # The columns that can have types are: proto and state: need to check if all representations are done \n",
    "    state_cols = [col for col in data_features if col.startswith('state_')]\n",
    "    proto_cols = [col for col in data_features if col.startswith('proto_')]\n",
    "    \n",
    "    # Check if all columns are present\n",
    "    if 'state_PAR' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_PAR', auxCol, True)\n",
    "    if 'state_ACC' not in state_cols: \n",
    "        data_features.insert(data_features.shape[1], 'state_ACC', auxCol, True)\n",
    "    if 'state_ECO' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_ECO', auxCol, True)\n",
    "    if 'state_CON' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_CON', auxCol, True)\n",
    "    if 'state_FIN' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_FIN', auxCol, True)\n",
    "    if 'state_INT' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_INT', auxCol, True)\n",
    "    if 'state_REQ' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_REQ', auxCol, True)\n",
    "    if 'state_RST' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_RST', auxCol, True)\n",
    "    if 'proto_igmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_igmp', auxCol, True)\n",
    "    if 'proto_arp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_arp', auxCol, True)\n",
    "    if 'proto_icmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_icmp', auxCol, True)\n",
    "    if 'proto_udp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_udp', auxCol, True)\n",
    "    if 'proto_tcp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_tcp', auxCol, True)\n",
    "\n",
    "    # Normalize all data features\n",
    "    data_features = StandardScaler().fit_transform(data_features)\n",
    "\n",
    "    #Add dimension to data features\n",
    "    data_features = np.expand_dims(data_features, axis=2)\n",
    "    data_features = np.expand_dims(data_features, axis=3)\n",
    "\n",
    "    x = data_features\n",
    "    y = data_labels.to_numpy()\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building and definition\n",
    "def build_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(filters=32,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(1, 1), padding='same'))\n",
    "    model.add(layers.Conv2D(filters=64,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(1, 1), padding='same'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(Dense(444, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns values of loss, accuracy, f1, precision and recall of model evaluating with test dataset \n",
    "def evaluation(model, x, y): \n",
    "    loss, accuracy = model.evaluate(x, y)\n",
    "    y_pred = model.predict(x)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y = np.argmax(y, axis=1)\n",
    "    report = classification_report(y, y_pred, target_names=['normal', 'attack'], output_dict=True)\n",
    "    # Obtain f1, precision and recall from the report\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    return loss, accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list, num_mal = 0):\n",
    "    \n",
    "    num_to_consider = num_nodes - num_mal - 2\n",
    "\n",
    "    # Flatten gradients to compute distances\n",
    "    flat_grads = [tf.concat([tf.reshape(g, [-1]) for g in grad], axis=0).numpy() for grad in grad_list]\n",
    "\n",
    "    # Compute pairwise squared Euclidean distances\n",
    "    distances = np.zeros((num_nodes, num_nodes))\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(i + 1, num_nodes):\n",
    "            dist = np.sum((flat_grads[i] - flat_grads[j]) ** 2)\n",
    "            distances[i, j] = dist\n",
    "            distances[j, i] = dist\n",
    "\n",
    "    # Find the Krum gradient\n",
    "    krum_scores = []\n",
    "    for i in range(num_nodes):\n",
    "        sorted_distances = np.sort(distances[i])\n",
    "        score = np.sum(sorted_distances[:num_to_consider])\n",
    "        krum_scores.append(score)\n",
    "    \n",
    "    krum_index = np.argmin(krum_scores)\n",
    "    selected_grad = grad_list[krum_index]\n",
    "\n",
    "    return selected_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_8464/3836997398.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n"
     ]
    }
   ],
   "source": [
    "test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n",
    "test_plus = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test+.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5A 5% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_8464/3687049449.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_8464/3687049449.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_8464/3687049449.py:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part4.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_8464/3687049449.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr55Akrum.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 9s 275ms/step - loss: 0.4649 - accuracy: 0.8491 - val_loss: 0.2441 - val_accuracy: 0.9182\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 0.1929 - accuracy: 0.9522 - val_loss: 0.1806 - val_accuracy: 0.9603\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 270ms/step - loss: 0.1678 - accuracy: 0.9647 - val_loss: 0.1640 - val_accuracy: 0.9631\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 277ms/step - loss: 0.1556 - accuracy: 0.9664 - val_loss: 0.1548 - val_accuracy: 0.9646\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 293ms/step - loss: 0.1478 - accuracy: 0.9674 - val_loss: 0.1493 - val_accuracy: 0.9657\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 384ms/step - loss: 0.0338 - accuracy: 0.9896 - val_loss: 0.4060 - val_accuracy: 0.7461\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 302ms/step - loss: 0.0236 - accuracy: 0.9906 - val_loss: 0.3226 - val_accuracy: 0.7786\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 367ms/step - loss: 0.0220 - accuracy: 0.9915 - val_loss: 0.3853 - val_accuracy: 0.6878\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 376ms/step - loss: 0.0209 - accuracy: 0.9926 - val_loss: 0.2734 - val_accuracy: 0.8169\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 337ms/step - loss: 0.0198 - accuracy: 0.9928 - val_loss: 0.2569 - val_accuracy: 0.8325\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 14s 436ms/step - loss: 0.0194 - accuracy: 0.9925 - val_loss: 0.3174 - val_accuracy: 0.7634\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 318ms/step - loss: 0.0181 - accuracy: 0.9932 - val_loss: 0.2775 - val_accuracy: 0.7969\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 362ms/step - loss: 0.0165 - accuracy: 0.9943 - val_loss: 0.3122 - val_accuracy: 0.7844\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 371ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 0.2734 - val_accuracy: 0.8227\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 326ms/step - loss: 0.0152 - accuracy: 0.9950 - val_loss: 0.4032 - val_accuracy: 0.7701\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 13s 419ms/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 0.2700 - val_accuracy: 0.8379\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 319ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.1827 - val_accuracy: 0.8991\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 316ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.4860 - val_accuracy: 0.7659\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 301ms/step - loss: 0.0146 - accuracy: 0.9955 - val_loss: 0.2630 - val_accuracy: 0.8509\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 245ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.4094 - val_accuracy: 0.8072\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 345ms/step - loss: 0.0162 - accuracy: 0.9954 - val_loss: 0.3020 - val_accuracy: 0.8371\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 311ms/step - loss: 0.0125 - accuracy: 0.9962 - val_loss: 0.3275 - val_accuracy: 0.8323\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 290ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.3038 - val_accuracy: 0.8433\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 307ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.4447 - val_accuracy: 0.7995\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 229ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.3062 - val_accuracy: 0.8448\n",
      "4279/4279 [==============================] - 52s 12ms/step - loss: 0.0402 - accuracy: 0.9809\n",
      "1721/1721 [==============================] - 15s 9ms/step - loss: 0.3410 - accuracy: 0.8243\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 341ms/step - loss: 0.2237 - accuracy: 0.9649 - val_loss: 0.1756 - val_accuracy: 0.9654\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 222ms/step - loss: 0.1530 - accuracy: 0.9677 - val_loss: 0.1528 - val_accuracy: 0.9657\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 319ms/step - loss: 0.1418 - accuracy: 0.9685 - val_loss: 0.1475 - val_accuracy: 0.9662\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 331ms/step - loss: 0.1393 - accuracy: 0.9687 - val_loss: 0.1448 - val_accuracy: 0.9662\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 317ms/step - loss: 0.1382 - accuracy: 0.9687 - val_loss: 0.1441 - val_accuracy: 0.9662\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 14s 457ms/step - loss: 0.0249 - accuracy: 0.9930 - val_loss: 0.3232 - val_accuracy: 0.7741\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 309ms/step - loss: 0.0164 - accuracy: 0.9951 - val_loss: 0.4477 - val_accuracy: 0.7240\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 13s 406ms/step - loss: 0.0157 - accuracy: 0.9952 - val_loss: 0.3123 - val_accuracy: 0.8121\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 402ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.4168 - val_accuracy: 0.7684\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 341ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.2890 - val_accuracy: 0.8393\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 14s 441ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.4869 - val_accuracy: 0.7723\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 302ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.3640 - val_accuracy: 0.8248\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 13s 418ms/step - loss: 0.0128 - accuracy: 0.9962 - val_loss: 0.4582 - val_accuracy: 0.7958\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 371ms/step - loss: 0.0128 - accuracy: 0.9962 - val_loss: 0.4121 - val_accuracy: 0.8167\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 352ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 0.4472 - val_accuracy: 0.8125\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 14s 454ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.3954 - val_accuracy: 0.8298\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 341ms/step - loss: 0.0133 - accuracy: 0.9962 - val_loss: 0.4245 - val_accuracy: 0.8246\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 367ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.2928 - val_accuracy: 0.8565\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 315ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.4665 - val_accuracy: 0.8191\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 263ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 0.4905 - val_accuracy: 0.8160\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 393ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.2990 - val_accuracy: 0.8587\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 344ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.4823 - val_accuracy: 0.8043\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 358ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.4027 - val_accuracy: 0.8328\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 321ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 0.4224 - val_accuracy: 0.8285\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 250ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.4041 - val_accuracy: 0.8354\n",
      "4279/4279 [==============================] - 48s 11ms/step - loss: 0.0592 - accuracy: 0.9722\n",
      "1721/1721 [==============================] - 16s 9ms/step - loss: 0.5945 - accuracy: 0.7246\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 246ms/step - loss: 0.2270 - accuracy: 0.9639 - val_loss: 0.1765 - val_accuracy: 0.9635\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 310ms/step - loss: 0.1505 - accuracy: 0.9677 - val_loss: 0.1529 - val_accuracy: 0.9657\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 316ms/step - loss: 0.1413 - accuracy: 0.9686 - val_loss: 0.1470 - val_accuracy: 0.9662\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 359ms/step - loss: 0.1390 - accuracy: 0.9687 - val_loss: 0.1449 - val_accuracy: 0.9663\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 338ms/step - loss: 0.1370 - accuracy: 0.9687 - val_loss: 0.1435 - val_accuracy: 0.9660\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 382ms/step - loss: 0.0196 - accuracy: 0.9945 - val_loss: 0.3064 - val_accuracy: 0.8240\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 353ms/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 0.3164 - val_accuracy: 0.8367\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 12s 387ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.4041 - val_accuracy: 0.8064\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 13s 428ms/step - loss: 0.0130 - accuracy: 0.9962 - val_loss: 0.4274 - val_accuracy: 0.8063\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 12s 394ms/step - loss: 0.0130 - accuracy: 0.9964 - val_loss: 0.3158 - val_accuracy: 0.8482\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 13s 431ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.3967 - val_accuracy: 0.8263\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 325ms/step - loss: 0.0118 - accuracy: 0.9967 - val_loss: 0.5358 - val_accuracy: 0.7850\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 12s 392ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.4934 - val_accuracy: 0.8096\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 13s 422ms/step - loss: 0.0109 - accuracy: 0.9967 - val_loss: 0.5663 - val_accuracy: 0.7898\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 12s 388ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.4364 - val_accuracy: 0.8334\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 15s 476ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.5077 - val_accuracy: 0.8151\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 348ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.2558 - val_accuracy: 0.8717\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 360ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.4351 - val_accuracy: 0.8383\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 354ms/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 0.5435 - val_accuracy: 0.8041\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 280ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.6220 - val_accuracy: 0.7879\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 357ms/step - loss: 0.0130 - accuracy: 0.9964 - val_loss: 0.3573 - val_accuracy: 0.8541\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 318ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.6998 - val_accuracy: 0.7592\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 327ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.3908 - val_accuracy: 0.8468\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 319ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.4330 - val_accuracy: 0.8351\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 249ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.4620 - val_accuracy: 0.8281\n",
      "4279/4279 [==============================] - 32s 7ms/step - loss: 0.0710 - accuracy: 0.9707\n",
      "1721/1721 [==============================] - 16s 9ms/step - loss: 0.5483 - accuracy: 0.7562\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr55Akrum.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.04024306684732437, 0.3410366177558899], [0.059216126799583435, 0.5945024490356445], [0.07099304348230362, 0.5482661724090576]]\n",
      "Accuracy for iterations:  [[0.9809007048606873, 0.8243115544319153], [0.9721946120262146, 0.7246057987213135], [0.9706535339355469, 0.7562486529350281]]\n",
      "F1 for iterations:  [[0.9808898894118244, 0.8155998058822741], [0.9721490752024962, 0.691143612706857], [0.9705968326335274, 0.7332728705765952]]\n",
      "Precision for iterations:  [[0.9810223768682153, 0.8577772105090989], [0.9729510504596791, 0.8047463105863021], [0.971636109762449, 0.8198943188648957]]\n",
      "Recall for iterations:  [[0.9809006982383359, 0.8243115599796556], [0.9721946302842619, 0.7246058272179031], [0.9706535393964183, 0.7562486376516748]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5B 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_8464/2463029928.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part1.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_8464/2463029928.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_8464/2463029928.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_8464/2463029928.py:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part4.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_8464/2463029928.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr105Akrum.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 258ms/step - loss: 0.4891 - accuracy: 0.8099 - val_loss: 0.3006 - val_accuracy: 0.8955\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 307ms/step - loss: 0.2618 - accuracy: 0.9315 - val_loss: 0.2424 - val_accuracy: 0.9406\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 322ms/step - loss: 0.2386 - accuracy: 0.9413 - val_loss: 0.2308 - val_accuracy: 0.9420\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 309ms/step - loss: 0.2296 - accuracy: 0.9425 - val_loss: 0.2259 - val_accuracy: 0.9427\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 329ms/step - loss: 0.2246 - accuracy: 0.9426 - val_loss: 0.2238 - val_accuracy: 0.9428\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 13s 413ms/step - loss: 0.0396 - accuracy: 0.9896 - val_loss: 0.6025 - val_accuracy: 0.6315\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 13s 414ms/step - loss: 0.0237 - accuracy: 0.9906 - val_loss: 0.2929 - val_accuracy: 0.8264\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 13s 424ms/step - loss: 0.0222 - accuracy: 0.9915 - val_loss: 0.3632 - val_accuracy: 0.6986\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 384ms/step - loss: 0.0210 - accuracy: 0.9922 - val_loss: 0.3215 - val_accuracy: 0.7447\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 314ms/step - loss: 0.0200 - accuracy: 0.9930 - val_loss: 0.3348 - val_accuracy: 0.7268\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 399ms/step - loss: 0.0208 - accuracy: 0.9921 - val_loss: 0.3909 - val_accuracy: 0.6955\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 13s 407ms/step - loss: 0.0177 - accuracy: 0.9937 - val_loss: 0.4075 - val_accuracy: 0.7140\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 14s 441ms/step - loss: 0.0169 - accuracy: 0.9942 - val_loss: 0.4657 - val_accuracy: 0.7145\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 369ms/step - loss: 0.0161 - accuracy: 0.9944 - val_loss: 0.3609 - val_accuracy: 0.7823\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 338ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.3296 - val_accuracy: 0.8085\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 392ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.3432 - val_accuracy: 0.8094\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 352ms/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 0.4702 - val_accuracy: 0.7689\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 350ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.4314 - val_accuracy: 0.7953\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 287ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 0.4120 - val_accuracy: 0.8112\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 230ms/step - loss: 0.0150 - accuracy: 0.9956 - val_loss: 0.3288 - val_accuracy: 0.8387\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 362ms/step - loss: 0.0174 - accuracy: 0.9954 - val_loss: 0.2836 - val_accuracy: 0.8434\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 333ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.3848 - val_accuracy: 0.8147\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 352ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.3769 - val_accuracy: 0.8230\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 259ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.4408 - val_accuracy: 0.8039\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 222ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.3689 - val_accuracy: 0.8304\n",
      "4279/4279 [==============================] - 49s 12ms/step - loss: 0.0472 - accuracy: 0.9742\n",
      "1721/1721 [==============================] - 16s 9ms/step - loss: 0.3651 - accuracy: 0.8103\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 9s 295ms/step - loss: 0.3439 - accuracy: 0.9365 - val_loss: 0.2482 - val_accuracy: 0.9426\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 312ms/step - loss: 0.2353 - accuracy: 0.9427 - val_loss: 0.2221 - val_accuracy: 0.9430\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 359ms/step - loss: 0.2225 - accuracy: 0.9428 - val_loss: 0.2173 - val_accuracy: 0.9435\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 331ms/step - loss: 0.2200 - accuracy: 0.9433 - val_loss: 0.2160 - val_accuracy: 0.9436\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 331ms/step - loss: 0.2183 - accuracy: 0.9434 - val_loss: 0.2154 - val_accuracy: 0.9435\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 401ms/step - loss: 0.0273 - accuracy: 0.9932 - val_loss: 0.2956 - val_accuracy: 0.8015\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 13s 414ms/step - loss: 0.0165 - accuracy: 0.9950 - val_loss: 0.4033 - val_accuracy: 0.7585\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 13s 412ms/step - loss: 0.0159 - accuracy: 0.9952 - val_loss: 0.4062 - val_accuracy: 0.7762\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 13s 408ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 0.3677 - val_accuracy: 0.8033\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 350ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.3235 - val_accuracy: 0.8330\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 392ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 0.4928 - val_accuracy: 0.7807\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 12s 390ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.5501 - val_accuracy: 0.7742\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 14s 442ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 0.4230 - val_accuracy: 0.8194\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 13s 406ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.6478 - val_accuracy: 0.7554\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 349ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.4869 - val_accuracy: 0.8060\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 389ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.5377 - val_accuracy: 0.7871\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 354ms/step - loss: 0.0137 - accuracy: 0.9962 - val_loss: 0.3528 - val_accuracy: 0.8413\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 356ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.5069 - val_accuracy: 0.7947\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 317ms/step - loss: 0.0131 - accuracy: 0.9964 - val_loss: 0.3626 - val_accuracy: 0.8422\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 247ms/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 0.4810 - val_accuracy: 0.8064\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 354ms/step - loss: 0.0136 - accuracy: 0.9963 - val_loss: 0.4252 - val_accuracy: 0.8198\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 348ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 0.4465 - val_accuracy: 0.8163\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 361ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.3860 - val_accuracy: 0.8340\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 321ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.3928 - val_accuracy: 0.8323\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 235ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.5893 - val_accuracy: 0.7738\n",
      "4279/4279 [==============================] - 50s 12ms/step - loss: 0.0888 - accuracy: 0.9645\n",
      "1721/1721 [==============================] - 16s 10ms/step - loss: 0.5638 - accuracy: 0.7493\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 238ms/step - loss: 0.3574 - accuracy: 0.9330 - val_loss: 0.2502 - val_accuracy: 0.9373\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 315ms/step - loss: 0.2328 - accuracy: 0.9415 - val_loss: 0.2217 - val_accuracy: 0.9430\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 333ms/step - loss: 0.2212 - accuracy: 0.9429 - val_loss: 0.2168 - val_accuracy: 0.9435\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 352ms/step - loss: 0.2182 - accuracy: 0.9432 - val_loss: 0.2155 - val_accuracy: 0.9435\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 342ms/step - loss: 0.2169 - accuracy: 0.9434 - val_loss: 0.2148 - val_accuracy: 0.9435\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 15s 476ms/step - loss: 0.0198 - accuracy: 0.9946 - val_loss: 0.3223 - val_accuracy: 0.8204\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 13s 429ms/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.3495 - val_accuracy: 0.8314\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 14s 464ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 0.3935 - val_accuracy: 0.8267\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 13s 434ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.4257 - val_accuracy: 0.8205\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 12s 374ms/step - loss: 0.0131 - accuracy: 0.9965 - val_loss: 0.3936 - val_accuracy: 0.8387\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 375ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 0.4160 - val_accuracy: 0.8221\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 14s 436ms/step - loss: 0.0119 - accuracy: 0.9966 - val_loss: 0.4064 - val_accuracy: 0.8277\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 14s 453ms/step - loss: 0.0116 - accuracy: 0.9967 - val_loss: 0.5423 - val_accuracy: 0.7918\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 13s 408ms/step - loss: 0.0119 - accuracy: 0.9965 - val_loss: 0.5649 - val_accuracy: 0.7869\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 367ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.5139 - val_accuracy: 0.8045\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 13s 404ms/step - loss: 0.0121 - accuracy: 0.9967 - val_loss: 0.3904 - val_accuracy: 0.8393\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 365ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.3548 - val_accuracy: 0.8484\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 367ms/step - loss: 0.0119 - accuracy: 0.9966 - val_loss: 0.4971 - val_accuracy: 0.8131\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 365ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 0.3991 - val_accuracy: 0.8409\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 313ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.3642 - val_accuracy: 0.8502\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 388ms/step - loss: 0.0135 - accuracy: 0.9965 - val_loss: 0.4041 - val_accuracy: 0.8526\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 345ms/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.4688 - val_accuracy: 0.8279\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 343ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.4896 - val_accuracy: 0.8203\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 342ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.4373 - val_accuracy: 0.8323\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 280ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.4388 - val_accuracy: 0.8308\n",
      "4279/4279 [==============================] - 38s 9ms/step - loss: 0.0691 - accuracy: 0.9715\n",
      "1721/1721 [==============================] - 13s 8ms/step - loss: 0.3613 - accuracy: 0.8018\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr105Akrum.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.04719569534063339, 0.3650592863559723], [0.0888303890824318, 0.5638192296028137], [0.06911387294530869, 0.3612609803676605]]\n",
      "Accuracy for iterations:  [[0.9742177724838257, 0.8103247880935669], [0.9644672870635986, 0.7493097186088562], [0.9715153574943542, 0.8018419146537781]]\n",
      "F1 for iterations:  [[0.9741852704659083, 0.7994188036670806], [0.9643681437205753, 0.7241521488267526], [0.9714632203775988, 0.7895104623190683]]\n",
      "Precision for iterations:  [[0.9747099407064148, 0.8494828961826225], [0.9661703450371655, 0.817042393301229], [0.9724199668271004, 0.8441920596159352]]\n",
      "Recall for iterations:  [[0.9742177685588244, 0.8103247838407324], [0.9644672646001928, 0.749309743515222], [0.9715153816938853, 0.8018418949356971]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5B 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_8464/3855986297.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_8464/3855986297.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_8464/3855986297.py:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part4.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_8464/3855986297.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr255Akrum.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 10s 314ms/step - loss: 0.4356 - accuracy: 0.8797 - val_loss: 0.1905 - val_accuracy: 0.9499\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 306ms/step - loss: 0.1486 - accuracy: 0.9646 - val_loss: 0.1265 - val_accuracy: 0.9752\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 299ms/step - loss: 0.1202 - accuracy: 0.9766 - val_loss: 0.1114 - val_accuracy: 0.9774\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 296ms/step - loss: 0.1058 - accuracy: 0.9788 - val_loss: 0.1034 - val_accuracy: 0.9788\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 298ms/step - loss: 0.0993 - accuracy: 0.9798 - val_loss: 0.0990 - val_accuracy: 0.9790\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 14s 466ms/step - loss: 0.0341 - accuracy: 0.9895 - val_loss: 0.3658 - val_accuracy: 0.7673\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 13s 415ms/step - loss: 0.0230 - accuracy: 0.9910 - val_loss: 0.4397 - val_accuracy: 0.6656\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 13s 431ms/step - loss: 0.0217 - accuracy: 0.9920 - val_loss: 0.3035 - val_accuracy: 0.7813\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 403ms/step - loss: 0.0208 - accuracy: 0.9925 - val_loss: 0.2481 - val_accuracy: 0.8585\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 332ms/step - loss: 0.0197 - accuracy: 0.9930 - val_loss: 0.2898 - val_accuracy: 0.7918\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 15s 480ms/step - loss: 0.0193 - accuracy: 0.9929 - val_loss: 0.2781 - val_accuracy: 0.8214\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 14s 451ms/step - loss: 0.0179 - accuracy: 0.9936 - val_loss: 0.1658 - val_accuracy: 0.9382\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 14s 438ms/step - loss: 0.0167 - accuracy: 0.9943 - val_loss: 0.3277 - val_accuracy: 0.7894\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 387ms/step - loss: 0.0158 - accuracy: 0.9946 - val_loss: 0.3575 - val_accuracy: 0.7872\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 318ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.3998 - val_accuracy: 0.7860\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 379ms/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 0.2921 - val_accuracy: 0.8339\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 353ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.3192 - val_accuracy: 0.8292\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 323ms/step - loss: 0.0147 - accuracy: 0.9955 - val_loss: 0.5788 - val_accuracy: 0.7498\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 242ms/step - loss: 0.0144 - accuracy: 0.9956 - val_loss: 0.4400 - val_accuracy: 0.8037\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 267ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.3060 - val_accuracy: 0.8471\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 376ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.3303 - val_accuracy: 0.8314\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 331ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.3486 - val_accuracy: 0.8314\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 295ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.3024 - val_accuracy: 0.8486\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 227ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.4356 - val_accuracy: 0.8134\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 12s 387ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.4380 - val_accuracy: 0.8148\n",
      "4279/4279 [==============================] - 43s 10ms/step - loss: 0.0589 - accuracy: 0.9716\n",
      "1721/1721 [==============================] - 10s 6ms/step - loss: 0.4205 - accuracy: 0.7891\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 362ms/step - loss: 0.1307 - accuracy: 0.9792 - val_loss: 0.1051 - val_accuracy: 0.9792\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 337ms/step - loss: 0.0988 - accuracy: 0.9804 - val_loss: 0.0971 - val_accuracy: 0.9798\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 336ms/step - loss: 0.0923 - accuracy: 0.9806 - val_loss: 0.0950 - val_accuracy: 0.9798\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 255ms/step - loss: 0.0911 - accuracy: 0.9806 - val_loss: 0.0943 - val_accuracy: 0.9798\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 329ms/step - loss: 0.0902 - accuracy: 0.9806 - val_loss: 0.0927 - val_accuracy: 0.9797\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 15s 491ms/step - loss: 0.0213 - accuracy: 0.9938 - val_loss: 0.2938 - val_accuracy: 0.8162\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 13s 427ms/step - loss: 0.0155 - accuracy: 0.9957 - val_loss: 0.3398 - val_accuracy: 0.8087\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 12s 377ms/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 0.3492 - val_accuracy: 0.8168\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 254ms/step - loss: 0.0142 - accuracy: 0.9960 - val_loss: 0.3464 - val_accuracy: 0.8258\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 340ms/step - loss: 0.0139 - accuracy: 0.9960 - val_loss: 0.4506 - val_accuracy: 0.7977\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 19s 605ms/step - loss: 0.0139 - accuracy: 0.9959 - val_loss: 0.5376 - val_accuracy: 0.7779\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 13s 407ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.6197 - val_accuracy: 0.7581\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 275ms/step - loss: 0.0125 - accuracy: 0.9964 - val_loss: 0.4555 - val_accuracy: 0.8202\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 326ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.4181 - val_accuracy: 0.8332\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 361ms/step - loss: 0.0119 - accuracy: 0.9967 - val_loss: 0.4862 - val_accuracy: 0.8194\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 346ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.4338 - val_accuracy: 0.8339\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 244ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.4088 - val_accuracy: 0.8410\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 219ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.3972 - val_accuracy: 0.8426\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 317ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 0.3415 - val_accuracy: 0.8595\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 317ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 0.5262 - val_accuracy: 0.8184\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 366ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.4779 - val_accuracy: 0.8279\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 270ms/step - loss: 0.0100 - accuracy: 0.9971 - val_loss: 0.4098 - val_accuracy: 0.8422\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 329ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.4786 - val_accuracy: 0.8287\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 389ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.4695 - val_accuracy: 0.8332\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 14s 446ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.3963 - val_accuracy: 0.8455\n",
      "4279/4279 [==============================] - 43s 10ms/step - loss: 0.0604 - accuracy: 0.9724\n",
      "1721/1721 [==============================] - 17s 10ms/step - loss: 0.3623 - accuracy: 0.8107\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 10s 321ms/step - loss: 0.1267 - accuracy: 0.9793 - val_loss: 0.1002 - val_accuracy: 0.9787\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 281ms/step - loss: 0.0935 - accuracy: 0.9802 - val_loss: 0.0941 - val_accuracy: 0.9798\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 13s 405ms/step - loss: 0.0909 - accuracy: 0.9805 - val_loss: 0.0935 - val_accuracy: 0.9798\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 13s 412ms/step - loss: 0.0895 - accuracy: 0.9806 - val_loss: 0.0922 - val_accuracy: 0.9798\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 13s 429ms/step - loss: 0.0884 - accuracy: 0.9806 - val_loss: 0.0916 - val_accuracy: 0.9796\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 13s 432ms/step - loss: 0.0166 - accuracy: 0.9952 - val_loss: 0.2998 - val_accuracy: 0.8398\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 327ms/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 0.4197 - val_accuracy: 0.8176\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 12s 376ms/step - loss: 0.0130 - accuracy: 0.9962 - val_loss: 0.2833 - val_accuracy: 0.8612\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 378ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.4129 - val_accuracy: 0.8357\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 13s 414ms/step - loss: 0.0119 - accuracy: 0.9966 - val_loss: 0.4210 - val_accuracy: 0.8371\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 364ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.4050 - val_accuracy: 0.8438\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 257ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.4644 - val_accuracy: 0.8308\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 266ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.4788 - val_accuracy: 0.8339\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 308ms/step - loss: 0.0101 - accuracy: 0.9971 - val_loss: 0.5813 - val_accuracy: 0.8137\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 320ms/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.5103 - val_accuracy: 0.8320\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 10s 331ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.5766 - val_accuracy: 0.8211\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 230ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.4410 - val_accuracy: 0.8446\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 291ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.5331 - val_accuracy: 0.8278\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 289ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 0.5294 - val_accuracy: 0.8343\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 318ms/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 0.5197 - val_accuracy: 0.8343\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 9s 282ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.5897 - val_accuracy: 0.8266\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 228ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.3985 - val_accuracy: 0.8565\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 221ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.6263 - val_accuracy: 0.8139\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 261ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.5945 - val_accuracy: 0.8184\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 278ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 0.4929 - val_accuracy: 0.8399\n",
      "4279/4279 [==============================] - 22s 5ms/step - loss: 0.0734 - accuracy: 0.9727\n",
      "1721/1721 [==============================] - 6s 4ms/step - loss: 0.3103 - accuracy: 0.8455\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr255Akrum.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.058896299451589584, 0.4204658567905426], [0.060395222157239914, 0.3623192608356476], [0.07335920631885529, 0.31031617522239685]]\n",
      "Accuracy for iterations:  [[0.9715518951416016, 0.7891448140144348], [0.972355306148529, 0.8107243776321411], [0.9727277755737305, 0.8455097079277039]]\n",
      "F1 for iterations:  [[0.9715039140687096, 0.7742793456575021], [0.9723113870920939, 0.7997299547989344], [0.9726827033508688, 0.8393311537717432]]\n",
      "Precision for iterations:  [[0.9723428089355969, 0.8372615773079198], [0.9730749416431967, 0.850605211982617], [0.973498221066896, 0.8722525917485232]]\n",
      "Recall for iterations:  [[0.9715519004353034, 0.7891448085446487], [0.9723553127465016, 0.8107244060161302], [0.9727278039089661, 0.8455096999200755]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5B 5% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_14132/3503541895.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_14132/3503541895.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_14132/3503541895.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr55Bkrum.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 184ms/step - loss: 0.4548 - accuracy: 0.8325 - val_loss: 0.2270 - val_accuracy: 0.9457\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.1945 - accuracy: 0.9523 - val_loss: 0.1711 - val_accuracy: 0.9627\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 0.1662 - accuracy: 0.9647 - val_loss: 0.1590 - val_accuracy: 0.9649\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.1537 - accuracy: 0.9666 - val_loss: 0.1504 - val_accuracy: 0.9658\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.1462 - accuracy: 0.9675 - val_loss: 0.1460 - val_accuracy: 0.9660\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 169ms/step - loss: 0.0337 - accuracy: 0.9902 - val_loss: 0.4542 - val_accuracy: 0.7043\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0231 - accuracy: 0.9914 - val_loss: 0.3972 - val_accuracy: 0.6865\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 169ms/step - loss: 0.0214 - accuracy: 0.9921 - val_loss: 0.3965 - val_accuracy: 0.6828\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 177ms/step - loss: 0.0204 - accuracy: 0.9928 - val_loss: 0.3937 - val_accuracy: 0.6975\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 180ms/step - loss: 0.0193 - accuracy: 0.9934 - val_loss: 0.3861 - val_accuracy: 0.7184\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 4.6649 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 172ms/step - loss: 4.6670e-07 - accuracy: 1.0000 - val_loss: 4.9911 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 194ms/step - loss: 3.7653e-07 - accuracy: 1.0000 - val_loss: 5.0094 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 271ms/step - loss: 3.7077e-07 - accuracy: 1.0000 - val_loss: 5.0124 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 336ms/step - loss: 3.6829e-07 - accuracy: 1.0000 - val_loss: 5.0149 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 10s 324ms/step - loss: 4.2005 - accuracy: 0.4947 - val_loss: 0.0268 - val_accuracy: 0.9928\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 306ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 271ms/step - loss: 6.3594e-04 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 261ms/step - loss: 5.3284e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 255ms/step - loss: 4.6218e-04 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 251ms/step - loss: 1.4723 - accuracy: 0.7121 - val_loss: 0.7359 - val_accuracy: 0.6326\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 257ms/step - loss: 0.0387 - accuracy: 0.9943 - val_loss: 0.6017 - val_accuracy: 0.6383\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 258ms/step - loss: 0.0221 - accuracy: 0.9942 - val_loss: 0.5845 - val_accuracy: 0.6385\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 255ms/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 0.5885 - val_accuracy: 0.6381\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 247ms/step - loss: 0.0192 - accuracy: 0.9942 - val_loss: 0.5814 - val_accuracy: 0.6379\n",
      "4279/4279 [==============================] - 20s 5ms/step - loss: 0.1684 - accuracy: 0.9238\n",
      "1721/1721 [==============================] - 6s 4ms/step - loss: 0.4095 - accuracy: 0.7483\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 177ms/step - loss: 0.1605 - accuracy: 0.9630 - val_loss: 0.1443 - val_accuracy: 0.9657\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 281ms/step - loss: 0.1417 - accuracy: 0.9676 - val_loss: 0.1434 - val_accuracy: 0.9660\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 251ms/step - loss: 0.1397 - accuracy: 0.9675 - val_loss: 0.1420 - val_accuracy: 0.9660\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 245ms/step - loss: 0.1386 - accuracy: 0.9676 - val_loss: 0.1419 - val_accuracy: 0.9658\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 255ms/step - loss: 0.1376 - accuracy: 0.9676 - val_loss: 0.1418 - val_accuracy: 0.9660\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 241ms/step - loss: 0.0234 - accuracy: 0.9932 - val_loss: 0.3060 - val_accuracy: 0.7723\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 239ms/step - loss: 0.0191 - accuracy: 0.9939 - val_loss: 0.3408 - val_accuracy: 0.7655\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 238ms/step - loss: 0.0183 - accuracy: 0.9937 - val_loss: 0.3550 - val_accuracy: 0.7757\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 236ms/step - loss: 0.0169 - accuracy: 0.9943 - val_loss: 0.3390 - val_accuracy: 0.7947\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 231ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.4913 - val_accuracy: 0.7559\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 233ms/step - loss: 0.0117 - accuracy: 0.9957 - val_loss: 4.7101 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 239ms/step - loss: 3.6893e-07 - accuracy: 1.0000 - val_loss: 5.0473 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 234ms/step - loss: 2.7583e-07 - accuracy: 1.0000 - val_loss: 5.0657 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 236ms/step - loss: 2.7106e-07 - accuracy: 1.0000 - val_loss: 5.0679 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 2.6991e-07 - accuracy: 1.0000 - val_loss: 5.0696 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 242ms/step - loss: 4.5762 - accuracy: 0.4650 - val_loss: 0.1264 - val_accuracy: 0.9369\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 243ms/step - loss: 0.0146 - accuracy: 0.9978 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 240ms/step - loss: 6.7493e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 241ms/step - loss: 4.2538e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 240ms/step - loss: 3.0576e-04 - accuracy: 1.0000 - val_loss: 7.2972e-04 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 240ms/step - loss: 1.2839 - accuracy: 0.7536 - val_loss: 0.7532 - val_accuracy: 0.6751\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 238ms/step - loss: 0.0216 - accuracy: 0.9945 - val_loss: 0.3958 - val_accuracy: 0.7324\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 239ms/step - loss: 0.0166 - accuracy: 0.9943 - val_loss: 0.5093 - val_accuracy: 0.7008\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 238ms/step - loss: 0.0161 - accuracy: 0.9943 - val_loss: 0.5188 - val_accuracy: 0.6993\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 235ms/step - loss: 0.0160 - accuracy: 0.9943 - val_loss: 0.5256 - val_accuracy: 0.6991\n",
      "4279/4279 [==============================] - 19s 5ms/step - loss: 0.1414 - accuracy: 0.9339\n",
      "1721/1721 [==============================] - 9s 5ms/step - loss: 0.3791 - accuracy: 0.8059\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 247ms/step - loss: 0.1455 - accuracy: 0.9673 - val_loss: 0.1424 - val_accuracy: 0.9660\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 251ms/step - loss: 0.1372 - accuracy: 0.9676 - val_loss: 0.1409 - val_accuracy: 0.9662\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 284ms/step - loss: 0.1363 - accuracy: 0.9678 - val_loss: 0.1412 - val_accuracy: 0.9664\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 251ms/step - loss: 0.1358 - accuracy: 0.9680 - val_loss: 0.1401 - val_accuracy: 0.9666\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 252ms/step - loss: 0.1356 - accuracy: 0.9684 - val_loss: 0.1400 - val_accuracy: 0.9667\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 248ms/step - loss: 0.0234 - accuracy: 0.9937 - val_loss: 0.2276 - val_accuracy: 0.8482\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 249ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.2893 - val_accuracy: 0.8088\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 242ms/step - loss: 0.0170 - accuracy: 0.9946 - val_loss: 0.2900 - val_accuracy: 0.8128\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 289ms/step - loss: 0.0159 - accuracy: 0.9948 - val_loss: 0.2953 - val_accuracy: 0.8167\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 250ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.3537 - val_accuracy: 0.8082\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 250ms/step - loss: 0.0619 - accuracy: 0.9733 - val_loss: 3.7406 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 246ms/step - loss: 3.7405e-06 - accuracy: 1.0000 - val_loss: 4.1152 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 239ms/step - loss: 2.6389e-06 - accuracy: 1.0000 - val_loss: 4.1382 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 243ms/step - loss: 2.5739e-06 - accuracy: 1.0000 - val_loss: 4.1438 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 242ms/step - loss: 2.5428e-06 - accuracy: 1.0000 - val_loss: 4.1491 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 247ms/step - loss: 3.2886 - accuracy: 0.5698 - val_loss: 0.0535 - val_accuracy: 0.9824\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 253ms/step - loss: 0.0034 - accuracy: 0.9999 - val_loss: 0.0062 - val_accuracy: 0.9994\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 253ms/step - loss: 8.5881e-04 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9997\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 251ms/step - loss: 6.5438e-04 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9998\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 250ms/step - loss: 5.0808e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9998\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 254ms/step - loss: 0.4377 - accuracy: 0.8774 - val_loss: 1.0027 - val_accuracy: 0.6707\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 266ms/step - loss: 0.0167 - accuracy: 0.9951 - val_loss: 0.6036 - val_accuracy: 0.7181\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 283ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 0.5684 - val_accuracy: 0.7267\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 277ms/step - loss: 0.0140 - accuracy: 0.9952 - val_loss: 0.5524 - val_accuracy: 0.7315\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 272ms/step - loss: 0.0138 - accuracy: 0.9955 - val_loss: 0.4822 - val_accuracy: 0.7517\n",
      "4279/4279 [==============================] - 21s 5ms/step - loss: 0.1160 - accuracy: 0.9453\n",
      "1721/1721 [==============================] - 8s 4ms/step - loss: 0.3906 - accuracy: 0.7962\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list, 1)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr55Bkrum.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.1684008687734604, 0.40952253341674805], [0.1413555145263672, 0.3790534436702728], [0.1160159781575203, 0.39062780141830444]]\n",
      "Accuracy for iterations:  [[0.9237927198410034, 0.7483288645744324], [0.933871865272522, 0.8059471249580383], [0.945258378982544, 0.7962108254432678]]\n",
      "F1 for iterations:  [[0.9230588667745264, 0.7225935812034462], [0.9333646098000338, 0.794245833679687], [0.9449435130368761, 0.7826309359104554]]\n",
      "Precision for iterations:  [[0.9324646335626502, 0.8178620846368236], [0.9404585965960172, 0.847160974044791], [0.9498496010451459, 0.8419750922243834]]\n",
      "Recall for iterations:  [[0.9237926904087178, 0.7483288527210638], [0.9338718630401122, 0.8059471045556929], [0.9452584066142744, 0.7962108551914554]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5B 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_14132/2097221778.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part1.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_14132/2097221778.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_14132/2097221778.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_14132/2097221778.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr105Bkrum.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 180ms/step - loss: 0.5200 - accuracy: 0.7977 - val_loss: 0.3249 - val_accuracy: 0.8611\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 178ms/step - loss: 0.2770 - accuracy: 0.9201 - val_loss: 0.2488 - val_accuracy: 0.9387\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 172ms/step - loss: 0.2454 - accuracy: 0.9391 - val_loss: 0.2326 - val_accuracy: 0.9418\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 176ms/step - loss: 0.2334 - accuracy: 0.9413 - val_loss: 0.2253 - val_accuracy: 0.9431\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 176ms/step - loss: 0.2260 - accuracy: 0.9424 - val_loss: 0.2205 - val_accuracy: 0.9433\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 0.0399 - accuracy: 0.9892 - val_loss: 0.3696 - val_accuracy: 0.7791\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 171ms/step - loss: 0.0238 - accuracy: 0.9911 - val_loss: 0.3963 - val_accuracy: 0.7012\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 175ms/step - loss: 0.0221 - accuracy: 0.9919 - val_loss: 0.3526 - val_accuracy: 0.7160\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0211 - accuracy: 0.9925 - val_loss: 0.3794 - val_accuracy: 0.6918\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 164ms/step - loss: 0.0204 - accuracy: 0.9925 - val_loss: 0.4914 - val_accuracy: 0.6683\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 4.4235 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 169ms/step - loss: 5.5257e-07 - accuracy: 1.0000 - val_loss: 4.7307 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 4.2279e-07 - accuracy: 1.0000 - val_loss: 4.7490 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 170ms/step - loss: 4.1456e-07 - accuracy: 1.0000 - val_loss: 4.7530 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 4.1083e-07 - accuracy: 1.0000 - val_loss: 4.7567 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 170ms/step - loss: 4.0896 - accuracy: 0.4543 - val_loss: 0.0308 - val_accuracy: 0.9931\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 175ms/step - loss: 7.2580e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 173ms/step - loss: 4.3714e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 176ms/step - loss: 2.7019e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 1.6098 - accuracy: 0.6864 - val_loss: 0.6209 - val_accuracy: 0.6356\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 183ms/step - loss: 0.0417 - accuracy: 0.9943 - val_loss: 0.5914 - val_accuracy: 0.6376\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 183ms/step - loss: 0.0240 - accuracy: 0.9942 - val_loss: 0.5868 - val_accuracy: 0.6381\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 176ms/step - loss: 0.0217 - accuracy: 0.9942 - val_loss: 0.6300 - val_accuracy: 0.6376\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 179ms/step - loss: 0.0206 - accuracy: 0.9942 - val_loss: 0.6359 - val_accuracy: 0.6370\n",
      "4279/4279 [==============================] - 13s 3ms/step - loss: 0.1319 - accuracy: 0.9240\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.2826 - accuracy: 0.8087\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 179ms/step - loss: 0.2379 - accuracy: 0.9407 - val_loss: 0.2200 - val_accuracy: 0.9431\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 176ms/step - loss: 0.2211 - accuracy: 0.9425 - val_loss: 0.2158 - val_accuracy: 0.9433\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 181ms/step - loss: 0.2187 - accuracy: 0.9425 - val_loss: 0.2152 - val_accuracy: 0.9431\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 0.2179 - accuracy: 0.9425 - val_loss: 0.2142 - val_accuracy: 0.9431\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 179ms/step - loss: 0.2173 - accuracy: 0.9426 - val_loss: 0.2141 - val_accuracy: 0.9433\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 187ms/step - loss: 0.0257 - accuracy: 0.9925 - val_loss: 0.3080 - val_accuracy: 0.7673\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 190ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.2670 - val_accuracy: 0.8092\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 177ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.3752 - val_accuracy: 0.7455\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 175ms/step - loss: 0.0181 - accuracy: 0.9940 - val_loss: 0.3460 - val_accuracy: 0.7756\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.4118 - val_accuracy: 0.7635\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 177ms/step - loss: 0.0104 - accuracy: 0.9962 - val_loss: 4.1320 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 173ms/step - loss: 1.1432e-06 - accuracy: 1.0000 - val_loss: 4.4285 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 179ms/step - loss: 8.8072e-07 - accuracy: 1.0000 - val_loss: 4.4464 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 175ms/step - loss: 8.6298e-07 - accuracy: 1.0000 - val_loss: 4.4505 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 178ms/step - loss: 8.5500e-07 - accuracy: 1.0000 - val_loss: 4.4545 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 176ms/step - loss: 4.1159 - accuracy: 0.4494 - val_loss: 0.1293 - val_accuracy: 0.9395\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 175ms/step - loss: 0.0188 - accuracy: 0.9982 - val_loss: 0.0042 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 177ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 177ms/step - loss: 6.7248e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 181ms/step - loss: 4.4682e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 1.3518 - accuracy: 0.7268 - val_loss: 0.5924 - val_accuracy: 0.6889\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 0.0246 - accuracy: 0.9946 - val_loss: 0.4100 - val_accuracy: 0.7136\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 180ms/step - loss: 0.0174 - accuracy: 0.9941 - val_loss: 0.4653 - val_accuracy: 0.6990\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 179ms/step - loss: 0.0169 - accuracy: 0.9942 - val_loss: 0.5114 - val_accuracy: 0.6923\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 0.0167 - accuracy: 0.9942 - val_loss: 0.5235 - val_accuracy: 0.6908\n",
      "4279/4279 [==============================] - 13s 3ms/step - loss: 0.1180 - accuracy: 0.9356\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.3055 - accuracy: 0.8283\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 176ms/step - loss: 0.2342 - accuracy: 0.9421 - val_loss: 0.2158 - val_accuracy: 0.9433\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 180ms/step - loss: 0.2180 - accuracy: 0.9425 - val_loss: 0.2137 - val_accuracy: 0.9433\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 179ms/step - loss: 0.2162 - accuracy: 0.9425 - val_loss: 0.2129 - val_accuracy: 0.9433\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 181ms/step - loss: 0.2158 - accuracy: 0.9426 - val_loss: 0.2131 - val_accuracy: 0.9432\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 175ms/step - loss: 0.2158 - accuracy: 0.9428 - val_loss: 0.2121 - val_accuracy: 0.9435\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 182ms/step - loss: 0.0229 - accuracy: 0.9937 - val_loss: 0.3061 - val_accuracy: 0.7909\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 175ms/step - loss: 0.0184 - accuracy: 0.9944 - val_loss: 0.4134 - val_accuracy: 0.7542\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 178ms/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.3149 - val_accuracy: 0.8040\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 177ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.2949 - val_accuracy: 0.8196\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 178ms/step - loss: 0.0161 - accuracy: 0.9948 - val_loss: 0.2953 - val_accuracy: 0.8260\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 180ms/step - loss: 0.0320 - accuracy: 0.9859 - val_loss: 3.6731 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 179ms/step - loss: 4.5717e-06 - accuracy: 1.0000 - val_loss: 4.0223 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 179ms/step - loss: 3.2722e-06 - accuracy: 1.0000 - val_loss: 4.0461 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 178ms/step - loss: 3.1741e-06 - accuracy: 1.0000 - val_loss: 4.0539 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 179ms/step - loss: 3.1151e-06 - accuracy: 1.0000 - val_loss: 4.0616 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 177ms/step - loss: 3.7958 - accuracy: 0.4447 - val_loss: 0.1948 - val_accuracy: 0.9289\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 180ms/step - loss: 0.0247 - accuracy: 0.9978 - val_loss: 0.0108 - val_accuracy: 0.9963\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 180ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 187ms/step - loss: 8.5023e-04 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 181ms/step - loss: 5.6675e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 180ms/step - loss: 0.5866 - accuracy: 0.8391 - val_loss: 0.6012 - val_accuracy: 0.7048\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 181ms/step - loss: 0.0188 - accuracy: 0.9945 - val_loss: 0.4411 - val_accuracy: 0.7314\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 177ms/step - loss: 0.0165 - accuracy: 0.9943 - val_loss: 0.5318 - val_accuracy: 0.7120\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 178ms/step - loss: 0.0160 - accuracy: 0.9944 - val_loss: 0.5189 - val_accuracy: 0.7152\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 178ms/step - loss: 0.0157 - accuracy: 0.9944 - val_loss: 0.5121 - val_accuracy: 0.7182\n",
      "4279/4279 [==============================] - 14s 3ms/step - loss: 0.0973 - accuracy: 0.9468\n",
      "1721/1721 [==============================] - 6s 3ms/step - loss: 0.2742 - accuracy: 0.8519: 0s - loss: 0.2844 - accu\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list,1)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr105Bkrum.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.13186179101467133, 0.28262853622436523], [0.11804281920194626, 0.30547288060188293], [0.09732036292552948, 0.274226576089859]]\n",
      "Accuracy for iterations:  [[0.9240337014198303, 0.808708131313324], [0.9356174468994141, 0.8282532691955566], [0.9467775821685791, 0.8518854975700378]]\n",
      "F1 for iterations:  [[0.9233071891439947, 0.7974891501913676], [0.9351506975574713, 0.8200429427291401], [0.946498396984034, 0.8464938030895175]]\n",
      "Precision for iterations:  [[0.9326330798875049, 0.8487547487978524], [0.9417476897623043, 0.8605265809104845], [0.9508262541299596, 0.8757591249282343]]\n",
      "Recall for iterations:  [[0.9240337141020771, 0.8087081304948049], [0.9356174588798971, 0.8282532878006249], [0.9467775862572673, 0.8518854900821042]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5B 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_14132/3291834707.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part1.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_14132/3291834707.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_14132/3291834707.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_14132/3291834707.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr255Bkrum.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 0.5465 - accuracy: 0.7763 - val_loss: 0.4250 - val_accuracy: 0.8530\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 171ms/step - loss: 0.4218 - accuracy: 0.8582 - val_loss: 0.4041 - val_accuracy: 0.8687\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.4073 - accuracy: 0.8661 - val_loss: 0.3949 - val_accuracy: 0.8695\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 164ms/step - loss: 0.3992 - accuracy: 0.8679 - val_loss: 0.3901 - val_accuracy: 0.8705\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 171ms/step - loss: 0.3948 - accuracy: 0.8683 - val_loss: 0.3885 - val_accuracy: 0.8705\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0557 - accuracy: 0.9899 - val_loss: 0.5896 - val_accuracy: 0.6540\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 171ms/step - loss: 0.0248 - accuracy: 0.9908 - val_loss: 0.3272 - val_accuracy: 0.7973\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 0.0228 - accuracy: 0.9912 - val_loss: 0.3987 - val_accuracy: 0.6839\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 166ms/step - loss: 0.0223 - accuracy: 0.9923 - val_loss: 0.2886 - val_accuracy: 0.7943\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 0.0210 - accuracy: 0.9927 - val_loss: 0.4289 - val_accuracy: 0.6808\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 4.6673 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 169ms/step - loss: 3.9081e-07 - accuracy: 1.0000 - val_loss: 4.9621 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 3.0594e-07 - accuracy: 1.0000 - val_loss: 4.9789 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 3.0095e-07 - accuracy: 1.0000 - val_loss: 4.9819 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 2.9908e-07 - accuracy: 1.0000 - val_loss: 4.9845 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 3.9127 - accuracy: 0.4790 - val_loss: 0.0143 - val_accuracy: 0.9980\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 172ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 166ms/step - loss: 5.2883e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 3.6313e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 2.4597e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 1.6177 - accuracy: 0.6874 - val_loss: 0.7086 - val_accuracy: 0.6358\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 172ms/step - loss: 0.0454 - accuracy: 0.9943 - val_loss: 0.5762 - val_accuracy: 0.6370\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 166ms/step - loss: 0.0267 - accuracy: 0.9942 - val_loss: 0.5921 - val_accuracy: 0.6374\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0239 - accuracy: 0.9942 - val_loss: 0.6319 - val_accuracy: 0.6368\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0223 - accuracy: 0.9942 - val_loss: 0.6387 - val_accuracy: 0.6367\n",
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.1344 - accuracy: 0.9239\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.2682 - accuracy: 0.8304\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 166ms/step - loss: 0.4299 - accuracy: 0.8669 - val_loss: 0.3934 - val_accuracy: 0.8701\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 164ms/step - loss: 0.3939 - accuracy: 0.8683 - val_loss: 0.3855 - val_accuracy: 0.8705\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 0.3914 - accuracy: 0.8683 - val_loss: 0.3850 - val_accuracy: 0.8705\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.3902 - accuracy: 0.8683 - val_loss: 0.3846 - val_accuracy: 0.8705\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 0.3897 - accuracy: 0.8683 - val_loss: 0.3848 - val_accuracy: 0.8705\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.0396 - accuracy: 0.9912 - val_loss: 0.3737 - val_accuracy: 0.6523\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 0.3523 - val_accuracy: 0.7000\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0208 - accuracy: 0.9929 - val_loss: 0.3644 - val_accuracy: 0.7052\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 0.0202 - accuracy: 0.9935 - val_loss: 0.3307 - val_accuracy: 0.7348\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 164ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.2229 - val_accuracy: 0.8567\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 169ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 3.6137 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 166ms/step - loss: 3.5314e-06 - accuracy: 1.0000 - val_loss: 3.9056 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 169ms/step - loss: 2.7207e-06 - accuracy: 1.0000 - val_loss: 3.9280 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 2.6387e-06 - accuracy: 1.0000 - val_loss: 3.9373 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 2.5808e-06 - accuracy: 1.0000 - val_loss: 3.9472 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 3.5441 - accuracy: 0.4468 - val_loss: 0.0981 - val_accuracy: 0.9827\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 171ms/step - loss: 0.0191 - accuracy: 0.9999 - val_loss: 0.0075 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 170ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 171ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 172ms/step - loss: 9.8125e-04 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 170ms/step - loss: 1.1227 - accuracy: 0.7102 - val_loss: 0.3606 - val_accuracy: 0.7891\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 0.0357 - accuracy: 0.9943 - val_loss: 0.4066 - val_accuracy: 0.6795\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 0.0227 - accuracy: 0.9939 - val_loss: 0.4516 - val_accuracy: 0.6537\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0203 - accuracy: 0.9943 - val_loss: 0.5289 - val_accuracy: 0.6405\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0192 - accuracy: 0.9943 - val_loss: 0.5318 - val_accuracy: 0.6420\n",
      "4279/4279 [==============================] - 13s 3ms/step - loss: 0.1283 - accuracy: 0.9256\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.2891 - accuracy: 0.8180\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 0.4315 - accuracy: 0.8671 - val_loss: 0.3895 - val_accuracy: 0.8703\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 171ms/step - loss: 0.3915 - accuracy: 0.8683 - val_loss: 0.3837 - val_accuracy: 0.8705\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 0.3895 - accuracy: 0.8682 - val_loss: 0.3836 - val_accuracy: 0.8705\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 171ms/step - loss: 0.3891 - accuracy: 0.8684 - val_loss: 0.3833 - val_accuracy: 0.8705\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 0.3886 - accuracy: 0.8684 - val_loss: 0.3831 - val_accuracy: 0.8705\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 0.0356 - accuracy: 0.9918 - val_loss: 0.3538 - val_accuracy: 0.7111\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 170ms/step - loss: 0.0203 - accuracy: 0.9932 - val_loss: 0.4043 - val_accuracy: 0.7082\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.3661 - val_accuracy: 0.7421\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 169ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 0.3109 - val_accuracy: 0.7894\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 166ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.3453 - val_accuracy: 0.7894\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 169ms/step - loss: 0.0151 - accuracy: 0.9942 - val_loss: 3.4564 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 5.7742e-06 - accuracy: 1.0000 - val_loss: 3.7569 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 4.3637e-06 - accuracy: 1.0000 - val_loss: 3.7831 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 4.1932e-06 - accuracy: 1.0000 - val_loss: 3.7964 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 164ms/step - loss: 4.0572e-06 - accuracy: 1.0000 - val_loss: 3.8107 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 3.5802 - accuracy: 0.4392 - val_loss: 0.1522 - val_accuracy: 0.9672\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 171ms/step - loss: 0.0270 - accuracy: 0.9998 - val_loss: 0.0144 - val_accuracy: 0.9997\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 170ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 0.5356 - accuracy: 0.8187 - val_loss: 0.6351 - val_accuracy: 0.6458\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 187ms/step - loss: 0.0210 - accuracy: 0.9943 - val_loss: 0.5683 - val_accuracy: 0.6535\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 173ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.5131 - val_accuracy: 0.6638\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 176ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 0.5051 - val_accuracy: 0.6658\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 169ms/step - loss: 0.0166 - accuracy: 0.9944 - val_loss: 0.5052 - val_accuracy: 0.6667\n",
      "4279/4279 [==============================] - 13s 3ms/step - loss: 0.1212 - accuracy: 0.9290\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.2937 - accuracy: 0.8317\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list,1)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr255Bkrum.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.13437610864639282, 0.2682327926158905], [0.12832242250442505, 0.28907695412635803], [0.12117831408977509, 0.29370149970054626]]\n",
      "Accuracy for iterations:  [[0.9238657355308533, 0.8304330706596375], [0.9255675077438354, 0.8179539442062378], [0.9290294647216797, 0.8316682577133179]]\n",
      "F1 for iterations:  [[0.9231360898246124, 0.8226153709281016], [0.9248794591083128, 0.8079918814333199], [0.9284234919289402, 0.82375894040829]]\n",
      "Precision for iterations:  [[0.93248409535391, 0.8612842189890098], [0.9338233596985744, 0.8557059456721707], [0.9365301622224658, 0.863652215937997]]\n",
      "Recall for iterations:  [[0.923865727891554, 0.8304330451209765], [0.9255675012416372, 0.8179539344619632], [0.9290294779280727, 0.8316682409358425]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 1 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_14132/591709827.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr55C1krum.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.6064 - accuracy: 0.7576 - val_loss: 0.4718 - val_accuracy: 0.8035\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 0.3617 - accuracy: 0.8703 - val_loss: 0.2506 - val_accuracy: 0.9255\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 163ms/step - loss: 0.2257 - accuracy: 0.9387 - val_loss: 0.2012 - val_accuracy: 0.9517\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 170ms/step - loss: 0.1975 - accuracy: 0.9567 - val_loss: 0.1817 - val_accuracy: 0.9622\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 169ms/step - loss: 0.1823 - accuracy: 0.9617 - val_loss: 0.1695 - val_accuracy: 0.9643\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 165ms/step - loss: 0.0418 - accuracy: 0.9897 - val_loss: 0.6628 - val_accuracy: 0.7272\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 171ms/step - loss: 0.0224 - accuracy: 0.9949 - val_loss: 0.8043 - val_accuracy: 0.7270\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 167ms/step - loss: 0.0215 - accuracy: 0.9950 - val_loss: 0.7051 - val_accuracy: 0.7271\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 163ms/step - loss: 0.0203 - accuracy: 0.9950 - val_loss: 0.5640 - val_accuracy: 0.7291\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 164ms/step - loss: 0.0196 - accuracy: 0.9950 - val_loss: 0.5649 - val_accuracy: 0.7293\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 162ms/step - loss: 0.0146 - accuracy: 0.9960 - val_loss: 1.9926 - val_accuracy: 0.4451\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 170ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 2.5395 - val_accuracy: 0.4417\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 159ms/step - loss: 0.0127 - accuracy: 0.9969 - val_loss: 1.7165 - val_accuracy: 0.4406\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 163ms/step - loss: 0.0124 - accuracy: 0.9971 - val_loss: 1.4307 - val_accuracy: 0.4427\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 164ms/step - loss: 0.0126 - accuracy: 0.9971 - val_loss: 1.8408 - val_accuracy: 0.4397\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 4s 164ms/step - loss: 1.8469 - accuracy: 0.6315 - val_loss: 0.0445 - val_accuracy: 0.9855\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 175ms/step - loss: 0.0047 - accuracy: 0.9997 - val_loss: 0.0104 - val_accuracy: 0.9952\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 167ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0068 - val_accuracy: 0.9971\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 167ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9977\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 4s 164ms/step - loss: 6.3725e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9989\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 168ms/step - loss: 0.4455 - accuracy: 0.8984 - val_loss: 0.3411 - val_accuracy: 0.8276\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 12s 172ms/step - loss: 0.0235 - accuracy: 0.9926 - val_loss: 0.2559 - val_accuracy: 0.8311\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 12s 171ms/step - loss: 0.0213 - accuracy: 0.9928 - val_loss: 0.2271 - val_accuracy: 0.8472\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 12s 169ms/step - loss: 0.0200 - accuracy: 0.9932 - val_loss: 0.2068 - val_accuracy: 0.8633\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 12s 169ms/step - loss: 0.0189 - accuracy: 0.9935 - val_loss: 0.1969 - val_accuracy: 0.8694\n",
      "4279/4279 [==============================] - 13s 3ms/step - loss: 0.0866 - accuracy: 0.9838\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1968 - accuracy: 0.9249\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 162ms/step - loss: 0.2073 - accuracy: 0.9500 - val_loss: 0.1664 - val_accuracy: 0.9652\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 166ms/step - loss: 0.1644 - accuracy: 0.9647 - val_loss: 0.1523 - val_accuracy: 0.9673\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 164ms/step - loss: 0.1560 - accuracy: 0.9653 - val_loss: 0.1486 - val_accuracy: 0.9673\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 163ms/step - loss: 0.1528 - accuracy: 0.9655 - val_loss: 0.1456 - val_accuracy: 0.9679\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.1502 - accuracy: 0.9657 - val_loss: 0.1439 - val_accuracy: 0.9679\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 162ms/step - loss: 0.0312 - accuracy: 0.9916 - val_loss: 0.7178 - val_accuracy: 0.7239\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 155ms/step - loss: 0.0174 - accuracy: 0.9952 - val_loss: 0.8174 - val_accuracy: 0.7251\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 159ms/step - loss: 0.0161 - accuracy: 0.9956 - val_loss: 0.4727 - val_accuracy: 0.7255\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.0156 - accuracy: 0.9956 - val_loss: 0.5299 - val_accuracy: 0.7224\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 166ms/step - loss: 0.0147 - accuracy: 0.9955 - val_loss: 0.6091 - val_accuracy: 0.7234\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 161ms/step - loss: 0.0113 - accuracy: 0.9972 - val_loss: 1.6088 - val_accuracy: 0.4410\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 161ms/step - loss: 0.0107 - accuracy: 0.9973 - val_loss: 1.5915 - val_accuracy: 0.4564\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 166ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 1.5073 - val_accuracy: 0.4779\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 156ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 1.9058 - val_accuracy: 0.4621\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 167ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 1.3676 - val_accuracy: 0.5326\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 4s 162ms/step - loss: 2.9928 - accuracy: 0.5583 - val_loss: 0.2184 - val_accuracy: 0.9212\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 167ms/step - loss: 0.0500 - accuracy: 0.9756 - val_loss: 0.0092 - val_accuracy: 0.9956\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 4s 163ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 0.9979\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 4s 165ms/step - loss: 6.9167e-04 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9982\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 4s 162ms/step - loss: 5.6802e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9984\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 167ms/step - loss: 0.5673 - accuracy: 0.8949 - val_loss: 0.2295 - val_accuracy: 0.8769\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 12s 171ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 0.1856 - val_accuracy: 0.8955\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 12s 171ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.1820 - val_accuracy: 0.8912\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 12s 172ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.1661 - val_accuracy: 0.8979\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 12s 171ms/step - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.1407 - val_accuracy: 0.9142\n",
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.0489 - accuracy: 0.9903\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1043 - accuracy: 0.9822\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 161ms/step - loss: 0.2041 - accuracy: 0.9547 - val_loss: 0.1569 - val_accuracy: 0.9675\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 168ms/step - loss: 0.1587 - accuracy: 0.9657 - val_loss: 0.1497 - val_accuracy: 0.9676\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 163ms/step - loss: 0.1527 - accuracy: 0.9657 - val_loss: 0.1453 - val_accuracy: 0.9678\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 167ms/step - loss: 0.1495 - accuracy: 0.9658 - val_loss: 0.1435 - val_accuracy: 0.9678\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 2s 154ms/step - loss: 0.1480 - accuracy: 0.9658 - val_loss: 0.1417 - val_accuracy: 0.9679\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 170ms/step - loss: 0.0305 - accuracy: 0.9928 - val_loss: 0.6390 - val_accuracy: 0.7247\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 153ms/step - loss: 0.0158 - accuracy: 0.9952 - val_loss: 0.7641 - val_accuracy: 0.7261\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 154ms/step - loss: 0.0150 - accuracy: 0.9956 - val_loss: 0.6501 - val_accuracy: 0.7262\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 161ms/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.5528 - val_accuracy: 0.7316\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 165ms/step - loss: 0.0134 - accuracy: 0.9964 - val_loss: 0.6457 - val_accuracy: 0.7313\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 162ms/step - loss: 0.0111 - accuracy: 0.9973 - val_loss: 1.4362 - val_accuracy: 0.4838\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 160ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 1.3564 - val_accuracy: 0.5261\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 166ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 1.6489 - val_accuracy: 0.5040\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 156ms/step - loss: 0.0100 - accuracy: 0.9975 - val_loss: 1.5120 - val_accuracy: 0.5422\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 158ms/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 1.5485 - val_accuracy: 0.5403\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 4s 162ms/step - loss: 2.6879 - accuracy: 0.6197 - val_loss: 0.1193 - val_accuracy: 0.9296\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 4s 164ms/step - loss: 0.0175 - accuracy: 0.9928 - val_loss: 0.0025 - val_accuracy: 0.9995\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 4s 165ms/step - loss: 2.6414e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 167ms/step - loss: 1.9555e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 4s 164ms/step - loss: 1.7571e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9997\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 167ms/step - loss: 0.4159 - accuracy: 0.9213 - val_loss: 0.2490 - val_accuracy: 0.8773\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 12s 167ms/step - loss: 0.0166 - accuracy: 0.9944 - val_loss: 0.1828 - val_accuracy: 0.9024\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 12s 169ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.1647 - val_accuracy: 0.9089\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 12s 170ms/step - loss: 0.0151 - accuracy: 0.9950 - val_loss: 0.1704 - val_accuracy: 0.9031\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 12s 169ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.1400 - val_accuracy: 0.9211\n",
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.0434 - accuracy: 0.9904\n",
      "1721/1721 [==============================] - 6s 3ms/step - loss: 0.1001 - accuracy: 0.9807\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list,1)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr55C1krum.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.08662975579500198, 0.19675715267658234], [0.04885745048522949, 0.10433225333690643], [0.043407466262578964, 0.10013923794031143]]\n",
      "Accuracy for iterations:  [[0.9837710857391357, 0.9249255061149597], [0.9903371334075928, 0.9821622967720032], [0.9903590679168701, 0.9806909561157227]]\n",
      "F1 for iterations:  [[0.9837713844765796, 0.9241394587228892], [0.9903415659214462, 0.9821832394220688], [0.9903634698516782, 0.9806997341844538]]\n",
      "Precision for iterations:  [[0.9837719204280907, 0.9296400775761161], [0.9905250878553817, 0.9824197982204333], [0.9905472636848005, 0.9807371103277795]]\n",
      "Recall for iterations:  [[0.9837710713137983, 0.9249255249582213], [0.9903371410207719, 0.9821623192617889], [0.9903590522656227, 0.9806909830705515]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 1 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_14132/372464333.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr105C1krum.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 170ms/step - loss: 0.6147 - accuracy: 0.7564 - val_loss: 0.4928 - val_accuracy: 0.7759\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 0.3927 - accuracy: 0.8574 - val_loss: 0.3094 - val_accuracy: 0.9054\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.2932 - accuracy: 0.9179 - val_loss: 0.2806 - val_accuracy: 0.9312\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 177ms/step - loss: 0.2683 - accuracy: 0.9337 - val_loss: 0.2646 - val_accuracy: 0.9381\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.2549 - accuracy: 0.9371 - val_loss: 0.2501 - val_accuracy: 0.9395\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 171ms/step - loss: 0.0468 - accuracy: 0.9909 - val_loss: 0.7060 - val_accuracy: 0.7270\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 164ms/step - loss: 0.0233 - accuracy: 0.9945 - val_loss: 0.8189 - val_accuracy: 0.7270\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 154ms/step - loss: 0.0219 - accuracy: 0.9950 - val_loss: 0.7256 - val_accuracy: 0.7270\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 156ms/step - loss: 0.0208 - accuracy: 0.9950 - val_loss: 0.5718 - val_accuracy: 0.7275\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 167ms/step - loss: 0.0200 - accuracy: 0.9950 - val_loss: 0.5829 - val_accuracy: 0.7278\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 161ms/step - loss: 0.0152 - accuracy: 0.9960 - val_loss: 2.2175 - val_accuracy: 0.4452\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 167ms/step - loss: 0.0139 - accuracy: 0.9962 - val_loss: 2.1304 - val_accuracy: 0.4449\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 159ms/step - loss: 0.0130 - accuracy: 0.9965 - val_loss: 1.7352 - val_accuracy: 0.4445\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 154ms/step - loss: 0.0128 - accuracy: 0.9965 - val_loss: 1.8565 - val_accuracy: 0.4430\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 162ms/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 2.1546 - val_accuracy: 0.4379\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 4s 165ms/step - loss: 1.8599 - accuracy: 0.6367 - val_loss: 0.0296 - val_accuracy: 0.9882\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.0054 - val_accuracy: 0.9976\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 4s 164ms/step - loss: 5.6836e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 167ms/step - loss: 1.8899e-04 - accuracy: 1.0000 - val_loss: 4.7799e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 4s 160ms/step - loss: 7.7170e-05 - accuracy: 1.0000 - val_loss: 1.9917e-04 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 169ms/step - loss: 0.7074 - accuracy: 0.8768 - val_loss: 0.3556 - val_accuracy: 0.8271\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 12s 169ms/step - loss: 0.0235 - accuracy: 0.9927 - val_loss: 0.2528 - val_accuracy: 0.8364\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 12s 170ms/step - loss: 0.0214 - accuracy: 0.9930 - val_loss: 0.2433 - val_accuracy: 0.8396\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 12s 172ms/step - loss: 0.0203 - accuracy: 0.9933 - val_loss: 0.2132 - val_accuracy: 0.8566\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 12s 170ms/step - loss: 0.0193 - accuracy: 0.9935 - val_loss: 0.2074 - val_accuracy: 0.8608\n",
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.0899 - accuracy: 0.9852\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1826 - accuracy: 0.9296TA: 0s - loss: 0.2106 -  - ETA: 0s - loss: 0.1\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 161ms/step - loss: 0.2914 - accuracy: 0.9269 - val_loss: 0.2448 - val_accuracy: 0.9406\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.2417 - accuracy: 0.9403 - val_loss: 0.2336 - val_accuracy: 0.9421\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 2s 154ms/step - loss: 0.2320 - accuracy: 0.9409 - val_loss: 0.2271 - val_accuracy: 0.9425\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 168ms/step - loss: 0.2283 - accuracy: 0.9411 - val_loss: 0.2243 - val_accuracy: 0.9428\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 162ms/step - loss: 0.2261 - accuracy: 0.9413 - val_loss: 0.2221 - val_accuracy: 0.9429\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 163ms/step - loss: 0.0350 - accuracy: 0.9921 - val_loss: 0.7385 - val_accuracy: 0.7260\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 162ms/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 0.8154 - val_accuracy: 0.7265\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 155ms/step - loss: 0.0168 - accuracy: 0.9952 - val_loss: 0.5902 - val_accuracy: 0.7255\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 155ms/step - loss: 0.0158 - accuracy: 0.9952 - val_loss: 0.4820 - val_accuracy: 0.7260\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 163ms/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 0.5364 - val_accuracy: 0.7287\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 165ms/step - loss: 0.0119 - accuracy: 0.9967 - val_loss: 1.8615 - val_accuracy: 0.4406\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 164ms/step - loss: 0.0111 - accuracy: 0.9972 - val_loss: 1.8427 - val_accuracy: 0.4458\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 169ms/step - loss: 0.0112 - accuracy: 0.9972 - val_loss: 1.7386 - val_accuracy: 0.4648\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 163ms/step - loss: 0.0108 - accuracy: 0.9973 - val_loss: 1.4386 - val_accuracy: 0.5161\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 167ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 1.7512 - val_accuracy: 0.4949\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 4s 163ms/step - loss: 2.6787 - accuracy: 0.5916 - val_loss: 0.1024 - val_accuracy: 0.9746\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 4s 165ms/step - loss: 0.0102 - accuracy: 0.9997 - val_loss: 0.0086 - val_accuracy: 0.9957\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 4s 166ms/step - loss: 4.6102e-04 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9968\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 4s 165ms/step - loss: 3.2026e-04 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9974\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 4s 167ms/step - loss: 2.6242e-04 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9980\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 169ms/step - loss: 0.5122 - accuracy: 0.8974 - val_loss: 0.2642 - val_accuracy: 0.8478\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 12s 169ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.2057 - val_accuracy: 0.8790\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 12s 171ms/step - loss: 0.0184 - accuracy: 0.9941 - val_loss: 0.1934 - val_accuracy: 0.8835\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 12s 171ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.1761 - val_accuracy: 0.8910\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 12s 170ms/step - loss: 0.0169 - accuracy: 0.9943 - val_loss: 0.1813 - val_accuracy: 0.8876\n",
      "4279/4279 [==============================] - 13s 3ms/step - loss: 0.0566 - accuracy: 0.9897 0s - loss: 0.0566 - accuracy\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1162 - accuracy: 0.9688\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.2948 - accuracy: 0.9287 - val_loss: 0.2394 - val_accuracy: 0.9421\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 164ms/step - loss: 0.2353 - accuracy: 0.9411 - val_loss: 0.2269 - val_accuracy: 0.9429\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 167ms/step - loss: 0.2276 - accuracy: 0.9414 - val_loss: 0.2227 - val_accuracy: 0.9428\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 163ms/step - loss: 0.2250 - accuracy: 0.9414 - val_loss: 0.2211 - val_accuracy: 0.9429\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 162ms/step - loss: 0.2237 - accuracy: 0.9415 - val_loss: 0.2201 - val_accuracy: 0.9428\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 163ms/step - loss: 0.0356 - accuracy: 0.9924 - val_loss: 0.6175 - val_accuracy: 0.7254\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 155ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 0.7946 - val_accuracy: 0.7257\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 154ms/step - loss: 0.0154 - accuracy: 0.9955 - val_loss: 0.6389 - val_accuracy: 0.7283\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 156ms/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.5573 - val_accuracy: 0.7367\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 170ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 0.6757 - val_accuracy: 0.7357\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 159ms/step - loss: 0.0109 - accuracy: 0.9972 - val_loss: 1.5671 - val_accuracy: 0.4934\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 159ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 1.6922 - val_accuracy: 0.5030\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 164ms/step - loss: 0.0100 - accuracy: 0.9975 - val_loss: 1.5958 - val_accuracy: 0.5337\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 154ms/step - loss: 0.0099 - accuracy: 0.9975 - val_loss: 1.5713 - val_accuracy: 0.5501\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 157ms/step - loss: 0.0099 - accuracy: 0.9975 - val_loss: 1.1176 - val_accuracy: 0.6303\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 4s 164ms/step - loss: 2.3944 - accuracy: 0.6411 - val_loss: 0.0951 - val_accuracy: 0.9767\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 4s 165ms/step - loss: 0.0103 - accuracy: 0.9999 - val_loss: 0.0068 - val_accuracy: 0.9962\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 4s 166ms/step - loss: 3.4843e-04 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9977\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 4s 164ms/step - loss: 2.6518e-04 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9978\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 4s 161ms/step - loss: 2.3768e-04 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9982\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 168ms/step - loss: 0.4578 - accuracy: 0.9128 - val_loss: 0.2603 - val_accuracy: 0.8747\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 12s 167ms/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 0.2041 - val_accuracy: 0.8959\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 12s 173ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 0.1757 - val_accuracy: 0.9083\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 12s 172ms/step - loss: 0.0151 - accuracy: 0.9950 - val_loss: 0.1705 - val_accuracy: 0.9099\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 12s 172ms/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.1618 - val_accuracy: 0.9148\n",
      "4279/4279 [==============================] - 13s 3ms/step - loss: 0.0547 - accuracy: 0.9905\n",
      "1721/1721 [==============================] - 6s 3ms/step - loss: 0.0970 - accuracy: 0.9792\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list,1)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr105C1krum.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.08986923098564148, 0.18257004022598267], [0.056640248745679855, 0.11619224399328232], [0.054749954491853714, 0.09699279069900513]]\n",
      "Accuracy for iterations:  [[0.9851734042167664, 0.9295756816864014], [0.9896798133850098, 0.9688476324081421], [0.9904612898826599, 0.9792196750640869]]\n",
      "F1 for iterations:  [[0.9851751497575643, 0.9289185993225917], [0.9896847079623124, 0.9688647354430518], [0.9904656539231713, 0.9792450871503925]]\n",
      "Precision for iterations:  [[0.9851858951589497, 0.9335531314834116], [0.9898860415960865, 0.96892390353904], [0.990647201756734, 0.9795069419566703]]\n",
      "Recall for iterations:  [[0.9851733909842532, 0.9295756739083049], [0.9896798036752461, 0.9688476349633074], [0.9904613047415934, 0.9792196468793141]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 1 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_14132/2868219575.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr255C1krum.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 167ms/step - loss: 0.6302 - accuracy: 0.7202 - val_loss: 0.5406 - val_accuracy: 0.7400\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 182ms/step - loss: 0.4878 - accuracy: 0.8044 - val_loss: 0.4417 - val_accuracy: 0.8490\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 162ms/step - loss: 0.4404 - accuracy: 0.8510 - val_loss: 0.4190 - val_accuracy: 0.8646\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 165ms/step - loss: 0.4236 - accuracy: 0.8617 - val_loss: 0.4084 - val_accuracy: 0.8677\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.4139 - accuracy: 0.8639 - val_loss: 0.4017 - val_accuracy: 0.8686\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 160ms/step - loss: 0.0744 - accuracy: 0.9905 - val_loss: 0.5449 - val_accuracy: 0.7270\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 165ms/step - loss: 0.0258 - accuracy: 0.9938 - val_loss: 0.7649 - val_accuracy: 0.7270\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 154ms/step - loss: 0.0225 - accuracy: 0.9950 - val_loss: 0.8984 - val_accuracy: 0.7270\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.0214 - accuracy: 0.9951 - val_loss: 0.6588 - val_accuracy: 0.7270\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 158ms/step - loss: 0.0206 - accuracy: 0.9950 - val_loss: 0.5478 - val_accuracy: 0.7272\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 163ms/step - loss: 0.0154 - accuracy: 0.9961 - val_loss: 2.3877 - val_accuracy: 0.4439\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 167ms/step - loss: 0.0139 - accuracy: 0.9961 - val_loss: 1.9711 - val_accuracy: 0.4436\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 163ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 1.8590 - val_accuracy: 0.4442\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 158ms/step - loss: 0.0126 - accuracy: 0.9967 - val_loss: 2.0635 - val_accuracy: 0.4395\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 169ms/step - loss: 0.0121 - accuracy: 0.9972 - val_loss: 1.7296 - val_accuracy: 0.4418\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 176ms/step - loss: 1.7035 - accuracy: 0.6543 - val_loss: 0.0241 - val_accuracy: 0.9911\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 171ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.0046 - val_accuracy: 0.9982\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 4s 167ms/step - loss: 8.6694e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9989\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 169ms/step - loss: 6.4683e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9996\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 4s 164ms/step - loss: 5.0190e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 171ms/step - loss: 0.5014 - accuracy: 0.8969 - val_loss: 0.3648 - val_accuracy: 0.8276\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 12s 171ms/step - loss: 0.0239 - accuracy: 0.9926 - val_loss: 0.2511 - val_accuracy: 0.8364\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 12s 170ms/step - loss: 0.0215 - accuracy: 0.9928 - val_loss: 0.2227 - val_accuracy: 0.8510\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 12s 174ms/step - loss: 0.0204 - accuracy: 0.9930 - val_loss: 0.2085 - val_accuracy: 0.8594\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 12s 172ms/step - loss: 0.0194 - accuracy: 0.9932 - val_loss: 0.1958 - val_accuracy: 0.8673\n",
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.0796 - accuracy: 0.9883\n",
      "1721/1721 [==============================] - 6s 3ms/step - loss: 0.1480 - accuracy: 0.9552: 0s - loss: 0.1499 - accuracy\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 167ms/step - loss: 0.5579 - accuracy: 0.8514 - val_loss: 0.4231 - val_accuracy: 0.8599\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 159ms/step - loss: 0.4203 - accuracy: 0.8643 - val_loss: 0.4079 - val_accuracy: 0.8693\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 162ms/step - loss: 0.4075 - accuracy: 0.8663 - val_loss: 0.3961 - val_accuracy: 0.8699\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 167ms/step - loss: 0.4016 - accuracy: 0.8666 - val_loss: 0.3938 - val_accuracy: 0.8698\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 161ms/step - loss: 0.3986 - accuracy: 0.8666 - val_loss: 0.3915 - val_accuracy: 0.8701\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 163ms/step - loss: 0.0630 - accuracy: 0.9906 - val_loss: 0.5775 - val_accuracy: 0.7252\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 156ms/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 0.7937 - val_accuracy: 0.7257\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 160ms/step - loss: 0.0176 - accuracy: 0.9952 - val_loss: 0.7761 - val_accuracy: 0.7248\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 156ms/step - loss: 0.0165 - accuracy: 0.9952 - val_loss: 0.5094 - val_accuracy: 0.7252\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 161ms/step - loss: 0.0159 - accuracy: 0.9953 - val_loss: 0.4886 - val_accuracy: 0.7245\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 168ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 1.3321 - val_accuracy: 0.4392\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 161ms/step - loss: 0.0117 - accuracy: 0.9970 - val_loss: 1.8958 - val_accuracy: 0.4368\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 159ms/step - loss: 0.0111 - accuracy: 0.9972 - val_loss: 1.3960 - val_accuracy: 0.4668\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 164ms/step - loss: 0.0110 - accuracy: 0.9973 - val_loss: 1.4187 - val_accuracy: 0.4871\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 165ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 1.4767 - val_accuracy: 0.5019\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 4s 164ms/step - loss: 2.8736 - accuracy: 0.5389 - val_loss: 0.2154 - val_accuracy: 0.9214\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 4s 164ms/step - loss: 0.0516 - accuracy: 0.9749 - val_loss: 0.0056 - val_accuracy: 0.9971\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 167ms/step - loss: 5.6383e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 0.9988\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 4s 166ms/step - loss: 3.5182e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9993\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 2.9523e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9995\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 174ms/step - loss: 0.6650 - accuracy: 0.8876 - val_loss: 0.2383 - val_accuracy: 0.8639\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 12s 172ms/step - loss: 0.0188 - accuracy: 0.9943 - val_loss: 0.2043 - val_accuracy: 0.8795\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 12s 175ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.1795 - val_accuracy: 0.8893\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 12s 172ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.1766 - val_accuracy: 0.8855\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 12s 171ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.1601 - val_accuracy: 0.8947\n",
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.0733 - accuracy: 0.9870\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1663 - accuracy: 0.9459\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 156ms/step - loss: 0.5837 - accuracy: 0.8576 - val_loss: 0.4242 - val_accuracy: 0.8681\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 164ms/step - loss: 0.4200 - accuracy: 0.8651 - val_loss: 0.4120 - val_accuracy: 0.8691\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.4067 - accuracy: 0.8670 - val_loss: 0.3982 - val_accuracy: 0.8703\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 169ms/step - loss: 0.4018 - accuracy: 0.8671 - val_loss: 0.3950 - val_accuracy: 0.8706\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 163ms/step - loss: 0.3989 - accuracy: 0.8671 - val_loss: 0.3930 - val_accuracy: 0.8706\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 164ms/step - loss: 0.0809 - accuracy: 0.9928 - val_loss: 0.5752 - val_accuracy: 0.7214\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 162ms/step - loss: 0.0201 - accuracy: 0.9952 - val_loss: 0.6868 - val_accuracy: 0.7255\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 155ms/step - loss: 0.0173 - accuracy: 0.9951 - val_loss: 0.8081 - val_accuracy: 0.7248\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 160ms/step - loss: 0.0159 - accuracy: 0.9954 - val_loss: 0.6032 - val_accuracy: 0.7252\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 157ms/step - loss: 0.0150 - accuracy: 0.9955 - val_loss: 0.5559 - val_accuracy: 0.7278\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 165ms/step - loss: 0.0114 - accuracy: 0.9972 - val_loss: 1.5870 - val_accuracy: 0.4458\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 162ms/step - loss: 0.0107 - accuracy: 0.9974 - val_loss: 1.6321 - val_accuracy: 0.4691\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 165ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 1.4924 - val_accuracy: 0.5081\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 162ms/step - loss: 0.0103 - accuracy: 0.9975 - val_loss: 1.3736 - val_accuracy: 0.5476\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 167ms/step - loss: 0.0101 - accuracy: 0.9975 - val_loss: 1.8896 - val_accuracy: 0.5015\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 4s 163ms/step - loss: 3.1576 - accuracy: 0.5685 - val_loss: 0.2270 - val_accuracy: 0.9257\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 169ms/step - loss: 0.0451 - accuracy: 0.9792 - val_loss: 0.0021 - val_accuracy: 0.9993\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 167ms/step - loss: 1.0966e-04 - accuracy: 1.0000 - val_loss: 9.0059e-04 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 169ms/step - loss: 6.9519e-05 - accuracy: 1.0000 - val_loss: 7.8912e-04 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 4s 166ms/step - loss: 6.1849e-05 - accuracy: 1.0000 - val_loss: 7.2329e-04 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 170ms/step - loss: 0.5905 - accuracy: 0.9040 - val_loss: 0.2985 - val_accuracy: 0.8613\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 12s 170ms/step - loss: 0.0184 - accuracy: 0.9941 - val_loss: 0.2142 - val_accuracy: 0.8919\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 12s 174ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.1600 - val_accuracy: 0.9152\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 12s 178ms/step - loss: 0.0163 - accuracy: 0.9944 - val_loss: 0.1742 - val_accuracy: 0.9016\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 12s 171ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 0.1817 - val_accuracy: 0.8954\n",
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.0745 - accuracy: 0.9858\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1436 - accuracy: 0.9554\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list,1)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr255C1krum.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.07960396260023117, 0.14799557626247406], [0.07333571463823318, 0.16630017757415771], [0.07445225864648819, 0.14362014830112457]]\n",
      "Accuracy for iterations:  [[0.9882774949073792, 0.9552241563796997], [0.9869773983955383, 0.9459238648414612], [0.9858234524726868, 0.9553694725036621]]\n",
      "F1 for iterations:  [[0.9882812829735476, 0.9550575842394174], [0.9869849646502328, 0.9461219806778096], [0.9858321220954305, 0.9555235376094493]]\n",
      "Precision for iterations:  [[0.9883637640535404, 0.956105398920262], [0.9873245914522379, 0.9518515615657411], [0.9862316971488606, 0.9594860397418689]]\n",
      "Recall for iterations:  [[0.9882774840047912, 0.9552241517111095], [0.986977416810307, 0.9459238538109423], [0.9858234245814952, 0.9553694688657997]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 3 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_14132/927562370.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr55C3krum.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 166ms/step - loss: 0.5378 - accuracy: 0.7513 - val_loss: 1.7451 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 0.2130 - accuracy: 0.9427 - val_loss: 3.6369 - val_accuracy: 0.1252\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 158ms/step - loss: 0.0908 - accuracy: 0.9893 - val_loss: 4.2255 - val_accuracy: 0.1338\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.0559 - accuracy: 0.9893 - val_loss: 2.3574 - val_accuracy: 0.1343\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 165ms/step - loss: 0.0377 - accuracy: 0.9900 - val_loss: 1.3178 - val_accuracy: 0.1912\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 165ms/step - loss: 0.0230 - accuracy: 0.9950 - val_loss: 0.8965 - val_accuracy: 0.7270\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 181ms/step - loss: 0.0199 - accuracy: 0.9951 - val_loss: 0.5689 - val_accuracy: 0.7291\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 156ms/step - loss: 0.0194 - accuracy: 0.9950 - val_loss: 0.5401 - val_accuracy: 0.7317\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 167ms/step - loss: 0.0188 - accuracy: 0.9951 - val_loss: 0.5852 - val_accuracy: 0.7304\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 157ms/step - loss: 0.0180 - accuracy: 0.9950 - val_loss: 0.5872 - val_accuracy: 0.7316\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 160ms/step - loss: 0.2347 - accuracy: 0.9426 - val_loss: 0.1840 - val_accuracy: 0.9620\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 172ms/step - loss: 0.1783 - accuracy: 0.9614 - val_loss: 0.1715 - val_accuracy: 0.9635\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 162ms/step - loss: 0.1692 - accuracy: 0.9624 - val_loss: 0.1657 - val_accuracy: 0.9640\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 163ms/step - loss: 0.1640 - accuracy: 0.9628 - val_loss: 0.1618 - val_accuracy: 0.9640\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 161ms/step - loss: 0.1601 - accuracy: 0.9632 - val_loss: 0.1587 - val_accuracy: 0.9640\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 4s 165ms/step - loss: 0.3053 - accuracy: 0.8856 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 8.8868e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 172ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.2312e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 4s 164ms/step - loss: 5.5620e-04 - accuracy: 1.0000 - val_loss: 2.2254e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 4s 165ms/step - loss: 3.0874e-04 - accuracy: 1.0000 - val_loss: 1.3195e-04 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 169ms/step - loss: 0.7196 - accuracy: 0.8504 - val_loss: 0.3013 - val_accuracy: 0.8295\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 13s 187ms/step - loss: 0.0305 - accuracy: 0.9915 - val_loss: 0.2628 - val_accuracy: 0.8299\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 15s 215ms/step - loss: 0.0245 - accuracy: 0.9912 - val_loss: 0.2244 - val_accuracy: 0.8361\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 13s 190ms/step - loss: 0.0225 - accuracy: 0.9913 - val_loss: 0.2016 - val_accuracy: 0.8463\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 12s 173ms/step - loss: 0.0213 - accuracy: 0.9920 - val_loss: 0.1880 - val_accuracy: 0.8598\n",
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.0938 - accuracy: 0.9892\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1117 - accuracy: 0.9701\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 167ms/step - loss: 0.0264 - accuracy: 0.9891 - val_loss: 0.5439 - val_accuracy: 0.7223\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 177ms/step - loss: 0.0234 - accuracy: 0.9907 - val_loss: 0.6524 - val_accuracy: 0.5633\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 0.0223 - accuracy: 0.9917 - val_loss: 0.7171 - val_accuracy: 0.5131\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 167ms/step - loss: 0.0215 - accuracy: 0.9926 - val_loss: 0.5910 - val_accuracy: 0.6412\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 162ms/step - loss: 0.0200 - accuracy: 0.9930 - val_loss: 0.6796 - val_accuracy: 0.5751\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 164ms/step - loss: 0.0173 - accuracy: 0.9952 - val_loss: 0.5462 - val_accuracy: 0.7394\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 169ms/step - loss: 0.0151 - accuracy: 0.9954 - val_loss: 0.4943 - val_accuracy: 0.7435\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 163ms/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.6823 - val_accuracy: 0.7339\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 166ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.5082 - val_accuracy: 0.7462\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 165ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 0.7320 - val_accuracy: 0.7353\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 164ms/step - loss: 0.2690 - accuracy: 0.9454 - val_loss: 0.1931 - val_accuracy: 0.9638\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 166ms/step - loss: 0.1746 - accuracy: 0.9632 - val_loss: 0.1648 - val_accuracy: 0.9639\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 169ms/step - loss: 0.1604 - accuracy: 0.9633 - val_loss: 0.1576 - val_accuracy: 0.9640\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 167ms/step - loss: 0.1555 - accuracy: 0.9635 - val_loss: 0.1550 - val_accuracy: 0.9640\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 173ms/step - loss: 0.1533 - accuracy: 0.9637 - val_loss: 0.1531 - val_accuracy: 0.9642\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 0.3919 - accuracy: 0.8460 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 175ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 7.0673e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 172ms/step - loss: 8.6672e-04 - accuracy: 1.0000 - val_loss: 3.5489e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 176ms/step - loss: 3.9880e-04 - accuracy: 1.0000 - val_loss: 1.2581e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 172ms/step - loss: 1.2972e-04 - accuracy: 1.0000 - val_loss: 3.9317e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 173ms/step - loss: 0.8503 - accuracy: 0.8365 - val_loss: 0.2322 - val_accuracy: 0.8425\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 12s 174ms/step - loss: 0.0237 - accuracy: 0.9930 - val_loss: 0.2020 - val_accuracy: 0.8545\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 12s 175ms/step - loss: 0.0196 - accuracy: 0.9936 - val_loss: 0.1582 - val_accuracy: 0.8968\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 12s 175ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 0.2062 - val_accuracy: 0.8715\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 12s 170ms/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.1806 - val_accuracy: 0.8901\n",
      "4279/4279 [==============================] - 13s 3ms/step - loss: 0.1872 - accuracy: 0.9627\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.2125 - accuracy: 0.9143\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.0201 - accuracy: 0.9934 - val_loss: 1.0081 - val_accuracy: 0.4108\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 0.0188 - accuracy: 0.9935 - val_loss: 0.9036 - val_accuracy: 0.4981\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 166ms/step - loss: 0.0186 - accuracy: 0.9937 - val_loss: 1.0633 - val_accuracy: 0.4614\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 5s 304ms/step - loss: 0.0180 - accuracy: 0.9938 - val_loss: 0.9063 - val_accuracy: 0.5389\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 170ms/step - loss: 0.0170 - accuracy: 0.9944 - val_loss: 0.7834 - val_accuracy: 0.5956\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 174ms/step - loss: 0.0138 - accuracy: 0.9964 - val_loss: 0.8111 - val_accuracy: 0.7383\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 175ms/step - loss: 0.0130 - accuracy: 0.9965 - val_loss: 0.6528 - val_accuracy: 0.7539\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 163ms/step - loss: 0.0126 - accuracy: 0.9967 - val_loss: 0.6934 - val_accuracy: 0.7555\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 182ms/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.7346 - val_accuracy: 0.7541\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 173ms/step - loss: 0.0123 - accuracy: 0.9967 - val_loss: 0.8295 - val_accuracy: 0.7473\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 176ms/step - loss: 0.2815 - accuracy: 0.9442 - val_loss: 0.1976 - val_accuracy: 0.9638\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 180ms/step - loss: 0.1759 - accuracy: 0.9630 - val_loss: 0.1628 - val_accuracy: 0.9641\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 175ms/step - loss: 0.1577 - accuracy: 0.9631 - val_loss: 0.1535 - val_accuracy: 0.9640\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 180ms/step - loss: 0.1524 - accuracy: 0.9635 - val_loss: 0.1513 - val_accuracy: 0.9641\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 178ms/step - loss: 0.1508 - accuracy: 0.9635 - val_loss: 0.1498 - val_accuracy: 0.9640\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 175ms/step - loss: 0.2805 - accuracy: 0.8820 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 171ms/step - loss: 9.6743e-04 - accuracy: 1.0000 - val_loss: 2.2868e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 175ms/step - loss: 2.8582e-04 - accuracy: 1.0000 - val_loss: 9.9377e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 171ms/step - loss: 1.3884e-04 - accuracy: 1.0000 - val_loss: 5.3863e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 173ms/step - loss: 8.0092e-05 - accuracy: 1.0000 - val_loss: 3.3061e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 176ms/step - loss: 0.7035 - accuracy: 0.8687 - val_loss: 0.2900 - val_accuracy: 0.8427\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 12s 175ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.1944 - val_accuracy: 0.8816\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 12s 176ms/step - loss: 0.0188 - accuracy: 0.9943 - val_loss: 0.1835 - val_accuracy: 0.8873\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 13s 182ms/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 0.1665 - val_accuracy: 0.8993\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 13s 183ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.1810 - val_accuracy: 0.8904\n",
      "4279/4279 [==============================] - 13s 3ms/step - loss: 0.2457 - accuracy: 0.9364\n",
      "1721/1721 [==============================] - 6s 4ms/step - loss: 0.2353 - accuracy: 0.8908\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list,1)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr55C3krum.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.09383776783943176, 0.1116621345281601], [0.1871568113565445, 0.21245206892490387], [0.24568936228752136, 0.23527847230434418]]\n",
      "Accuracy for iterations:  [[0.9892342686653137, 0.9701191782951355], [0.9627216458320618, 0.9142628908157349], [0.936413586139679, 0.8908305168151855]]\n",
      "F1 for iterations:  [[0.9892384395018187, 0.9700797572620499], [0.9626600208631052, 0.9131182784715846], [0.9360802316775654, 0.8885853397678093]]\n",
      "Precision for iterations:  [[0.9893613943206596, 0.9702327402213295], [0.963450010331636, 0.9209371639443125], [0.9402978585222659, 0.902717012577678]]\n",
      "Recall for iterations:  [[0.9892342750299453, 0.9701191600668458], [0.9627216687604079, 0.9142628787328344], [0.9364135674428117, 0.890830487539054]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 3 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_14132/4114672810.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr105C3krum.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 181ms/step - loss: 0.5581 - accuracy: 0.7275 - val_loss: 1.5746 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 181ms/step - loss: 0.2147 - accuracy: 0.9578 - val_loss: 3.5486 - val_accuracy: 0.1334\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 0.0899 - accuracy: 0.9892 - val_loss: 3.8852 - val_accuracy: 0.1339\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 170ms/step - loss: 0.0565 - accuracy: 0.9893 - val_loss: 1.8051 - val_accuracy: 0.1378\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 0.0405 - accuracy: 0.9886 - val_loss: 1.3167 - val_accuracy: 0.2215\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 185ms/step - loss: 0.0226 - accuracy: 0.9947 - val_loss: 0.8777 - val_accuracy: 0.7270\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 180ms/step - loss: 0.0202 - accuracy: 0.9950 - val_loss: 0.4879 - val_accuracy: 0.7382\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 161ms/step - loss: 0.0198 - accuracy: 0.9949 - val_loss: 0.5660 - val_accuracy: 0.7318\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 178ms/step - loss: 0.0190 - accuracy: 0.9951 - val_loss: 0.5619 - val_accuracy: 0.7331\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 166ms/step - loss: 0.0183 - accuracy: 0.9950 - val_loss: 0.5043 - val_accuracy: 0.7400\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 172ms/step - loss: 0.3505 - accuracy: 0.9150 - val_loss: 0.2712 - val_accuracy: 0.9305\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 180ms/step - loss: 0.2607 - accuracy: 0.9369 - val_loss: 0.2548 - val_accuracy: 0.9362\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 173ms/step - loss: 0.2480 - accuracy: 0.9387 - val_loss: 0.2469 - val_accuracy: 0.9374\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 178ms/step - loss: 0.2414 - accuracy: 0.9394 - val_loss: 0.2414 - val_accuracy: 0.9377\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 175ms/step - loss: 0.2364 - accuracy: 0.9393 - val_loss: 0.2378 - val_accuracy: 0.9380\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 176ms/step - loss: 0.2909 - accuracy: 0.8751 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 180ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 4.5751e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 182ms/step - loss: 5.9625e-04 - accuracy: 1.0000 - val_loss: 2.0439e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 179ms/step - loss: 3.1315e-04 - accuracy: 1.0000 - val_loss: 1.2273e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 179ms/step - loss: 1.9777e-04 - accuracy: 1.0000 - val_loss: 8.1527e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 13s 183ms/step - loss: 0.7821 - accuracy: 0.8511 - val_loss: 0.3471 - val_accuracy: 0.8283\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 13s 185ms/step - loss: 0.0348 - accuracy: 0.9917 - val_loss: 0.3049 - val_accuracy: 0.8285\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 13s 182ms/step - loss: 0.0269 - accuracy: 0.9919 - val_loss: 0.2505 - val_accuracy: 0.8328\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 13s 185ms/step - loss: 0.0241 - accuracy: 0.9912 - val_loss: 0.2260 - val_accuracy: 0.8404\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 15s 211ms/step - loss: 0.0226 - accuracy: 0.9914 - val_loss: 0.2156 - val_accuracy: 0.8445\n",
      "4279/4279 [==============================] - 14s 3ms/step - loss: 0.0956 - accuracy: 0.9874\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1176 - accuracy: 0.9762\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 165ms/step - loss: 0.0268 - accuracy: 0.9893 - val_loss: 0.5905 - val_accuracy: 0.6577\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.0235 - accuracy: 0.9908 - val_loss: 0.8547 - val_accuracy: 0.4116\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 168ms/step - loss: 0.0221 - accuracy: 0.9919 - val_loss: 0.8431 - val_accuracy: 0.4417\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 165ms/step - loss: 0.0211 - accuracy: 0.9923 - val_loss: 0.6871 - val_accuracy: 0.5820\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 158ms/step - loss: 0.0207 - accuracy: 0.9929 - val_loss: 0.6624 - val_accuracy: 0.6116\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 163ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.6737 - val_accuracy: 0.7354\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 159ms/step - loss: 0.0147 - accuracy: 0.9957 - val_loss: 0.6647 - val_accuracy: 0.7361\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 166ms/step - loss: 0.0146 - accuracy: 0.9959 - val_loss: 0.7036 - val_accuracy: 0.7359\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 155ms/step - loss: 0.0142 - accuracy: 0.9960 - val_loss: 0.8391 - val_accuracy: 0.7330\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 159ms/step - loss: 0.0140 - accuracy: 0.9963 - val_loss: 0.7109 - val_accuracy: 0.7379\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 170ms/step - loss: 0.4226 - accuracy: 0.9156 - val_loss: 0.2991 - val_accuracy: 0.9353\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 166ms/step - loss: 0.2646 - accuracy: 0.9380 - val_loss: 0.2512 - val_accuracy: 0.9378\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 163ms/step - loss: 0.2416 - accuracy: 0.9395 - val_loss: 0.2409 - val_accuracy: 0.9380\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 169ms/step - loss: 0.2348 - accuracy: 0.9395 - val_loss: 0.2364 - val_accuracy: 0.9381\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 164ms/step - loss: 0.2315 - accuracy: 0.9397 - val_loss: 0.2337 - val_accuracy: 0.9377\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 172ms/step - loss: 0.4446 - accuracy: 0.8266 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 4s 163ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.2401e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 167ms/step - loss: 2.8940e-04 - accuracy: 1.0000 - val_loss: 1.0390e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 1.5808e-04 - accuracy: 1.0000 - val_loss: 6.3850e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 167ms/step - loss: 1.0060e-04 - accuracy: 1.0000 - val_loss: 4.2016e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 174ms/step - loss: 0.9476 - accuracy: 0.8265 - val_loss: 0.3017 - val_accuracy: 0.8329\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 12s 173ms/step - loss: 0.0310 - accuracy: 0.9926 - val_loss: 0.2474 - val_accuracy: 0.8450\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 12s 172ms/step - loss: 0.0236 - accuracy: 0.9926 - val_loss: 0.2102 - val_accuracy: 0.8667\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 12s 174ms/step - loss: 0.0212 - accuracy: 0.9930 - val_loss: 0.1953 - val_accuracy: 0.8747\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 12s 173ms/step - loss: 0.0196 - accuracy: 0.9935 - val_loss: 0.1707 - val_accuracy: 0.8932\n",
      "4279/4279 [==============================] - 13s 3ms/step - loss: 0.1120 - accuracy: 0.9881\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1584 - accuracy: 0.9450\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 168ms/step - loss: 0.0215 - accuracy: 0.9925 - val_loss: 0.7833 - val_accuracy: 0.5243\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 166ms/step - loss: 0.0198 - accuracy: 0.9934 - val_loss: 0.7902 - val_accuracy: 0.5490\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.0188 - accuracy: 0.9937 - val_loss: 0.9501 - val_accuracy: 0.5128\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 163ms/step - loss: 0.0182 - accuracy: 0.9939 - val_loss: 0.7126 - val_accuracy: 0.6246\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 164ms/step - loss: 0.0181 - accuracy: 0.9938 - val_loss: 0.7349 - val_accuracy: 0.6260\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 168ms/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 0.7623 - val_accuracy: 0.7407\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 160ms/step - loss: 0.0137 - accuracy: 0.9967 - val_loss: 0.8103 - val_accuracy: 0.7394\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 164ms/step - loss: 0.0130 - accuracy: 0.9967 - val_loss: 0.6687 - val_accuracy: 0.7534\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 162ms/step - loss: 0.0128 - accuracy: 0.9968 - val_loss: 0.7588 - val_accuracy: 0.7483\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 169ms/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.8893 - val_accuracy: 0.7416\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 166ms/step - loss: 0.4249 - accuracy: 0.9124 - val_loss: 0.3024 - val_accuracy: 0.9360\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 168ms/step - loss: 0.2633 - accuracy: 0.9392 - val_loss: 0.2513 - val_accuracy: 0.9379\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 163ms/step - loss: 0.2399 - accuracy: 0.9396 - val_loss: 0.2404 - val_accuracy: 0.9381\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 164ms/step - loss: 0.2333 - accuracy: 0.9397 - val_loss: 0.2357 - val_accuracy: 0.9378\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 168ms/step - loss: 0.2302 - accuracy: 0.9397 - val_loss: 0.2334 - val_accuracy: 0.9377\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 173ms/step - loss: 0.5237 - accuracy: 0.8009 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 171ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.5915e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 173ms/step - loss: 1.7631e-04 - accuracy: 1.0000 - val_loss: 4.2222e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 173ms/step - loss: 4.8378e-05 - accuracy: 1.0000 - val_loss: 1.2926e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 1.7823e-05 - accuracy: 1.0000 - val_loss: 6.0347e-06 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 177ms/step - loss: 1.1751 - accuracy: 0.8126 - val_loss: 0.2492 - val_accuracy: 0.8483\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 12s 176ms/step - loss: 0.0255 - accuracy: 0.9933 - val_loss: 0.2278 - val_accuracy: 0.8544\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 12s 175ms/step - loss: 0.0220 - accuracy: 0.9934 - val_loss: 0.2038 - val_accuracy: 0.8690\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 13s 182ms/step - loss: 0.0205 - accuracy: 0.9935 - val_loss: 0.1896 - val_accuracy: 0.8784\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 12s 176ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 0.1863 - val_accuracy: 0.8783\n",
      "4279/4279 [==============================] - 14s 3ms/step - loss: 0.1049 - accuracy: 0.9884\n",
      "1721/1721 [==============================] - 6s 4ms/step - loss: 0.1451 - accuracy: 0.9514: 0s - loss:\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list,1)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr105C3krum.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.09564570337533951, 0.11760050803422928], [0.11199367791414261, 0.1584279090166092], [0.10485518723726273, 0.1450893133878708]]\n",
      "Accuracy for iterations:  [[0.9873571991920471, 0.9762043356895447], [0.9880729913711548, 0.9449793100357056], [0.9883724451065063, 0.9513550996780396]]\n",
      "F1 for iterations:  [[0.9873610568222886, 0.9761933244015109], [0.9880765019718583, 0.9446595180383826], [0.9883761664384368, 0.9511333102702614]]\n",
      "Precision for iterations:  [[0.9874329652087068, 0.9762085150909667], [0.9881438005791636, 0.9468737670164072], [0.9884569580419813, 0.9526185930330656]]\n",
      "Recall for iterations:  [[0.9873572117210553, 0.9762043159194943], [0.98807297905285, 0.9449792923054566], [0.9883724327324783, 0.9513550824674852]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 3 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_14132/512859027.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr255C3krum.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 178ms/step - loss: 0.5228 - accuracy: 0.7493 - val_loss: 1.8066 - val_accuracy: 0.0433\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 178ms/step - loss: 0.1801 - accuracy: 0.9798 - val_loss: 3.8603 - val_accuracy: 0.1330\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 169ms/step - loss: 0.0786 - accuracy: 0.9894 - val_loss: 3.5279 - val_accuracy: 0.1339\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 0.0490 - accuracy: 0.9893 - val_loss: 1.5701 - val_accuracy: 0.1440\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 181ms/step - loss: 0.0360 - accuracy: 0.9896 - val_loss: 1.4584 - val_accuracy: 0.1703\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 170ms/step - loss: 0.0217 - accuracy: 0.9949 - val_loss: 0.8944 - val_accuracy: 0.7270\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 182ms/step - loss: 0.0202 - accuracy: 0.9950 - val_loss: 0.7971 - val_accuracy: 0.7272\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 170ms/step - loss: 0.0204 - accuracy: 0.9950 - val_loss: 0.6535 - val_accuracy: 0.7280\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 172ms/step - loss: 0.0187 - accuracy: 0.9951 - val_loss: 0.7351 - val_accuracy: 0.7274\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 165ms/step - loss: 0.0182 - accuracy: 0.9950 - val_loss: 0.6624 - val_accuracy: 0.7284\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 173ms/step - loss: 0.6819 - accuracy: 0.8250 - val_loss: 0.4610 - val_accuracy: 0.8561\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 181ms/step - loss: 0.4379 - accuracy: 0.8618 - val_loss: 0.4263 - val_accuracy: 0.8635\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 172ms/step - loss: 0.4215 - accuracy: 0.8645 - val_loss: 0.4164 - val_accuracy: 0.8646\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 171ms/step - loss: 0.4141 - accuracy: 0.8655 - val_loss: 0.4112 - val_accuracy: 0.8650\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 171ms/step - loss: 0.4087 - accuracy: 0.8657 - val_loss: 0.4070 - val_accuracy: 0.8653\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 6s 209ms/step - loss: 0.1909 - accuracy: 0.9174 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 202ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.3299e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 6s 207ms/step - loss: 4.3973e-04 - accuracy: 1.0000 - val_loss: 1.4248e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 6s 220ms/step - loss: 2.0293e-04 - accuracy: 1.0000 - val_loss: 6.8984e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 6s 208ms/step - loss: 1.0073e-04 - accuracy: 1.0000 - val_loss: 3.5841e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 15s 210ms/step - loss: 0.9262 - accuracy: 0.8378 - val_loss: 0.4454 - val_accuracy: 0.8277\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 15s 217ms/step - loss: 0.0373 - accuracy: 0.9921 - val_loss: 0.3436 - val_accuracy: 0.8277\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 14s 201ms/step - loss: 0.0270 - accuracy: 0.9921 - val_loss: 0.2653 - val_accuracy: 0.8295\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 14s 204ms/step - loss: 0.0240 - accuracy: 0.9913 - val_loss: 0.2422 - val_accuracy: 0.8337\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 14s 202ms/step - loss: 0.0225 - accuracy: 0.9914 - val_loss: 0.2281 - val_accuracy: 0.8348\n",
      "4279/4279 [==============================] - 15s 3ms/step - loss: 0.1473 - accuracy: 0.9660\n",
      "1721/1721 [==============================] - 6s 4ms/step - loss: 0.2049 - accuracy: 0.9168\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 203ms/step - loss: 0.0254 - accuracy: 0.9889 - val_loss: 1.0474 - val_accuracy: 0.2002\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 0.0230 - accuracy: 0.9911 - val_loss: 0.7561 - val_accuracy: 0.4788\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 0.0216 - accuracy: 0.9923 - val_loss: 0.8325 - val_accuracy: 0.4148\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 207ms/step - loss: 0.0205 - accuracy: 0.9929 - val_loss: 0.6739 - val_accuracy: 0.5717\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.0194 - accuracy: 0.9931 - val_loss: 0.5590 - val_accuracy: 0.6699\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 217ms/step - loss: 0.0156 - accuracy: 0.9957 - val_loss: 0.5432 - val_accuracy: 0.7396\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 211ms/step - loss: 0.0144 - accuracy: 0.9958 - val_loss: 0.5129 - val_accuracy: 0.7412\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 189ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.6116 - val_accuracy: 0.7373\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 177ms/step - loss: 0.0136 - accuracy: 0.9963 - val_loss: 0.6578 - val_accuracy: 0.7373\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 180ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.5718 - val_accuracy: 0.7468\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.8369 - accuracy: 0.8189 - val_loss: 0.5208 - val_accuracy: 0.8560\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 193ms/step - loss: 0.4524 - accuracy: 0.8579 - val_loss: 0.4280 - val_accuracy: 0.8644\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.4160 - accuracy: 0.8653 - val_loss: 0.4117 - val_accuracy: 0.8649\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.4062 - accuracy: 0.8658 - val_loss: 0.4068 - val_accuracy: 0.8641\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 189ms/step - loss: 0.4024 - accuracy: 0.8656 - val_loss: 0.4037 - val_accuracy: 0.8641\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 6s 231ms/step - loss: 0.3679 - accuracy: 0.8471 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 6s 233ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.8595e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 6s 236ms/step - loss: 4.5949e-04 - accuracy: 1.0000 - val_loss: 1.4752e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 6s 231ms/step - loss: 2.1910e-04 - accuracy: 1.0000 - val_loss: 8.3878e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 6s 235ms/step - loss: 1.3214e-04 - accuracy: 1.0000 - val_loss: 5.3359e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 17s 240ms/step - loss: 0.9943 - accuracy: 0.8156 - val_loss: 0.3834 - val_accuracy: 0.8283\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 17s 244ms/step - loss: 0.0329 - accuracy: 0.9926 - val_loss: 0.2836 - val_accuracy: 0.8334\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 17s 240ms/step - loss: 0.0241 - accuracy: 0.9929 - val_loss: 0.2322 - val_accuracy: 0.8560\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 17s 242ms/step - loss: 0.0214 - accuracy: 0.9932 - val_loss: 0.2224 - val_accuracy: 0.8618\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 17s 240ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.1907 - val_accuracy: 0.8825\n",
      "4279/4279 [==============================] - 18s 4ms/step - loss: 0.1653 - accuracy: 0.9584\n",
      "1721/1721 [==============================] - 7s 4ms/step - loss: 0.1972 - accuracy: 0.9208: 0s - loss: 0.1994 - accuracy: \n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.0218 - accuracy: 0.9929 - val_loss: 0.8703 - val_accuracy: 0.4408\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.0196 - accuracy: 0.9933 - val_loss: 0.8229 - val_accuracy: 0.5262\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 4s 245ms/step - loss: 0.0184 - accuracy: 0.9937 - val_loss: 0.7907 - val_accuracy: 0.5660\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 4s 234ms/step - loss: 0.0180 - accuracy: 0.9941 - val_loss: 0.7784 - val_accuracy: 0.5969\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.0172 - accuracy: 0.9941 - val_loss: 0.7465 - val_accuracy: 0.6185\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 239ms/step - loss: 0.0144 - accuracy: 0.9959 - val_loss: 0.6988 - val_accuracy: 0.7475\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 236ms/step - loss: 0.0130 - accuracy: 0.9965 - val_loss: 0.6638 - val_accuracy: 0.7532\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 229ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.8607 - val_accuracy: 0.7392\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 239ms/step - loss: 0.0124 - accuracy: 0.9968 - val_loss: 0.7314 - val_accuracy: 0.7517\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 230ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.8127 - val_accuracy: 0.7483\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 6s 241ms/step - loss: 0.8710 - accuracy: 0.8123 - val_loss: 0.5249 - val_accuracy: 0.8499\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 6s 237ms/step - loss: 0.4530 - accuracy: 0.8590 - val_loss: 0.4282 - val_accuracy: 0.8637\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 6s 234ms/step - loss: 0.4130 - accuracy: 0.8653 - val_loss: 0.4120 - val_accuracy: 0.8640\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 6s 236ms/step - loss: 0.4043 - accuracy: 0.8655 - val_loss: 0.4062 - val_accuracy: 0.8639\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 6s 239ms/step - loss: 0.3995 - accuracy: 0.8657 - val_loss: 0.4023 - val_accuracy: 0.8641\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 6s 233ms/step - loss: 0.3428 - accuracy: 0.8443 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 6s 238ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.4634e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 6s 238ms/step - loss: 3.2283e-04 - accuracy: 1.0000 - val_loss: 1.2424e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 6s 237ms/step - loss: 1.9452e-04 - accuracy: 1.0000 - val_loss: 8.3598e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 6s 239ms/step - loss: 1.3569e-04 - accuracy: 1.0000 - val_loss: 5.9348e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 17s 241ms/step - loss: 0.8715 - accuracy: 0.8217 - val_loss: 0.2869 - val_accuracy: 0.8348\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 17s 241ms/step - loss: 0.0231 - accuracy: 0.9940 - val_loss: 0.2039 - val_accuracy: 0.8666\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 17s 242ms/step - loss: 0.0184 - accuracy: 0.9943 - val_loss: 0.1646 - val_accuracy: 0.8985\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 17s 246ms/step - loss: 0.0174 - accuracy: 0.9946 - val_loss: 0.1660 - val_accuracy: 0.9010\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 16s 226ms/step - loss: 0.0166 - accuracy: 0.9949 - val_loss: 0.1663 - val_accuracy: 0.9030\n",
      "4279/4279 [==============================] - 45s 10ms/step - loss: 0.2380 - accuracy: 0.9374\n",
      "1721/1721 [==============================] - 20s 11ms/step - loss: 0.2361 - accuracy: 0.8830\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list,1)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr255C3krum.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.14725399017333984, 0.20486125349998474], [0.1653129756450653, 0.19722625613212585], [0.23801814019680023, 0.2360980212688446]]\n",
      "Accuracy for iterations:  [[0.9659791588783264, 0.9168241024017334], [0.9584489464759827, 0.9208202958106995], [0.9373630285263062, 0.8830015063285828]]\n",
      "F1 for iterations:  [[0.9659263331942735, 0.9157854905944768], [0.9583641109046129, 0.9199154182913], [0.9370426037032887, 0.8802791267222402]]\n",
      "Precision for iterations:  [[0.9666463352845058, 0.9228811357604424], [0.9594580735964156, 0.9261601643956267], [0.9411268351843823, 0.8968913352484783]]\n",
      "Recall for iterations:  [[0.965979140494902, 0.9168240935842477], [0.9584489760144906, 0.9208203153382257], [0.9373630547196822, 0.8830015258301243]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
