{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Attack classification: FTL with Bot-IoT as source dataset and UNSWNB-15 as target dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDs are = **idFTLcat5x**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Disable warns\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for test and training datasets (to be able to train and make predictions to evaluate)\n",
    "def preprocessing(data): \n",
    "\n",
    "    # Select the 'proto' and 'state' values that I want\n",
    "    data = data.loc[(data['proto'] == 'tcp') | (data['proto'] =='udp') | (data['proto'] =='icmp') | (data['proto'] =='arp') | (data['proto'] =='ipv6-icmp') | (data['proto'] =='igmp') | (data['proto'] =='rarp'), :]\n",
    "    data = data.loc[(data['state'] == 'RST') | (data['state'] =='REQ') | (data['state'] =='INT') | (data['state'] =='FIN') | (data['state'] =='CON') | (data['state'] =='ECO') | (data['state'] =='ACC') | (data['state'] == 'PAR'), :]\n",
    "\n",
    "    # Creating categories dataframe\n",
    "    data_labels = pd.DataFrame()\n",
    "\n",
    "    # Drop the invalid features and select interested data features\n",
    "    data_features=data[['proto','srcip','sport','dstip','dsport','spkts','dpkts','sbytes','dbytes','state','stime','ltime','dur']]\n",
    "\n",
    "    \"\"\"PREPROCESSING\"\"\"\n",
    "\n",
    "\n",
    "    # Preprocess IP and ports features\n",
    "    # IP Source Address\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "\n",
    "    # IP Destination Address\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "    # Ports\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "\n",
    "    # Convert all ports with 0 decimal, and HEX to DEC\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    # Convert field to int format\n",
    "    data_features['srcip'] = data_features['srcip'].astype(int)\n",
    "    data_features['sport'] = data_features['sport'].astype(int)\n",
    "    data_features['dstip'] = data_features['dstip'].astype(int)\n",
    "    data_features['dsport'] = data_features['dsport'].astype(int)\n",
    "\n",
    "    # Convert some fields to logarithmic\n",
    "    log1p_col = ['dur', 'sbytes', 'dbytes', 'spkts']\n",
    "\n",
    "    for col in log1p_col:\n",
    "        data_features[col] = data_features[col].apply(np.log1p)\n",
    "        \n",
    "    # Transform to One Hot Encoding the Categories - normal, dos, reconnaissance, generic, exploits, worms, fuzzers, analysis, backdoor, shellcode\n",
    "    data_labels.insert(0, 'dos', data['attack_cat'].replace('dos', 1).replace(['reconnaissance', 'generic', 'exploits', 'worms', 'fuzzers', 'analysis', 'backdoor', 'shellcode'], 0))\n",
    "    data_labels.insert(1, 'reconnaissance', data['attack_cat'].replace('reconnaissance', 1).replace([ 'dos', 'generic', 'exploits', 'worms', 'fuzzers', 'analysis', 'backdoor', 'shellcode'], 0))\n",
    "    data_labels.insert(2, 'generic', data['attack_cat'].replace('generic', 1).replace(['dos', 'reconnaissance', 'exploits', 'worms', 'fuzzers', 'analysis', 'backdoor', 'shellcode'], 0))\n",
    "    data_labels.insert(3, 'exploits', data['attack_cat'].replace('exploits', 1).replace([ 'dos', 'reconnaissance', 'generic', 'worms', 'fuzzers', 'analysis', 'backdoor', 'shellcode'], 0))\n",
    "    data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "    # Transform to One hot encoding - FEATURES\n",
    "    data_features=pd.get_dummies(data_features)\n",
    "\n",
    "    # Generate 2 new columns to fit with training\n",
    "    auxCol=data_features['sbytes']\n",
    "    auxCol=0\n",
    "\n",
    "      # As we are using different datasets that might not have all representations, we are going to detect and add the missing columns \n",
    "    # The columns that can have types are: proto and state: need to check if all representations are done \n",
    "    state_cols = [col for col in data_features if col.startswith('state_')]\n",
    "    proto_cols = [col for col in data_features if col.startswith('proto_')]\n",
    "    \n",
    "    # Check if all columns are present\n",
    "    if 'state_PAR' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_PAR', auxCol, True)\n",
    "    if 'state_ACC' not in state_cols: \n",
    "        data_features.insert(data_features.shape[1], 'state_ACC', auxCol, True)\n",
    "    if 'state_ECO' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_ECO', auxCol, True)\n",
    "    if 'state_CON' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_CON', auxCol, True)\n",
    "    if 'state_FIN' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_FIN', auxCol, True)\n",
    "    if 'state_INT' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_INT', auxCol, True)\n",
    "    if 'state_REQ' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_REQ', auxCol, True)\n",
    "    if 'state_RST' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_RST', auxCol, True)\n",
    "    if 'proto_igmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_igmp', auxCol, True)\n",
    "    if 'proto_arp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_arp', auxCol, True)\n",
    "    if 'proto_icmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_icmp', auxCol, True)\n",
    "    if 'proto_udp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_udp', auxCol, True)\n",
    "    if 'proto_tcp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_tcp', auxCol, True)\n",
    "\n",
    "    # Normalize all data features\n",
    "    data_features = StandardScaler().fit_transform(data_features)\n",
    "\n",
    "    #Add dimension to data features\n",
    "    data_features = np.expand_dims(data_features, axis=2)\n",
    "    data_features = np.expand_dims(data_features, axis=3)\n",
    "\n",
    "    x = data_features\n",
    "    y = data_labels.to_numpy()\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cat = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Categories.csv')\n",
    "test_cat_eq = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Categories_Eq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc, yc = preprocessing(test_cat)\n",
    "xce, yce = preprocessing(test_cat_eq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# found to be best model \n",
    "pretrained_mod = models.load_model('../code/models/Bot_cat5_5_15.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all layers to not trainable\n",
    "pretrained_mod.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only convolutional base layers \n",
    "pretrained_mod.pop()\n",
    "pretrained_mod.pop()\n",
    "pretrained_mod.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 24, 1, 108)        216       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 1, 16)         3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 1, 16)         64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 24, 1, 16)         0         \n",
      "=================================================================\n",
      "Total params: 3,752\n",
      "Trainable params: 0\n",
      "Non-trainable params: 3,752\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrained_mod.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build TL model (local nodes) + global eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(pretrained_mod)\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(Dense(160, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(Dense(320, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns values of loss, accuracy, f1, precision and recall of model evaluating with test dataset \n",
    "def evaluation(model, x, y): \n",
    "    loss, accuracy = model.evaluate(x, y)\n",
    "    y_pred = model.predict(x)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y = np.argmax(y, axis=1)\n",
    "    report = classification_report(y, y_pred, labels = [i for i in range(4)], target_names=['dos', 'reconnaissance', 'generic', 'exploits'], output_dict=True)\n",
    "    # Obtain f1, precision and recall from the report\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    return loss, accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weiszfeld_update(points, tol=1e-5, max_iter=100):\n",
    "    \"\"\"\n",
    "    Compute the geometric median using Weiszfeld's algorithm.\n",
    "\n",
    "    Args:\n",
    "    points: A list of points (numpy arrays) to find the geometric median of.\n",
    "    tol: Tolerance for stopping criterion.\n",
    "    max_iter: Maximum number of iterations.\n",
    "\n",
    "    Returns:\n",
    "    The geometric median of the points.\n",
    "    \"\"\"\n",
    "    points = np.array(points)\n",
    "    median = np.mean(points, axis=0)\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        distances = np.linalg.norm(points - median, axis=1)\n",
    "        nonzero_distances = np.where(distances != 0, distances, np.finfo(float).eps)\n",
    "        weights = 1 / nonzero_distances\n",
    "        new_median = np.sum(points * weights[:, None], axis=0) / np.sum(weights)\n",
    "\n",
    "        if np.linalg.norm(new_median - median) < tol:\n",
    "            return new_median\n",
    "\n",
    "        median = new_median\n",
    "\n",
    "    return median\n",
    "\n",
    "def aggregate(grad_list):\n",
    "    \"\"\"\n",
    "    Apply Geometric Median aggregation method to a list of gradients.\n",
    "\n",
    "    Args:\n",
    "    grad_list: List of gradients from different models. Each element in the list\n",
    "               is a list of gradients for each layer of a model.\n",
    "\n",
    "    Returns:\n",
    "    The geometric median of the gradients.\n",
    "    \"\"\"\n",
    "    # Flatten gradients to compute geometric median\n",
    "    flat_grads = [tf.concat([tf.reshape(g, [-1]) for g in grad], axis=0).numpy() for grad in grad_list]\n",
    "\n",
    "    # Compute geometric median using Weiszfeld's algorithm\n",
    "    flat_median = weiszfeld_update(flat_grads)\n",
    "\n",
    "    # Reshape the flat median back to the original shape\n",
    "    median_grad = []\n",
    "    index = 0\n",
    "    for grad in grad_list[0]:\n",
    "        shape = tf.shape(grad)\n",
    "        size = tf.reduce_prod(shape)\n",
    "        median_grad.append(tf.reshape(flat_median[index:index + size], shape))\n",
    "        index += size\n",
    "\n",
    "    return median_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cat5A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat5A-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat5A-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat5A-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat5A-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat5A-Part5.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idFTLcat51.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=1024)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 0.4229 - accuracy: 0.9105 - val_loss: 5.6599 - val_accuracy: 0.1411\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 116ms/step - loss: 0.0153 - accuracy: 0.9999 - val_loss: 7.1935 - val_accuracy: 0.1411\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 118ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 7.8593 - val_accuracy: 0.1411\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 3s 96ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 8.4090 - val_accuracy: 0.1411\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 115ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 9.0717 - val_accuracy: 0.1411\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 187ms/step - loss: 1.8439e-04 - accuracy: 1.0000 - val_loss: 14.0552 - val_accuracy: 0.1411\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 3s 104ms/step - loss: 9.4973e-06 - accuracy: 1.0000 - val_loss: 15.2879 - val_accuracy: 0.1411\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 3s 100ms/step - loss: 9.4614e-06 - accuracy: 1.0000 - val_loss: 16.2193 - val_accuracy: 0.1411\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 3.5286e-06 - accuracy: 1.0000 - val_loss: 16.7728 - val_accuracy: 0.1411\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 3s 85ms/step - loss: 2.5535e-06 - accuracy: 1.0000 - val_loss: 17.0686 - val_accuracy: 0.1411\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 1.6711e-06 - accuracy: 1.0000 - val_loss: 18.7601 - val_accuracy: 0.1411\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 3s 99ms/step - loss: 8.1642e-07 - accuracy: 1.0000 - val_loss: 19.9525 - val_accuracy: 0.1411\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 3s 90ms/step - loss: 3.6842e-07 - accuracy: 1.0000 - val_loss: 20.5439 - val_accuracy: 0.1411\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 3s 97ms/step - loss: 1.7117e-06 - accuracy: 1.0000 - val_loss: 21.8893 - val_accuracy: 0.1411\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 3s 94ms/step - loss: 9.8319e-08 - accuracy: 1.0000 - val_loss: 22.1728 - val_accuracy: 0.1411\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 1.2729e-07 - accuracy: 1.0000 - val_loss: 22.3107 - val_accuracy: 0.1410\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 5.0670e-08 - accuracy: 1.0000 - val_loss: 22.5077 - val_accuracy: 0.1410\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 3s 86ms/step - loss: 1.1223e-07 - accuracy: 1.0000 - val_loss: 22.8610 - val_accuracy: 0.1410\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 3s 94ms/step - loss: 3.8728e-08 - accuracy: 1.0000 - val_loss: 23.0832 - val_accuracy: 0.1410\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 3s 81ms/step - loss: 4.7971e-08 - accuracy: 1.0000 - val_loss: 23.3904 - val_accuracy: 0.1410\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 3s 108ms/step - loss: 2.9755e-08 - accuracy: 1.0000 - val_loss: 23.7878 - val_accuracy: 0.1413\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 3s 86ms/step - loss: 4.6609e-08 - accuracy: 1.0000 - val_loss: 24.0515 - val_accuracy: 0.1413\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 3.1142e-08 - accuracy: 1.0000 - val_loss: 24.2285 - val_accuracy: 0.1413\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 7.5053e-08 - accuracy: 1.0000 - val_loss: 24.6025 - val_accuracy: 0.1413\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 3s 82ms/step - loss: 1.4081e-08 - accuracy: 1.0000 - val_loss: 24.7236 - val_accuracy: 0.1413\n",
      "2017/2017 [==============================] - 10s 5ms/step - loss: 4.2384 - accuracy: 0.8320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 1s 7ms/step - loss: 14.5404 - accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 3s 103ms/step - loss: 2.2340e-08 - accuracy: 1.0000 - val_loss: 24.6762 - val_accuracy: 0.1411\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 3s 81ms/step - loss: 2.2683e-08 - accuracy: 1.0000 - val_loss: 24.8108 - val_accuracy: 0.1411s: 2\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 2s 71ms/step - loss: 1.6845e-08 - accuracy: 1.0000 - val_loss: 24.8923 - val_accuracy: 0.1411\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 2s 79ms/step - loss: 1.8946e-08 - accuracy: 1.0000 - val_loss: 25.0081 - val_accuracy: 0.1411\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 3s 85ms/step - loss: 1.5727e-08 - accuracy: 1.0000 - val_loss: 25.1729 - val_accuracy: 0.1411\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 4s 118ms/step - loss: 1.7755e-08 - accuracy: 1.0000 - val_loss: 25.0997 - val_accuracy: 0.1411\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 3s 91ms/step - loss: 8.0894e-09 - accuracy: 1.0000 - val_loss: 25.1600 - val_accuracy: 0.1411\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 2s 78ms/step - loss: 1.5966e-08 - accuracy: 1.0000 - val_loss: 25.2332 - val_accuracy: 0.1411\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 3s 93ms/step - loss: 2.0634e-08 - accuracy: 1.0000 - val_loss: 25.4318 - val_accuracy: 0.1411\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 3s 87ms/step - loss: 2.3862e-08 - accuracy: 1.0000 - val_loss: 25.5506 - val_accuracy: 0.1411\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 3s 111ms/step - loss: 9.7010e-09 - accuracy: 1.0000 - val_loss: 25.5728 - val_accuracy: 0.1411\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 3s 91ms/step - loss: 1.4112e-08 - accuracy: 1.0000 - val_loss: 25.6227 - val_accuracy: 0.1411\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 2s 77ms/step - loss: 6.7553e-09 - accuracy: 1.0000 - val_loss: 25.7026 - val_accuracy: 0.1411\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 3s 86ms/step - loss: 8.8873e-09 - accuracy: 1.0000 - val_loss: 25.7491 - val_accuracy: 0.1411\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 3s 85ms/step - loss: 1.9211e-08 - accuracy: 1.0000 - val_loss: 25.8529 - val_accuracy: 0.1411\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 3s 95ms/step - loss: 7.2871e-09 - accuracy: 1.0000 - val_loss: 25.7699 - val_accuracy: 0.1410\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 8.3124e-09 - accuracy: 1.0000 - val_loss: 25.8333 - val_accuracy: 0.1410\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 2s 71ms/step - loss: 8.4437e-09 - accuracy: 1.0000 - val_loss: 25.8847 - val_accuracy: 0.1410\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 3.5665e-09 - accuracy: 1.0000 - val_loss: 25.9213 - val_accuracy: 0.1410\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 2s 79ms/step - loss: 1.0395e-08 - accuracy: 1.0000 - val_loss: 25.9773 - val_accuracy: 0.1410\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 3s 99ms/step - loss: 7.0946e-09 - accuracy: 1.0000 - val_loss: 26.3239 - val_accuracy: 0.1413\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 2s 79ms/step - loss: 5.5793e-09 - accuracy: 1.0000 - val_loss: 26.3590 - val_accuracy: 0.1413\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 2s 79ms/step - loss: 6.8324e-09 - accuracy: 1.0000 - val_loss: 26.3975 - val_accuracy: 0.1413\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 2s 73ms/step - loss: 4.9238e-09 - accuracy: 1.0000 - val_loss: 26.4341 - val_accuracy: 0.1413\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 2s 80ms/step - loss: 3.8172e-09 - accuracy: 1.0000 - val_loss: 26.4822 - val_accuracy: 0.1413\n",
      "2017/2017 [==============================] - 7s 3ms/step - loss: 4.5287 - accuracy: 0.8320\n",
      " 32/119 [=======>......................] - ETA: 0s - loss: 1.5259 - accuracy: 0.9268    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 3ms/step - loss: 15.5768 - accuracy: 0.2500A: 0s - loss: 15.1958 - accuracy: 0.264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 8.8141e-09 - accuracy: 1.0000 - val_loss: 26.4119 - val_accuracy: 0.1411\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 8.2243e-09 - accuracy: 1.0000 - val_loss: 26.4592 - val_accuracy: 0.1411\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 1.1922e-08 - accuracy: 1.0000 - val_loss: 26.5408 - val_accuracy: 0.1411\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 7.9697e-09 - accuracy: 1.0000 - val_loss: 26.5962 - val_accuracy: 0.1411\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 2.9051e-08 - accuracy: 1.0000 - val_loss: 26.7099 - val_accuracy: 0.1411\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 4.1797e-09 - accuracy: 1.0000 - val_loss: 26.5864 - val_accuracy: 0.1411\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 8.3473e-09 - accuracy: 1.0000 - val_loss: 26.6185 - val_accuracy: 0.1411\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 2s 56ms/step - loss: 2.4137e-09 - accuracy: 1.0000 - val_loss: 26.6402 - val_accuracy: 0.1411\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 5.8106e-09 - accuracy: 1.0000 - val_loss: 26.7008 - val_accuracy: 0.1411\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 2s 56ms/step - loss: 3.5396e-09 - accuracy: 1.0000 - val_loss: 26.7487 - val_accuracy: 0.1411\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 2s 63ms/step - loss: 2.0783e-09 - accuracy: 1.0000 - val_loss: 26.7531 - val_accuracy: 0.1411\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 3.6591e-09 - accuracy: 1.0000 - val_loss: 26.7671 - val_accuracy: 0.1411\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 3.1540e-09 - accuracy: 1.0000 - val_loss: 26.7919 - val_accuracy: 0.1411\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 9.6967e-09 - accuracy: 1.0000 - val_loss: 26.8400 - val_accuracy: 0.1411\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 3.5280e-09 - accuracy: 1.0000 - val_loss: 26.8709 - val_accuracy: 0.1411\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 2s 72ms/step - loss: 2.1900e-09 - accuracy: 1.0000 - val_loss: 26.7698 - val_accuracy: 0.1410\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 8.2620e-09 - accuracy: 1.0000 - val_loss: 26.7824 - val_accuracy: 0.1410\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 2.9689e-09 - accuracy: 1.0000 - val_loss: 26.8230 - val_accuracy: 0.1410\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 4.9776e-09 - accuracy: 1.0000 - val_loss: 26.8905 - val_accuracy: 0.1410\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 2.1862e-09 - accuracy: 1.0000 - val_loss: 26.9120 - val_accuracy: 0.1410\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 2s 71ms/step - loss: 4.6577e-09 - accuracy: 1.0000 - val_loss: 27.2606 - val_accuracy: 0.1413\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 9.0607e-09 - accuracy: 1.0000 - val_loss: 27.3120 - val_accuracy: 0.1413\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 2.8918e-09 - accuracy: 1.0000 - val_loss: 27.3316 - val_accuracy: 0.1413\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 4.4110e-09 - accuracy: 1.0000 - val_loss: 27.3674 - val_accuracy: 0.1413\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 6.2538e-09 - accuracy: 1.0000 - val_loss: 27.4680 - val_accuracy: 0.1413\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 4.6922 - accuracy: 0.8320\n",
      " 36/119 [========>.....................] - ETA: 0s - loss: 3.7116 - accuracy: 0.8238    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 3ms/step - loss: 16.1453 - accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3:\n",
    "            x, y = x4, y4\n",
    "        elif node == 4:\n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(y, predictions)\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xc, yc) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xce, yce)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idFTLcat51.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[4.23840856552124, 14.540366172790527], [4.528692245483398, 15.576830863952637], [4.692199230194092, 16.145299911499023]]\n",
      "Accuracy for iterations:  [[0.8319951891899109, 0.25], [0.8319951891899109, 0.25], [0.8319951891899109, 0.25]]\n",
      "F1 for iterations:  [[0.7556962665726199, 0.1], [0.7556962665726199, 0.1], [0.7556962665726199, 0.1]]\n",
      "Precision for iterations:  [[0.6922159529032929, 0.0625], [0.6922159529032929, 0.0625], [0.6922159529032929, 0.0625]]\n",
      "Recall for iterations:  [[0.831995163990328, 0.25], [0.831995163990328, 0.25], [0.831995163990328, 0.25]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cat5B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat5B-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat5B-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat5B-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat5B-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat5B-Part5.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idFTLcat52.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=4e-3)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=1024)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=4e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 258ms/step - loss: 1.6015 - accuracy: 0.4276 - val_loss: 4.8969 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 1.0164 - accuracy: 0.6217 - val_loss: 3.6059 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.8611 - accuracy: 0.6254 - val_loss: 2.1902 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.7904 - accuracy: 0.6385 - val_loss: 2.0228 - val_accuracy: 0.0356\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.7715 - accuracy: 0.6396 - val_loss: 2.0673 - val_accuracy: 0.0356\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 0s 244ms/step - loss: 1.0044 - accuracy: 0.5016 - val_loss: 2.3302 - val_accuracy: 0.0063\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.7943 - accuracy: 0.6327 - val_loss: 2.8985 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.8497 - accuracy: 0.6343 - val_loss: 2.1118 - val_accuracy: 0.0021\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.7488 - accuracy: 0.6563 - val_loss: 2.0812 - val_accuracy: 0.0021\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.7514 - accuracy: 0.6501 - val_loss: 2.4469 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 0s 238ms/step - loss: 0.7660 - accuracy: 0.6474 - val_loss: 2.0553 - val_accuracy: 0.0189\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.7485 - accuracy: 0.6590 - val_loss: 2.1283 - val_accuracy: 0.0147\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6937 - accuracy: 0.6731 - val_loss: 1.8710 - val_accuracy: 0.0482\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.7000 - accuracy: 0.6637 - val_loss: 1.6950 - val_accuracy: 0.1698\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6715 - accuracy: 0.6920 - val_loss: 1.8868 - val_accuracy: 0.1090\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 331ms/step - loss: 0.7470 - accuracy: 0.6464 - val_loss: 1.9813 - val_accuracy: 0.0776\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6835 - accuracy: 0.6773 - val_loss: 1.8004 - val_accuracy: 0.1027\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6621 - accuracy: 0.6905 - val_loss: 1.5872 - val_accuracy: 0.4319\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6329 - accuracy: 0.6946 - val_loss: 1.6591 - val_accuracy: 0.4340\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6255 - accuracy: 0.6936 - val_loss: 1.5536 - val_accuracy: 0.3312\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 0s 171ms/step - loss: 0.7060 - accuracy: 0.6688 - val_loss: 1.3382 - val_accuracy: 0.4612\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6348 - accuracy: 0.6861 - val_loss: 2.5517 - val_accuracy: 0.0797\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6401 - accuracy: 0.6835 - val_loss: 1.7587 - val_accuracy: 0.2180\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5984 - accuracy: 0.7102 - val_loss: 1.2532 - val_accuracy: 0.5094\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5955 - accuracy: 0.7223 - val_loss: 1.3097 - val_accuracy: 0.5283\n",
      "2017/2017 [==============================] - 8s 4ms/step - loss: 1.7138 - accuracy: 0.1716\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 0.9549 - accuracy: 0.5788\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 0s 190ms/step - loss: 0.9778 - accuracy: 0.5682 - val_loss: 2.8939 - val_accuracy: 0.0776\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7477 - accuracy: 0.6800 - val_loss: 3.7387 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.7232 - accuracy: 0.6899 - val_loss: 2.6535 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6964 - accuracy: 0.6794 - val_loss: 1.9830 - val_accuracy: 0.0042\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6549 - accuracy: 0.6899 - val_loss: 1.8032 - val_accuracy: 0.1321\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 0.7300 - accuracy: 0.6469 - val_loss: 1.7815 - val_accuracy: 0.0273\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6601 - accuracy: 0.6637 - val_loss: 1.6419 - val_accuracy: 0.4193\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6632 - accuracy: 0.6663 - val_loss: 1.3033 - val_accuracy: 0.4403\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.6416 - accuracy: 0.6868 - val_loss: 1.4682 - val_accuracy: 0.3564\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6243 - accuracy: 0.6894 - val_loss: 1.5269 - val_accuracy: 0.3983\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 0.6552 - accuracy: 0.6852 - val_loss: 1.2281 - val_accuracy: 0.5556\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6389 - accuracy: 0.6952 - val_loss: 2.0044 - val_accuracy: 0.2096\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6149 - accuracy: 0.6847 - val_loss: 1.4665 - val_accuracy: 0.2956\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6042 - accuracy: 0.7067 - val_loss: 1.1394 - val_accuracy: 0.4948\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5940 - accuracy: 0.7088 - val_loss: 1.3279 - val_accuracy: 0.4277\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 0.6889 - accuracy: 0.6705 - val_loss: 1.5613 - val_accuracy: 0.4423\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6008 - accuracy: 0.6999 - val_loss: 1.5351 - val_accuracy: 0.5681\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6475 - accuracy: 0.6857 - val_loss: 1.2451 - val_accuracy: 0.5094\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5774 - accuracy: 0.7093 - val_loss: 1.3564 - val_accuracy: 0.4172\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5861 - accuracy: 0.7130 - val_loss: 1.3657 - val_accuracy: 0.4486\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 318ms/step - loss: 0.6467 - accuracy: 0.6940 - val_loss: 1.1290 - val_accuracy: 0.5933\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.5943 - accuracy: 0.7034 - val_loss: 1.8542 - val_accuracy: 0.3522\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5776 - accuracy: 0.7129 - val_loss: 1.4914 - val_accuracy: 0.4549\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5517 - accuracy: 0.7276 - val_loss: 0.9093 - val_accuracy: 0.6981\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5519 - accuracy: 0.7291 - val_loss: 0.9535 - val_accuracy: 0.6771\n",
      "2017/2017 [==============================] - 9s 4ms/step - loss: 1.6421 - accuracy: 0.3061\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 0.8339 - accuracy: 0.6154\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 0s 190ms/step - loss: 0.8677 - accuracy: 0.6149 - val_loss: 2.3285 - val_accuracy: 0.2746\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6944 - accuracy: 0.6910 - val_loss: 2.8734 - val_accuracy: 0.0231\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6761 - accuracy: 0.6894 - val_loss: 2.1052 - val_accuracy: 0.0105\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6446 - accuracy: 0.6894 - val_loss: 1.5855 - val_accuracy: 0.1551\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6174 - accuracy: 0.7015 - val_loss: 1.5094 - val_accuracy: 0.2306\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 0s 234ms/step - loss: 0.7263 - accuracy: 0.6385 - val_loss: 1.2519 - val_accuracy: 0.5115\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6329 - accuracy: 0.6847 - val_loss: 1.6068 - val_accuracy: 0.5388\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6361 - accuracy: 0.6779 - val_loss: 1.3380 - val_accuracy: 0.5094\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6195 - accuracy: 0.6747 - val_loss: 1.1812 - val_accuracy: 0.5577\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5852 - accuracy: 0.7219 - val_loss: 1.1159 - val_accuracy: 0.5786\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 0.6200 - accuracy: 0.6852 - val_loss: 1.0335 - val_accuracy: 0.6352\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5938 - accuracy: 0.7067 - val_loss: 1.1983 - val_accuracy: 0.5723\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5758 - accuracy: 0.7104 - val_loss: 1.0595 - val_accuracy: 0.6247\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5544 - accuracy: 0.7151 - val_loss: 0.9395 - val_accuracy: 0.6981\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5449 - accuracy: 0.7188 - val_loss: 1.0200 - val_accuracy: 0.6478\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 0.6206 - accuracy: 0.6925 - val_loss: 1.1039 - val_accuracy: 0.5765\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5841 - accuracy: 0.7177 - val_loss: 1.6622 - val_accuracy: 0.4486\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5813 - accuracy: 0.7114 - val_loss: 1.1779 - val_accuracy: 0.5577\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5425 - accuracy: 0.7251 - val_loss: 0.8688 - val_accuracy: 0.6730\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5481 - accuracy: 0.7267 - val_loss: 0.9381 - val_accuracy: 0.6855\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 0.6385 - accuracy: 0.7150 - val_loss: 0.9522 - val_accuracy: 0.6478\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5820 - accuracy: 0.7234 - val_loss: 1.0981 - val_accuracy: 0.5996\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5334 - accuracy: 0.7344 - val_loss: 1.1612 - val_accuracy: 0.6038\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.5279 - accuracy: 0.7328 - val_loss: 0.8593 - val_accuracy: 0.7107\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5291 - accuracy: 0.7281 - val_loss: 0.8581 - val_accuracy: 0.7212\n",
      "2017/2017 [==============================] - 7s 3ms/step - loss: 1.6978 - accuracy: 0.4330: 0s - loss: 1\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 0.7640 - accuracy: 0.6662\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3:\n",
    "            x, y = x4, y4\n",
    "        elif node == 4:\n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(y, predictions)\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xc, yc) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xce, yce)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idFTLcat52.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[1.7138394117355347, 0.9549169540405273], [1.6420501470565796, 0.8339034914970398], [1.6977685689926147, 0.7639550566673279]]\n",
      "Accuracy for iterations:  [[0.1716008484363556, 0.5787671208381653], [0.30614110827445984, 0.6153846383094788], [0.4329778552055359, 0.6662275791168213]]\n",
      "F1 for iterations:  [[0.18693199653482287, 0.557625939613617], [0.3890261024843981, 0.6046166354040272], [0.5470595348702226, 0.6618960925929357]]\n",
      "Precision for iterations:  [[0.9050586310451745, 0.6491788968586947], [0.9053662343906709, 0.6360320979960882], [0.9048363263006283, 0.6724528571878456]]\n",
      "Recall for iterations:  [[0.1716008432016864, 0.5787671232876712], [0.30614111228222457, 0.6153846153846154], [0.4329778659557319, 0.66622760800843]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cat5C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat5C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat5C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat5C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat5C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat5C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_nodes = 5\n",
    "global_updates = 5\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idFTLcat53.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=1024)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 1.4679 - accuracy: 0.2844 - val_loss: 1.6180 - val_accuracy: 0.0021\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.3803 - accuracy: 0.3379 - val_loss: 1.7281 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.2561 - accuracy: 0.4386 - val_loss: 1.8447 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.1735 - accuracy: 0.4948 - val_loss: 1.9655 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.1238 - accuracy: 0.5556 - val_loss: 2.0911 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0573 - accuracy: 0.5703 - val_loss: 2.2154 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.0010 - accuracy: 0.5897 - val_loss: 2.3357 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.9625 - accuracy: 0.6007 - val_loss: 2.4527 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.9417 - accuracy: 0.6196 - val_loss: 2.5614 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.9141 - accuracy: 0.6275 - val_loss: 2.6607 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.8810 - accuracy: 0.6249 - val_loss: 2.7465 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 215ms/step - loss: 0.8911 - accuracy: 0.6165 - val_loss: 2.7926 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.8490 - accuracy: 0.6275 - val_loss: 2.8080 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8416 - accuracy: 0.6264 - val_loss: 2.8125 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.8319 - accuracy: 0.6317 - val_loss: 2.7989 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.8235 - accuracy: 0.6222 - val_loss: 2.7806 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.8137 - accuracy: 0.6196 - val_loss: 2.7624 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8016 - accuracy: 0.6380 - val_loss: 2.7443 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.7900 - accuracy: 0.6411 - val_loss: 2.7202 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7827 - accuracy: 0.6522 - val_loss: 2.6994 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.7807 - accuracy: 0.6359 - val_loss: 2.6810 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.7863 - accuracy: 0.6296 - val_loss: 2.6580 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.7821 - accuracy: 0.6348 - val_loss: 2.6362 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.7798 - accuracy: 0.6348 - val_loss: 2.6119 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.7724 - accuracy: 0.6380 - val_loss: 2.5819 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.7688 - accuracy: 0.6464 - val_loss: 2.5515 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.7644 - accuracy: 0.6632 - val_loss: 2.5229 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.7728 - accuracy: 0.6364 - val_loss: 2.4924 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.7587 - accuracy: 0.6432 - val_loss: 2.4669 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.7514 - accuracy: 0.6553 - val_loss: 2.4457 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7635 - accuracy: 0.6396 - val_loss: 2.4265 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 246ms/step - loss: 0.7662 - accuracy: 0.6280 - val_loss: 2.4170 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.7528 - accuracy: 0.6485 - val_loss: 2.4375 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.7701 - accuracy: 0.6438 - val_loss: 2.4329 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.7600 - accuracy: 0.6542 - val_loss: 2.4297 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.7322 - accuracy: 0.6511 - val_loss: 2.4201 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7553 - accuracy: 0.6480 - val_loss: 2.3951 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.7557 - accuracy: 0.6348 - val_loss: 2.3719 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.7407 - accuracy: 0.6653 - val_loss: 2.3389 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.7323 - accuracy: 0.6632 - val_loss: 2.3110 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.7365 - accuracy: 0.6611 - val_loss: 2.2874 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7257 - accuracy: 0.6626 - val_loss: 2.2668 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7211 - accuracy: 0.6600 - val_loss: 2.2532 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7191 - accuracy: 0.6632 - val_loss: 2.2417 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7255 - accuracy: 0.6595 - val_loss: 2.2321 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.7209 - accuracy: 0.6527 - val_loss: 2.2213 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7126 - accuracy: 0.6626 - val_loss: 2.2084 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7144 - accuracy: 0.6474 - val_loss: 2.1948 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7105 - accuracy: 0.6668 - val_loss: 2.1799 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6973 - accuracy: 0.6752 - val_loss: 2.1689 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7080 - accuracy: 0.6663 - val_loss: 2.1527 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 360ms/step - loss: 0.7198 - accuracy: 0.6406 - val_loss: 2.1020 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.7207 - accuracy: 0.6569 - val_loss: 2.0915 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.7113 - accuracy: 0.6390 - val_loss: 2.0770 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.7159 - accuracy: 0.6506 - val_loss: 2.0583 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.7223 - accuracy: 0.6354 - val_loss: 2.0356 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 0.7064 - accuracy: 0.6679 - val_loss: 2.0154 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.7104 - accuracy: 0.6506 - val_loss: 1.9986 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6970 - accuracy: 0.6584 - val_loss: 1.9850 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6933 - accuracy: 0.6584 - val_loss: 1.9813 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6913 - accuracy: 0.6637 - val_loss: 1.9745 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6924 - accuracy: 0.6632 - val_loss: 1.9629 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6892 - accuracy: 0.6695 - val_loss: 1.9460 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6823 - accuracy: 0.6647 - val_loss: 1.9222 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6722 - accuracy: 0.6873 - val_loss: 1.9060 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6830 - accuracy: 0.6663 - val_loss: 1.8833 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6707 - accuracy: 0.6642 - val_loss: 1.8663 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6792 - accuracy: 0.6674 - val_loss: 1.8571 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6672 - accuracy: 0.6836 - val_loss: 1.8535 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6679 - accuracy: 0.6695 - val_loss: 1.8552 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6745 - accuracy: 0.6689 - val_loss: 1.8481 - val_accuracy: 0.0021\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 228ms/step - loss: 0.6901 - accuracy: 0.6688 - val_loss: 1.8998 - val_accuracy: 0.0021\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.7091 - accuracy: 0.6562 - val_loss: 1.8762 - val_accuracy: 0.0063\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6809 - accuracy: 0.6766 - val_loss: 1.8721 - val_accuracy: 0.0126\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6851 - accuracy: 0.6787 - val_loss: 1.8700 - val_accuracy: 0.0231\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6680 - accuracy: 0.6819 - val_loss: 1.8784 - val_accuracy: 0.0294\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6607 - accuracy: 0.6835 - val_loss: 1.8830 - val_accuracy: 0.0377\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6790 - accuracy: 0.6688 - val_loss: 1.8897 - val_accuracy: 0.0524\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6777 - accuracy: 0.6745 - val_loss: 1.8900 - val_accuracy: 0.0545\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6483 - accuracy: 0.6955 - val_loss: 1.8860 - val_accuracy: 0.0587\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6658 - accuracy: 0.6798 - val_loss: 1.8791 - val_accuracy: 0.0650\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6468 - accuracy: 0.6829 - val_loss: 1.8653 - val_accuracy: 0.0671\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6495 - accuracy: 0.6824 - val_loss: 1.8506 - val_accuracy: 0.0734\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6567 - accuracy: 0.6730 - val_loss: 1.8364 - val_accuracy: 0.0881\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6395 - accuracy: 0.6856 - val_loss: 1.8295 - val_accuracy: 0.0985\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6485 - accuracy: 0.6877 - val_loss: 1.8134 - val_accuracy: 0.1048\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6333 - accuracy: 0.6997 - val_loss: 1.7983 - val_accuracy: 0.1111\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6421 - accuracy: 0.6829 - val_loss: 1.7806 - val_accuracy: 0.1237\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.6348 - accuracy: 0.7008 - val_loss: 1.7760 - val_accuracy: 0.1279\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6413 - accuracy: 0.6929 - val_loss: 1.7627 - val_accuracy: 0.1321\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6291 - accuracy: 0.7055 - val_loss: 1.7593 - val_accuracy: 0.1468\n",
      "2017/2017 [==============================] - 6s 3ms/step - loss: 1.3814 - accuracy: 0.5086\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 0.9091 - accuracy: 0.5785\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 366ms/step - loss: 0.6800 - accuracy: 0.6884 - val_loss: 1.6674 - val_accuracy: 0.2306\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6908 - accuracy: 0.6695 - val_loss: 1.7330 - val_accuracy: 0.1614\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.6749 - accuracy: 0.6878 - val_loss: 1.7522 - val_accuracy: 0.1279\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6784 - accuracy: 0.6826 - val_loss: 1.7669 - val_accuracy: 0.0922\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6774 - accuracy: 0.6737 - val_loss: 1.7619 - val_accuracy: 0.0922\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6699 - accuracy: 0.6847 - val_loss: 1.7398 - val_accuracy: 0.0901\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6698 - accuracy: 0.6779 - val_loss: 1.6964 - val_accuracy: 0.1048\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6574 - accuracy: 0.6994 - val_loss: 1.6618 - val_accuracy: 0.1279\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6629 - accuracy: 0.6810 - val_loss: 1.6368 - val_accuracy: 0.1426\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6547 - accuracy: 0.6831 - val_loss: 1.6207 - val_accuracy: 0.1677\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6636 - accuracy: 0.6826 - val_loss: 1.6227 - val_accuracy: 0.1761\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6547 - accuracy: 0.6831 - val_loss: 1.6369 - val_accuracy: 0.1677\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6516 - accuracy: 0.6967 - val_loss: 1.6380 - val_accuracy: 0.1614\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6481 - accuracy: 0.6962 - val_loss: 1.6444 - val_accuracy: 0.1488\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6491 - accuracy: 0.6768 - val_loss: 1.6504 - val_accuracy: 0.1447\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6459 - accuracy: 0.6946 - val_loss: 1.6542 - val_accuracy: 0.1426\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6473 - accuracy: 0.6967 - val_loss: 1.6496 - val_accuracy: 0.1447\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6540 - accuracy: 0.6915 - val_loss: 1.6386 - val_accuracy: 0.1740\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6415 - accuracy: 0.6973 - val_loss: 1.6261 - val_accuracy: 0.1929\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6356 - accuracy: 0.7088 - val_loss: 1.6076 - val_accuracy: 0.2138\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 215ms/step - loss: 0.6757 - accuracy: 0.6674 - val_loss: 1.5909 - val_accuracy: 0.1698\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6487 - accuracy: 0.6878 - val_loss: 1.5434 - val_accuracy: 0.1845\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6616 - accuracy: 0.6621 - val_loss: 1.5248 - val_accuracy: 0.1971\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6585 - accuracy: 0.6721 - val_loss: 1.5366 - val_accuracy: 0.1950\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6554 - accuracy: 0.6600 - val_loss: 1.5449 - val_accuracy: 0.2055\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6422 - accuracy: 0.6663 - val_loss: 1.5386 - val_accuracy: 0.2348\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6476 - accuracy: 0.6710 - val_loss: 1.5293 - val_accuracy: 0.2453\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6492 - accuracy: 0.6710 - val_loss: 1.5113 - val_accuracy: 0.2642\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6445 - accuracy: 0.6626 - val_loss: 1.5010 - val_accuracy: 0.2725\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6395 - accuracy: 0.6794 - val_loss: 1.4867 - val_accuracy: 0.2914\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6393 - accuracy: 0.6768 - val_loss: 1.4794 - val_accuracy: 0.2956\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6448 - accuracy: 0.6647 - val_loss: 1.4844 - val_accuracy: 0.3019\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6401 - accuracy: 0.6847 - val_loss: 1.4917 - val_accuracy: 0.3040\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6373 - accuracy: 0.6721 - val_loss: 1.4880 - val_accuracy: 0.3061\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.6344 - accuracy: 0.6920 - val_loss: 1.4915 - val_accuracy: 0.3040\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6282 - accuracy: 0.6899 - val_loss: 1.4944 - val_accuracy: 0.2998\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6305 - accuracy: 0.6800 - val_loss: 1.4917 - val_accuracy: 0.3040\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6296 - accuracy: 0.7015 - val_loss: 1.4869 - val_accuracy: 0.3061\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6248 - accuracy: 0.6910 - val_loss: 1.4833 - val_accuracy: 0.3166\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6223 - accuracy: 0.6794 - val_loss: 1.4674 - val_accuracy: 0.3291\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 244ms/step - loss: 0.6342 - accuracy: 0.6800 - val_loss: 1.4669 - val_accuracy: 0.3249\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6336 - accuracy: 0.6852 - val_loss: 1.4395 - val_accuracy: 0.3375\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6268 - accuracy: 0.6920 - val_loss: 1.4195 - val_accuracy: 0.3417\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6371 - accuracy: 0.6773 - val_loss: 1.4176 - val_accuracy: 0.3417\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6207 - accuracy: 0.6910 - val_loss: 1.4331 - val_accuracy: 0.3312\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6313 - accuracy: 0.6773 - val_loss: 1.4526 - val_accuracy: 0.3124\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6216 - accuracy: 0.6941 - val_loss: 1.4682 - val_accuracy: 0.2956\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6184 - accuracy: 0.6905 - val_loss: 1.4717 - val_accuracy: 0.2977\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6233 - accuracy: 0.6957 - val_loss: 1.4741 - val_accuracy: 0.2998\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6274 - accuracy: 0.6784 - val_loss: 1.4580 - val_accuracy: 0.3040\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6153 - accuracy: 0.6899 - val_loss: 1.4313 - val_accuracy: 0.3312\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6109 - accuracy: 0.7015 - val_loss: 1.4147 - val_accuracy: 0.3396\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6123 - accuracy: 0.7004 - val_loss: 1.3960 - val_accuracy: 0.3564\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6158 - accuracy: 0.6941 - val_loss: 1.3867 - val_accuracy: 0.3606\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6038 - accuracy: 0.7072 - val_loss: 1.3751 - val_accuracy: 0.3669\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6069 - accuracy: 0.6952 - val_loss: 1.3695 - val_accuracy: 0.3816\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6103 - accuracy: 0.7062 - val_loss: 1.3668 - val_accuracy: 0.3878\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6079 - accuracy: 0.7036 - val_loss: 1.3576 - val_accuracy: 0.3962\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6019 - accuracy: 0.6973 - val_loss: 1.3505 - val_accuracy: 0.4025\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.6015 - accuracy: 0.7193 - val_loss: 1.3419 - val_accuracy: 0.4151\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 255ms/step - loss: 0.6149 - accuracy: 0.6894 - val_loss: 1.3247 - val_accuracy: 0.4382\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6158 - accuracy: 0.6863 - val_loss: 1.3266 - val_accuracy: 0.4319\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6056 - accuracy: 0.7009 - val_loss: 1.2994 - val_accuracy: 0.4444\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6116 - accuracy: 0.6889 - val_loss: 1.2579 - val_accuracy: 0.4717\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6091 - accuracy: 0.6863 - val_loss: 1.2445 - val_accuracy: 0.4759\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5942 - accuracy: 0.7057 - val_loss: 1.2447 - val_accuracy: 0.4738\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5982 - accuracy: 0.7067 - val_loss: 1.2524 - val_accuracy: 0.4759\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5923 - accuracy: 0.7041 - val_loss: 1.2608 - val_accuracy: 0.4801\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5970 - accuracy: 0.7041 - val_loss: 1.2690 - val_accuracy: 0.4675\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5981 - accuracy: 0.6988 - val_loss: 1.2519 - val_accuracy: 0.4843\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5869 - accuracy: 0.7078 - val_loss: 1.2385 - val_accuracy: 0.4822\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5832 - accuracy: 0.7099 - val_loss: 1.2252 - val_accuracy: 0.4885\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.5896 - accuracy: 0.7104 - val_loss: 1.2188 - val_accuracy: 0.4864\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5844 - accuracy: 0.7120 - val_loss: 1.2219 - val_accuracy: 0.4864\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5904 - accuracy: 0.6994 - val_loss: 1.2284 - val_accuracy: 0.4801\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5770 - accuracy: 0.7109 - val_loss: 1.2235 - val_accuracy: 0.4759\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5814 - accuracy: 0.7036 - val_loss: 1.2209 - val_accuracy: 0.4864\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5893 - accuracy: 0.7025 - val_loss: 1.2084 - val_accuracy: 0.4906\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5754 - accuracy: 0.7156 - val_loss: 1.1913 - val_accuracy: 0.4969\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5844 - accuracy: 0.6857 - val_loss: 1.1834 - val_accuracy: 0.5052\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 374ms/step - loss: 0.6072 - accuracy: 0.6961 - val_loss: 1.1805 - val_accuracy: 0.4927\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6025 - accuracy: 0.6987 - val_loss: 1.1512 - val_accuracy: 0.5115\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5925 - accuracy: 0.7139 - val_loss: 1.1466 - val_accuracy: 0.5136\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.6072 - accuracy: 0.6982 - val_loss: 1.1633 - val_accuracy: 0.5031\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5967 - accuracy: 0.6924 - val_loss: 1.1735 - val_accuracy: 0.4969\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5995 - accuracy: 0.7113 - val_loss: 1.1918 - val_accuracy: 0.4822\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6005 - accuracy: 0.7108 - val_loss: 1.2063 - val_accuracy: 0.4801\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5968 - accuracy: 0.7013 - val_loss: 1.2172 - val_accuracy: 0.4801\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5898 - accuracy: 0.7108 - val_loss: 1.2270 - val_accuracy: 0.4696\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5804 - accuracy: 0.7118 - val_loss: 1.2306 - val_accuracy: 0.4696\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5918 - accuracy: 0.6940 - val_loss: 1.2395 - val_accuracy: 0.4675\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5835 - accuracy: 0.7024 - val_loss: 1.2329 - val_accuracy: 0.4696\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5918 - accuracy: 0.7207 - val_loss: 1.2184 - val_accuracy: 0.4759\n",
      "2017/2017 [==============================] - 8s 4ms/step - loss: 1.7255 - accuracy: 0.2104\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 0.8270 - accuracy: 0.6470\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 389ms/step - loss: 0.6309 - accuracy: 0.6905 - val_loss: 1.1725 - val_accuracy: 0.5220\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6207 - accuracy: 0.7088 - val_loss: 1.2551 - val_accuracy: 0.4885\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6153 - accuracy: 0.7025 - val_loss: 1.2892 - val_accuracy: 0.4885\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6101 - accuracy: 0.6973 - val_loss: 1.2847 - val_accuracy: 0.4990\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6021 - accuracy: 0.7046 - val_loss: 1.2750 - val_accuracy: 0.5010\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6106 - accuracy: 0.7004 - val_loss: 1.2544 - val_accuracy: 0.5157\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6058 - accuracy: 0.7130 - val_loss: 1.2284 - val_accuracy: 0.5409\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6137 - accuracy: 0.6999 - val_loss: 1.2018 - val_accuracy: 0.5535\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6058 - accuracy: 0.7057 - val_loss: 1.1848 - val_accuracy: 0.5660\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5975 - accuracy: 0.7093 - val_loss: 1.1750 - val_accuracy: 0.5723\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5985 - accuracy: 0.7198 - val_loss: 1.1610 - val_accuracy: 0.5723\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6093 - accuracy: 0.7051 - val_loss: 1.1517 - val_accuracy: 0.5849\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6063 - accuracy: 0.7067 - val_loss: 1.1568 - val_accuracy: 0.5828\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5974 - accuracy: 0.7083 - val_loss: 1.1707 - val_accuracy: 0.5765\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5870 - accuracy: 0.7156 - val_loss: 1.1802 - val_accuracy: 0.5681\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5911 - accuracy: 0.7125 - val_loss: 1.1893 - val_accuracy: 0.5639\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5878 - accuracy: 0.7198 - val_loss: 1.2008 - val_accuracy: 0.5556\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5865 - accuracy: 0.7209 - val_loss: 1.2002 - val_accuracy: 0.5556\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5943 - accuracy: 0.7093 - val_loss: 1.1904 - val_accuracy: 0.5681\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5898 - accuracy: 0.7088 - val_loss: 1.1839 - val_accuracy: 0.5765\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 409ms/step - loss: 0.6107 - accuracy: 0.6815 - val_loss: 1.1533 - val_accuracy: 0.5556\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6076 - accuracy: 0.6915 - val_loss: 1.1396 - val_accuracy: 0.5660\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5975 - accuracy: 0.6978 - val_loss: 1.1242 - val_accuracy: 0.5849\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5975 - accuracy: 0.6941 - val_loss: 1.1045 - val_accuracy: 0.5870\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6046 - accuracy: 0.6915 - val_loss: 1.0931 - val_accuracy: 0.6059\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.5846 - accuracy: 0.7004 - val_loss: 1.0902 - val_accuracy: 0.6059\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5957 - accuracy: 0.6946 - val_loss: 1.0962 - val_accuracy: 0.6017\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5895 - accuracy: 0.6962 - val_loss: 1.1018 - val_accuracy: 0.5975\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5923 - accuracy: 0.6978 - val_loss: 1.1070 - val_accuracy: 0.5933\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5838 - accuracy: 0.7072 - val_loss: 1.1126 - val_accuracy: 0.5891\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5898 - accuracy: 0.6925 - val_loss: 1.1098 - val_accuracy: 0.5954\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5793 - accuracy: 0.7177 - val_loss: 1.1037 - val_accuracy: 0.5975\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5866 - accuracy: 0.6884 - val_loss: 1.0940 - val_accuracy: 0.6038\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5902 - accuracy: 0.6967 - val_loss: 1.0955 - val_accuracy: 0.6017\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5825 - accuracy: 0.7009 - val_loss: 1.0986 - val_accuracy: 0.6059\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5794 - accuracy: 0.7125 - val_loss: 1.1093 - val_accuracy: 0.6017\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.5959 - accuracy: 0.6973 - val_loss: 1.1001 - val_accuracy: 0.5912\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5836 - accuracy: 0.7057 - val_loss: 1.0983 - val_accuracy: 0.5996\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5883 - accuracy: 0.7025 - val_loss: 1.0950 - val_accuracy: 0.6122\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5853 - accuracy: 0.7036 - val_loss: 1.1000 - val_accuracy: 0.6101\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.5721 - accuracy: 0.7256 - val_loss: 1.0999 - val_accuracy: 0.6101\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5692 - accuracy: 0.7235 - val_loss: 1.0913 - val_accuracy: 0.6101\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5601 - accuracy: 0.7308 - val_loss: 1.0877 - val_accuracy: 0.6205\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5764 - accuracy: 0.7067 - val_loss: 1.0873 - val_accuracy: 0.6184\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5797 - accuracy: 0.7120 - val_loss: 1.0801 - val_accuracy: 0.6226\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5680 - accuracy: 0.7114 - val_loss: 1.0716 - val_accuracy: 0.6247\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5727 - accuracy: 0.7114 - val_loss: 1.0703 - val_accuracy: 0.6226\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5691 - accuracy: 0.7225 - val_loss: 1.0761 - val_accuracy: 0.6143\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5706 - accuracy: 0.7093 - val_loss: 1.0786 - val_accuracy: 0.6122\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5607 - accuracy: 0.7366 - val_loss: 1.0872 - val_accuracy: 0.6059\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5590 - accuracy: 0.7277 - val_loss: 1.0863 - val_accuracy: 0.6101\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5750 - accuracy: 0.7267 - val_loss: 1.0926 - val_accuracy: 0.6038\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5663 - accuracy: 0.7272 - val_loss: 1.0954 - val_accuracy: 0.6038\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5635 - accuracy: 0.7167 - val_loss: 1.0901 - val_accuracy: 0.6038\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5622 - accuracy: 0.7162 - val_loss: 1.0801 - val_accuracy: 0.6080\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5603 - accuracy: 0.7240 - val_loss: 1.0727 - val_accuracy: 0.6164\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 231ms/step - loss: 0.5751 - accuracy: 0.7125 - val_loss: 1.0270 - val_accuracy: 0.6352\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5639 - accuracy: 0.7093 - val_loss: 1.0586 - val_accuracy: 0.6373\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5644 - accuracy: 0.7083 - val_loss: 1.0512 - val_accuracy: 0.6415\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5618 - accuracy: 0.7072 - val_loss: 1.0292 - val_accuracy: 0.6520\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5622 - accuracy: 0.7146 - val_loss: 1.0112 - val_accuracy: 0.6604\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5560 - accuracy: 0.7235 - val_loss: 1.0005 - val_accuracy: 0.6646\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.5521 - accuracy: 0.7067 - val_loss: 0.9894 - val_accuracy: 0.6667\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5516 - accuracy: 0.7209 - val_loss: 0.9791 - val_accuracy: 0.6688\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5435 - accuracy: 0.7246 - val_loss: 0.9763 - val_accuracy: 0.6730\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5470 - accuracy: 0.7235 - val_loss: 0.9755 - val_accuracy: 0.6751\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5580 - accuracy: 0.7183 - val_loss: 0.9776 - val_accuracy: 0.6709\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5405 - accuracy: 0.7235 - val_loss: 0.9897 - val_accuracy: 0.6625\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5403 - accuracy: 0.7288 - val_loss: 0.9838 - val_accuracy: 0.6604\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5424 - accuracy: 0.7288 - val_loss: 0.9784 - val_accuracy: 0.6667\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5412 - accuracy: 0.7261 - val_loss: 0.9760 - val_accuracy: 0.6688\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5443 - accuracy: 0.7172 - val_loss: 0.9738 - val_accuracy: 0.6688\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5418 - accuracy: 0.7261 - val_loss: 0.9691 - val_accuracy: 0.6667\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5403 - accuracy: 0.7324 - val_loss: 0.9665 - val_accuracy: 0.6667\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5430 - accuracy: 0.7230 - val_loss: 0.9595 - val_accuracy: 0.6730\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5366 - accuracy: 0.7298 - val_loss: 0.9592 - val_accuracy: 0.6730\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 202ms/step - loss: 0.5841 - accuracy: 0.7050 - val_loss: 0.9380 - val_accuracy: 0.7002\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.5649 - accuracy: 0.7239 - val_loss: 0.8988 - val_accuracy: 0.6939\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5742 - accuracy: 0.7108 - val_loss: 0.8781 - val_accuracy: 0.7065\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5608 - accuracy: 0.7260 - val_loss: 0.8822 - val_accuracy: 0.7023\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5754 - accuracy: 0.7165 - val_loss: 0.9032 - val_accuracy: 0.6960\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5542 - accuracy: 0.7202 - val_loss: 0.9271 - val_accuracy: 0.6709\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5523 - accuracy: 0.7265 - val_loss: 0.9579 - val_accuracy: 0.6499\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5529 - accuracy: 0.7260 - val_loss: 0.9773 - val_accuracy: 0.6331\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5495 - accuracy: 0.7239 - val_loss: 0.9956 - val_accuracy: 0.6247\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5540 - accuracy: 0.7239 - val_loss: 0.9963 - val_accuracy: 0.6205\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.5595 - accuracy: 0.7213 - val_loss: 0.9970 - val_accuracy: 0.6164\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5482 - accuracy: 0.7302 - val_loss: 0.9878 - val_accuracy: 0.6247\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5569 - accuracy: 0.7181 - val_loss: 0.9757 - val_accuracy: 0.6331\n",
      "2017/2017 [==============================] - 7s 4ms/step - loss: 1.9621 - accuracy: 0.1657\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 0.8185 - accuracy: 0.6512\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 238ms/step - loss: 0.5963 - accuracy: 0.7188 - val_loss: 0.9353 - val_accuracy: 0.6562\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5809 - accuracy: 0.7114 - val_loss: 1.0021 - val_accuracy: 0.6541\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5757 - accuracy: 0.7167 - val_loss: 1.0437 - val_accuracy: 0.6583\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5746 - accuracy: 0.7230 - val_loss: 1.0396 - val_accuracy: 0.6709\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5656 - accuracy: 0.7204 - val_loss: 1.0271 - val_accuracy: 0.6792\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5787 - accuracy: 0.7125 - val_loss: 1.0114 - val_accuracy: 0.6897\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5729 - accuracy: 0.7267 - val_loss: 0.9908 - val_accuracy: 0.6981\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5676 - accuracy: 0.7135 - val_loss: 0.9742 - val_accuracy: 0.7002\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5698 - accuracy: 0.7277 - val_loss: 0.9541 - val_accuracy: 0.7086\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5626 - accuracy: 0.7340 - val_loss: 0.9400 - val_accuracy: 0.7128\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5663 - accuracy: 0.7282 - val_loss: 0.9363 - val_accuracy: 0.7170\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 0.5807 - accuracy: 0.7104 - val_loss: 0.9864 - val_accuracy: 0.6792\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5800 - accuracy: 0.7015 - val_loss: 0.9572 - val_accuracy: 0.6813\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5604 - accuracy: 0.7162 - val_loss: 0.9380 - val_accuracy: 0.6897\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5613 - accuracy: 0.7015 - val_loss: 0.9267 - val_accuracy: 0.7002\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5631 - accuracy: 0.7030 - val_loss: 0.9298 - val_accuracy: 0.6981\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5667 - accuracy: 0.7120 - val_loss: 0.9447 - val_accuracy: 0.6897\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5578 - accuracy: 0.7162 - val_loss: 0.9505 - val_accuracy: 0.6855\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5535 - accuracy: 0.7135 - val_loss: 0.9617 - val_accuracy: 0.6855\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5638 - accuracy: 0.7051 - val_loss: 0.9583 - val_accuracy: 0.6876\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.5599 - accuracy: 0.7114 - val_loss: 0.9532 - val_accuracy: 0.6918\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5531 - accuracy: 0.7230 - val_loss: 0.9462 - val_accuracy: 0.6960\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5541 - accuracy: 0.7246 - val_loss: 0.9436 - val_accuracy: 0.6981\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5539 - accuracy: 0.7214 - val_loss: 0.9461 - val_accuracy: 0.6897\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5533 - accuracy: 0.7230 - val_loss: 0.9379 - val_accuracy: 0.6918\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 241ms/step - loss: 0.5568 - accuracy: 0.7308 - val_loss: 0.9565 - val_accuracy: 0.7065\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5612 - accuracy: 0.7193 - val_loss: 0.9667 - val_accuracy: 0.6981\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5513 - accuracy: 0.7146 - val_loss: 0.9683 - val_accuracy: 0.6834\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5616 - accuracy: 0.7177 - val_loss: 0.9508 - val_accuracy: 0.7023\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5538 - accuracy: 0.7267 - val_loss: 0.9405 - val_accuracy: 0.7086\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5417 - accuracy: 0.7308 - val_loss: 0.9341 - val_accuracy: 0.7149\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5472 - accuracy: 0.7282 - val_loss: 0.9324 - val_accuracy: 0.7128\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5433 - accuracy: 0.7277 - val_loss: 0.9366 - val_accuracy: 0.7023\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5446 - accuracy: 0.7335 - val_loss: 0.9500 - val_accuracy: 0.6981\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5436 - accuracy: 0.7377 - val_loss: 0.9543 - val_accuracy: 0.6981\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5432 - accuracy: 0.7356 - val_loss: 0.9628 - val_accuracy: 0.6981\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5436 - accuracy: 0.7413 - val_loss: 0.9617 - val_accuracy: 0.7044\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5409 - accuracy: 0.7293 - val_loss: 0.9601 - val_accuracy: 0.7065\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5365 - accuracy: 0.7398 - val_loss: 0.9517 - val_accuracy: 0.7107\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5399 - accuracy: 0.7403 - val_loss: 0.9457 - val_accuracy: 0.7107\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.5247 - accuracy: 0.7413 - val_loss: 0.9474 - val_accuracy: 0.7128\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5288 - accuracy: 0.7518 - val_loss: 0.9530 - val_accuracy: 0.7107\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.5427 - accuracy: 0.7235 - val_loss: 0.9224 - val_accuracy: 0.7107\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5365 - accuracy: 0.7235 - val_loss: 0.9212 - val_accuracy: 0.7128\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5354 - accuracy: 0.7256 - val_loss: 0.9146 - val_accuracy: 0.7317\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5370 - accuracy: 0.7329 - val_loss: 0.9040 - val_accuracy: 0.7358\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5327 - accuracy: 0.7256 - val_loss: 0.8915 - val_accuracy: 0.7338\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.5371 - accuracy: 0.7214 - val_loss: 0.8799 - val_accuracy: 0.7358\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.5255 - accuracy: 0.7329 - val_loss: 0.8790 - val_accuracy: 0.7296\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5231 - accuracy: 0.7293 - val_loss: 0.8834 - val_accuracy: 0.7338\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5236 - accuracy: 0.7350 - val_loss: 0.8877 - val_accuracy: 0.7358\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5277 - accuracy: 0.7319 - val_loss: 0.8845 - val_accuracy: 0.7379\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5272 - accuracy: 0.7345 - val_loss: 0.8808 - val_accuracy: 0.7442\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5158 - accuracy: 0.7455 - val_loss: 0.8666 - val_accuracy: 0.7484\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5243 - accuracy: 0.7419 - val_loss: 0.8562 - val_accuracy: 0.7505\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5161 - accuracy: 0.7434 - val_loss: 0.8560 - val_accuracy: 0.7463\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5194 - accuracy: 0.7267 - val_loss: 0.8572 - val_accuracy: 0.7463\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5137 - accuracy: 0.7392 - val_loss: 0.8567 - val_accuracy: 0.7379\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5137 - accuracy: 0.7371 - val_loss: 0.8663 - val_accuracy: 0.7317\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5118 - accuracy: 0.7471 - val_loss: 0.8751 - val_accuracy: 0.7275\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5177 - accuracy: 0.7476 - val_loss: 0.8763 - val_accuracy: 0.7317\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5176 - accuracy: 0.7403 - val_loss: 0.8837 - val_accuracy: 0.7275\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.5534 - accuracy: 0.7176 - val_loss: 0.8367 - val_accuracy: 0.7505\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5412 - accuracy: 0.7344 - val_loss: 0.7748 - val_accuracy: 0.7778\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5455 - accuracy: 0.7234 - val_loss: 0.7499 - val_accuracy: 0.7883\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5430 - accuracy: 0.7223 - val_loss: 0.7633 - val_accuracy: 0.7778\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5463 - accuracy: 0.7260 - val_loss: 0.7964 - val_accuracy: 0.7610\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5439 - accuracy: 0.7286 - val_loss: 0.8288 - val_accuracy: 0.7296\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5356 - accuracy: 0.7244 - val_loss: 0.8590 - val_accuracy: 0.6981\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5399 - accuracy: 0.7318 - val_loss: 0.8801 - val_accuracy: 0.6876\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5500 - accuracy: 0.7344 - val_loss: 0.8943 - val_accuracy: 0.6751\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.5375 - accuracy: 0.7381 - val_loss: 0.9001 - val_accuracy: 0.6709\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5311 - accuracy: 0.7286 - val_loss: 0.8942 - val_accuracy: 0.6751\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5337 - accuracy: 0.7339 - val_loss: 0.8755 - val_accuracy: 0.6813\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5340 - accuracy: 0.7286 - val_loss: 0.8506 - val_accuracy: 0.6960\n",
      "2017/2017 [==============================] - 11s 5ms/step - loss: 2.0472 - accuracy: 0.1651\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.8100 - accuracy: 0.6504\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.5718 - accuracy: 0.7183 - val_loss: 0.8070 - val_accuracy: 0.7421\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5574 - accuracy: 0.7324 - val_loss: 0.8876 - val_accuracy: 0.7275\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5612 - accuracy: 0.7272 - val_loss: 0.9429 - val_accuracy: 0.7275\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5559 - accuracy: 0.7261 - val_loss: 0.9788 - val_accuracy: 0.7275\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5512 - accuracy: 0.7293 - val_loss: 0.9799 - val_accuracy: 0.7317\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5519 - accuracy: 0.7256 - val_loss: 0.9504 - val_accuracy: 0.7400\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5466 - accuracy: 0.7382 - val_loss: 0.9161 - val_accuracy: 0.7484\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5496 - accuracy: 0.7288 - val_loss: 0.8793 - val_accuracy: 0.7631\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5466 - accuracy: 0.7382 - val_loss: 0.8496 - val_accuracy: 0.7715\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5508 - accuracy: 0.7324 - val_loss: 0.8230 - val_accuracy: 0.7757\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5426 - accuracy: 0.7419 - val_loss: 0.8012 - val_accuracy: 0.7862\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.5409 - accuracy: 0.7408 - val_loss: 0.7979 - val_accuracy: 0.7883\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5434 - accuracy: 0.7366 - val_loss: 0.8076 - val_accuracy: 0.7820\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5434 - accuracy: 0.7413 - val_loss: 0.8195 - val_accuracy: 0.7820\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5464 - accuracy: 0.7298 - val_loss: 0.8354 - val_accuracy: 0.7757\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5359 - accuracy: 0.7408 - val_loss: 0.8439 - val_accuracy: 0.7757\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5369 - accuracy: 0.7419 - val_loss: 0.8502 - val_accuracy: 0.7694\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5406 - accuracy: 0.7440 - val_loss: 0.8539 - val_accuracy: 0.7652\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5286 - accuracy: 0.7445 - val_loss: 0.8606 - val_accuracy: 0.7631\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5303 - accuracy: 0.7419 - val_loss: 0.8658 - val_accuracy: 0.7610\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 0.5568 - accuracy: 0.7219 - val_loss: 0.8604 - val_accuracy: 0.7442\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5534 - accuracy: 0.7183 - val_loss: 0.8385 - val_accuracy: 0.7421\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5519 - accuracy: 0.7162 - val_loss: 0.8258 - val_accuracy: 0.7526\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5491 - accuracy: 0.7230 - val_loss: 0.8099 - val_accuracy: 0.7568\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5420 - accuracy: 0.7104 - val_loss: 0.8046 - val_accuracy: 0.7610\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5451 - accuracy: 0.7235 - val_loss: 0.8198 - val_accuracy: 0.7589\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5489 - accuracy: 0.7088 - val_loss: 0.8346 - val_accuracy: 0.7484\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5447 - accuracy: 0.7204 - val_loss: 0.8413 - val_accuracy: 0.7505\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5410 - accuracy: 0.7235 - val_loss: 0.8479 - val_accuracy: 0.7442\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5315 - accuracy: 0.7288 - val_loss: 0.8575 - val_accuracy: 0.7442\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5345 - accuracy: 0.7340 - val_loss: 0.8640 - val_accuracy: 0.7442\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5360 - accuracy: 0.7340 - val_loss: 0.8668 - val_accuracy: 0.7442\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5318 - accuracy: 0.7335 - val_loss: 0.8668 - val_accuracy: 0.7421\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5383 - accuracy: 0.7193 - val_loss: 0.8596 - val_accuracy: 0.7421\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5331 - accuracy: 0.7356 - val_loss: 0.8522 - val_accuracy: 0.7463\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 0.5391 - accuracy: 0.7361 - val_loss: 0.8276 - val_accuracy: 0.7589\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5278 - accuracy: 0.7392 - val_loss: 0.8271 - val_accuracy: 0.7610\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5389 - accuracy: 0.7350 - val_loss: 0.8177 - val_accuracy: 0.7631\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5320 - accuracy: 0.7382 - val_loss: 0.8224 - val_accuracy: 0.7631\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5221 - accuracy: 0.7508 - val_loss: 0.8401 - val_accuracy: 0.7568\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5331 - accuracy: 0.7403 - val_loss: 0.8739 - val_accuracy: 0.7484\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5247 - accuracy: 0.7350 - val_loss: 0.8921 - val_accuracy: 0.7463\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5216 - accuracy: 0.7492 - val_loss: 0.8939 - val_accuracy: 0.7463\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5178 - accuracy: 0.7398 - val_loss: 0.8728 - val_accuracy: 0.7463\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5320 - accuracy: 0.7350 - val_loss: 0.8554 - val_accuracy: 0.7505\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5160 - accuracy: 0.7450 - val_loss: 0.8340 - val_accuracy: 0.7568\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5288 - accuracy: 0.7382 - val_loss: 0.8234 - val_accuracy: 0.7589\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5203 - accuracy: 0.7329 - val_loss: 0.8266 - val_accuracy: 0.7589\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.5256 - accuracy: 0.7340 - val_loss: 0.8093 - val_accuracy: 0.7589\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5194 - accuracy: 0.7377 - val_loss: 0.8229 - val_accuracy: 0.7547\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5190 - accuracy: 0.7356 - val_loss: 0.8042 - val_accuracy: 0.7652\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5211 - accuracy: 0.7329 - val_loss: 0.7843 - val_accuracy: 0.7715\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5148 - accuracy: 0.7492 - val_loss: 0.7853 - val_accuracy: 0.7736\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5160 - accuracy: 0.7314 - val_loss: 0.7854 - val_accuracy: 0.7778\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5034 - accuracy: 0.7476 - val_loss: 0.7867 - val_accuracy: 0.7757\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5165 - accuracy: 0.7429 - val_loss: 0.7937 - val_accuracy: 0.7715\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5041 - accuracy: 0.7539 - val_loss: 0.7899 - val_accuracy: 0.7715\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5097 - accuracy: 0.7408 - val_loss: 0.7793 - val_accuracy: 0.7820\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.5024 - accuracy: 0.7392 - val_loss: 0.7719 - val_accuracy: 0.7841\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5042 - accuracy: 0.7508 - val_loss: 0.7825 - val_accuracy: 0.7820\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4997 - accuracy: 0.7377 - val_loss: 0.7941 - val_accuracy: 0.7736\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.4982 - accuracy: 0.7487 - val_loss: 0.8045 - val_accuracy: 0.7694\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4939 - accuracy: 0.7539 - val_loss: 0.8033 - val_accuracy: 0.7673\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4965 - accuracy: 0.7455 - val_loss: 0.8094 - val_accuracy: 0.7631\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4920 - accuracy: 0.7503 - val_loss: 0.8120 - val_accuracy: 0.7610\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5007 - accuracy: 0.7476 - val_loss: 0.8091 - val_accuracy: 0.7610\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4984 - accuracy: 0.7487 - val_loss: 0.8129 - val_accuracy: 0.7589\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4972 - accuracy: 0.7497 - val_loss: 0.8119 - val_accuracy: 0.7547\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.5482 - accuracy: 0.7318 - val_loss: 0.7588 - val_accuracy: 0.7799\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5416 - accuracy: 0.7333 - val_loss: 0.7169 - val_accuracy: 0.7883\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5418 - accuracy: 0.7260 - val_loss: 0.6946 - val_accuracy: 0.8050\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5283 - accuracy: 0.7328 - val_loss: 0.6949 - val_accuracy: 0.8113\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5271 - accuracy: 0.7375 - val_loss: 0.7090 - val_accuracy: 0.7987\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5189 - accuracy: 0.7360 - val_loss: 0.7327 - val_accuracy: 0.7820\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5189 - accuracy: 0.7454 - val_loss: 0.7583 - val_accuracy: 0.7589\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5312 - accuracy: 0.7323 - val_loss: 0.7776 - val_accuracy: 0.7484\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5185 - accuracy: 0.7438 - val_loss: 0.7998 - val_accuracy: 0.7338\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5159 - accuracy: 0.7423 - val_loss: 0.8213 - val_accuracy: 0.7233\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5236 - accuracy: 0.7417 - val_loss: 0.8312 - val_accuracy: 0.7170\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5159 - accuracy: 0.7423 - val_loss: 0.8325 - val_accuracy: 0.7191\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5147 - accuracy: 0.7470 - val_loss: 0.8264 - val_accuracy: 0.7212\n",
      "2017/2017 [==============================] - 10s 5ms/step - loss: 2.0243 - accuracy: 0.2130\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 0.8428 - accuracy: 0.5785\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3:\n",
    "            x, y = x4, y4\n",
    "        elif node == 4:\n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(y, predictions)\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xc, yc) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xce, yce)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idFTLcat53.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[1.483901858329773, 1.077278733253479], [1.5853056907653809, 1.0109777450561523], [1.6442493200302124, 0.9646216034889221], [1.6731053590774536, 0.929453432559967], [1.7892502546310425, 0.9133396744728088]]\n",
      "Accuracy for iterations:  [[0.41206833720207214, 0.5247629284858704], [0.1596968173980713, 0.5237091779708862], [0.06531713157892227, 0.5255532264709473], [0.06585963070392609, 0.5305584669113159], [0.06992063671350479, 0.5339831113815308]]\n",
      "F1 for iterations:  [[0.5529292345027684, 0.45282473180912775], [0.2345593250747663, 0.45120739727904025], [0.06614822184157323, 0.4540656465502913], [0.06634143383580202, 0.4618626283791211], [0.06846760991367741, 0.46979010220027717]]\n",
      "Precision for iterations:  [[0.910015680566624, 0.40811505197556225], [0.912477498169993, 0.4136746641752634], [0.4368564304551748, 0.4175488158080132], [0.4952365935180386, 0.4716424544031258], [0.35330783709470664, 0.516264443009011]]\n",
      "Recall for iterations:  [[0.4120683241366483, 0.5247629083245522], [0.15969681939363878, 0.523709167544784], [0.06531713063426127, 0.5255532139093783], [0.06585963171926344, 0.5305584826132771], [0.06992063984127968, 0.5339831401475237]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
