{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Federated Learning for attack detection: 5 nodes sharing gradients: GEOMETRIC MEDIAN**\n",
    "\n",
    "IDs from this file = **idGEOxy** (x = 0 if experiment with dataset, x = 1 if epochs & iterations, y being integer equal or greater than 0)\n",
    "\n",
    "In this file, experiments with different datasets, and number of epochs & iterations are done. The experiments are divided into sections, based on the elements being changed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static elements for all experiments (execute first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Disable warns\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data): \n",
    "\n",
    "    # Select the 'proto' and 'state' values that I want\n",
    "    data = data.loc[(data['proto'] == 'tcp') | (data['proto'] =='udp') | (data['proto'] =='icmp') | (data['proto'] =='arp') | (data['proto'] =='ipv6-icmp') | (data['proto'] =='igmp') | (data['proto'] =='rarp'), :]\n",
    "    data = data.loc[(data['state'] == 'RST') | (data['state'] =='REQ') | (data['state'] =='INT') | (data['state'] =='FIN') | (data['state'] =='CON') | (data['state'] =='ECO') | (data['state'] =='ACC') | (data['state'] == 'PAR'), :]\n",
    "\n",
    "    # Extracting labels \n",
    "    data_labels = data[['label']]\n",
    "\n",
    "    # Drop the invalid features and select interested data features\n",
    "    data_features=data[['proto','srcip','sport','dstip','dsport','spkts','dpkts','sbytes','dbytes','state','stime','ltime','dur']]\n",
    "\n",
    "    \"\"\"PREPROCESSING\"\"\"\n",
    "\n",
    "\n",
    "    # Preprocess IP and ports features\n",
    "    # IP Source Address\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "\n",
    "    # IP Destination Address\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "    # Ports\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "\n",
    "    # Convert all ports with 0 decimal, and HEX to DEC\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    # Convert field to int format\n",
    "    data_features['srcip'] = data_features['srcip'].astype(int)\n",
    "    data_features['sport'] = data_features['sport'].astype(int)\n",
    "    data_features['dstip'] = data_features['dstip'].astype(int)\n",
    "    data_features['dsport'] = data_features['dsport'].astype(int)\n",
    "\n",
    "    # Convert some fields to logarithmic\n",
    "    log1p_col = ['dur', 'sbytes', 'dbytes', 'spkts']\n",
    "\n",
    "    for col in log1p_col:\n",
    "        data_features[col] = data_features[col].apply(np.log1p)\n",
    "\n",
    "    # Create a complementary field of attack & Transform to One hot encoding - LABELS\n",
    "    normal=data_labels['label']\n",
    "    normal=normal.replace(1,2)\n",
    "    normal=normal.replace(0,1)\n",
    "    normal=normal.replace(2,0)\n",
    "\n",
    "    # Insert the new column in data labels\n",
    "    data_labels.insert(1, 'normal', normal)\n",
    "    data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "    data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "    # Transform to One hot encoding - FEATURES\n",
    "    data_features=pd.get_dummies(data_features)\n",
    "\n",
    "    # Value given for the missing columns\n",
    "    auxCol=0\n",
    "\n",
    "    # As we are using different datasets that might not have all representations, we are going to detect and add the missing columns \n",
    "    # The columns that can have types are: proto and state: need to check if all representations are done \n",
    "    state_cols = [col for col in data_features if col.startswith('state_')]\n",
    "    proto_cols = [col for col in data_features if col.startswith('proto_')]\n",
    "    \n",
    "    # Check if all columns are present\n",
    "    if 'state_PAR' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_PAR', auxCol, True)\n",
    "    if 'state_ACC' not in state_cols: \n",
    "        data_features.insert(data_features.shape[1], 'state_ACC', auxCol, True)\n",
    "    if 'state_ECO' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_ECO', auxCol, True)\n",
    "    if 'state_CON' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_CON', auxCol, True)\n",
    "    if 'state_FIN' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_FIN', auxCol, True)\n",
    "    if 'state_INT' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_INT', auxCol, True)\n",
    "    if 'state_REQ' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_REQ', auxCol, True)\n",
    "    if 'state_RST' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_RST', auxCol, True)\n",
    "    if 'proto_igmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_igmp', auxCol, True)\n",
    "    if 'proto_arp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_arp', auxCol, True)\n",
    "    if 'proto_icmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_icmp', auxCol, True)\n",
    "    if 'proto_udp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_udp', auxCol, True)\n",
    "    if 'proto_tcp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_tcp', auxCol, True)\n",
    "\n",
    "    # Normalize all data features\n",
    "    data_features = StandardScaler().fit_transform(data_features)\n",
    "\n",
    "    #Add dimension to data features\n",
    "    data_features = np.expand_dims(data_features, axis=2)\n",
    "    data_features = np.expand_dims(data_features, axis=3)\n",
    "\n",
    "    x = data_features\n",
    "    y = data_labels.to_numpy()\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building and definition\n",
    "def build_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(filters=32,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(1, 2), padding='same'))\n",
    "    model.add(layers.Conv2D(filters=64,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(1, 2), padding='same'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(Dense(444, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns values of loss, accuracy, f1, precision and recall of model evaluating with test dataset \n",
    "def evaluation(model, x, y): \n",
    "    loss, accuracy = model.evaluate(x, y)\n",
    "    y_pred = model.predict(x)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y = np.argmax(y, axis=1)\n",
    "    report = classification_report(y, y_pred, target_names=['normal', 'attack'], output_dict=True)\n",
    "    # Obtain f1, precision and recall from the report\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    return loss, accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_15184/3457440085.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_15184/3457440085.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_complete = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Complete.csv')\n"
     ]
    }
   ],
   "source": [
    "test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n",
    "test_plus = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test+.csv')\n",
    "test_complete = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)\n",
    "xcomplete, ycomplete = preprocessing(test_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments with datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Filt5A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part1.csv', low_memory=False)\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part2.csv', low_memory=False)\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part3.csv', low_memory=False)\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part4.csv', low_memory=False)\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part5.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idGEO00.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weiszfeld_update(points, tol=1e-5, max_iter=100):\n",
    "    \"\"\"\n",
    "    Compute the geometric median using Weiszfeld's algorithm.\n",
    "\n",
    "    Args:\n",
    "    points: A list of points (numpy arrays) to find the geometric median of.\n",
    "    tol: Tolerance for stopping criterion.\n",
    "    max_iter: Maximum number of iterations.\n",
    "\n",
    "    Returns:\n",
    "    The geometric median of the points.\n",
    "    \"\"\"\n",
    "    points = np.array(points)\n",
    "    median = np.mean(points, axis=0)\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        distances = np.linalg.norm(points - median, axis=1)\n",
    "        nonzero_distances = np.where(distances != 0, distances, np.finfo(float).eps)\n",
    "        weights = 1 / nonzero_distances\n",
    "        new_median = np.sum(points * weights[:, None], axis=0) / np.sum(weights)\n",
    "\n",
    "        if np.linalg.norm(new_median - median) < tol:\n",
    "            return new_median\n",
    "\n",
    "        median = new_median\n",
    "\n",
    "    return median\n",
    "\n",
    "def aggregate(grad_list):\n",
    "    \"\"\"\n",
    "    Apply Geometric Median aggregation method to a list of gradients.\n",
    "\n",
    "    Args:\n",
    "    grad_list: List of gradients from different models. Each element in the list\n",
    "               is a list of gradients for each layer of a model.\n",
    "\n",
    "    Returns:\n",
    "    The geometric median of the gradients.\n",
    "    \"\"\"\n",
    "    # Flatten gradients to compute geometric median\n",
    "    flat_grads = [tf.concat([tf.reshape(g, [-1]) for g in grad], axis=0).numpy() for grad in grad_list]\n",
    "\n",
    "    # Compute geometric median using Weiszfeld's algorithm\n",
    "    flat_median = weiszfeld_update(flat_grads)\n",
    "\n",
    "    # Reshape the flat median back to the original shape\n",
    "    median_grad = []\n",
    "    index = 0\n",
    "    for grad in grad_list[0]:\n",
    "        shape = tf.shape(grad)\n",
    "        size = tf.reduce_prod(shape)\n",
    "        median_grad.append(tf.reshape(flat_median[index:index + size], shape))\n",
    "        index += size\n",
    "\n",
    "    return median_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 184ms/step - loss: 0.3827 - accuracy: 0.9650 - val_loss: 1.8270 - val_accuracy: 0.6196\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 187ms/step - loss: 0.0620 - accuracy: 0.9916 - val_loss: 0.9786 - val_accuracy: 0.6200\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 204ms/step - loss: 0.0299 - accuracy: 0.9919 - val_loss: 0.6993 - val_accuracy: 0.6301\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 193ms/step - loss: 0.0268 - accuracy: 0.9922 - val_loss: 0.5889 - val_accuracy: 0.6538\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 200ms/step - loss: 0.0253 - accuracy: 0.9920 - val_loss: 0.5823 - val_accuracy: 0.6533\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 10s 320ms/step - loss: 0.0391 - accuracy: 0.9900 - val_loss: 0.5308 - val_accuracy: 0.7069\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 293ms/step - loss: 0.0257 - accuracy: 0.9913 - val_loss: 0.4643 - val_accuracy: 0.6890\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 256ms/step - loss: 0.0228 - accuracy: 0.9919 - val_loss: 0.4347 - val_accuracy: 0.7024\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 224ms/step - loss: 0.0215 - accuracy: 0.9922 - val_loss: 0.5376 - val_accuracy: 0.6447\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 284ms/step - loss: 0.0205 - accuracy: 0.9930 - val_loss: 0.4602 - val_accuracy: 0.6900\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 9s 275ms/step - loss: 0.0198 - accuracy: 0.9934 - val_loss: 0.3515 - val_accuracy: 0.7731\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 280ms/step - loss: 0.0181 - accuracy: 0.9936 - val_loss: 0.6662 - val_accuracy: 0.6612\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 284ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.5051 - val_accuracy: 0.7234\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 312ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 0.3509 - val_accuracy: 0.7998\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 359ms/step - loss: 0.0154 - accuracy: 0.9950 - val_loss: 0.4575 - val_accuracy: 0.7739\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 376ms/step - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.4476 - val_accuracy: 0.7889\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 343ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.2625 - val_accuracy: 0.8530\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 304ms/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.3690 - val_accuracy: 0.8245\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 362ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.2915 - val_accuracy: 0.8481\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 12s 393ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 0.3021 - val_accuracy: 0.8471\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 402ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.4422 - val_accuracy: 0.8096\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 303ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.3269 - val_accuracy: 0.8391\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 363ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.4871 - val_accuracy: 0.7968\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 13s 404ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.4257 - val_accuracy: 0.8200\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 297ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 0.4292 - val_accuracy: 0.8192\n",
      "4279/4279 [==============================] - 39s 9ms/step - loss: 0.0570 - accuracy: 0.9711\n",
      "1721/1721 [==============================] - 11s 6ms/step - loss: 0.2462 - accuracy: 0.8905\n",
      "4481/4481 [==============================] - 28s 6ms/step - loss: 0.0956 - accuracy: 0.9521\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 9s 299ms/step - loss: 0.0155 - accuracy: 0.9955 - val_loss: 0.3735 - val_accuracy: 0.8343\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 293ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.6135 - val_accuracy: 0.7671\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 223ms/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 0.5878 - val_accuracy: 0.7767\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 227ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.5523 - val_accuracy: 0.7834\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 282ms/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.3625 - val_accuracy: 0.8423\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 9s 291ms/step - loss: 0.0151 - accuracy: 0.9954 - val_loss: 0.5317 - val_accuracy: 0.7946\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 266ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.5136 - val_accuracy: 0.8050\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 217ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.3800 - val_accuracy: 0.8469\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 223ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.4237 - val_accuracy: 0.8424\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 273ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.5830 - val_accuracy: 0.7968\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 264ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.5099 - val_accuracy: 0.8144\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 244ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 0.5182 - val_accuracy: 0.8145\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 197ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 0.4917 - val_accuracy: 0.8196\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 197ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.5858 - val_accuracy: 0.7998\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 199ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 0.6124 - val_accuracy: 0.7915\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 187ms/step - loss: 0.0128 - accuracy: 0.9962 - val_loss: 0.3910 - val_accuracy: 0.8449\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 190ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.4415 - val_accuracy: 0.8367\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 179ms/step - loss: 0.0122 - accuracy: 0.9962 - val_loss: 0.3156 - val_accuracy: 0.8623\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 183ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.5221 - val_accuracy: 0.8182\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 176ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.4246 - val_accuracy: 0.8444\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 0.5634 - val_accuracy: 0.8115\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 186ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 0.5211 - val_accuracy: 0.8206\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 190ms/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.3904 - val_accuracy: 0.8548\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 199ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.5411 - val_accuracy: 0.8138\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 190ms/step - loss: 0.0097 - accuracy: 0.9967 - val_loss: 0.4263 - val_accuracy: 0.8487\n",
      "4279/4279 [==============================] - 14s 3ms/step - loss: 0.0572 - accuracy: 0.9744\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.3343 - accuracy: 0.8482\n",
      "4481/4481 [==============================] - 17s 4ms/step - loss: 0.1019 - accuracy: 0.9570\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 173ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.4721 - val_accuracy: 0.8365\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 173ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.5343 - val_accuracy: 0.8074\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 187ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.5342 - val_accuracy: 0.8122\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 222ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 0.3038 - val_accuracy: 0.8757\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 227ms/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.4439 - val_accuracy: 0.8404\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 260ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 0.6593 - val_accuracy: 0.7806\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 194ms/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 0.4447 - val_accuracy: 0.8413\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 186ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 0.4317 - val_accuracy: 0.8457\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 178ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.5183 - val_accuracy: 0.8297\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 179ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.4067 - val_accuracy: 0.8499\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 208ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.5352 - val_accuracy: 0.8272\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 205ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.4414 - val_accuracy: 0.8451\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 230ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.4139 - val_accuracy: 0.8536\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 265ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 0.5971 - val_accuracy: 0.8175\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 242ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 0.5253 - val_accuracy: 0.8314\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 193ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.5171 - val_accuracy: 0.8332\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 177ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.2390 - val_accuracy: 0.8977\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.5559 - val_accuracy: 0.8263\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 172ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.6105 - val_accuracy: 0.8189\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.5189 - val_accuracy: 0.8338\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.4723 - val_accuracy: 0.8460\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.4852 - val_accuracy: 0.8442\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.5565 - val_accuracy: 0.8295\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 169ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.5947 - val_accuracy: 0.8155\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.5279 - val_accuracy: 0.8275\n",
      "4279/4279 [==============================] - 10s 2ms/step - loss: 0.0599 - accuracy: 0.9755\n",
      "1721/1721 [==============================] - 4s 2ms/step - loss: 0.5076 - accuracy: 0.7823\n",
      "4481/4481 [==============================] - 10s 2ms/step - loss: 0.1156 - accuracy: 0.9564\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "    loss_complete, accuracy_complete, f1_complete, precision_complete, recall_complete = evaluation(global_model, xcomplete, ycomplete)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus, loss_complete])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus, accuracy_complete])\n",
    "    f1_it.append([f1_basic, f1_plus, f1_complete])\n",
    "    precision_it.append([precision_basic, precision_plus, precision_complete])\n",
    "    recall_it.append([recall_basic, recall_plus, recall_complete])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idGEO00.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.05698449909687042, 0.2462124079465866, 0.0956316888332367], [0.05720860883593559, 0.33429884910583496, 0.10186640918254852], [0.05987226217985153, 0.5076313018798828, 0.11560719460248947]]\n",
      "Accuracy for iterations:  [[0.971055269241333, 0.8905217051506042, 0.9520816802978516], [0.97443687915802, 0.8481798768043518, 0.95700603723526], [0.9754886031150818, 0.7823330760002136, 0.9564061760902405]]\n",
      "F1 for iterations:  [[0.9710081194459265, 0.8882009653299612, 0.952007564857771], [0.9744031721520753, 0.8422994633806594, 0.9569546411223356], [0.9754574277724276, 0.7656067274071545, 0.9563495550864797]]\n",
      "Precision for iterations:  [[0.9717991720361379, 0.9029758527340818, 0.9548915693299354], [0.9749692369443568, 0.8739761527340623, 0.9591991495473647], [0.9759929096074956, 0.8355189360247318, 0.9587870328222783]]\n",
      "Recall for iterations:  [[0.9710552455520173, 0.8905216885853375, 0.9520816913000718], [0.974436881007333, 0.8481799026375063, 0.957006047332408], [0.9754886207601742, 0.7823330669185498, 0.9564061965975909]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Filt5B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part1.csv', low_memory=False)\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part2.csv', low_memory=False)\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part3.csv', low_memory=False)\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part4.csv', low_memory=False)\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part5.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idGEO01.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.3854 - accuracy: 0.9307 - val_loss: 2.1654 - val_accuracy: 0.5486\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0713 - accuracy: 0.9910 - val_loss: 1.5919 - val_accuracy: 0.5526\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 164ms/step - loss: 0.0307 - accuracy: 0.9919 - val_loss: 0.7599 - val_accuracy: 0.5617\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.0255 - accuracy: 0.9919 - val_loss: 0.6106 - val_accuracy: 0.6172\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 0.0241 - accuracy: 0.9921 - val_loss: 0.6820 - val_accuracy: 0.5831\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 4s 145ms/step - loss: 0.0311 - accuracy: 0.9904 - val_loss: 0.4304 - val_accuracy: 0.7339\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 150ms/step - loss: 0.0232 - accuracy: 0.9918 - val_loss: 0.4138 - val_accuracy: 0.7199\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 0.0211 - accuracy: 0.9927 - val_loss: 0.3132 - val_accuracy: 0.7896\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 150ms/step - loss: 0.0203 - accuracy: 0.9927 - val_loss: 0.3688 - val_accuracy: 0.7360\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 144ms/step - loss: 0.0191 - accuracy: 0.9933 - val_loss: 0.3246 - val_accuracy: 0.7760\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 146ms/step - loss: 0.0099 - accuracy: 0.9971 - val_loss: 4.8609 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 2.3094e-07 - accuracy: 1.0000 - val_loss: 5.2369 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 145ms/step - loss: 1.5897e-07 - accuracy: 1.0000 - val_loss: 5.2566 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 146ms/step - loss: 1.5635e-07 - accuracy: 1.0000 - val_loss: 5.2583 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 143ms/step - loss: 1.5593e-07 - accuracy: 1.0000 - val_loss: 5.2593 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 146ms/step - loss: 5.1555 - accuracy: 0.3922 - val_loss: 0.0450 - val_accuracy: 0.9889\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9988\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 7.7021e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 145ms/step - loss: 4.6677e-04 - accuracy: 1.0000 - val_loss: 9.8775e-04 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 1.5865 - accuracy: 0.6858 - val_loss: 0.8737 - val_accuracy: 0.6320\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.0484 - accuracy: 0.9943 - val_loss: 0.7104 - val_accuracy: 0.6367\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.0253 - accuracy: 0.9942 - val_loss: 0.7085 - val_accuracy: 0.6372\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.0227 - accuracy: 0.9942 - val_loss: 0.7496 - val_accuracy: 0.6368\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 151ms/step - loss: 0.0212 - accuracy: 0.9942 - val_loss: 0.7412 - val_accuracy: 0.6367\n",
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.1384 - accuracy: 0.9240\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.2994 - accuracy: 0.8047\n",
      "4481/4481 [==============================] - 14s 3ms/step - loss: 0.1982 - accuracy: 0.8911\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 0.0209 - accuracy: 0.9932 - val_loss: 0.4923 - val_accuracy: 0.6590\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.0181 - accuracy: 0.9946 - val_loss: 0.3910 - val_accuracy: 0.7440\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.3590 - val_accuracy: 0.7769\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 151ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.4912 - val_accuracy: 0.7132\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 146ms/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.5043 - val_accuracy: 0.7231\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 145ms/step - loss: 0.0171 - accuracy: 0.9946 - val_loss: 0.4130 - val_accuracy: 0.7885\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 0.0160 - accuracy: 0.9950 - val_loss: 0.3372 - val_accuracy: 0.8212\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 0.3570 - val_accuracy: 0.8219\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 169ms/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 0.5805 - val_accuracy: 0.7685\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 0.4828 - val_accuracy: 0.8005\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 175ms/step - loss: 0.0158 - accuracy: 0.9939 - val_loss: 5.4269 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 1.3753e-07 - accuracy: 1.0000 - val_loss: 5.8056 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 172ms/step - loss: 1.0070e-07 - accuracy: 1.0000 - val_loss: 5.8253 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 180ms/step - loss: 9.9191e-08 - accuracy: 1.0000 - val_loss: 5.8266 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 177ms/step - loss: 9.8950e-08 - accuracy: 1.0000 - val_loss: 5.8272 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 8.4170 - accuracy: 0.3072 - val_loss: 0.7369 - val_accuracy: 0.8422\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 195ms/step - loss: 0.1827 - accuracy: 0.9410 - val_loss: 0.0086 - val_accuracy: 0.9962\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 203ms/step - loss: 6.4612e-04 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9979\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 176ms/step - loss: 4.2490e-04 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9980\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 181ms/step - loss: 3.6911e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9981\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 1.9005 - accuracy: 0.7188 - val_loss: 0.6139 - val_accuracy: 0.6890\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0193 - accuracy: 0.9945 - val_loss: 0.6225 - val_accuracy: 0.6895\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 150ms/step - loss: 0.0166 - accuracy: 0.9942 - val_loss: 0.6050 - val_accuracy: 0.6908\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 0.0163 - accuracy: 0.9943 - val_loss: 0.6072 - val_accuracy: 0.6905\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 146ms/step - loss: 0.0160 - accuracy: 0.9943 - val_loss: 0.5714 - val_accuracy: 0.6936\n",
      "4279/4279 [==============================] - 9s 2ms/step - loss: 0.0969 - accuracy: 0.9460\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.2273 - accuracy: 0.8864\n",
      "4481/4481 [==============================] - 13s 3ms/step - loss: 0.1574 - accuracy: 0.9138\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 0.3468 - val_accuracy: 0.7935\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.3665 - val_accuracy: 0.8009\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.3123 - val_accuracy: 0.8422\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 145ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.3169 - val_accuracy: 0.8429\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.0138 - accuracy: 0.9961 - val_loss: 0.2659 - val_accuracy: 0.8733\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 146ms/step - loss: 0.0178 - accuracy: 0.9951 - val_loss: 0.3946 - val_accuracy: 0.8277\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 150ms/step - loss: 0.0151 - accuracy: 0.9958 - val_loss: 0.4511 - val_accuracy: 0.8126\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.5054 - val_accuracy: 0.7990\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 145ms/step - loss: 0.0144 - accuracy: 0.9959 - val_loss: 0.3111 - val_accuracy: 0.8488\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 0.0145 - accuracy: 0.9955 - val_loss: 0.3308 - val_accuracy: 0.8462\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 0.0646 - accuracy: 0.9766 - val_loss: 4.3633 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 2.0653e-06 - accuracy: 1.0000 - val_loss: 4.8037 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 175ms/step - loss: 1.4962e-06 - accuracy: 1.0000 - val_loss: 4.8289 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 184ms/step - loss: 1.4528e-06 - accuracy: 1.0000 - val_loss: 4.8327 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 188ms/step - loss: 1.4408e-06 - accuracy: 1.0000 - val_loss: 4.8362 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 187ms/step - loss: 7.5989 - accuracy: 0.3143 - val_loss: 0.7953 - val_accuracy: 0.8407\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 198ms/step - loss: 0.1798 - accuracy: 0.9446 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 190ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 208ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 7.3528e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 197ms/step - loss: 6.5731e-04 - accuracy: 1.0000 - val_loss: 4.6688e-04 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 1.0485 - accuracy: 0.7850 - val_loss: 0.5448 - val_accuracy: 0.7007\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 0.0177 - accuracy: 0.9942 - val_loss: 0.5347 - val_accuracy: 0.6991\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 271ms/step - loss: 0.0166 - accuracy: 0.9941 - val_loss: 0.5554 - val_accuracy: 0.6951\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 279ms/step - loss: 0.0162 - accuracy: 0.9942 - val_loss: 0.5174 - val_accuracy: 0.7020\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 280ms/step - loss: 0.0159 - accuracy: 0.9943 - val_loss: 0.5384 - val_accuracy: 0.6982\n",
      "4279/4279 [==============================] - 32s 7ms/step - loss: 0.0977 - accuracy: 0.9444\n",
      "1721/1721 [==============================] - 18s 10ms/step - loss: 0.1923 - accuracy: 0.9176\n",
      "4481/4481 [==============================] - 43s 10ms/step - loss: 0.1530 - accuracy: 0.9136\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "    loss_complete, accuracy_complete, f1_complete, precision_complete, recall_complete = evaluation(global_model, xcomplete, ycomplete)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus, loss_complete])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus, accuracy_complete])\n",
    "    f1_it.append([f1_basic, f1_plus, f1_complete])\n",
    "    precision_it.append([precision_basic, precision_plus, precision_complete])\n",
    "    recall_it.append([recall_basic, recall_plus, recall_complete])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idGEO01.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.13843773305416107, 0.2994016706943512, 0.19816967844963074], [0.09693670272827148, 0.22727085649967194, 0.15739957988262177], [0.09774153679609299, 0.19225603342056274, 0.15302471816539764]]\n",
      "Accuracy for iterations:  [[0.9239533543586731, 0.8046937584877014, 0.8910852670669556], [0.9459522366523743, 0.886380136013031, 0.9138447046279907], [0.9443600177764893, 0.9175688624382019, 0.9135656952857971]]\n",
      "F1 for iterations:  [[0.923226195238611, 0.7930928482415546, 0.8898655570024935], [0.9456611518452166, 0.8838644354346318, 0.9132670204316425], [0.9440509381249023, 0.9165176387721264, 0.9129895350603425]]\n",
      "Precision for iterations:  [[0.9325484311301909, 0.844653757561124, 0.9092111666571719], [0.9501438442304992, 0.8994442471374056, 0.9251708336730285], [0.948714588262095, 0.9238694111759653, 0.9248167226582382]]\n",
      "Recall for iterations:  [[0.9239533728709574, 0.8046937440964906, 0.8910852415794209], [0.9459522627012182, 0.8863801496766693, 0.9138446944597507], [0.9443600455753893, 0.9175688440020344, 0.9135656941179753]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Filt5C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part1.csv', low_memory=False)\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part2.csv', low_memory=False)\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part3.csv', low_memory=False)\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part4.csv', low_memory=False)\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part5.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idGEO02.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 11s 709ms/step - loss: 0.5450 - accuracy: 0.7213 - val_loss: 1.6593 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 9s 591ms/step - loss: 0.2015 - accuracy: 0.9510 - val_loss: 3.3367 - val_accuracy: 0.1334\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 8s 473ms/step - loss: 0.0783 - accuracy: 0.9893 - val_loss: 3.4470 - val_accuracy: 0.1342\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 8s 503ms/step - loss: 0.0497 - accuracy: 0.9893 - val_loss: 1.8136 - val_accuracy: 0.1379\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 10s 640ms/step - loss: 0.0370 - accuracy: 0.9898 - val_loss: 1.4136 - val_accuracy: 0.1942\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 9s 626ms/step - loss: 0.0227 - accuracy: 0.9948 - val_loss: 0.8248 - val_accuracy: 0.7271\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 5s 364ms/step - loss: 0.0214 - accuracy: 0.9950 - val_loss: 0.6812 - val_accuracy: 0.7284\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 6s 422ms/step - loss: 0.0202 - accuracy: 0.9950 - val_loss: 0.7872 - val_accuracy: 0.7277\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 7s 482ms/step - loss: 0.0197 - accuracy: 0.9950 - val_loss: 0.7260 - val_accuracy: 0.7287\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 5s 383ms/step - loss: 0.0190 - accuracy: 0.9951 - val_loss: 0.7201 - val_accuracy: 0.7287\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 14s 543ms/step - loss: 0.0141 - accuracy: 0.9961 - val_loss: 2.5340 - val_accuracy: 0.4415\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 9s 361ms/step - loss: 0.0135 - accuracy: 0.9962 - val_loss: 2.3700 - val_accuracy: 0.4413\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 12s 470ms/step - loss: 0.0128 - accuracy: 0.9965 - val_loss: 2.1013 - val_accuracy: 0.4405\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 11s 438ms/step - loss: 0.0125 - accuracy: 0.9966 - val_loss: 2.4389 - val_accuracy: 0.4410\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 10s 399ms/step - loss: 0.0123 - accuracy: 0.9968 - val_loss: 2.2734 - val_accuracy: 0.4377\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 15s 540ms/step - loss: 2.1606 - accuracy: 0.5951 - val_loss: 0.0365 - val_accuracy: 0.9866\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 12s 443ms/step - loss: 0.0061 - accuracy: 0.9998 - val_loss: 0.0068 - val_accuracy: 0.9977\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 11s 412ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 10s 367ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 11s 394ms/step - loss: 7.2675e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 28s 398ms/step - loss: 0.5082 - accuracy: 0.8964 - val_loss: 0.4268 - val_accuracy: 0.8271\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 33s 478ms/step - loss: 0.0240 - accuracy: 0.9926 - val_loss: 0.2612 - val_accuracy: 0.8393\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 29s 412ms/step - loss: 0.0216 - accuracy: 0.9930 - val_loss: 0.2540 - val_accuracy: 0.8444\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 32s 458ms/step - loss: 0.0206 - accuracy: 0.9932 - val_loss: 0.2375 - val_accuracy: 0.8520\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 30s 423ms/step - loss: 0.0197 - accuracy: 0.9935 - val_loss: 0.2127 - val_accuracy: 0.8672\n",
      "4279/4279 [==============================] - 47s 11ms/step - loss: 0.0888 - accuracy: 0.9864\n",
      "1721/1721 [==============================] - 20s 11ms/step - loss: 0.1707 - accuracy: 0.94230s - loss: 0.1719 - accura\n",
      "4481/4481 [==============================] - 51s 11ms/step - loss: 0.1016 - accuracy: 0.9779\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 9s 576ms/step - loss: 0.0252 - accuracy: 0.9905 - val_loss: 0.8441 - val_accuracy: 0.4897\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 8s 471ms/step - loss: 0.0225 - accuracy: 0.9920 - val_loss: 0.7012 - val_accuracy: 0.6184\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 7s 461ms/step - loss: 0.0210 - accuracy: 0.9925 - val_loss: 0.8689 - val_accuracy: 0.5252\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 8s 488ms/step - loss: 0.0201 - accuracy: 0.9931 - val_loss: 0.8317 - val_accuracy: 0.5602\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 6s 404ms/step - loss: 0.0194 - accuracy: 0.9935 - val_loss: 0.7091 - val_accuracy: 0.6366\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 10s 681ms/step - loss: 0.0158 - accuracy: 0.9957 - val_loss: 0.6344 - val_accuracy: 0.7410\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 6s 436ms/step - loss: 0.0144 - accuracy: 0.9962 - val_loss: 0.5490 - val_accuracy: 0.7504\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 6s 402ms/step - loss: 0.0137 - accuracy: 0.9964 - val_loss: 0.6957 - val_accuracy: 0.7405\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 5s 326ms/step - loss: 0.0133 - accuracy: 0.9966 - val_loss: 0.8987 - val_accuracy: 0.7343\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 5s 352ms/step - loss: 0.0132 - accuracy: 0.9968 - val_loss: 0.6686 - val_accuracy: 0.7459\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 12s 453ms/step - loss: 0.0113 - accuracy: 0.9973 - val_loss: 1.9237 - val_accuracy: 0.4758\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 12s 473ms/step - loss: 0.0104 - accuracy: 0.9973 - val_loss: 1.9268 - val_accuracy: 0.4918\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 13s 504ms/step - loss: 0.0110 - accuracy: 0.9973 - val_loss: 1.5858 - val_accuracy: 0.5339\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 12s 473ms/step - loss: 0.0103 - accuracy: 0.9975 - val_loss: 1.5083 - val_accuracy: 0.5574\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 12s 445ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 1.9415 - val_accuracy: 0.5115\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 10s 378ms/step - loss: 4.5957 - accuracy: 0.4129 - val_loss: 0.6082 - val_accuracy: 0.8583\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 7s 251ms/step - loss: 0.2551 - accuracy: 0.9145 - val_loss: 0.0511 - val_accuracy: 0.9847\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 11s 395ms/step - loss: 0.0043 - accuracy: 0.9998 - val_loss: 0.0240 - val_accuracy: 0.9916\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 8s 312ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0182 - val_accuracy: 0.9933\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 11s 394ms/step - loss: 8.2885e-04 - accuracy: 0.9999 - val_loss: 0.0146 - val_accuracy: 0.9944\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 32s 450ms/step - loss: 0.6564 - accuracy: 0.8907 - val_loss: 0.3015 - val_accuracy: 0.8558\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 33s 477ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 0.2019 - val_accuracy: 0.8972\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 28s 398ms/step - loss: 0.0172 - accuracy: 0.9947 - val_loss: 0.1855 - val_accuracy: 0.8997\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 32s 456ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 0.1599 - val_accuracy: 0.9110\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 29s 407ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.1598 - val_accuracy: 0.9098\n",
      "4279/4279 [==============================] - 43s 10ms/step - loss: 0.0547 - accuracy: 0.9896\n",
      "1721/1721 [==============================] - 20s 11ms/step - loss: 0.1364 - accuracy: 0.9542\n",
      "4481/4481 [==============================] - 56s 13ms/step - loss: 0.0599 - accuracy: 0.9861\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 8s 531ms/step - loss: 0.0200 - accuracy: 0.9931 - val_loss: 0.9256 - val_accuracy: 0.5143\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 6s 401ms/step - loss: 0.0187 - accuracy: 0.9940 - val_loss: 1.2403 - val_accuracy: 0.4545\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 5s 334ms/step - loss: 0.0180 - accuracy: 0.9944 - val_loss: 1.2299 - val_accuracy: 0.4839\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 6s 350ms/step - loss: 0.0176 - accuracy: 0.9946 - val_loss: 0.9231 - val_accuracy: 0.5882\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 7s 418ms/step - loss: 0.0171 - accuracy: 0.9946 - val_loss: 0.9791 - val_accuracy: 0.5730\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 10s 726ms/step - loss: 0.0137 - accuracy: 0.9965 - val_loss: 0.8283 - val_accuracy: 0.7458\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 7s 511ms/step - loss: 0.0126 - accuracy: 0.9970 - val_loss: 0.6875 - val_accuracy: 0.7617\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 7s 472ms/step - loss: 0.0126 - accuracy: 0.9971 - val_loss: 0.7887 - val_accuracy: 0.7561\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 6s 403ms/step - loss: 0.0121 - accuracy: 0.9971 - val_loss: 0.9027 - val_accuracy: 0.7532\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 6s 401ms/step - loss: 0.0120 - accuracy: 0.9973 - val_loss: 0.9129 - val_accuracy: 0.7518\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 358ms/step - loss: 0.0107 - accuracy: 0.9975 - val_loss: 1.1693 - val_accuracy: 0.6068\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 7s 283ms/step - loss: 0.0101 - accuracy: 0.9975 - val_loss: 1.5480 - val_accuracy: 0.5588\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 9s 335ms/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 1.2262 - val_accuracy: 0.6286\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 9s 340ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 1.8946 - val_accuracy: 0.5274\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 10s 374ms/step - loss: 0.0094 - accuracy: 0.9975 - val_loss: 1.7040 - val_accuracy: 0.5618\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 11s 399ms/step - loss: 4.8222 - accuracy: 0.5020 - val_loss: 0.4960 - val_accuracy: 0.8933\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 8s 307ms/step - loss: 0.1243 - accuracy: 0.9593 - val_loss: 0.0062 - val_accuracy: 0.9975\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 6s 233ms/step - loss: 6.8316e-05 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 0.9985\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 8s 307ms/step - loss: 3.7515e-05 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9986\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 9s 319ms/step - loss: 3.5423e-05 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9987\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 33s 477ms/step - loss: 1.0579 - accuracy: 0.8807 - val_loss: 0.2354 - val_accuracy: 0.8986\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 27s 382ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 0.1864 - val_accuracy: 0.9143\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 25s 350ms/step - loss: 0.0155 - accuracy: 0.9952 - val_loss: 0.1596 - val_accuracy: 0.9222\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 19s 269ms/step - loss: 0.0145 - accuracy: 0.9955 - val_loss: 0.1420 - val_accuracy: 0.9281\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 24s 341ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.1331 - val_accuracy: 0.9318\n",
      "4279/4279 [==============================] - 50s 12ms/step - loss: 0.0512 - accuracy: 0.9899\n",
      "1721/1721 [==============================] - 18s 11ms/step - loss: 0.0817 - accuracy: 0.9862\n",
      "4481/4481 [==============================] - 64s 14ms/step - loss: 0.0488 - accuracy: 0.9903\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "    loss_complete, accuracy_complete, f1_complete, precision_complete, recall_complete = evaluation(global_model, xcomplete, ycomplete)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus, loss_complete])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus, accuracy_complete])\n",
    "    f1_it.append([f1_basic, f1_plus, f1_complete])\n",
    "    precision_it.append([precision_basic, precision_plus, precision_complete])\n",
    "    recall_it.append([recall_basic, recall_plus, recall_complete])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idGEO02.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.08878658711910248, 0.17068345844745636, 0.10156106948852539], [0.05471533536911011, 0.13642050325870514, 0.05986447632312775], [0.05124828219413757, 0.08169283717870712, 0.04878015071153641]]\n",
      "Accuracy for iterations:  [[0.9864369630813599, 0.9422727823257446, 0.9779450297355652], [0.9896140694618225, 0.9542069435119629, 0.9861197471618652], [0.9898843169212341, 0.9862130284309387, 0.9903466105461121]]\n",
      "F1 for iterations:  [[0.9864399692915574, 0.9419277626643375, 0.9779443146183981], [0.9896183584435108, 0.954072465228889, 0.9861195645109446], [0.9898891213014196, 0.9862322162185762, 0.990345722631171]]\n",
      "Precision for iterations:  [[0.9864773933002633, 0.9442268026446218, 0.9780063543909912], [0.989761533913747, 0.9547431539113531, 0.9861433849071188], [0.9900909806559807, 0.9865685957771482, 0.9905226280682651]]\n",
      "Recall for iterations:  [[0.9864369394373192, 0.9422727602993534, 0.9779450229826532], [0.9896140699406936, 0.9542069316282787, 0.9861197329966729], [0.9898843086271875, 0.9862130349487757, 0.9903465881745706]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
