{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated Learning with one corrupted node: median\n",
    "Using one balanced and one unbalanced dataset with one corrupted node (5%, 25% and 50% corrupted samples) to test different aggregation functions and determine the more robust one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Disable warns\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data): \n",
    "\n",
    "    # Select the 'proto' and 'state' values that I want\n",
    "    data = data.loc[(data['proto'] == 'tcp') | (data['proto'] =='udp') | (data['proto'] =='icmp') | (data['proto'] =='arp') | (data['proto'] =='ipv6-icmp') | (data['proto'] =='igmp') | (data['proto'] =='rarp'), :]\n",
    "    data = data.loc[(data['state'] == 'RST') | (data['state'] =='REQ') | (data['state'] =='INT') | (data['state'] =='FIN') | (data['state'] =='CON') | (data['state'] =='ECO') | (data['state'] =='ACC') | (data['state'] == 'PAR'), :]\n",
    "\n",
    "    # Extracting labels \n",
    "    data_labels = data[['label']]\n",
    "\n",
    "    # Drop the invalid features and select interested data features\n",
    "    data_features=data[['proto','srcip','sport','dstip','dsport','spkts','dpkts','sbytes','dbytes','state','stime','ltime','dur']]\n",
    "\n",
    "    \"\"\"PREPROCESSING\"\"\"\n",
    "\n",
    "\n",
    "    # Preprocess IP and ports features\n",
    "    # IP Source Address\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "\n",
    "    # IP Destination Address\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "    # Ports\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "\n",
    "    # Convert all ports with 0 decimal, and HEX to DEC\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    # Convert field to int format\n",
    "    data_features['srcip'] = data_features['srcip'].astype(int)\n",
    "    data_features['sport'] = data_features['sport'].astype(int)\n",
    "    data_features['dstip'] = data_features['dstip'].astype(int)\n",
    "    data_features['dsport'] = data_features['dsport'].astype(int)\n",
    "\n",
    "    # Convert some fields to logarithmic\n",
    "    log1p_col = ['dur', 'sbytes', 'dbytes', 'spkts']\n",
    "\n",
    "    for col in log1p_col:\n",
    "        data_features[col] = data_features[col].apply(np.log1p)\n",
    "\n",
    "    # Create a complementary field of attack & Transform to One hot encoding - LABELS\n",
    "    normal=data_labels['label']\n",
    "    normal=normal.replace(1,2)\n",
    "    normal=normal.replace(0,1)\n",
    "    normal=normal.replace(2,0)\n",
    "\n",
    "    # Insert the new column in data labels\n",
    "    data_labels.insert(1, 'normal', normal)\n",
    "    data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "    data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "    # Transform to One hot encoding - FEATURES\n",
    "    data_features=pd.get_dummies(data_features)\n",
    "\n",
    "    # Value given for the missing columns\n",
    "    auxCol=0\n",
    "\n",
    "    # As we are using different datasets that might not have all representations, we are going to detect and add the missing columns \n",
    "    # The columns that can have types are: proto and state: need to check if all representations are done \n",
    "    state_cols = [col for col in data_features if col.startswith('state_')]\n",
    "    proto_cols = [col for col in data_features if col.startswith('proto_')]\n",
    "    \n",
    "    # Check if all columns are present\n",
    "    if 'state_PAR' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_PAR', auxCol, True)\n",
    "    if 'state_ACC' not in state_cols: \n",
    "        data_features.insert(data_features.shape[1], 'state_ACC', auxCol, True)\n",
    "    if 'state_ECO' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_ECO', auxCol, True)\n",
    "    if 'state_CON' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_CON', auxCol, True)\n",
    "    if 'state_FIN' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_FIN', auxCol, True)\n",
    "    if 'state_INT' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_INT', auxCol, True)\n",
    "    if 'state_REQ' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_REQ', auxCol, True)\n",
    "    if 'state_RST' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_RST', auxCol, True)\n",
    "    if 'proto_igmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_igmp', auxCol, True)\n",
    "    if 'proto_arp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_arp', auxCol, True)\n",
    "    if 'proto_icmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_icmp', auxCol, True)\n",
    "    if 'proto_udp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_udp', auxCol, True)\n",
    "    if 'proto_tcp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_tcp', auxCol, True)\n",
    "\n",
    "    # Normalize all data features\n",
    "    data_features = StandardScaler().fit_transform(data_features)\n",
    "\n",
    "    #Add dimension to data features\n",
    "    data_features = np.expand_dims(data_features, axis=2)\n",
    "    data_features = np.expand_dims(data_features, axis=3)\n",
    "\n",
    "    x = data_features\n",
    "    y = data_labels.to_numpy()\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building and definition\n",
    "def build_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(filters=32,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(1, 1), padding='same'))\n",
    "    model.add(layers.Conv2D(filters=64,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(1, 1), padding='same'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(Dense(444, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns values of loss, accuracy, f1, precision and recall of model evaluating with test dataset \n",
    "def evaluation(model, x, y): \n",
    "    loss, accuracy = model.evaluate(x, y)\n",
    "    y_pred = model.predict(x)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y = np.argmax(y, axis=1)\n",
    "    report = classification_report(y, y_pred, target_names=['normal', 'attack'], output_dict=True)\n",
    "    # Obtain f1, precision and recall from the report\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    return loss, accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    \n",
    "    # Compute the median gradient for each layer\n",
    "    med_grad = [\n",
    "        tf.numpy_function(lambda grads: np.median(grads, axis=0), [tf.stack(layer_grads)], tf.float32)\n",
    "        for layer_grads in zip(*grad_list)\n",
    "    ]\n",
    "    return med_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_10604/3836997398.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n"
     ]
    }
   ],
   "source": [
    "test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n",
    "test_plus = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test+.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5A 5% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_10604/3687049449.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_10604/3687049449.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_10604/3687049449.py:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part4.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_10604/3687049449.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr55Amed.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 173ms/step - loss: 0.4550 - accuracy: 0.8707 - val_loss: 0.2285 - val_accuracy: 0.9369\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 0.1898 - accuracy: 0.9533 - val_loss: 0.1798 - val_accuracy: 0.9592\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 178ms/step - loss: 0.1656 - accuracy: 0.9651 - val_loss: 0.1622 - val_accuracy: 0.9633\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 179ms/step - loss: 0.1543 - accuracy: 0.9669 - val_loss: 0.1539 - val_accuracy: 0.9653\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 171ms/step - loss: 0.1476 - accuracy: 0.9676 - val_loss: 0.1494 - val_accuracy: 0.9657\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.0358 - accuracy: 0.9897 - val_loss: 0.3443 - val_accuracy: 0.8025\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.0236 - accuracy: 0.9909 - val_loss: 0.4366 - val_accuracy: 0.6613\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.0220 - accuracy: 0.9919 - val_loss: 0.4430 - val_accuracy: 0.6500\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.0211 - accuracy: 0.9924 - val_loss: 0.3471 - val_accuracy: 0.7198\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 151ms/step - loss: 0.0201 - accuracy: 0.9931 - val_loss: 0.3941 - val_accuracy: 0.6935\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 9s 289ms/step - loss: 0.0208 - accuracy: 0.9920 - val_loss: 0.3726 - val_accuracy: 0.7112\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 275ms/step - loss: 0.0181 - accuracy: 0.9933 - val_loss: 0.3799 - val_accuracy: 0.7256\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 287ms/step - loss: 0.0167 - accuracy: 0.9939 - val_loss: 0.3458 - val_accuracy: 0.7688\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 346ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.2502 - val_accuracy: 0.8452\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 328ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.4129 - val_accuracy: 0.7729\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 14s 455ms/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 0.3150 - val_accuracy: 0.8213\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 364ms/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 0.3224 - val_accuracy: 0.8269\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 334ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.2791 - val_accuracy: 0.8454\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 345ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.3956 - val_accuracy: 0.8100\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 287ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.1954 - val_accuracy: 0.8852\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 15s 470ms/step - loss: 0.0158 - accuracy: 0.9955 - val_loss: 0.3974 - val_accuracy: 0.8094\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 12s 373ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.4742 - val_accuracy: 0.7842\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 328ms/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 0.3663 - val_accuracy: 0.8244\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 357ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.4295 - val_accuracy: 0.8083\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 271ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.5735 - val_accuracy: 0.7629\n",
      "4279/4279 [==============================] - 39s 9ms/step - loss: 0.0669 - accuracy: 0.9691\n",
      "1721/1721 [==============================] - 16s 9ms/step - loss: 0.4486 - accuracy: 0.7739\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 14s 445ms/step - loss: 0.2142 - accuracy: 0.9649 - val_loss: 0.1752 - val_accuracy: 0.9652\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 12s 376ms/step - loss: 0.1512 - accuracy: 0.9678 - val_loss: 0.1510 - val_accuracy: 0.9660\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 12s 376ms/step - loss: 0.1420 - accuracy: 0.9683 - val_loss: 0.1476 - val_accuracy: 0.9657\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 381ms/step - loss: 0.1397 - accuracy: 0.9685 - val_loss: 0.1460 - val_accuracy: 0.9660\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 263ms/step - loss: 0.1381 - accuracy: 0.9685 - val_loss: 0.1437 - val_accuracy: 0.9660\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 9s 304ms/step - loss: 0.0222 - accuracy: 0.9939 - val_loss: 0.3846 - val_accuracy: 0.7337\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 264ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.3078 - val_accuracy: 0.8118\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.4161 - val_accuracy: 0.7714\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 205ms/step - loss: 0.0147 - accuracy: 0.9957 - val_loss: 0.3162 - val_accuracy: 0.8312\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 194ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.3832 - val_accuracy: 0.8110\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 387ms/step - loss: 0.0144 - accuracy: 0.9956 - val_loss: 0.4091 - val_accuracy: 0.8052\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 334ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.3418 - val_accuracy: 0.8328\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 308ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 0.4292 - val_accuracy: 0.8103\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 368ms/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 0.5487 - val_accuracy: 0.7794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 272ms/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 0.4845 - val_accuracy: 0.8035\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 15s 477ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.4062 - val_accuracy: 0.8278\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 12s 397ms/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 0.2776 - val_accuracy: 0.8579\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 349ms/step - loss: 0.0132 - accuracy: 0.9959 - val_loss: 0.3943 - val_accuracy: 0.8322\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 371ms/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: 0.4163 - val_accuracy: 0.8268\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 290ms/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.3401 - val_accuracy: 0.8477\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 15s 476ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.5492 - val_accuracy: 0.7843\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 12s 400ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.4081 - val_accuracy: 0.8266\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 326ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.4705 - val_accuracy: 0.8048\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 360ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.4293 - val_accuracy: 0.8231\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 303ms/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.3852 - val_accuracy: 0.8393\n",
      "4279/4279 [==============================] - 44s 10ms/step - loss: 0.0573 - accuracy: 0.9720\n",
      "1721/1721 [==============================] - 19s 11ms/step - loss: 0.4666 - accuracy: 0.7521\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 361ms/step - loss: 0.2044 - accuracy: 0.9655 - val_loss: 0.1639 - val_accuracy: 0.9655\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 346ms/step - loss: 0.1447 - accuracy: 0.9681 - val_loss: 0.1486 - val_accuracy: 0.9660\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 342ms/step - loss: 0.1394 - accuracy: 0.9686 - val_loss: 0.1448 - val_accuracy: 0.9664\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 342ms/step - loss: 0.1375 - accuracy: 0.9686 - val_loss: 0.1434 - val_accuracy: 0.9662\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 337ms/step - loss: 0.1368 - accuracy: 0.9687 - val_loss: 0.1441 - val_accuracy: 0.9660\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 254ms/step - loss: 0.0187 - accuracy: 0.9945 - val_loss: 0.2658 - val_accuracy: 0.8455\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 222ms/step - loss: 0.0144 - accuracy: 0.9959 - val_loss: 0.3029 - val_accuracy: 0.8420\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 255ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.3055 - val_accuracy: 0.8473\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 257ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.2825 - val_accuracy: 0.8576\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 219ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.4435 - val_accuracy: 0.8034\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 382ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.3188 - val_accuracy: 0.8530\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 339ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.3610 - val_accuracy: 0.8449\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 339ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 0.4051 - val_accuracy: 0.8365\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 334ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 0.5604 - val_accuracy: 0.7946\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 310ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.4907 - val_accuracy: 0.8205\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 15s 491ms/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 0.4343 - val_accuracy: 0.8317\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 13s 412ms/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 0.3703 - val_accuracy: 0.8497\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 13s 431ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 0.3308 - val_accuracy: 0.8557\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 352ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.4940 - val_accuracy: 0.8229\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 321ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.4569 - val_accuracy: 0.8317\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 15s 482ms/step - loss: 0.0123 - accuracy: 0.9965 - val_loss: 0.5786 - val_accuracy: 0.8073\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 14s 453ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.5514 - val_accuracy: 0.8085\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 12s 384ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.3603 - val_accuracy: 0.8517\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 323ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.5583 - val_accuracy: 0.7986\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 310ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.3477 - val_accuracy: 0.8559\n",
      "4279/4279 [==============================] - 45s 11ms/step - loss: 0.0553 - accuracy: 0.9748\n",
      "1721/1721 [==============================] - 18s 10ms/step - loss: 0.4275 - accuracy: 0.7949\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr55Amed.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.06691569089889526, 0.4485682249069214], [0.05725914612412453, 0.46658557653427124], [0.05533405765891075, 0.4274962842464447]]\n",
      "Accuracy for iterations:  [[0.9691343307495117, 0.7738502025604248], [0.9720120429992676, 0.7521252632141113], [0.9748020768165588, 0.7949393391609192]]\n",
      "F1 for iterations:  [[0.96907056257358, 0.7554715856687966], [0.9719681107465905, 0.72787197302513], [0.9747699338127015, 0.7811387610664655]]\n",
      "Precision for iterations:  [[0.970221054115231, 0.8292692346163768], [0.9727156962330306, 0.8181768445573764], [0.9753060270434274, 0.841100703673347]]\n",
      "Recall for iterations:  [[0.9691343597534254, 0.7738501780135145], [0.9720120365771714, 0.7521252633873429], [0.974802068421514, 0.7949393300879168]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5B 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_10604/2463029928.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part1.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_10604/2463029928.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_10604/2463029928.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_10604/2463029928.py:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part4.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_10604/2463029928.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr105Amed.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 249ms/step - loss: 0.4871 - accuracy: 0.8352 - val_loss: 0.2880 - val_accuracy: 0.9100\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 243ms/step - loss: 0.2651 - accuracy: 0.9287 - val_loss: 0.2475 - val_accuracy: 0.9396\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 268ms/step - loss: 0.2438 - accuracy: 0.9399 - val_loss: 0.2349 - val_accuracy: 0.9418\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 237ms/step - loss: 0.2328 - accuracy: 0.9421 - val_loss: 0.2273 - val_accuracy: 0.9424\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 257ms/step - loss: 0.2261 - accuracy: 0.9426 - val_loss: 0.2247 - val_accuracy: 0.9425\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 215ms/step - loss: 0.0445 - accuracy: 0.9893 - val_loss: 0.5502 - val_accuracy: 0.6659\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 211ms/step - loss: 0.0243 - accuracy: 0.9902 - val_loss: 0.3455 - val_accuracy: 0.7673\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 219ms/step - loss: 0.0227 - accuracy: 0.9911 - val_loss: 0.3551 - val_accuracy: 0.7308\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 201ms/step - loss: 0.0219 - accuracy: 0.9917 - val_loss: 0.3199 - val_accuracy: 0.7611\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 195ms/step - loss: 0.0211 - accuracy: 0.9923 - val_loss: 0.4720 - val_accuracy: 0.6483\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 10s 319ms/step - loss: 0.0229 - accuracy: 0.9915 - val_loss: 0.3865 - val_accuracy: 0.6798\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 325ms/step - loss: 0.0191 - accuracy: 0.9928 - val_loss: 0.3179 - val_accuracy: 0.7618\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 293ms/step - loss: 0.0179 - accuracy: 0.9936 - val_loss: 0.3672 - val_accuracy: 0.7344\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 298ms/step - loss: 0.0170 - accuracy: 0.9939 - val_loss: 0.4200 - val_accuracy: 0.7339\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 12s 383ms/step - loss: 0.0165 - accuracy: 0.9943 - val_loss: 0.3677 - val_accuracy: 0.7788\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 14s 452ms/step - loss: 0.0165 - accuracy: 0.9948 - val_loss: 0.3257 - val_accuracy: 0.8063\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 13s 432ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.4715 - val_accuracy: 0.7660\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 12s 389ms/step - loss: 0.0153 - accuracy: 0.9949 - val_loss: 0.3649 - val_accuracy: 0.8160\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 342ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.3884 - val_accuracy: 0.8163\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 12s 398ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 0.5978 - val_accuracy: 0.7512\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 15s 477ms/step - loss: 0.0163 - accuracy: 0.9952 - val_loss: 0.2832 - val_accuracy: 0.8448\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 13s 419ms/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 0.4579 - val_accuracy: 0.7956\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 12s 389ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.3183 - val_accuracy: 0.8415\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 330ms/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 0.4263 - val_accuracy: 0.8086\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 13s 409ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.4162 - val_accuracy: 0.8165\n",
      "4279/4279 [==============================] - 47s 11ms/step - loss: 0.0505 - accuracy: 0.97280s - loss: 0.0506 - \n",
      "1721/1721 [==============================] - 19s 11ms/step - loss: 0.3515 - accuracy: 0.8348\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 13s 422ms/step - loss: 0.3537 - accuracy: 0.9359 - val_loss: 0.2523 - val_accuracy: 0.9423\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 358ms/step - loss: 0.2358 - accuracy: 0.9424 - val_loss: 0.2213 - val_accuracy: 0.9429\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 367ms/step - loss: 0.2228 - accuracy: 0.9428 - val_loss: 0.2181 - val_accuracy: 0.9431\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 366ms/step - loss: 0.2204 - accuracy: 0.9429 - val_loss: 0.2162 - val_accuracy: 0.9431\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 12s 374ms/step - loss: 0.2185 - accuracy: 0.9433 - val_loss: 0.2155 - val_accuracy: 0.9431\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 247ms/step - loss: 0.0272 - accuracy: 0.9932 - val_loss: 0.3810 - val_accuracy: 0.7389\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 0.3272 - val_accuracy: 0.8005\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 221ms/step - loss: 0.0155 - accuracy: 0.9954 - val_loss: 0.2730 - val_accuracy: 0.8446\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 248ms/step - loss: 0.0150 - accuracy: 0.9955 - val_loss: 0.3606 - val_accuracy: 0.8178\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 240ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.3179 - val_accuracy: 0.8413\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 10s 335ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.3674 - val_accuracy: 0.8224\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 328ms/step - loss: 0.0133 - accuracy: 0.9959 - val_loss: 0.4753 - val_accuracy: 0.7994\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 350ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 0.4379 - val_accuracy: 0.8137\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 335ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.3784 - val_accuracy: 0.8380\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 325ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.5334 - val_accuracy: 0.7954\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 14s 462ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.4139 - val_accuracy: 0.8283\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 13s 432ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.4796 - val_accuracy: 0.8154\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 13s 431ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 0.4325 - val_accuracy: 0.8246\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 360ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.3901 - val_accuracy: 0.8385\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 352ms/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 0.5048 - val_accuracy: 0.8087\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 15s 477ms/step - loss: 0.0129 - accuracy: 0.9965 - val_loss: 0.5199 - val_accuracy: 0.7977\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 14s 442ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.4403 - val_accuracy: 0.8255\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 14s 439ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.4504 - val_accuracy: 0.8219\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 349ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.5197 - val_accuracy: 0.8010\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 367ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.5001 - val_accuracy: 0.8074\n",
      "4279/4279 [==============================] - 46s 11ms/step - loss: 0.0702 - accuracy: 0.9708\n",
      "1721/1721 [==============================] - 21s 12ms/step - loss: 0.4887 - accuracy: 0.7520\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 13s 409ms/step - loss: 0.3689 - accuracy: 0.9345 - val_loss: 0.2488 - val_accuracy: 0.9403\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 358ms/step - loss: 0.2317 - accuracy: 0.9422 - val_loss: 0.2216 - val_accuracy: 0.9424\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 12s 374ms/step - loss: 0.2210 - accuracy: 0.9427 - val_loss: 0.2174 - val_accuracy: 0.9429\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 356ms/step - loss: 0.2188 - accuracy: 0.9432 - val_loss: 0.2163 - val_accuracy: 0.9433\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 369ms/step - loss: 0.2174 - accuracy: 0.9433 - val_loss: 0.2144 - val_accuracy: 0.9433\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 9s 304ms/step - loss: 0.0214 - accuracy: 0.9945 - val_loss: 0.3742 - val_accuracy: 0.7872\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 235ms/step - loss: 0.0144 - accuracy: 0.9959 - val_loss: 0.3805 - val_accuracy: 0.8177\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 258ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 0.4210 - val_accuracy: 0.8134\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 265ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.3500 - val_accuracy: 0.8467\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 235ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.4065 - val_accuracy: 0.8332\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 374ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.4609 - val_accuracy: 0.8143\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 358ms/step - loss: 0.0115 - accuracy: 0.9967 - val_loss: 0.5002 - val_accuracy: 0.8098\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 343ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 0.6503 - val_accuracy: 0.7782\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 351ms/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 0.5417 - val_accuracy: 0.8019\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 332ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.5991 - val_accuracy: 0.7984\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 15s 493ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.4943 - val_accuracy: 0.8277\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 14s 456ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.4717 - val_accuracy: 0.8323\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 13s 427ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.6486 - val_accuracy: 0.7790\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 377ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.5975 - val_accuracy: 0.7984\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 365ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.4196 - val_accuracy: 0.8461\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 16s 522ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.5023 - val_accuracy: 0.8263\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 15s 479ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.4243 - val_accuracy: 0.8442\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 12s 401ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.3264 - val_accuracy: 0.8655\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 356ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.6213 - val_accuracy: 0.7828\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 341ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.3869 - val_accuracy: 0.8523\n",
      "4279/4279 [==============================] - 52s 12ms/step - loss: 0.0593 - accuracy: 0.9743\n",
      "1721/1721 [==============================] - 20s 11ms/step - loss: 0.2517 - accuracy: 0.8715\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr105Amed.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.05049462243914604, 0.351478636264801], [0.07023373246192932, 0.4887283146381378], [0.05930818244814873, 0.2516592741012573]]\n",
      "Accuracy for iterations:  [[0.9728227257728577, 0.8347925543785095], [0.9708288311958313, 0.7519981265068054], [0.974254310131073, 0.8714669942855835]]\n",
      "F1 for iterations:  [[0.9727837449695576, 0.8273961723240721], [0.9707727317440585, 0.7277151380453881], [0.9742197222524658, 0.8677772285101247]]\n",
      "Precision for iterations:  [[0.9734314129700049, 0.8649459379121415], [0.9718046650406867, 0.8180750152503118], [0.9748025513826907, 0.8896848809784373]]\n",
      "Recall for iterations:  [[0.9728227526366531, 0.8347925597616799], [0.9708288293552251, 0.751998110876989], [0.9742542873002424, 0.8714669766765967]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5B 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_10604/3855986297.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_10604/3855986297.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_10604/3855986297.py:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part4.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_10604/3855986297.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr255Amed.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 244ms/step - loss: 0.4551 - accuracy: 0.8538 - val_loss: 0.2205 - val_accuracy: 0.9108\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 234ms/step - loss: 0.1498 - accuracy: 0.9636 - val_loss: 0.1231 - val_accuracy: 0.9765\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 229ms/step - loss: 0.1164 - accuracy: 0.9774 - val_loss: 0.1103 - val_accuracy: 0.9776\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 233ms/step - loss: 0.1052 - accuracy: 0.9789 - val_loss: 0.1033 - val_accuracy: 0.9786\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 226ms/step - loss: 0.0996 - accuracy: 0.9796 - val_loss: 0.1001 - val_accuracy: 0.9787\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 225ms/step - loss: 0.0319 - accuracy: 0.9899 - val_loss: 0.3505 - val_accuracy: 0.7823\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 215ms/step - loss: 0.0229 - accuracy: 0.9909 - val_loss: 0.3052 - val_accuracy: 0.7820\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 193ms/step - loss: 0.0215 - accuracy: 0.9919 - val_loss: 0.3501 - val_accuracy: 0.6991\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 189ms/step - loss: 0.0203 - accuracy: 0.9924 - val_loss: 0.3789 - val_accuracy: 0.6909\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 193ms/step - loss: 0.0192 - accuracy: 0.9931 - val_loss: 0.2934 - val_accuracy: 0.7764\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 268ms/step - loss: 0.0188 - accuracy: 0.9930 - val_loss: 0.4327 - val_accuracy: 0.6958\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 285ms/step - loss: 0.0173 - accuracy: 0.9939 - val_loss: 0.4002 - val_accuracy: 0.7272\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 279ms/step - loss: 0.0168 - accuracy: 0.9942 - val_loss: 0.3929 - val_accuracy: 0.7478\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 277ms/step - loss: 0.0163 - accuracy: 0.9944 - val_loss: 0.2665 - val_accuracy: 0.8275\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 281ms/step - loss: 0.0163 - accuracy: 0.9945 - val_loss: 0.3821 - val_accuracy: 0.7736\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 366ms/step - loss: 0.0165 - accuracy: 0.9946 - val_loss: 0.2636 - val_accuracy: 0.8378\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 12s 384ms/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 0.3759 - val_accuracy: 0.7924\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 13s 420ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.4886 - val_accuracy: 0.7632\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 13s 415ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.3578 - val_accuracy: 0.8191\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 12s 390ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.2816 - val_accuracy: 0.8469\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 360ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.3578 - val_accuracy: 0.8103\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 12s 393ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.3857 - val_accuracy: 0.8074\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 13s 410ms/step - loss: 0.0119 - accuracy: 0.9965 - val_loss: 0.2860 - val_accuracy: 0.8462\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 13s 411ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.4276 - val_accuracy: 0.8022\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 12s 387ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.2505 - val_accuracy: 0.8613\n",
      "4279/4279 [==============================] - 46s 11ms/step - loss: 0.0377 - accuracy: 0.9832\n",
      "1721/1721 [==============================] - 20s 12ms/step - loss: 0.3008 - accuracy: 0.8607\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 14s 436ms/step - loss: 0.1345 - accuracy: 0.9786 - val_loss: 0.1091 - val_accuracy: 0.9799\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 12s 403ms/step - loss: 0.1032 - accuracy: 0.9803 - val_loss: 0.0988 - val_accuracy: 0.9797\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 342ms/step - loss: 0.0944 - accuracy: 0.9806 - val_loss: 0.0954 - val_accuracy: 0.9798\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 349ms/step - loss: 0.0918 - accuracy: 0.9806 - val_loss: 0.0941 - val_accuracy: 0.9798\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 336ms/step - loss: 0.0907 - accuracy: 0.9806 - val_loss: 0.0934 - val_accuracy: 0.9798\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 247ms/step - loss: 0.0226 - accuracy: 0.9934 - val_loss: 0.3190 - val_accuracy: 0.7852\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 222ms/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 0.3229 - val_accuracy: 0.7958\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 215ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 0.3750 - val_accuracy: 0.7762\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 224ms/step - loss: 0.0151 - accuracy: 0.9954 - val_loss: 0.3197 - val_accuracy: 0.8171\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 214ms/step - loss: 0.0147 - accuracy: 0.9957 - val_loss: 0.4608 - val_accuracy: 0.7601\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 225ms/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.4483 - val_accuracy: 0.7718\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 198ms/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.5204 - val_accuracy: 0.7591\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 290ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.4932 - val_accuracy: 0.7779\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 304ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.3921 - val_accuracy: 0.8167\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 307ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.3972 - val_accuracy: 0.8239\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 14s 451ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 0.3854 - val_accuracy: 0.8262\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 343ms/step - loss: 0.0134 - accuracy: 0.9961 - val_loss: 0.3207 - val_accuracy: 0.8475\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 351ms/step - loss: 0.0132 - accuracy: 0.9959 - val_loss: 0.3288 - val_accuracy: 0.8487\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 372ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.4125 - val_accuracy: 0.8299\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 13s 423ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.2293 - val_accuracy: 0.8763\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 13s 433ms/step - loss: 0.0131 - accuracy: 0.9965 - val_loss: 0.5521 - val_accuracy: 0.7839\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 362ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 0.4790 - val_accuracy: 0.8076\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 316ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.3898 - val_accuracy: 0.8347\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 397ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.3604 - val_accuracy: 0.8427\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 12s 374ms/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.4993 - val_accuracy: 0.8002\n",
      "4279/4279 [==============================] - 46s 11ms/step - loss: 0.0739 - accuracy: 0.9693\n",
      "1721/1721 [==============================] - 17s 10ms/step - loss: 0.6587 - accuracy: 0.7015\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 362ms/step - loss: 0.1258 - accuracy: 0.9785 - val_loss: 0.1032 - val_accuracy: 0.9796\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 12s 395ms/step - loss: 0.0967 - accuracy: 0.9806 - val_loss: 0.0967 - val_accuracy: 0.9798\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 13s 410ms/step - loss: 0.0921 - accuracy: 0.9806 - val_loss: 0.0938 - val_accuracy: 0.9799\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 13s 411ms/step - loss: 0.0902 - accuracy: 0.9806 - val_loss: 0.0925 - val_accuracy: 0.9798\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 347ms/step - loss: 0.0895 - accuracy: 0.9806 - val_loss: 0.0924 - val_accuracy: 0.9798\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 249ms/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 0.3114 - val_accuracy: 0.8321\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 228ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.4106 - val_accuracy: 0.8066\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 226ms/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 0.3650 - val_accuracy: 0.8326\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 225ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.4078 - val_accuracy: 0.8259\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 215ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 0.5353 - val_accuracy: 0.7773\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 221ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.5722 - val_accuracy: 0.7733\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 208ms/step - loss: 0.0118 - accuracy: 0.9967 - val_loss: 0.5321 - val_accuracy: 0.7905\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 218ms/step - loss: 0.0117 - accuracy: 0.9966 - val_loss: 0.3766 - val_accuracy: 0.8444\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 219ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.6408 - val_accuracy: 0.7669\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 207ms/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 0.4323 - val_accuracy: 0.8364\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 10s 325ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.5830 - val_accuracy: 0.7929\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 309ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.3750 - val_accuracy: 0.8477\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 12s 388ms/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 0.5881 - val_accuracy: 0.7996\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 13s 412ms/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.5915 - val_accuracy: 0.8014\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 13s 413ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.4665 - val_accuracy: 0.8303\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 14s 440ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 0.5514 - val_accuracy: 0.8173\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 317ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.5431 - val_accuracy: 0.8220\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 13s 413ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.3885 - val_accuracy: 0.8504\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 389ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.4629 - val_accuracy: 0.8330\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 13s 420ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 0.4134 - val_accuracy: 0.8451\n",
      "4279/4279 [==============================] - 45s 10ms/step - loss: 0.0651 - accuracy: 0.9722\n",
      "1721/1721 [==============================] - 18s 10ms/step - loss: 0.5783 - accuracy: 0.7412\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr255Amed.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.037744056433439255, 0.30084630846977234], [0.07391563802957535, 0.6586554050445557], [0.0651039332151413, 0.5782988667488098]]\n",
      "Accuracy for iterations:  [[0.9832159876823425, 0.8607134819030762], [0.9692804217338562, 0.701500415802002], [0.972172737121582, 0.7411538362503052]]\n",
      "F1 for iterations:  [[0.9832096387142932, 0.8562097192925908], [0.9692161591417824, 0.658271347893325], [0.972128241436249, 0.7132048262937432]]\n",
      "Precision for iterations:  [[0.9832727804796078, 0.8814826660015413], [0.9703893942707573, 0.7950497465978846], [0.9728986964229371, 0.8140293191190128]]\n",
      "Recall for iterations:  [[0.9832159864442432, 0.8607135072295284], [0.9692804347190979, 0.7015003996221754], [0.972172719039411, 0.7411538182082394]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5B 5% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16348/3503541895.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16348/3503541895.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16348/3503541895.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr55Bmed.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 361ms/step - loss: 0.4603 - accuracy: 0.8307 - val_loss: 0.2359 - val_accuracy: 0.9394\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 323ms/step - loss: 0.1960 - accuracy: 0.9515 - val_loss: 0.1720 - val_accuracy: 0.9622\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 256ms/step - loss: 0.1646 - accuracy: 0.9651 - val_loss: 0.1575 - val_accuracy: 0.9649\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 332ms/step - loss: 0.1522 - accuracy: 0.9673 - val_loss: 0.1519 - val_accuracy: 0.9658\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 333ms/step - loss: 0.1461 - accuracy: 0.9675 - val_loss: 0.1463 - val_accuracy: 0.9660\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 384ms/step - loss: 0.0361 - accuracy: 0.9897 - val_loss: 0.4074 - val_accuracy: 0.7282\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 305ms/step - loss: 0.0231 - accuracy: 0.9910 - val_loss: 0.3046 - val_accuracy: 0.7799\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 268ms/step - loss: 0.0215 - accuracy: 0.9920 - val_loss: 0.3112 - val_accuracy: 0.7433\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 320ms/step - loss: 0.0204 - accuracy: 0.9928 - val_loss: 0.3947 - val_accuracy: 0.6898\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 344ms/step - loss: 0.0198 - accuracy: 0.9931 - val_loss: 0.2984 - val_accuracy: 0.7724\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 360ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 5.1202 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 322ms/step - loss: 1.0329e-07 - accuracy: 1.0000 - val_loss: 5.4571 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 263ms/step - loss: 7.7437e-08 - accuracy: 1.0000 - val_loss: 5.4748 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 322ms/step - loss: 7.6220e-08 - accuracy: 1.0000 - val_loss: 5.4762 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 351ms/step - loss: 7.6074e-08 - accuracy: 1.0000 - val_loss: 5.4770 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 366ms/step - loss: 4.2469 - accuracy: 0.4955 - val_loss: 0.0167 - val_accuracy: 0.9963\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 305ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 258ms/step - loss: 3.6342e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 265ms/step - loss: 2.4320e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 253ms/step - loss: 1.6390e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 247ms/step - loss: 1.7335 - accuracy: 0.6994 - val_loss: 0.7567 - val_accuracy: 0.6333\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 221ms/step - loss: 0.0386 - accuracy: 0.9943 - val_loss: 0.5759 - val_accuracy: 0.6381\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 235ms/step - loss: 0.0224 - accuracy: 0.9942 - val_loss: 0.6266 - val_accuracy: 0.6376\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 215ms/step - loss: 0.0205 - accuracy: 0.9942 - val_loss: 0.6128 - val_accuracy: 0.6369\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 227ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.5585 - val_accuracy: 0.6368\n",
      "4279/4279 [==============================] - 33s 8ms/step - loss: 0.1069 - accuracy: 0.9253 0s - loss: 0.1070 \n",
      "1721/1721 [==============================] - 18s 10ms/step - loss: 0.2444 - accuracy: 0.8564\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 374ms/step - loss: 0.1557 - accuracy: 0.9654 - val_loss: 0.1462 - val_accuracy: 0.9659\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 247ms/step - loss: 0.1418 - accuracy: 0.9676 - val_loss: 0.1428 - val_accuracy: 0.9660\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 352ms/step - loss: 0.1395 - accuracy: 0.9675 - val_loss: 0.1419 - val_accuracy: 0.9660\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 324ms/step - loss: 0.1382 - accuracy: 0.9676 - val_loss: 0.1422 - val_accuracy: 0.9658\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 362ms/step - loss: 0.1374 - accuracy: 0.9677 - val_loss: 0.1412 - val_accuracy: 0.9664\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 351ms/step - loss: 0.0247 - accuracy: 0.9927 - val_loss: 0.3010 - val_accuracy: 0.7775\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 273ms/step - loss: 0.0197 - accuracy: 0.9941 - val_loss: 0.2894 - val_accuracy: 0.7896\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 348ms/step - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.2640 - val_accuracy: 0.8161\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 359ms/step - loss: 0.0172 - accuracy: 0.9943 - val_loss: 0.4126 - val_accuracy: 0.7590\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 362ms/step - loss: 0.0165 - accuracy: 0.9942 - val_loss: 0.2609 - val_accuracy: 0.8288\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 356ms/step - loss: 0.0139 - accuracy: 0.9945 - val_loss: 4.4965 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 277ms/step - loss: 5.4889e-07 - accuracy: 1.0000 - val_loss: 4.8144 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 347ms/step - loss: 4.1231e-07 - accuracy: 1.0000 - val_loss: 4.8319 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 359ms/step - loss: 4.0567e-07 - accuracy: 1.0000 - val_loss: 4.8344 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 363ms/step - loss: 4.0366e-07 - accuracy: 1.0000 - val_loss: 4.8363 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 261ms/step - loss: 4.0897 - accuracy: 0.4919 - val_loss: 0.1168 - val_accuracy: 0.9407\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 214ms/step - loss: 0.0150 - accuracy: 0.9978 - val_loss: 0.0060 - val_accuracy: 0.9977\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 201ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9995\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 205ms/step - loss: 8.1767e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9998\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 212ms/step - loss: 6.1271e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 218ms/step - loss: 1.1561 - accuracy: 0.7590 - val_loss: 0.5612 - val_accuracy: 0.6931\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 0.0232 - accuracy: 0.9943 - val_loss: 0.3138 - val_accuracy: 0.7689\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 237ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.4615 - val_accuracy: 0.7005\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 236ms/step - loss: 0.0168 - accuracy: 0.9943 - val_loss: 0.4802 - val_accuracy: 0.6971\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 197ms/step - loss: 0.0165 - accuracy: 0.9943 - val_loss: 0.4883 - val_accuracy: 0.6967\n",
      "4279/4279 [==============================] - 28s 7ms/step - loss: 0.0836 - accuracy: 0.9466\n",
      "1721/1721 [==============================] - 15s 9ms/step - loss: 0.2290 - accuracy: 0.8632\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 9s 285ms/step - loss: 0.1432 - accuracy: 0.9676 - val_loss: 0.1415 - val_accuracy: 0.9660\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 246ms/step - loss: 0.1371 - accuracy: 0.9678 - val_loss: 0.1407 - val_accuracy: 0.9660\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 286ms/step - loss: 0.1359 - accuracy: 0.9679 - val_loss: 0.1400 - val_accuracy: 0.9666\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 309ms/step - loss: 0.1356 - accuracy: 0.9684 - val_loss: 0.1400 - val_accuracy: 0.9666\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 300ms/step - loss: 0.1357 - accuracy: 0.9685 - val_loss: 0.1412 - val_accuracy: 0.9665\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 270ms/step - loss: 0.0222 - accuracy: 0.9938 - val_loss: 0.3198 - val_accuracy: 0.7931\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 260ms/step - loss: 0.0182 - accuracy: 0.9943 - val_loss: 0.2348 - val_accuracy: 0.8370\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 289ms/step - loss: 0.0173 - accuracy: 0.9942 - val_loss: 0.2890 - val_accuracy: 0.8149\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 326ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.4331 - val_accuracy: 0.7788\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 349ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 0.3531 - val_accuracy: 0.8109\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 393ms/step - loss: 0.0341 - accuracy: 0.9850 - val_loss: 3.7168 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 292ms/step - loss: 5.0925e-06 - accuracy: 1.0000 - val_loss: 4.0431 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 334ms/step - loss: 3.7609e-06 - accuracy: 1.0000 - val_loss: 4.0675 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 13s 406ms/step - loss: 3.6309e-06 - accuracy: 1.0000 - val_loss: 4.0776 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 12s 403ms/step - loss: 3.5356e-06 - accuracy: 1.0000 - val_loss: 4.0884 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 373ms/step - loss: 2.8561 - accuracy: 0.5635 - val_loss: 0.0811 - val_accuracy: 0.9679\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 282ms/step - loss: 0.0074 - accuracy: 0.9999 - val_loss: 0.0157 - val_accuracy: 0.9988\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 272ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 265ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 268ms/step - loss: 8.6347e-04 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 255ms/step - loss: 0.1822 - accuracy: 0.9313 - val_loss: 0.6490 - val_accuracy: 0.7097\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 246ms/step - loss: 0.0165 - accuracy: 0.9943 - val_loss: 0.5650 - val_accuracy: 0.7214\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 259ms/step - loss: 0.0158 - accuracy: 0.9945 - val_loss: 0.5262 - val_accuracy: 0.7270\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 228ms/step - loss: 0.0155 - accuracy: 0.9945 - val_loss: 0.5224 - val_accuracy: 0.7295\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 256ms/step - loss: 0.0151 - accuracy: 0.9947 - val_loss: 0.4609 - val_accuracy: 0.7463\n",
      "4279/4279 [==============================] - 22s 5ms/step - loss: 0.0710 - accuracy: 0.9572\n",
      "1721/1721 [==============================] - 14s 8ms/step - loss: 0.2055 - accuracy: 0.8993\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr55Bmed.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.10690359771251678, 0.244381844997406], [0.08362846821546555, 0.22898931801319122], [0.07095488160848618, 0.20549599826335907]]\n",
      "Accuracy for iterations:  [[0.9252680540084839, 0.8563902974128723], [0.946609616279602, 0.8632020354270935], [0.9572292566299438, 0.8992589116096497]]\n",
      "F1 for iterations:  [[0.9245748861778189, 0.8514425599764278], [0.9463300839036289, 0.8589810118026715], [0.9570748654616772, 0.8974500173269647]]\n",
      "Precision for iterations:  [[0.9335533079035829, 0.8788159632177689], [0.9506441815206756, 0.8827556103007188], [0.9596707431635976, 0.909251160417791]]\n",
      "Recall for iterations:  [[0.9252680475620089, 0.8563903218774976], [0.946609600046744, 0.8632020635035966], [0.9572292500511262, 0.8992588825110804]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5B 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_1864/2097221778.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part1.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_1864/2097221778.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_1864/2097221778.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_1864/2097221778.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr105Bmed.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 354ms/step - loss: 0.4953 - accuracy: 0.8018 - val_loss: 0.2969 - val_accuracy: 0.9195\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 298ms/step - loss: 0.2683 - accuracy: 0.9282 - val_loss: 0.2432 - val_accuracy: 0.9398\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 348ms/step - loss: 0.2414 - accuracy: 0.9402 - val_loss: 0.2296 - val_accuracy: 0.9420\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 340ms/step - loss: 0.2305 - accuracy: 0.9422 - val_loss: 0.2228 - val_accuracy: 0.9432\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 353ms/step - loss: 0.2243 - accuracy: 0.9425 - val_loss: 0.2189 - val_accuracy: 0.9433\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 359ms/step - loss: 0.0371 - accuracy: 0.9904 - val_loss: 0.4993 - val_accuracy: 0.6725\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 289ms/step - loss: 0.0230 - accuracy: 0.9911 - val_loss: 0.3812 - val_accuracy: 0.7009\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 365ms/step - loss: 0.0215 - accuracy: 0.9920 - val_loss: 0.3076 - val_accuracy: 0.7627\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 333ms/step - loss: 0.0206 - accuracy: 0.9926 - val_loss: 0.4282 - val_accuracy: 0.6853\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 13s 414ms/step - loss: 0.0196 - accuracy: 0.9935 - val_loss: 0.3055 - val_accuracy: 0.7704\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 375ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 4.4293 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 311ms/step - loss: 5.6197e-07 - accuracy: 1.0000 - val_loss: 4.7444 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 312ms/step - loss: 4.1759e-07 - accuracy: 1.0000 - val_loss: 4.7622 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 325ms/step - loss: 4.1030e-07 - accuracy: 1.0000 - val_loss: 4.7650 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 349ms/step - loss: 4.0782e-07 - accuracy: 1.0000 - val_loss: 4.7674 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 389ms/step - loss: 4.0171 - accuracy: 0.4638 - val_loss: 0.0410 - val_accuracy: 0.9886\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 345ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9995\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 273ms/step - loss: 8.2701e-04 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 251ms/step - loss: 6.3400e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 243ms/step - loss: 4.4065e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 251ms/step - loss: 1.5113 - accuracy: 0.7041 - val_loss: 0.6587 - val_accuracy: 0.6343\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 242ms/step - loss: 0.0383 - accuracy: 0.9942 - val_loss: 0.5707 - val_accuracy: 0.6385\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 230ms/step - loss: 0.0226 - accuracy: 0.9942 - val_loss: 0.7292 - val_accuracy: 0.6370\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 231ms/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 0.6111 - val_accuracy: 0.6368\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 240ms/step - loss: 0.0192 - accuracy: 0.9942 - val_loss: 0.6110 - val_accuracy: 0.6367\n",
      "4279/4279 [==============================] - 31s 7ms/step - loss: 0.1181 - accuracy: 0.9239\n",
      "1721/1721 [==============================] - 17s 10ms/step - loss: 0.2481 - accuracy: 0.8439\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 10s 332ms/step - loss: 0.2396 - accuracy: 0.9403 - val_loss: 0.2198 - val_accuracy: 0.9433\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 267ms/step - loss: 0.2217 - accuracy: 0.9425 - val_loss: 0.2176 - val_accuracy: 0.9433\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 338ms/step - loss: 0.2190 - accuracy: 0.9425 - val_loss: 0.2152 - val_accuracy: 0.9433\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 338ms/step - loss: 0.2179 - accuracy: 0.9425 - val_loss: 0.2154 - val_accuracy: 0.9433\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 299ms/step - loss: 0.2174 - accuracy: 0.9425 - val_loss: 0.2143 - val_accuracy: 0.9433\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 9s 289ms/step - loss: 0.0257 - accuracy: 0.9924 - val_loss: 0.3169 - val_accuracy: 0.7607\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 201ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.2435 - val_accuracy: 0.8342\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 326ms/step - loss: 0.0192 - accuracy: 0.9937 - val_loss: 0.2199 - val_accuracy: 0.8519\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 352ms/step - loss: 0.0183 - accuracy: 0.9939 - val_loss: 0.3970 - val_accuracy: 0.7590\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 343ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.3544 - val_accuracy: 0.7878\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 348ms/step - loss: 0.0235 - accuracy: 0.9902 - val_loss: 4.2219 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 244ms/step - loss: 1.2271e-06 - accuracy: 1.0000 - val_loss: 4.5721 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 327ms/step - loss: 8.9948e-07 - accuracy: 1.0000 - val_loss: 4.5921 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 368ms/step - loss: 8.8166e-07 - accuracy: 1.0000 - val_loss: 4.5955 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 352ms/step - loss: 8.7525e-07 - accuracy: 1.0000 - val_loss: 4.5985 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 356ms/step - loss: 4.2376 - accuracy: 0.4456 - val_loss: 0.1878 - val_accuracy: 0.8915\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 266ms/step - loss: 0.0294 - accuracy: 0.9892 - val_loss: 0.0063 - val_accuracy: 0.9986\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 262ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 271ms/step - loss: 9.6453e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 266ms/step - loss: 5.9337e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 244ms/step - loss: 0.9533 - accuracy: 0.7779 - val_loss: 0.6085 - val_accuracy: 0.6891\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 224ms/step - loss: 0.0237 - accuracy: 0.9937 - val_loss: 0.3305 - val_accuracy: 0.7903\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 230ms/step - loss: 0.0180 - accuracy: 0.9936 - val_loss: 0.4874 - val_accuracy: 0.6991\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 223ms/step - loss: 0.0173 - accuracy: 0.9942 - val_loss: 0.4956 - val_accuracy: 0.6982\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 243ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 0.5043 - val_accuracy: 0.6975\n",
      "4279/4279 [==============================] - 34s 8ms/step - loss: 0.0859 - accuracy: 0.9466\n",
      "1721/1721 [==============================] - 15s 9ms/step - loss: 0.2051 - accuracy: 0.8828\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 10s 323ms/step - loss: 0.2354 - accuracy: 0.9417 - val_loss: 0.2174 - val_accuracy: 0.9433\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 224ms/step - loss: 0.2178 - accuracy: 0.9426 - val_loss: 0.2136 - val_accuracy: 0.9433\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 323ms/step - loss: 0.2164 - accuracy: 0.9426 - val_loss: 0.2132 - val_accuracy: 0.9433\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 345ms/step - loss: 0.2161 - accuracy: 0.9426 - val_loss: 0.2128 - val_accuracy: 0.9436\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 332ms/step - loss: 0.2154 - accuracy: 0.9430 - val_loss: 0.2131 - val_accuracy: 0.9432\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 9s 279ms/step - loss: 0.0260 - accuracy: 0.9930 - val_loss: 0.3161 - val_accuracy: 0.7775\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 214ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.2933 - val_accuracy: 0.7940\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 283ms/step - loss: 0.0178 - accuracy: 0.9943 - val_loss: 0.2797 - val_accuracy: 0.8076\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 299ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 0.2797 - val_accuracy: 0.8154\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 306ms/step - loss: 0.0164 - accuracy: 0.9946 - val_loss: 0.3012 - val_accuracy: 0.8165\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 9s 305ms/step - loss: 0.0707 - accuracy: 0.9705 - val_loss: 3.8052 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 240ms/step - loss: 3.6960e-06 - accuracy: 1.0000 - val_loss: 4.2070 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 274ms/step - loss: 2.5108e-06 - accuracy: 1.0000 - val_loss: 4.2305 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 313ms/step - loss: 2.4456e-06 - accuracy: 1.0000 - val_loss: 4.2349 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 324ms/step - loss: 2.4221e-06 - accuracy: 1.0000 - val_loss: 4.2389 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 10s 323ms/step - loss: 3.3863 - accuracy: 0.5425 - val_loss: 0.0703 - val_accuracy: 0.9802\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 221ms/step - loss: 0.0036 - accuracy: 0.9998 - val_loss: 0.0064 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 239ms/step - loss: 6.6158e-04 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 265ms/step - loss: 3.5970e-04 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 263ms/step - loss: 2.0160e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 204ms/step - loss: 0.3335 - accuracy: 0.8889 - val_loss: 0.6200 - val_accuracy: 0.7001\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 203ms/step - loss: 0.0180 - accuracy: 0.9943 - val_loss: 0.4060 - val_accuracy: 0.7557\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 206ms/step - loss: 0.0163 - accuracy: 0.9944 - val_loss: 0.5017 - val_accuracy: 0.7311\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 205ms/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 0.5038 - val_accuracy: 0.7328\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 196ms/step - loss: 0.0157 - accuracy: 0.9944 - val_loss: 0.4675 - val_accuracy: 0.7460\n",
      "4279/4279 [==============================] - 18s 4ms/step - loss: 0.0689 - accuracy: 0.9549\n",
      "1721/1721 [==============================] - 8s 5ms/step - loss: 0.1928 - accuracy: 0.8966\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr105Bmed.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.1181071475148201, 0.24809576570987701], [0.08594716340303421, 0.20506659150123596], [0.0689178928732872, 0.1927899867296219]]\n",
      "Accuracy for iterations:  [[0.9239022731781006, 0.8438930511474609], [0.9465584754943848, 0.8827654123306274], [0.9548555612564087, 0.8966068625450134]]\n",
      "F1 for iterations:  [[0.9231742327834022, 0.8376277834189282], [0.9462780117656485, 0.8800293158357178], [0.9546814595297561, 0.8946788398873966]]\n",
      "Precision for iterations:  [[0.9325013096001444, 0.8705604423698192], [0.9506062984634849, 0.8967041757328372], [0.9575231853740371, 0.9070789639401701]]\n",
      "Recall for iterations:  [[0.923902246632972, 0.8438930465741481], [0.9465584738087587, 0.8827653854537528], [0.95485553185895, 0.8966068444379859]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5B 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_1864/3291834707.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part1.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_1864/3291834707.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_1864/3291834707.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_1864/3291834707.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr255Bmed.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.5573 - accuracy: 0.7594 - val_loss: 0.4323 - val_accuracy: 0.8537\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 0.4239 - accuracy: 0.8576 - val_loss: 0.4052 - val_accuracy: 0.8686\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 150ms/step - loss: 0.4080 - accuracy: 0.8657 - val_loss: 0.3946 - val_accuracy: 0.8697\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.3987 - accuracy: 0.8676 - val_loss: 0.3895 - val_accuracy: 0.8700\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.3939 - accuracy: 0.8682 - val_loss: 0.3868 - val_accuracy: 0.8705\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 219ms/step - loss: 0.0514 - accuracy: 0.9898 - val_loss: 0.5494 - val_accuracy: 0.6584\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 188ms/step - loss: 0.0245 - accuracy: 0.9907 - val_loss: 0.4366 - val_accuracy: 0.6795\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 0.0227 - accuracy: 0.9914 - val_loss: 0.2814 - val_accuracy: 0.8184\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.0219 - accuracy: 0.9920 - val_loss: 0.3144 - val_accuracy: 0.7660\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 166ms/step - loss: 0.0210 - accuracy: 0.9927 - val_loss: 0.3562 - val_accuracy: 0.7211\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 185ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 3.9268 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 178ms/step - loss: 2.6698e-06 - accuracy: 1.0000 - val_loss: 4.2026 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 2.1798e-06 - accuracy: 1.0000 - val_loss: 4.2237 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 169ms/step - loss: 2.1182e-06 - accuracy: 1.0000 - val_loss: 4.2330 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 178ms/step - loss: 2.0696e-06 - accuracy: 1.0000 - val_loss: 4.2426 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 3.5849 - accuracy: 0.4709 - val_loss: 0.0195 - val_accuracy: 0.9962\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 172ms/step - loss: 6.2912e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 211ms/step - loss: 3.8257e-04 - accuracy: 1.0000 - val_loss: 9.2706e-04 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 216ms/step - loss: 2.2651e-04 - accuracy: 1.0000 - val_loss: 4.8112e-04 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 229ms/step - loss: 1.6798 - accuracy: 0.6751 - val_loss: 0.6572 - val_accuracy: 0.6357\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 215ms/step - loss: 0.0473 - accuracy: 0.9943 - val_loss: 0.5476 - val_accuracy: 0.6377\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 218ms/step - loss: 0.0264 - accuracy: 0.9942 - val_loss: 0.5695 - val_accuracy: 0.6379\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 221ms/step - loss: 0.0234 - accuracy: 0.9942 - val_loss: 0.6231 - val_accuracy: 0.6372\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 218ms/step - loss: 0.0218 - accuracy: 0.9942 - val_loss: 0.6321 - val_accuracy: 0.6367\n",
      "   1/4279 [..............................] - ETA: 1s - loss: 0.1049 - accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0036s vs `on_test_batch_end` time: 0.0067s). Check your callbacks.\n",
      "4279/4279 [==============================] - 26s 6ms/step - loss: 0.1235 - accuracy: 0.9240\n",
      "1721/1721 [==============================] - 9s 5ms/step - loss: 0.2495 - accuracy: 0.8517\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 225ms/step - loss: 0.4280 - accuracy: 0.8665 - val_loss: 0.3920 - val_accuracy: 0.8703\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 229ms/step - loss: 0.3936 - accuracy: 0.8683 - val_loss: 0.3850 - val_accuracy: 0.8705\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 248ms/step - loss: 0.3908 - accuracy: 0.8683 - val_loss: 0.3843 - val_accuracy: 0.8705\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 244ms/step - loss: 0.3897 - accuracy: 0.8683 - val_loss: 0.3847 - val_accuracy: 0.8705\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 257ms/step - loss: 0.3893 - accuracy: 0.8684 - val_loss: 0.3839 - val_accuracy: 0.8705\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 0.0355 - accuracy: 0.9913 - val_loss: 0.4031 - val_accuracy: 0.6543\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 234ms/step - loss: 0.0214 - accuracy: 0.9928 - val_loss: 0.3030 - val_accuracy: 0.7601\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 233ms/step - loss: 0.0204 - accuracy: 0.9937 - val_loss: 0.2931 - val_accuracy: 0.7715\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 239ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.3750 - val_accuracy: 0.7303\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 234ms/step - loss: 0.0190 - accuracy: 0.9940 - val_loss: 0.2794 - val_accuracy: 0.8013\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 268ms/step - loss: 0.0142 - accuracy: 0.9946 - val_loss: 3.5759 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 212ms/step - loss: 4.8445e-06 - accuracy: 1.0000 - val_loss: 3.8696 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 221ms/step - loss: 3.7669e-06 - accuracy: 1.0000 - val_loss: 3.8919 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 236ms/step - loss: 3.6582e-06 - accuracy: 1.0000 - val_loss: 3.9013 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 223ms/step - loss: 3.5790e-06 - accuracy: 1.0000 - val_loss: 3.9110 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 247ms/step - loss: 3.7240 - accuracy: 0.4370 - val_loss: 0.1216 - val_accuracy: 0.9435\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 230ms/step - loss: 0.0252 - accuracy: 0.9978 - val_loss: 0.0059 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 238ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 230ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 230ms/step - loss: 6.4397e-04 - accuracy: 1.0000 - val_loss: 9.1561e-04 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 231ms/step - loss: 1.2478 - accuracy: 0.7054 - val_loss: 0.4998 - val_accuracy: 0.6711\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 228ms/step - loss: 0.0339 - accuracy: 0.9940 - val_loss: 0.3970 - val_accuracy: 0.7046\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 223ms/step - loss: 0.0217 - accuracy: 0.9935 - val_loss: 0.5481 - val_accuracy: 0.6490\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 0.0201 - accuracy: 0.9942 - val_loss: 0.5819 - val_accuracy: 0.6441\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.5678 - val_accuracy: 0.6471\n",
      "4279/4279 [==============================] - 23s 5ms/step - loss: 0.1135 - accuracy: 0.9297\n",
      "1721/1721 [==============================] - 10s 6ms/step - loss: 0.2399 - accuracy: 0.8635\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 236ms/step - loss: 0.4261 - accuracy: 0.8673 - val_loss: 0.3911 - val_accuracy: 0.8700\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 247ms/step - loss: 0.3916 - accuracy: 0.8683 - val_loss: 0.3839 - val_accuracy: 0.8705\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 240ms/step - loss: 0.3896 - accuracy: 0.8684 - val_loss: 0.3835 - val_accuracy: 0.8705\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 248ms/step - loss: 0.3891 - accuracy: 0.8684 - val_loss: 0.3838 - val_accuracy: 0.8705\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 234ms/step - loss: 0.3891 - accuracy: 0.8683 - val_loss: 0.3841 - val_accuracy: 0.8705\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 243ms/step - loss: 0.0361 - accuracy: 0.9919 - val_loss: 0.3763 - val_accuracy: 0.7083\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 248ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 0.4378 - val_accuracy: 0.7097\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 240ms/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 0.2825 - val_accuracy: 0.8016\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 252ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.3799 - val_accuracy: 0.7648\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 243ms/step - loss: 0.0175 - accuracy: 0.9945 - val_loss: 0.2737 - val_accuracy: 0.8240\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 247ms/step - loss: 0.0245 - accuracy: 0.9898 - val_loss: 3.1638 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 242ms/step - loss: 1.4218e-05 - accuracy: 1.0000 - val_loss: 3.4763 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 245ms/step - loss: 1.0835e-05 - accuracy: 1.0000 - val_loss: 3.5074 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 241ms/step - loss: 1.0301e-05 - accuracy: 1.0000 - val_loss: 3.5253 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 248ms/step - loss: 9.8634e-06 - accuracy: 1.0000 - val_loss: 3.5445 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 241ms/step - loss: 3.6936 - accuracy: 0.4244 - val_loss: 0.2088 - val_accuracy: 0.8713\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 239ms/step - loss: 0.0332 - accuracy: 0.9949 - val_loss: 0.0128 - val_accuracy: 0.9984\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 246ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 248ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 247ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 251ms/step - loss: 0.5676 - accuracy: 0.8076 - val_loss: 0.5573 - val_accuracy: 0.6588\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 250ms/step - loss: 0.0204 - accuracy: 0.9944 - val_loss: 0.5396 - val_accuracy: 0.6629\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 244ms/step - loss: 0.0176 - accuracy: 0.9939 - val_loss: 0.4872 - val_accuracy: 0.6711\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 262ms/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.5207 - val_accuracy: 0.6669\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 281ms/step - loss: 0.0169 - accuracy: 0.9943 - val_loss: 0.5100 - val_accuracy: 0.6702\n",
      "4279/4279 [==============================] - 35s 8ms/step - loss: 0.0999 - accuracy: 0.9374\n",
      "1721/1721 [==============================] - 13s 7ms/step - loss: 0.2449 - accuracy: 0.8655\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr255Bmed.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.1235242709517479, 0.24945220351219177], [0.11349524557590485, 0.23985375463962555], [0.09985047578811646, 0.24491889774799347]]\n",
      "Accuracy for iterations:  [[0.9240118265151978, 0.8516675233840942], [0.92970871925354, 0.8634745478630066], [0.9374215006828308, 0.8655089735984802]]\n",
      "F1 for iterations:  [[0.9232865704973329, 0.8463798930050868], [0.9291219478769307, 0.8591791071503254], [0.9369931311537052, 0.8613149899300455]]\n",
      "Precision for iterations:  [[0.932586396290269, 0.8747490856128913], [0.9369985108197456, 0.8836588544370999], [0.9431179109978058, 0.8856218871314806]]\n",
      "Recall for iterations:  [[0.9240118028572263, 0.851667514350069], [0.9297087265184493, 0.8634745331686405], [0.9374214847059511, 0.8655089733343021]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 1 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_1864/591709827.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr55C1med.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 8s 482ms/step - loss: 0.6125 - accuracy: 0.7656 - val_loss: 0.4799 - val_accuracy: 0.7966\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 5s 320ms/step - loss: 0.3703 - accuracy: 0.8611 - val_loss: 0.2562 - val_accuracy: 0.9233\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 6s 358ms/step - loss: 0.2315 - accuracy: 0.9356 - val_loss: 0.2081 - val_accuracy: 0.9461\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 5s 310ms/step - loss: 0.2011 - accuracy: 0.9539 - val_loss: 0.1845 - val_accuracy: 0.9608\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 6s 392ms/step - loss: 0.1839 - accuracy: 0.9607 - val_loss: 0.1712 - val_accuracy: 0.9630\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 4s 302ms/step - loss: 0.0389 - accuracy: 0.9919 - val_loss: 0.6918 - val_accuracy: 0.7271\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 4s 309ms/step - loss: 0.0224 - accuracy: 0.9950 - val_loss: 0.7403 - val_accuracy: 0.7271\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 4s 285ms/step - loss: 0.0216 - accuracy: 0.9950 - val_loss: 0.7370 - val_accuracy: 0.7271\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 4s 317ms/step - loss: 0.0205 - accuracy: 0.9950 - val_loss: 0.5774 - val_accuracy: 0.7287\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 5s 328ms/step - loss: 0.0199 - accuracy: 0.9950 - val_loss: 0.5162 - val_accuracy: 0.7318\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 7s 284ms/step - loss: 0.0153 - accuracy: 0.9960 - val_loss: 2.2544 - val_accuracy: 0.4451\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 7s 282ms/step - loss: 0.0142 - accuracy: 0.9962 - val_loss: 2.4236 - val_accuracy: 0.4429\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 7s 270ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 2.0040 - val_accuracy: 0.4448\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 7s 276ms/step - loss: 0.0128 - accuracy: 0.9965 - val_loss: 2.3613 - val_accuracy: 0.4392\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 7s 272ms/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 2.0328 - val_accuracy: 0.4402\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 9s 321ms/step - loss: 1.5213 - accuracy: 0.6641 - val_loss: 0.0215 - val_accuracy: 0.9913\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 9s 326ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9981\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 8s 314ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9996\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 9s 342ms/step - loss: 8.4540e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 9s 350ms/step - loss: 5.9723e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 22s 318ms/step - loss: 0.4227 - accuracy: 0.9067 - val_loss: 0.3478 - val_accuracy: 0.8275\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 24s 343ms/step - loss: 0.0240 - accuracy: 0.9925 - val_loss: 0.2553 - val_accuracy: 0.8291\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 22s 308ms/step - loss: 0.0218 - accuracy: 0.9927 - val_loss: 0.2300 - val_accuracy: 0.8403\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 20s 290ms/step - loss: 0.0207 - accuracy: 0.9928 - val_loss: 0.2298 - val_accuracy: 0.8424\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 21s 299ms/step - loss: 0.0198 - accuracy: 0.9930 - val_loss: 0.2099 - val_accuracy: 0.8561\n",
      "4279/4279 [==============================] - 41s 9ms/step - loss: 0.0711 - accuracy: 0.9859\n",
      "1721/1721 [==============================] - 13s 7ms/step - loss: 0.1398 - accuracy: 0.9646\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 4s 279ms/step - loss: 0.1873 - accuracy: 0.9595 - val_loss: 0.1618 - val_accuracy: 0.9661\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 4s 267ms/step - loss: 0.1606 - accuracy: 0.9646 - val_loss: 0.1515 - val_accuracy: 0.9666\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 5s 284ms/step - loss: 0.1539 - accuracy: 0.9651 - val_loss: 0.1465 - val_accuracy: 0.9671\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 4s 259ms/step - loss: 0.1508 - accuracy: 0.9654 - val_loss: 0.1440 - val_accuracy: 0.9676\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 4s 266ms/step - loss: 0.1488 - accuracy: 0.9656 - val_loss: 0.1426 - val_accuracy: 0.9679\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 4s 273ms/step - loss: 0.0298 - accuracy: 0.9917 - val_loss: 0.7595 - val_accuracy: 0.7255\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 4s 271ms/step - loss: 0.0178 - accuracy: 0.9952 - val_loss: 0.8118 - val_accuracy: 0.7255\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 4s 256ms/step - loss: 0.0161 - accuracy: 0.9953 - val_loss: 0.4581 - val_accuracy: 0.7268\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 4s 267ms/step - loss: 0.0156 - accuracy: 0.9956 - val_loss: 0.4767 - val_accuracy: 0.7262\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 4s 252ms/step - loss: 0.0149 - accuracy: 0.9955 - val_loss: 0.6083 - val_accuracy: 0.7264\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 7s 276ms/step - loss: 0.0119 - accuracy: 0.9971 - val_loss: 1.7181 - val_accuracy: 0.4403\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 7s 265ms/step - loss: 0.0113 - accuracy: 0.9971 - val_loss: 1.6115 - val_accuracy: 0.4435\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 7s 259ms/step - loss: 0.0111 - accuracy: 0.9973 - val_loss: 1.4264 - val_accuracy: 0.4573\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 7s 270ms/step - loss: 0.0107 - accuracy: 0.9973 - val_loss: 1.7874 - val_accuracy: 0.4563\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 7s 255ms/step - loss: 0.0110 - accuracy: 0.9972 - val_loss: 1.8134 - val_accuracy: 0.4636\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 8s 280ms/step - loss: 3.2100 - accuracy: 0.5211 - val_loss: 0.2369 - val_accuracy: 0.9180\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 7s 267ms/step - loss: 0.0518 - accuracy: 0.9759 - val_loss: 0.0058 - val_accuracy: 0.9968\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 7s 271ms/step - loss: 5.2967e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9989\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 7s 264ms/step - loss: 3.4571e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9994\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 7s 268ms/step - loss: 3.0284e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9996\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 19s 276ms/step - loss: 0.6314 - accuracy: 0.8935 - val_loss: 0.2283 - val_accuracy: 0.8641\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 19s 276ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 0.1938 - val_accuracy: 0.8794\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 19s 273ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.1772 - val_accuracy: 0.8865\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 20s 281ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 0.1651 - val_accuracy: 0.8907\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 20s 286ms/step - loss: 0.0166 - accuracy: 0.9942 - val_loss: 0.1389 - val_accuracy: 0.9102\n",
      "4279/4279 [==============================] - 26s 6ms/step - loss: 0.0563 - accuracy: 0.9895\n",
      "1721/1721 [==============================] - 17s 10ms/step - loss: 0.1051 - accuracy: 0.9770\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 4s 275ms/step - loss: 0.1811 - accuracy: 0.9633 - val_loss: 0.1533 - val_accuracy: 0.9680\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 4s 268ms/step - loss: 0.1544 - accuracy: 0.9658 - val_loss: 0.1450 - val_accuracy: 0.9678\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 4s 273ms/step - loss: 0.1497 - accuracy: 0.9657 - val_loss: 0.1428 - val_accuracy: 0.9678\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 4s 263ms/step - loss: 0.1473 - accuracy: 0.9658 - val_loss: 0.1416 - val_accuracy: 0.9680\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 4s 251ms/step - loss: 0.1461 - accuracy: 0.9659 - val_loss: 0.1405 - val_accuracy: 0.9680\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 4s 291ms/step - loss: 0.0315 - accuracy: 0.9920 - val_loss: 0.6196 - val_accuracy: 0.7245\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 245ms/step - loss: 0.0164 - accuracy: 0.9952 - val_loss: 0.8470 - val_accuracy: 0.7245\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 4s 256ms/step - loss: 0.0156 - accuracy: 0.9958 - val_loss: 0.5693 - val_accuracy: 0.7272\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 4s 278ms/step - loss: 0.0144 - accuracy: 0.9959 - val_loss: 0.5001 - val_accuracy: 0.7350\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 4s 291ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 0.6238 - val_accuracy: 0.7341\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 7s 285ms/step - loss: 0.0108 - accuracy: 0.9973 - val_loss: 1.6568 - val_accuracy: 0.4716\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 7s 270ms/step - loss: 0.0107 - accuracy: 0.9974 - val_loss: 1.5074 - val_accuracy: 0.5016\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 7s 275ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 1.8650 - val_accuracy: 0.4824\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 7s 268ms/step - loss: 0.0100 - accuracy: 0.9975 - val_loss: 1.4520 - val_accuracy: 0.5442\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 7s 268ms/step - loss: 0.0099 - accuracy: 0.9975 - val_loss: 1.9232 - val_accuracy: 0.5054\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 7s 262ms/step - loss: 3.3512 - accuracy: 0.5659 - val_loss: 0.2401 - val_accuracy: 0.9199\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 7s 256ms/step - loss: 0.0386 - accuracy: 0.9806 - val_loss: 0.0044 - val_accuracy: 0.9978\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 8s 282ms/step - loss: 1.2718e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9995\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 7s 264ms/step - loss: 8.8458e-05 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9995\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 7s 272ms/step - loss: 8.2189e-05 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9996\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 18s 252ms/step - loss: 0.4746 - accuracy: 0.9161 - val_loss: 0.2696 - val_accuracy: 0.8680\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 17s 250ms/step - loss: 0.0174 - accuracy: 0.9946 - val_loss: 0.1976 - val_accuracy: 0.8954\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 17s 249ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.1745 - val_accuracy: 0.9022\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 18s 250ms/step - loss: 0.0153 - accuracy: 0.9949 - val_loss: 0.1558 - val_accuracy: 0.9109\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 18s 250ms/step - loss: 0.0149 - accuracy: 0.9952 - val_loss: 0.1501 - val_accuracy: 0.9142\n",
      "4279/4279 [==============================] - 23s 5ms/step - loss: 0.0446 - accuracy: 0.9904\n",
      "1721/1721 [==============================] - 9s 5ms/step - loss: 0.0752 - accuracy: 0.9880\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr55C1med.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.07111847400665283, 0.13982725143432617], [0.056271787732839584, 0.10512643307447433], [0.04458804056048393, 0.07523000240325928]]\n",
      "Accuracy for iterations:  [[0.9858964681625366, 0.9646152853965759], [0.9895483255386353, 0.9770035743713379], [0.9903955459594727, 0.9879568219184875]]\n",
      "F1 for iterations:  [[0.9858995413258369, 0.9645747616430032], [0.9895534793036914, 0.9770561746141869], [0.9903999907930509, 0.9879729119059167]]\n",
      "Precision for iterations:  [[0.9859353314564655, 0.9646811208681008], [0.9897732856068177, 0.9781476437653115], [0.990585726092373, 0.9882782308608551]]\n",
      "Recall for iterations:  [[0.9858964620643315, 0.9646152728329579], [0.989548336206141, 0.9770035602702899], [0.9903955710070408, 0.9879568408050571]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 1 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_1864/372464333.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr105C1med.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 4s 233ms/step - loss: 0.6355 - accuracy: 0.7508 - val_loss: 0.5335 - val_accuracy: 0.7700\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 4s 221ms/step - loss: 0.4347 - accuracy: 0.8116 - val_loss: 0.3296 - val_accuracy: 0.9021\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 215ms/step - loss: 0.2981 - accuracy: 0.9151 - val_loss: 0.2821 - val_accuracy: 0.9256\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 4s 222ms/step - loss: 0.2676 - accuracy: 0.9327 - val_loss: 0.2628 - val_accuracy: 0.9380\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.2542 - accuracy: 0.9374 - val_loss: 0.2524 - val_accuracy: 0.9395\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 237ms/step - loss: 0.0542 - accuracy: 0.9900 - val_loss: 0.5435 - val_accuracy: 0.7281\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 240ms/step - loss: 0.0280 - accuracy: 0.9937 - val_loss: 0.8794 - val_accuracy: 0.7267\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 217ms/step - loss: 0.0231 - accuracy: 0.9940 - val_loss: 0.7736 - val_accuracy: 0.7267\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 242ms/step - loss: 0.0206 - accuracy: 0.9950 - val_loss: 0.6522 - val_accuracy: 0.7267\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 230ms/step - loss: 0.0197 - accuracy: 0.9950 - val_loss: 0.5624 - val_accuracy: 0.7274\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 7s 256ms/step - loss: 0.0149 - accuracy: 0.9961 - val_loss: 2.6621 - val_accuracy: 0.4423\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 6s 246ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 1.7462 - val_accuracy: 0.4436\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 6s 232ms/step - loss: 0.0132 - accuracy: 0.9965 - val_loss: 2.4864 - val_accuracy: 0.4397\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 6s 236ms/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 2.2295 - val_accuracy: 0.4398\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 6s 239ms/step - loss: 0.0124 - accuracy: 0.9971 - val_loss: 2.2885 - val_accuracy: 0.4384\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 7s 251ms/step - loss: 1.9556 - accuracy: 0.5913 - val_loss: 0.0551 - val_accuracy: 0.9811\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 7s 249ms/step - loss: 0.0038 - accuracy: 0.9997 - val_loss: 0.0089 - val_accuracy: 0.9960\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 6s 236ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0057 - val_accuracy: 0.9978\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 6s 239ms/step - loss: 7.5248e-04 - accuracy: 0.9999 - val_loss: 0.0039 - val_accuracy: 0.9986\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 7s 245ms/step - loss: 4.7047e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9997\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 17s 246ms/step - loss: 0.4313 - accuracy: 0.8965 - val_loss: 0.3358 - val_accuracy: 0.8278\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 17s 245ms/step - loss: 0.0246 - accuracy: 0.9926 - val_loss: 0.2688 - val_accuracy: 0.8284\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 17s 244ms/step - loss: 0.0223 - accuracy: 0.9926 - val_loss: 0.2517 - val_accuracy: 0.8314\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 17s 242ms/step - loss: 0.0212 - accuracy: 0.9927 - val_loss: 0.2295 - val_accuracy: 0.8440\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 17s 242ms/step - loss: 0.0203 - accuracy: 0.9928 - val_loss: 0.2116 - val_accuracy: 0.8562\n",
      "4279/4279 [==============================] - 25s 6ms/step - loss: 0.0679 - accuracy: 0.9843\n",
      "1721/1721 [==============================] - 9s 5ms/step - loss: 0.1324 - accuracy: 0.9676\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 4s 247ms/step - loss: 0.2878 - accuracy: 0.9335 - val_loss: 0.2485 - val_accuracy: 0.9405\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.2435 - accuracy: 0.9398 - val_loss: 0.2340 - val_accuracy: 0.9418\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 4s 230ms/step - loss: 0.2337 - accuracy: 0.9402 - val_loss: 0.2275 - val_accuracy: 0.9420\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 4s 252ms/step - loss: 0.2295 - accuracy: 0.9409 - val_loss: 0.2244 - val_accuracy: 0.9426\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 4s 242ms/step - loss: 0.2268 - accuracy: 0.9412 - val_loss: 0.2223 - val_accuracy: 0.9428\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 4s 253ms/step - loss: 0.0360 - accuracy: 0.9912 - val_loss: 0.7078 - val_accuracy: 0.7257\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 247ms/step - loss: 0.0183 - accuracy: 0.9951 - val_loss: 0.8383 - val_accuracy: 0.7267\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 225ms/step - loss: 0.0176 - accuracy: 0.9953 - val_loss: 0.6279 - val_accuracy: 0.7260\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 243ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 0.4838 - val_accuracy: 0.7254\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 233ms/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 0.5126 - val_accuracy: 0.7245\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 7s 253ms/step - loss: 0.0121 - accuracy: 0.9971 - val_loss: 1.3589 - val_accuracy: 0.4392\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 6s 238ms/step - loss: 0.0117 - accuracy: 0.9972 - val_loss: 1.6726 - val_accuracy: 0.4408\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 6s 238ms/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 1.8693 - val_accuracy: 0.4384\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 6s 243ms/step - loss: 0.0110 - accuracy: 0.9973 - val_loss: 1.6062 - val_accuracy: 0.4518\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 6s 236ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 1.5982 - val_accuracy: 0.4599\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 7s 256ms/step - loss: 2.7337 - accuracy: 0.5455 - val_loss: 0.1306 - val_accuracy: 0.9264\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 7s 247ms/step - loss: 0.0204 - accuracy: 0.9930 - val_loss: 0.0034 - val_accuracy: 0.9987\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 7s 248ms/step - loss: 4.2447e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 7s 255ms/step - loss: 3.0102e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 7s 247ms/step - loss: 2.6590e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 18s 256ms/step - loss: 0.6071 - accuracy: 0.8848 - val_loss: 0.2519 - val_accuracy: 0.8456\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 18s 256ms/step - loss: 0.0193 - accuracy: 0.9941 - val_loss: 0.2016 - val_accuracy: 0.8712\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 18s 254ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.1726 - val_accuracy: 0.8904\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 19s 271ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.1713 - val_accuracy: 0.8834\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 18s 257ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 0.1474 - val_accuracy: 0.9004\n",
      "4279/4279 [==============================] - 23s 5ms/step - loss: 0.0585 - accuracy: 0.9896\n",
      "1721/1721 [==============================] - 10s 6ms/step - loss: 0.1035 - accuracy: 0.9798\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 4s 253ms/step - loss: 0.2820 - accuracy: 0.9383 - val_loss: 0.2376 - val_accuracy: 0.9429\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 4s 242ms/step - loss: 0.2358 - accuracy: 0.9413 - val_loss: 0.2260 - val_accuracy: 0.9429\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.2282 - accuracy: 0.9414 - val_loss: 0.2243 - val_accuracy: 0.9425\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 4s 251ms/step - loss: 0.2256 - accuracy: 0.9413 - val_loss: 0.2209 - val_accuracy: 0.9429\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 4s 249ms/step - loss: 0.2237 - accuracy: 0.9415 - val_loss: 0.2197 - val_accuracy: 0.9429\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 4s 255ms/step - loss: 0.0362 - accuracy: 0.9917 - val_loss: 0.6477 - val_accuracy: 0.7255\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 4s 252ms/step - loss: 0.0162 - accuracy: 0.9951 - val_loss: 0.8583 - val_accuracy: 0.7252\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 244ms/step - loss: 0.0157 - accuracy: 0.9956 - val_loss: 0.6284 - val_accuracy: 0.7254\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 240ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.4896 - val_accuracy: 0.7278\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 227ms/step - loss: 0.0140 - accuracy: 0.9960 - val_loss: 0.5388 - val_accuracy: 0.7281\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 7s 255ms/step - loss: 0.0112 - accuracy: 0.9972 - val_loss: 1.3076 - val_accuracy: 0.4590\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 6s 241ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 1.3916 - val_accuracy: 0.4722\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 6s 241ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 1.2585 - val_accuracy: 0.5261\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 7s 251ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 1.2375 - val_accuracy: 0.5641\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 6s 236ms/step - loss: 0.0101 - accuracy: 0.9975 - val_loss: 1.5392 - val_accuracy: 0.5177\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 7s 250ms/step - loss: 3.0280 - accuracy: 0.5514 - val_loss: 0.2628 - val_accuracy: 0.9194\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 7s 242ms/step - loss: 0.0628 - accuracy: 0.9715 - val_loss: 0.0030 - val_accuracy: 0.9990\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 7s 242ms/step - loss: 3.5024e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 6s 238ms/step - loss: 2.0685e-04 - accuracy: 1.0000 - val_loss: 9.7469e-04 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 7s 246ms/step - loss: 1.7155e-04 - accuracy: 1.0000 - val_loss: 8.3059e-04 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 17s 241ms/step - loss: 0.5344 - accuracy: 0.9011 - val_loss: 0.2226 - val_accuracy: 0.8824\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 17s 246ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 0.1846 - val_accuracy: 0.8985\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 17s 244ms/step - loss: 0.0167 - accuracy: 0.9943 - val_loss: 0.1575 - val_accuracy: 0.9103\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 17s 243ms/step - loss: 0.0162 - accuracy: 0.9943 - val_loss: 0.1715 - val_accuracy: 0.8972\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 17s 245ms/step - loss: 0.0158 - accuracy: 0.9946 - val_loss: 0.1577 - val_accuracy: 0.9043\n",
      "4279/4279 [==============================] - 22s 5ms/step - loss: 0.0586 - accuracy: 0.9897\n",
      "1721/1721 [==============================] - 9s 5ms/step - loss: 0.1100 - accuracy: 0.9769\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr105C1med.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.06786628812551498, 0.13243860006332397], [0.05849339812994003, 0.10348297655582428], [0.05857144296169281, 0.11004547774791718]]\n",
      "Accuracy for iterations:  [[0.9842677116394043, 0.967557966709137], [0.9895775318145752, 0.9798372387886047], [0.9896724820137024, 0.9768945574760437]]\n",
      "F1 for iterations:  [[0.9842698489483893, 0.9675487599684763], [0.9895826687055785, 0.9798788785524012], [0.989677534573539, 0.9769476267394956]]\n",
      "Precision for iterations:  [[0.9842837178181156, 0.9675495402370538], [0.989801253213745, 0.9807221705819592], [0.9898921713734905, 0.9780492537346367]]\n",
      "Recall for iterations:  [[0.9842677261970844, 0.9675579452154327], [0.9895775511992755, 0.979837244786747], [0.9896724999269625, 0.9768945724042724]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 1 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_1864/2868219575.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr255C1med.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 4s 251ms/step - loss: 0.6367 - accuracy: 0.7120 - val_loss: 0.5530 - val_accuracy: 0.7273\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 4s 256ms/step - loss: 0.4974 - accuracy: 0.7913 - val_loss: 0.4441 - val_accuracy: 0.8451\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.4405 - accuracy: 0.8482 - val_loss: 0.4195 - val_accuracy: 0.8645\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.4258 - accuracy: 0.8618 - val_loss: 0.4114 - val_accuracy: 0.8682\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 4s 245ms/step - loss: 0.4159 - accuracy: 0.8639 - val_loss: 0.4039 - val_accuracy: 0.8682\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 4s 254ms/step - loss: 0.0808 - accuracy: 0.9898 - val_loss: 0.5626 - val_accuracy: 0.7270\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 4s 296ms/step - loss: 0.0269 - accuracy: 0.9937 - val_loss: 0.7068 - val_accuracy: 0.7270\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 7s 465ms/step - loss: 0.0228 - accuracy: 0.9949 - val_loss: 0.9085 - val_accuracy: 0.7270\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 5s 363ms/step - loss: 0.0217 - accuracy: 0.9951 - val_loss: 0.7394 - val_accuracy: 0.7270\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 5s 377ms/step - loss: 0.0207 - accuracy: 0.9950 - val_loss: 0.5821 - val_accuracy: 0.7271\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 8s 305ms/step - loss: 0.0152 - accuracy: 0.9960 - val_loss: 2.2426 - val_accuracy: 0.4439\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 7s 258ms/step - loss: 0.0139 - accuracy: 0.9962 - val_loss: 2.1342 - val_accuracy: 0.4421\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 6s 246ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 2.3378 - val_accuracy: 0.4422\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 6s 241ms/step - loss: 0.0125 - accuracy: 0.9968 - val_loss: 2.3048 - val_accuracy: 0.4381\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 6s 245ms/step - loss: 0.0122 - accuracy: 0.9969 - val_loss: 1.7893 - val_accuracy: 0.4387\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 7s 269ms/step - loss: 1.8392 - accuracy: 0.6282 - val_loss: 0.0343 - val_accuracy: 0.9877\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 7s 253ms/step - loss: 0.0040 - accuracy: 0.9997 - val_loss: 0.0071 - val_accuracy: 0.9971\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 7s 269ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0049 - val_accuracy: 0.9980\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 7s 257ms/step - loss: 9.5412e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9993\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 7s 249ms/step - loss: 5.3786e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 18s 257ms/step - loss: 0.5061 - accuracy: 0.8939 - val_loss: 0.3512 - val_accuracy: 0.8275\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 18s 256ms/step - loss: 0.0227 - accuracy: 0.9926 - val_loss: 0.2474 - val_accuracy: 0.8359\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 18s 254ms/step - loss: 0.0210 - accuracy: 0.9929 - val_loss: 0.2269 - val_accuracy: 0.8475\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 18s 260ms/step - loss: 0.0202 - accuracy: 0.9929 - val_loss: 0.2153 - val_accuracy: 0.8552\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 14s 200ms/step - loss: 0.0195 - accuracy: 0.9931 - val_loss: 0.2088 - val_accuracy: 0.8600\n",
      "4279/4279 [==============================] - 17s 4ms/step - loss: 0.0656 - accuracy: 0.9868\n",
      "1721/1721 [==============================] - 6s 3ms/step - loss: 0.1311 - accuracy: 0.9707\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 201ms/step - loss: 0.5513 - accuracy: 0.8535 - val_loss: 0.4200 - val_accuracy: 0.8637\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 179ms/step - loss: 0.4187 - accuracy: 0.8652 - val_loss: 0.4080 - val_accuracy: 0.8691\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 0.4066 - accuracy: 0.8660 - val_loss: 0.3963 - val_accuracy: 0.8694\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 184ms/step - loss: 0.4012 - accuracy: 0.8664 - val_loss: 0.3933 - val_accuracy: 0.8701\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 180ms/step - loss: 0.3984 - accuracy: 0.8667 - val_loss: 0.3911 - val_accuracy: 0.8699\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 219ms/step - loss: 0.0586 - accuracy: 0.9918 - val_loss: 0.6502 - val_accuracy: 0.7251\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 200ms/step - loss: 0.0184 - accuracy: 0.9952 - val_loss: 0.8534 - val_accuracy: 0.7254\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 178ms/step - loss: 0.0180 - accuracy: 0.9952 - val_loss: 0.7660 - val_accuracy: 0.7251\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 181ms/step - loss: 0.0169 - accuracy: 0.9952 - val_loss: 0.5988 - val_accuracy: 0.7252\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 186ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 0.5121 - val_accuracy: 0.7248\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.0128 - accuracy: 0.9967 - val_loss: 1.9587 - val_accuracy: 0.4376\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 186ms/step - loss: 0.0115 - accuracy: 0.9972 - val_loss: 1.6028 - val_accuracy: 0.4392\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 187ms/step - loss: 0.0112 - accuracy: 0.9972 - val_loss: 1.5085 - val_accuracy: 0.4548\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 191ms/step - loss: 0.0108 - accuracy: 0.9973 - val_loss: 1.7709 - val_accuracy: 0.4483\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 185ms/step - loss: 0.0108 - accuracy: 0.9973 - val_loss: 2.1848 - val_accuracy: 0.4395\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 199ms/step - loss: 2.8600 - accuracy: 0.5545 - val_loss: 0.2176 - val_accuracy: 0.9139\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 191ms/step - loss: 0.0437 - accuracy: 0.9803 - val_loss: 0.0175 - val_accuracy: 0.9932\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 186ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0104 - val_accuracy: 0.9947\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 193ms/step - loss: 9.4427e-04 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 0.9954\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 183ms/step - loss: 6.8946e-04 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9968\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 13s 182ms/step - loss: 0.4285 - accuracy: 0.9052 - val_loss: 0.3051 - val_accuracy: 0.8364\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 13s 185ms/step - loss: 0.0189 - accuracy: 0.9938 - val_loss: 0.1882 - val_accuracy: 0.8947\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 12s 176ms/step - loss: 0.0178 - accuracy: 0.9941 - val_loss: 0.1801 - val_accuracy: 0.8937\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 12s 175ms/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.1648 - val_accuracy: 0.8999\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 12s 175ms/step - loss: 0.0167 - accuracy: 0.9943 - val_loss: 0.1669 - val_accuracy: 0.8957\n",
      "4279/4279 [==============================] - 15s 3ms/step - loss: 0.0714 - accuracy: 0.9870\n",
      "1721/1721 [==============================] - 6s 3ms/step - loss: 0.1497 - accuracy: 0.9553\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 163ms/step - loss: 0.5797 - accuracy: 0.8569 - val_loss: 0.4228 - val_accuracy: 0.8685\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 169ms/step - loss: 0.4193 - accuracy: 0.8640 - val_loss: 0.4112 - val_accuracy: 0.8683\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 0.4067 - accuracy: 0.8666 - val_loss: 0.3968 - val_accuracy: 0.8703\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.4004 - accuracy: 0.8669 - val_loss: 0.3938 - val_accuracy: 0.8701\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 0.3975 - accuracy: 0.8667 - val_loss: 0.3919 - val_accuracy: 0.8701\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 192ms/step - loss: 0.0770 - accuracy: 0.9929 - val_loss: 0.6194 - val_accuracy: 0.7214\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 162ms/step - loss: 0.0195 - accuracy: 0.9953 - val_loss: 0.7010 - val_accuracy: 0.7258\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 159ms/step - loss: 0.0176 - accuracy: 0.9950 - val_loss: 0.7969 - val_accuracy: 0.7252\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 161ms/step - loss: 0.0162 - accuracy: 0.9953 - val_loss: 0.6642 - val_accuracy: 0.7248\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 174ms/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 0.5437 - val_accuracy: 0.7265\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 174ms/step - loss: 0.0121 - accuracy: 0.9971 - val_loss: 1.6548 - val_accuracy: 0.4381\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 171ms/step - loss: 0.0111 - accuracy: 0.9973 - val_loss: 1.5593 - val_accuracy: 0.4597\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 178ms/step - loss: 0.0108 - accuracy: 0.9973 - val_loss: 1.3393 - val_accuracy: 0.5009\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 172ms/step - loss: 0.0107 - accuracy: 0.9973 - val_loss: 1.5674 - val_accuracy: 0.4969\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 6s 214ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 1.6535 - val_accuracy: 0.5033\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 188ms/step - loss: 2.8100 - accuracy: 0.5791 - val_loss: 0.2059 - val_accuracy: 0.9210\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 177ms/step - loss: 0.0407 - accuracy: 0.9807 - val_loss: 0.0091 - val_accuracy: 0.9949\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 182ms/step - loss: 6.9200e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9975\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 171ms/step - loss: 4.4248e-04 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9978\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 3.6475e-04 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9980\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 15s 219ms/step - loss: 0.3457 - accuracy: 0.9205 - val_loss: 0.2887 - val_accuracy: 0.8559\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 17s 246ms/step - loss: 0.0180 - accuracy: 0.9944 - val_loss: 0.2120 - val_accuracy: 0.8889\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 16s 228ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 0.1759 - val_accuracy: 0.9023\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 15s 209ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 0.1652 - val_accuracy: 0.9046\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 15s 209ms/step - loss: 0.0155 - accuracy: 0.9948 - val_loss: 0.1757 - val_accuracy: 0.8972\n",
      "4279/4279 [==============================] - 17s 4ms/step - loss: 0.0708 - accuracy: 0.9878\n",
      "1721/1721 [==============================] - 7s 4ms/step - loss: 0.1146 - accuracy: 0.9703\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr255C1med.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.06564079970121384, 0.13114283978939056], [0.07139751315116882, 0.149677574634552], [0.0708380863070488, 0.11464150249958038]]\n",
      "Accuracy for iterations:  [[0.9867802262306213, 0.9707004427909851], [0.9870139360427856, 0.9552604556083679], [0.9878100156784058, 0.9702826142311096]]\n",
      "F1 for iterations:  [[0.9867837717367531, 0.9707073370850269], [0.9870214532090624, 0.9554150810797553], [0.9878167854153588, 0.9703644051403378]]\n",
      "Precision for iterations:  [[0.9868390269264712, 0.9707216758611735], [0.9873599414442409, 0.9593962502272831], [0.9881152975602482, 0.9721658040422457]]\n",
      "Recall for iterations:  [[0.9867802156066493, 0.9707004286856064], [0.9870139355517251, 0.955260480999782], [0.9878100441146397, 0.9702826418658723]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 3 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_1864/927562370.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr55C3med.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 5s 294ms/step - loss: 0.5421 - accuracy: 0.7268 - val_loss: 1.7275 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 4s 256ms/step - loss: 0.2099 - accuracy: 0.9406 - val_loss: 3.4472 - val_accuracy: 0.1332\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.0855 - accuracy: 0.9893 - val_loss: 3.9308 - val_accuracy: 0.1339\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 4s 221ms/step - loss: 0.0536 - accuracy: 0.9893 - val_loss: 2.0808 - val_accuracy: 0.1343\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 177ms/step - loss: 0.0367 - accuracy: 0.9900 - val_loss: 1.4119 - val_accuracy: 0.1722\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 200ms/step - loss: 0.0225 - accuracy: 0.9949 - val_loss: 0.8312 - val_accuracy: 0.7271\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 194ms/step - loss: 0.0209 - accuracy: 0.9949 - val_loss: 0.5744 - val_accuracy: 0.7308\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 181ms/step - loss: 0.0199 - accuracy: 0.9950 - val_loss: 0.6616 - val_accuracy: 0.7284\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 185ms/step - loss: 0.0194 - accuracy: 0.9950 - val_loss: 0.5574 - val_accuracy: 0.7320\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 184ms/step - loss: 0.0189 - accuracy: 0.9951 - val_loss: 0.5540 - val_accuracy: 0.7310\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 193ms/step - loss: 0.2338 - accuracy: 0.9408 - val_loss: 0.1845 - val_accuracy: 0.9612\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.1787 - accuracy: 0.9613 - val_loss: 0.1703 - val_accuracy: 0.9639\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.1678 - accuracy: 0.9627 - val_loss: 0.1640 - val_accuracy: 0.9642\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 170ms/step - loss: 0.1622 - accuracy: 0.9631 - val_loss: 0.1598 - val_accuracy: 0.9642\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 163ms/step - loss: 0.1578 - accuracy: 0.9635 - val_loss: 0.1561 - val_accuracy: 0.9642\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 178ms/step - loss: 0.2700 - accuracy: 0.8944 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 174ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 6.8591e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 173ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.9931e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 167ms/step - loss: 6.2170e-04 - accuracy: 1.0000 - val_loss: 2.5586e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 4.0290e-04 - accuracy: 1.0000 - val_loss: 1.6427e-04 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 170ms/step - loss: 0.6645 - accuracy: 0.8656 - val_loss: 0.3336 - val_accuracy: 0.8290\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 12s 173ms/step - loss: 0.0303 - accuracy: 0.9914 - val_loss: 0.2731 - val_accuracy: 0.8327\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 12s 174ms/step - loss: 0.0251 - accuracy: 0.9910 - val_loss: 0.2313 - val_accuracy: 0.8451\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 12s 174ms/step - loss: 0.0228 - accuracy: 0.9916 - val_loss: 0.2078 - val_accuracy: 0.8580\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 12s 175ms/step - loss: 0.0213 - accuracy: 0.9925 - val_loss: 0.2035 - val_accuracy: 0.8596\n",
      "4279/4279 [==============================] - 14s 3ms/step - loss: 0.1032 - accuracy: 0.9898\n",
      "1721/1721 [==============================] - 6s 3ms/step - loss: 0.1089 - accuracy: 0.9717\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 0.0256 - accuracy: 0.9904 - val_loss: 0.6149 - val_accuracy: 0.6189\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 159ms/step - loss: 0.0220 - accuracy: 0.9923 - val_loss: 0.5632 - val_accuracy: 0.6680\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 157ms/step - loss: 0.0206 - accuracy: 0.9928 - val_loss: 0.7977 - val_accuracy: 0.4890\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 157ms/step - loss: 0.0200 - accuracy: 0.9932 - val_loss: 0.6895 - val_accuracy: 0.5872\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 165ms/step - loss: 0.0186 - accuracy: 0.9936 - val_loss: 0.9261 - val_accuracy: 0.4960\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 169ms/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 0.5732 - val_accuracy: 0.7412\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 154ms/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 0.8202 - val_accuracy: 0.7360\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 154ms/step - loss: 0.0135 - accuracy: 0.9962 - val_loss: 0.6556 - val_accuracy: 0.7471\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 167ms/step - loss: 0.0131 - accuracy: 0.9966 - val_loss: 0.9705 - val_accuracy: 0.7308\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 158ms/step - loss: 0.0130 - accuracy: 0.9967 - val_loss: 0.6770 - val_accuracy: 0.7524\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 175ms/step - loss: 0.2743 - accuracy: 0.9475 - val_loss: 0.1905 - val_accuracy: 0.9639\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 176ms/step - loss: 0.1740 - accuracy: 0.9632 - val_loss: 0.1608 - val_accuracy: 0.9642\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.1573 - accuracy: 0.9636 - val_loss: 0.1542 - val_accuracy: 0.9642\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 172ms/step - loss: 0.1532 - accuracy: 0.9637 - val_loss: 0.1519 - val_accuracy: 0.9642\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 177ms/step - loss: 0.1516 - accuracy: 0.9637 - val_loss: 0.1508 - val_accuracy: 0.9642\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 189ms/step - loss: 0.3572 - accuracy: 0.8647 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 180ms/step - loss: 8.3694e-04 - accuracy: 1.0000 - val_loss: 2.4379e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 202ms/step - loss: 3.7193e-04 - accuracy: 1.0000 - val_loss: 1.6568e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 192ms/step - loss: 2.6904e-04 - accuracy: 1.0000 - val_loss: 1.2250e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 194ms/step - loss: 2.0061e-04 - accuracy: 1.0000 - val_loss: 9.1180e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 13s 185ms/step - loss: 0.7409 - accuracy: 0.8619 - val_loss: 0.2710 - val_accuracy: 0.8466\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 13s 187ms/step - loss: 0.0238 - accuracy: 0.9936 - val_loss: 0.2044 - val_accuracy: 0.8792\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 13s 189ms/step - loss: 0.0205 - accuracy: 0.9938 - val_loss: 0.1925 - val_accuracy: 0.8809\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 14s 195ms/step - loss: 0.0189 - accuracy: 0.9942 - val_loss: 0.1889 - val_accuracy: 0.8794\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 13s 192ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.1797 - val_accuracy: 0.8846\n",
      "   1/4279 [..............................] - ETA: 0s - loss: 0.1232 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0156s). Check your callbacks.\n",
      "4279/4279 [==============================] - 15s 4ms/step - loss: 0.1354 - accuracy: 0.9892\n",
      "1721/1721 [==============================] - 6s 3ms/step - loss: 0.1508 - accuracy: 0.9373\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 0.0201 - accuracy: 0.9932 - val_loss: 0.6744 - val_accuracy: 0.5756\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 168ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.5716 - val_accuracy: 0.6531\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 168ms/step - loss: 0.0176 - accuracy: 0.9940 - val_loss: 0.7678 - val_accuracy: 0.5907\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 0.9760 - val_accuracy: 0.5281\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.0173 - accuracy: 0.9946 - val_loss: 0.8437 - val_accuracy: 0.5853\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 207ms/step - loss: 0.0130 - accuracy: 0.9965 - val_loss: 0.8623 - val_accuracy: 0.7406\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 182ms/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.7428 - val_accuracy: 0.7548\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 188ms/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.8729 - val_accuracy: 0.7475\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 193ms/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 0.8438 - val_accuracy: 0.7532\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 180ms/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 1.0928 - val_accuracy: 0.7389\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.2881 - accuracy: 0.9404 - val_loss: 0.1878 - val_accuracy: 0.9639\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 190ms/step - loss: 0.1679 - accuracy: 0.9630 - val_loss: 0.1569 - val_accuracy: 0.9639\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.1543 - accuracy: 0.9634 - val_loss: 0.1521 - val_accuracy: 0.9642\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.1515 - accuracy: 0.9636 - val_loss: 0.1504 - val_accuracy: 0.9640\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.1501 - accuracy: 0.9637 - val_loss: 0.1491 - val_accuracy: 0.9642\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 197ms/step - loss: 0.3260 - accuracy: 0.8661 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 194ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.3860e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 179ms/step - loss: 4.7554e-04 - accuracy: 1.0000 - val_loss: 2.1225e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 203ms/step - loss: 3.1984e-04 - accuracy: 1.0000 - val_loss: 1.4514e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 192ms/step - loss: 2.2249e-04 - accuracy: 1.0000 - val_loss: 9.9063e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 13s 191ms/step - loss: 0.6923 - accuracy: 0.8654 - val_loss: 0.2361 - val_accuracy: 0.8699\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 13s 183ms/step - loss: 0.0214 - accuracy: 0.9943 - val_loss: 0.1874 - val_accuracy: 0.8909\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 13s 183ms/step - loss: 0.0185 - accuracy: 0.9946 - val_loss: 0.1802 - val_accuracy: 0.8912\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 13s 190ms/step - loss: 0.0171 - accuracy: 0.9949 - val_loss: 0.1588 - val_accuracy: 0.9045\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 13s 189ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 0.1627 - val_accuracy: 0.9015\n",
      "4279/4279 [==============================] - 15s 4ms/step - loss: 0.1891 - accuracy: 0.9655\n",
      "1721/1721 [==============================] - 6s 3ms/step - loss: 0.1965 - accuracy: 0.8879\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr55C3med.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.10317321866750717, 0.10890663415193558], [0.13543936610221863, 0.15077562630176544], [0.18911060690879822, 0.1965211182832718]]\n",
      "Accuracy for iterations:  [[0.9898039698600769, 0.9716994762420654], [0.9892196655273438, 0.93729567527771], [0.9655190110206604, 0.8878878355026245]]\n",
      "F1 for iterations:  [[0.989808280414325, 0.9716685344645218], [0.9892236702120993, 0.9368286631446465], [0.9654729476641315, 0.885465503738214]]\n",
      "Precision for iterations:  [[0.9899598662859304, 0.9717733720643744], [0.9893355259061654, 0.9401087061244824], [0.9660336299461918, 0.900551895405503]]\n",
      "Recall for iterations:  [[0.9898039673960677, 0.9716994841241009], [0.9892196675333781, 0.937295647751217], [0.965519004353034, 0.8878878151565792]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 3 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_1864/4114672810.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr105C3med.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 197ms/step - loss: 0.5331 - accuracy: 0.7347 - val_loss: 1.7967 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 177ms/step - loss: 0.1934 - accuracy: 0.9616 - val_loss: 3.7692 - val_accuracy: 0.1330\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 167ms/step - loss: 0.0809 - accuracy: 0.9893 - val_loss: 3.6043 - val_accuracy: 0.1340\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 0.0508 - accuracy: 0.9893 - val_loss: 1.5942 - val_accuracy: 0.1454\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 170ms/step - loss: 0.0366 - accuracy: 0.9890 - val_loss: 1.4648 - val_accuracy: 0.1721\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 184ms/step - loss: 0.0222 - accuracy: 0.9949 - val_loss: 0.7898 - val_accuracy: 0.7271\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 195ms/step - loss: 0.0206 - accuracy: 0.9950 - val_loss: 0.5994 - val_accuracy: 0.7294\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 176ms/step - loss: 0.0194 - accuracy: 0.9950 - val_loss: 0.7333 - val_accuracy: 0.7277\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 180ms/step - loss: 0.0187 - accuracy: 0.9950 - val_loss: 0.6463 - val_accuracy: 0.7298\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 173ms/step - loss: 0.0182 - accuracy: 0.9952 - val_loss: 0.7344 - val_accuracy: 0.7275\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 181ms/step - loss: 0.3736 - accuracy: 0.9111 - val_loss: 0.2796 - val_accuracy: 0.9277\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 189ms/step - loss: 0.2620 - accuracy: 0.9366 - val_loss: 0.2552 - val_accuracy: 0.9366\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 182ms/step - loss: 0.2478 - accuracy: 0.9389 - val_loss: 0.2467 - val_accuracy: 0.9376\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 189ms/step - loss: 0.2411 - accuracy: 0.9395 - val_loss: 0.2420 - val_accuracy: 0.9377\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 185ms/step - loss: 0.2366 - accuracy: 0.9395 - val_loss: 0.2370 - val_accuracy: 0.9382\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 185ms/step - loss: 0.2369 - accuracy: 0.8999 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 199ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 5.0032e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 181ms/step - loss: 7.4948e-04 - accuracy: 1.0000 - val_loss: 2.8708e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 185ms/step - loss: 4.7311e-04 - accuracy: 1.0000 - val_loss: 1.9382e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 180ms/step - loss: 3.2857e-04 - accuracy: 1.0000 - val_loss: 1.3785e-04 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 13s 180ms/step - loss: 0.7643 - accuracy: 0.8518 - val_loss: 0.3912 - val_accuracy: 0.8281\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 13s 185ms/step - loss: 0.0349 - accuracy: 0.9921 - val_loss: 0.3084 - val_accuracy: 0.8283\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 13s 180ms/step - loss: 0.0261 - accuracy: 0.9916 - val_loss: 0.2369 - val_accuracy: 0.8381\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 13s 187ms/step - loss: 0.0232 - accuracy: 0.9913 - val_loss: 0.2055 - val_accuracy: 0.8563\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 16s 230ms/step - loss: 0.0215 - accuracy: 0.9922 - val_loss: 0.1947 - val_accuracy: 0.8624\n",
      "4279/4279 [==============================] - 14s 3ms/step - loss: 0.0895 - accuracy: 0.9890\n",
      "1721/1721 [==============================] - 6s 4ms/step - loss: 0.1068 - accuracy: 0.9779\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 0.0247 - accuracy: 0.9899 - val_loss: 0.8929 - val_accuracy: 0.3533\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.0220 - accuracy: 0.9916 - val_loss: 1.0950 - val_accuracy: 0.3023\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 181ms/step - loss: 0.0215 - accuracy: 0.9922 - val_loss: 0.8204 - val_accuracy: 0.4718\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 212ms/step - loss: 0.0204 - accuracy: 0.9930 - val_loss: 0.7063 - val_accuracy: 0.5693\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 0.0193 - accuracy: 0.9935 - val_loss: 0.7790 - val_accuracy: 0.5439\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 213ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.6035 - val_accuracy: 0.7383\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 206ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.5682 - val_accuracy: 0.7428\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 203ms/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 0.6000 - val_accuracy: 0.7432\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 206ms/step - loss: 0.0133 - accuracy: 0.9965 - val_loss: 0.7345 - val_accuracy: 0.7359\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 198ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.6816 - val_accuracy: 0.7436\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.4356 - accuracy: 0.9149 - val_loss: 0.3030 - val_accuracy: 0.9371\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 186ms/step - loss: 0.2643 - accuracy: 0.9374 - val_loss: 0.2494 - val_accuracy: 0.9379\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.2393 - accuracy: 0.9395 - val_loss: 0.2392 - val_accuracy: 0.9379\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 191ms/step - loss: 0.2330 - accuracy: 0.9394 - val_loss: 0.2350 - val_accuracy: 0.9372\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 189ms/step - loss: 0.2302 - accuracy: 0.9393 - val_loss: 0.2330 - val_accuracy: 0.9375\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 6s 224ms/step - loss: 0.4300 - accuracy: 0.8329 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 193ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.9412e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 6s 205ms/step - loss: 3.9956e-04 - accuracy: 1.0000 - val_loss: 1.5197e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 197ms/step - loss: 2.4289e-04 - accuracy: 1.0000 - val_loss: 1.0344e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 191ms/step - loss: 1.6941e-04 - accuracy: 1.0000 - val_loss: 7.2726e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 14s 196ms/step - loss: 0.8264 - accuracy: 0.8356 - val_loss: 0.2680 - val_accuracy: 0.8444\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 14s 194ms/step - loss: 0.0248 - accuracy: 0.9933 - val_loss: 0.1950 - val_accuracy: 0.8728\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 14s 196ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.1815 - val_accuracy: 0.8847\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 14s 198ms/step - loss: 0.0184 - accuracy: 0.9943 - val_loss: 0.1843 - val_accuracy: 0.8860\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 14s 195ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.1536 - val_accuracy: 0.9064\n",
      "4279/4279 [==============================] - 17s 4ms/step - loss: 0.0957 - accuracy: 0.9894\n",
      "1721/1721 [==============================] - 7s 4ms/step - loss: 0.1272 - accuracy: 0.9638\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.0213 - accuracy: 0.9930 - val_loss: 0.8807 - val_accuracy: 0.4563\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 181ms/step - loss: 0.0193 - accuracy: 0.9936 - val_loss: 0.9761 - val_accuracy: 0.4626\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 0.0183 - accuracy: 0.9941 - val_loss: 0.8914 - val_accuracy: 0.5330\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 180ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: 0.8277 - val_accuracy: 0.5744\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.8979 - val_accuracy: 0.5640\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 177ms/step - loss: 0.0138 - accuracy: 0.9961 - val_loss: 0.7563 - val_accuracy: 0.7394\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 173ms/step - loss: 0.0133 - accuracy: 0.9966 - val_loss: 0.7704 - val_accuracy: 0.7419\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 179ms/step - loss: 0.0126 - accuracy: 0.9966 - val_loss: 0.7644 - val_accuracy: 0.7445\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 192ms/step - loss: 0.0123 - accuracy: 0.9971 - val_loss: 0.7943 - val_accuracy: 0.7473\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 174ms/step - loss: 0.0122 - accuracy: 0.9969 - val_loss: 0.7337 - val_accuracy: 0.7532\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 183ms/step - loss: 0.4402 - accuracy: 0.9137 - val_loss: 0.3127 - val_accuracy: 0.9368\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 178ms/step - loss: 0.2652 - accuracy: 0.9378 - val_loss: 0.2469 - val_accuracy: 0.9381\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 180ms/step - loss: 0.2357 - accuracy: 0.9394 - val_loss: 0.2354 - val_accuracy: 0.9370\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 185ms/step - loss: 0.2298 - accuracy: 0.9391 - val_loss: 0.2324 - val_accuracy: 0.9370\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 188ms/step - loss: 0.2277 - accuracy: 0.9389 - val_loss: 0.2305 - val_accuracy: 0.9372\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 190ms/step - loss: 0.2870 - accuracy: 0.8771 - val_loss: 7.8395e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 185ms/step - loss: 6.2757e-04 - accuracy: 1.0000 - val_loss: 1.3552e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 188ms/step - loss: 1.7831e-04 - accuracy: 1.0000 - val_loss: 5.5552e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 189ms/step - loss: 7.4403e-05 - accuracy: 1.0000 - val_loss: 2.3525e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 190ms/step - loss: 3.4249e-05 - accuracy: 1.0000 - val_loss: 1.1974e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 14s 206ms/step - loss: 0.8658 - accuracy: 0.8434 - val_loss: 0.1989 - val_accuracy: 0.8887\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 14s 200ms/step - loss: 0.0230 - accuracy: 0.9939 - val_loss: 0.1955 - val_accuracy: 0.8796\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 14s 197ms/step - loss: 0.0189 - accuracy: 0.9945 - val_loss: 0.1736 - val_accuracy: 0.8964\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 14s 198ms/step - loss: 0.0171 - accuracy: 0.9948 - val_loss: 0.1990 - val_accuracy: 0.8881\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 14s 195ms/step - loss: 0.0163 - accuracy: 0.9950 - val_loss: 0.1950 - val_accuracy: 0.8940\n",
      "4279/4279 [==============================] - 16s 4ms/step - loss: 0.1559 - accuracy: 0.9885\n",
      "1721/1721 [==============================] - 7s 4ms/step - loss: 0.1878 - accuracy: 0.9179\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr105C3med.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.08947675675153732, 0.10681921988725662], [0.09570728987455368, 0.12717324495315552], [0.1559392809867859, 0.187766894698143]]\n",
      "Accuracy for iterations:  [[0.9889713525772095, 0.977929949760437], [0.9893584251403809, 0.9637978672981262], [0.9884819984436035, 0.9178776144981384]]\n",
      "F1 for iterations:  [[0.9889755858741193, 0.9779247832186535], [0.9893624729056961, 0.9637145823361895], [0.9884856073697068, 0.9168663752792593]]\n",
      "Precision for iterations:  [[0.9890972505055337, 0.9779265600134767], [0.9894797778972626, 0.9641593904540664], [0.9885625507173158, 0.9238307470458704]]\n",
      "Recall for iterations:  [[0.988971340091735, 0.9779299571314394], [0.9893584387507669, 0.9637978638378261], [0.9884819889567326, 0.9178776429557509]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 3 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16348/512859027.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr255C3med.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 198ms/step - loss: 0.5469 - accuracy: 0.7382 - val_loss: 1.6891 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 182ms/step - loss: 0.2158 - accuracy: 0.9386 - val_loss: 3.4275 - val_accuracy: 0.1330\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 0.0869 - accuracy: 0.9893 - val_loss: 3.9847 - val_accuracy: 0.1339\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 0.0543 - accuracy: 0.9893 - val_loss: 2.0878 - val_accuracy: 0.1343\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 183ms/step - loss: 0.0371 - accuracy: 0.9900 - val_loss: 1.4474 - val_accuracy: 0.1666\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 192ms/step - loss: 0.0220 - accuracy: 0.9950 - val_loss: 0.9446 - val_accuracy: 0.7268\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 184ms/step - loss: 0.0205 - accuracy: 0.9950 - val_loss: 0.6951 - val_accuracy: 0.7280\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 168ms/step - loss: 0.0201 - accuracy: 0.9950 - val_loss: 0.9132 - val_accuracy: 0.7267\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 175ms/step - loss: 0.0191 - accuracy: 0.9950 - val_loss: 0.6762 - val_accuracy: 0.7284\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 170ms/step - loss: 0.0184 - accuracy: 0.9951 - val_loss: 0.7126 - val_accuracy: 0.7277\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 190ms/step - loss: 0.6954 - accuracy: 0.8242 - val_loss: 0.4644 - val_accuracy: 0.8580\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 194ms/step - loss: 0.4395 - accuracy: 0.8622 - val_loss: 0.4268 - val_accuracy: 0.8633\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 184ms/step - loss: 0.4224 - accuracy: 0.8642 - val_loss: 0.4168 - val_accuracy: 0.8638\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 181ms/step - loss: 0.4149 - accuracy: 0.8650 - val_loss: 0.4112 - val_accuracy: 0.8648\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.4097 - accuracy: 0.8656 - val_loss: 0.4072 - val_accuracy: 0.8651\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 185ms/step - loss: 0.1985 - accuracy: 0.9166 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 173ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.4384e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 171ms/step - loss: 4.6996e-04 - accuracy: 1.0000 - val_loss: 1.8151e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 174ms/step - loss: 2.8475e-04 - accuracy: 1.0000 - val_loss: 1.2064e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 1.9544e-04 - accuracy: 1.0000 - val_loss: 8.4713e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 169ms/step - loss: 0.7458 - accuracy: 0.8528 - val_loss: 0.4684 - val_accuracy: 0.8277\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 12s 177ms/step - loss: 0.0361 - accuracy: 0.9923 - val_loss: 0.3657 - val_accuracy: 0.8277\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 12s 178ms/step - loss: 0.0268 - accuracy: 0.9921 - val_loss: 0.2723 - val_accuracy: 0.8303\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 12s 176ms/step - loss: 0.0239 - accuracy: 0.9917 - val_loss: 0.2436 - val_accuracy: 0.8366\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 12s 177ms/step - loss: 0.0223 - accuracy: 0.9917 - val_loss: 0.2290 - val_accuracy: 0.8414\n",
      "4279/4279 [==============================] - 16s 4ms/step - loss: 0.0937 - accuracy: 0.9876\n",
      "1721/1721 [==============================] - 7s 4ms/step - loss: 0.1195 - accuracy: 0.9769\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.0275 - accuracy: 0.9893 - val_loss: 0.7767 - val_accuracy: 0.4605\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 0.0239 - accuracy: 0.9910 - val_loss: 0.7954 - val_accuracy: 0.4568\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 2s 150ms/step - loss: 0.0224 - accuracy: 0.9918 - val_loss: 0.7329 - val_accuracy: 0.5332\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 0.0211 - accuracy: 0.9926 - val_loss: 0.7330 - val_accuracy: 0.5431\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 158ms/step - loss: 0.0203 - accuracy: 0.9929 - val_loss: 0.7285 - val_accuracy: 0.5637\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 170ms/step - loss: 0.0155 - accuracy: 0.9955 - val_loss: 0.5684 - val_accuracy: 0.7406\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 155ms/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.6013 - val_accuracy: 0.7399\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 0.6081 - val_accuracy: 0.7412\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.0133 - accuracy: 0.9964 - val_loss: 0.5813 - val_accuracy: 0.7471\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.0133 - accuracy: 0.9966 - val_loss: 0.6181 - val_accuracy: 0.7466\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 166ms/step - loss: 0.8914 - accuracy: 0.8191 - val_loss: 0.5529 - val_accuracy: 0.8571\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 155ms/step - loss: 0.4665 - accuracy: 0.8544 - val_loss: 0.4315 - val_accuracy: 0.8634\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 157ms/step - loss: 0.4176 - accuracy: 0.8655 - val_loss: 0.4135 - val_accuracy: 0.8643\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.4068 - accuracy: 0.8655 - val_loss: 0.4074 - val_accuracy: 0.8641\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 168ms/step - loss: 0.4023 - accuracy: 0.8656 - val_loss: 0.4042 - val_accuracy: 0.8643\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 4s 166ms/step - loss: 0.3523 - accuracy: 0.8480 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 5.7543e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 174ms/step - loss: 6.5217e-04 - accuracy: 1.0000 - val_loss: 1.9716e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 179ms/step - loss: 2.6134e-04 - accuracy: 1.0000 - val_loss: 9.2819e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 177ms/step - loss: 1.3552e-04 - accuracy: 1.0000 - val_loss: 5.2957e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 172ms/step - loss: 0.9359 - accuracy: 0.8200 - val_loss: 0.3295 - val_accuracy: 0.8294\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 12s 176ms/step - loss: 0.0270 - accuracy: 0.9933 - val_loss: 0.2260 - val_accuracy: 0.8584\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 12s 175ms/step - loss: 0.0198 - accuracy: 0.9940 - val_loss: 0.2126 - val_accuracy: 0.8761\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 12s 173ms/step - loss: 0.0185 - accuracy: 0.9943 - val_loss: 0.1937 - val_accuracy: 0.8872\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 12s 175ms/step - loss: 0.0175 - accuracy: 0.9946 - val_loss: 0.2045 - val_accuracy: 0.8853\n",
      "4279/4279 [==============================] - 16s 4ms/step - loss: 0.2347 - accuracy: 0.9612\n",
      "1721/1721 [==============================] - 7s 4ms/step - loss: 0.2645 - accuracy: 0.8832\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 163ms/step - loss: 0.0208 - accuracy: 0.9929 - val_loss: 0.6965 - val_accuracy: 0.5943\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 0.0192 - accuracy: 0.9935 - val_loss: 0.7572 - val_accuracy: 0.5701\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 2s 155ms/step - loss: 0.0183 - accuracy: 0.9941 - val_loss: 0.6235 - val_accuracy: 0.6558\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 163ms/step - loss: 0.0184 - accuracy: 0.9937 - val_loss: 0.8954 - val_accuracy: 0.5528\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 2s 154ms/step - loss: 0.0174 - accuracy: 0.9940 - val_loss: 0.8439 - val_accuracy: 0.5798\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 161ms/step - loss: 0.0138 - accuracy: 0.9961 - val_loss: 0.7261 - val_accuracy: 0.7456\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 158ms/step - loss: 0.0128 - accuracy: 0.9968 - val_loss: 0.6515 - val_accuracy: 0.7529\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.0125 - accuracy: 0.9968 - val_loss: 0.7345 - val_accuracy: 0.7511\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.8294 - val_accuracy: 0.7468\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 160ms/step - loss: 0.0121 - accuracy: 0.9971 - val_loss: 0.8898 - val_accuracy: 0.7443\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 163ms/step - loss: 0.9292 - accuracy: 0.8124 - val_loss: 0.5866 - val_accuracy: 0.8491\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 151ms/step - loss: 0.4836 - accuracy: 0.8519 - val_loss: 0.4398 - val_accuracy: 0.8592\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 156ms/step - loss: 0.4167 - accuracy: 0.8647 - val_loss: 0.4137 - val_accuracy: 0.8638\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 159ms/step - loss: 0.4043 - accuracy: 0.8656 - val_loss: 0.4071 - val_accuracy: 0.8640\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 176ms/step - loss: 0.4000 - accuracy: 0.8656 - val_loss: 0.4042 - val_accuracy: 0.8640\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 4s 163ms/step - loss: 0.2798 - accuracy: 0.8696 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 171ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 4.1760e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 176ms/step - loss: 5.1513e-04 - accuracy: 1.0000 - val_loss: 1.7505e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 174ms/step - loss: 2.3838e-04 - accuracy: 1.0000 - val_loss: 8.5755e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 1.2497e-04 - accuracy: 1.0000 - val_loss: 4.8438e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 175ms/step - loss: 0.8357 - accuracy: 0.8273 - val_loss: 0.3114 - val_accuracy: 0.8339\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 13s 180ms/step - loss: 0.0254 - accuracy: 0.9934 - val_loss: 0.2198 - val_accuracy: 0.8610\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 12s 176ms/step - loss: 0.0197 - accuracy: 0.9941 - val_loss: 0.1998 - val_accuracy: 0.8780\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 12s 177ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.1921 - val_accuracy: 0.8866\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 12s 176ms/step - loss: 0.0165 - accuracy: 0.9950 - val_loss: 0.1708 - val_accuracy: 0.9028\n",
      "4279/4279 [==============================] - 16s 4ms/step - loss: 0.1113 - accuracy: 0.9894\n",
      "1721/1721 [==============================] - 6s 4ms/step - loss: 0.1424 - accuracy: 0.9607\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr255C3med.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.09371992200613022, 0.11951834708452225], [0.2347034364938736, 0.2644708752632141], [0.11127892136573792, 0.1424078494310379]]\n",
      "Accuracy for iterations:  [[0.9876420497894287, 0.9768763780593872], [0.9611732959747314, 0.8831650018692017], [0.9894022345542908, 0.9606553912162781]]\n",
      "F1 for iterations:  [[0.9876460831178917, 0.9768677509101268], [0.9611111593452082, 0.8804515915801114], [0.9894061661916472, 0.9605432836813234]]\n",
      "Precision for iterations:  [[0.9877296528638703, 0.9768764913923293], [0.9618557854207639, 0.8970246225318564], [0.989516031415439, 0.9612002217028675]]\n",
      "Recall for iterations:  [[0.9876420579041164, 0.976876407759936], [0.9611732741242806, 0.8831650076291506], [0.9894022612404686, 0.9606553803676524]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
