{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Federated Learning for attack detection: 5 nodes sharing gradients: FedAVG**\n",
    "\n",
    "IDs from this file = **id7xy** (x = 0 if experiment with dataset, x = 1 if epochs & iterations, y being integer equal or greater than 0)\n",
    "\n",
    "In this file, experiments with different datasets, and number of epochs & iterations are done. The experiments are divided into sections, based on the elements being changed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static elements for all experiments (execute first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Disable warns\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data): \n",
    "\n",
    "    # Select the 'proto' and 'state' values that I want\n",
    "    data = data.loc[(data['proto'] == 'tcp') | (data['proto'] =='udp') | (data['proto'] =='icmp') | (data['proto'] =='arp') | (data['proto'] =='ipv6-icmp') | (data['proto'] =='igmp') | (data['proto'] =='rarp'), :]\n",
    "    data = data.loc[(data['state'] == 'RST') | (data['state'] =='REQ') | (data['state'] =='INT') | (data['state'] =='FIN') | (data['state'] =='CON') | (data['state'] =='ECO') | (data['state'] =='ACC') | (data['state'] == 'PAR'), :]\n",
    "\n",
    "    # Extracting labels \n",
    "    data_labels = data[['label']]\n",
    "\n",
    "    # Drop the invalid features and select interested data features\n",
    "    data_features=data[['proto','srcip','sport','dstip','dsport','spkts','dpkts','sbytes','dbytes','state','stime','ltime','dur']]\n",
    "\n",
    "    \"\"\"PREPROCESSING\"\"\"\n",
    "\n",
    "\n",
    "    # Preprocess IP and ports features\n",
    "    # IP Source Address\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "\n",
    "    # IP Destination Address\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "    # Ports\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "\n",
    "    # Convert all ports with 0 decimal, and HEX to DEC\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    # Convert field to int format\n",
    "    data_features['srcip'] = data_features['srcip'].astype(int)\n",
    "    data_features['sport'] = data_features['sport'].astype(int)\n",
    "    data_features['dstip'] = data_features['dstip'].astype(int)\n",
    "    data_features['dsport'] = data_features['dsport'].astype(int)\n",
    "\n",
    "    # Convert some fields to logarithmic\n",
    "    log1p_col = ['dur', 'sbytes', 'dbytes', 'spkts']\n",
    "\n",
    "    for col in log1p_col:\n",
    "        data_features[col] = data_features[col].apply(np.log1p)\n",
    "\n",
    "    # Create a complementary field of attack & Transform to One hot encoding - LABELS\n",
    "    normal=data_labels['label']\n",
    "    normal=normal.replace(1,2)\n",
    "    normal=normal.replace(0,1)\n",
    "    normal=normal.replace(2,0)\n",
    "\n",
    "    # Insert the new column in data labels\n",
    "    data_labels.insert(1, 'normal', normal)\n",
    "    data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "    data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "    # Transform to One hot encoding - FEATURES\n",
    "    data_features=pd.get_dummies(data_features)\n",
    "\n",
    "    # Value given for the missing columns\n",
    "    auxCol=0\n",
    "\n",
    "    # As we are using different datasets that might not have all representations, we are going to detect and add the missing columns \n",
    "    # The columns that can have types are: proto and state: need to check if all representations are done \n",
    "    state_cols = [col for col in data_features if col.startswith('state_')]\n",
    "    proto_cols = [col for col in data_features if col.startswith('proto_')]\n",
    "    \n",
    "    # Check if all columns are present\n",
    "    if 'state_PAR' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_PAR', auxCol, True)\n",
    "    if 'state_ACC' not in state_cols: \n",
    "        data_features.insert(data_features.shape[1], 'state_ACC', auxCol, True)\n",
    "    if 'state_ECO' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_ECO', auxCol, True)\n",
    "    if 'state_CON' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_CON', auxCol, True)\n",
    "    if 'state_FIN' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_FIN', auxCol, True)\n",
    "    if 'state_INT' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_INT', auxCol, True)\n",
    "    if 'state_REQ' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_REQ', auxCol, True)\n",
    "    if 'state_RST' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_RST', auxCol, True)\n",
    "    if 'proto_igmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_igmp', auxCol, True)\n",
    "    if 'proto_arp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_arp', auxCol, True)\n",
    "    if 'proto_icmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_icmp', auxCol, True)\n",
    "    if 'proto_udp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_udp', auxCol, True)\n",
    "    if 'proto_tcp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_tcp', auxCol, True)\n",
    "\n",
    "    # Normalize all data features\n",
    "    data_features = StandardScaler().fit_transform(data_features)\n",
    "\n",
    "    #Add dimension to data features\n",
    "    data_features = np.expand_dims(data_features, axis=2)\n",
    "    data_features = np.expand_dims(data_features, axis=3)\n",
    "\n",
    "    x = data_features\n",
    "    y = data_labels.to_numpy()\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building and definition\n",
    "def build_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(filters=32,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(1, 2), padding='same'))\n",
    "    model.add(layers.Conv2D(filters=64,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(1, 2), padding='same'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(Dense(444, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns values of loss, accuracy, f1, precision and recall of model evaluating with test dataset \n",
    "def evaluation(model, x, y): \n",
    "    loss, accuracy = model.evaluate(x, y)\n",
    "    y_pred = model.predict(x)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y = np.argmax(y, axis=1)\n",
    "    report = classification_report(y, y_pred, target_names=['normal', 'attack'], output_dict=True)\n",
    "    # Obtain f1, precision and recall from the report\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    return loss, accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_14900/3457440085.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_14900/3457440085.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_complete = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Complete.csv')\n"
     ]
    }
   ],
   "source": [
    "test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n",
    "test_plus = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test+.csv')\n",
    "test_complete = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)\n",
    "xcomplete, ycomplete = preprocessing(test_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments with datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Filt5A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part1.csv', low_memory=False)\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part2.csv', low_memory=False)\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part3.csv', low_memory=False)\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part4.csv', low_memory=False)\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part5.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'id700.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    # Calculate mean gradient for each layer\n",
    "    mean_grad = [tf.reduce_mean(layer_grads, axis=0) for layer_grads in zip(*grad_list)]\n",
    "    \n",
    "    return mean_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 228ms/step - loss: 0.3873 - accuracy: 0.9344 - val_loss: 1.7899 - val_accuracy: 0.6197\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 213ms/step - loss: 0.0630 - accuracy: 0.9916 - val_loss: 1.0702 - val_accuracy: 0.6200\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 221ms/step - loss: 0.0310 - accuracy: 0.9919 - val_loss: 0.6936 - val_accuracy: 0.6360\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 215ms/step - loss: 0.0269 - accuracy: 0.9921 - val_loss: 0.6353 - val_accuracy: 0.6487\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 217ms/step - loss: 0.0256 - accuracy: 0.9921 - val_loss: 0.5572 - val_accuracy: 0.6683\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 228ms/step - loss: 0.0422 - accuracy: 0.9899 - val_loss: 0.5192 - val_accuracy: 0.7309\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 219ms/step - loss: 0.0268 - accuracy: 0.9907 - val_loss: 0.5183 - val_accuracy: 0.6733\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 217ms/step - loss: 0.0244 - accuracy: 0.9915 - val_loss: 0.5576 - val_accuracy: 0.6361\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 217ms/step - loss: 0.0226 - accuracy: 0.9922 - val_loss: 0.4117 - val_accuracy: 0.7247\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 216ms/step - loss: 0.0214 - accuracy: 0.9926 - val_loss: 0.3738 - val_accuracy: 0.7455\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 212ms/step - loss: 0.0202 - accuracy: 0.9928 - val_loss: 0.3845 - val_accuracy: 0.7412\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 215ms/step - loss: 0.0180 - accuracy: 0.9939 - val_loss: 0.3336 - val_accuracy: 0.7885\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 217ms/step - loss: 0.0166 - accuracy: 0.9944 - val_loss: 0.3394 - val_accuracy: 0.7955\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 212ms/step - loss: 0.0158 - accuracy: 0.9948 - val_loss: 0.3707 - val_accuracy: 0.7947\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 216ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.3225 - val_accuracy: 0.8238\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 218ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.3508 - val_accuracy: 0.8176\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 215ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.2936 - val_accuracy: 0.8433\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 221ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.5170 - val_accuracy: 0.7771\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 214ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 0.4765 - val_accuracy: 0.7961\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 219ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.3198 - val_accuracy: 0.8412\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 220ms/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 0.2187 - val_accuracy: 0.8692\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 215ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.5168 - val_accuracy: 0.7854\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 215ms/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 0.3706 - val_accuracy: 0.8295\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 209ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.4131 - val_accuracy: 0.8190\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 216ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.4244 - val_accuracy: 0.8193\n",
      "4279/4279 [==============================] - 17s 4ms/step - loss: 0.0574 - accuracy: 0.9707\n",
      "1721/1721 [==============================] - 7s 4ms/step - loss: 0.2939 - accuracy: 0.8688\n",
      "4481/4481 [==============================] - 18s 4ms/step - loss: 0.0997 - accuracy: 0.9496\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 222ms/step - loss: 0.0152 - accuracy: 0.9955 - val_loss: 0.2721 - val_accuracy: 0.8596\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 212ms/step - loss: 0.0139 - accuracy: 0.9959 - val_loss: 0.4221 - val_accuracy: 0.8193\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 209ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 0.4188 - val_accuracy: 0.8218\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 211ms/step - loss: 0.0136 - accuracy: 0.9960 - val_loss: 0.5180 - val_accuracy: 0.7898\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 212ms/step - loss: 0.0136 - accuracy: 0.9960 - val_loss: 0.5311 - val_accuracy: 0.7926\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 213ms/step - loss: 0.0151 - accuracy: 0.9956 - val_loss: 0.6488 - val_accuracy: 0.7532\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 225ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.5224 - val_accuracy: 0.7968\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 235ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.3848 - val_accuracy: 0.8411\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 229ms/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 0.5349 - val_accuracy: 0.8015\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 219ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.5150 - val_accuracy: 0.8061\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 214ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 0.4832 - val_accuracy: 0.8183\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 0.4515 - val_accuracy: 0.8297\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.3946 - val_accuracy: 0.8462\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 0.6521 - val_accuracy: 0.7788\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0115 - accuracy: 0.9967 - val_loss: 0.4133 - val_accuracy: 0.8447\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 0.5360 - val_accuracy: 0.8152\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 0.4304 - val_accuracy: 0.8416\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.5651 - val_accuracy: 0.8103\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 0.4036 - val_accuracy: 0.8496\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 0.4481 - val_accuracy: 0.8410\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.4536 - val_accuracy: 0.8407\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.6130 - val_accuracy: 0.7994\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 0.5696 - val_accuracy: 0.8045\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.5706 - val_accuracy: 0.8057\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.4760 - val_accuracy: 0.8350\n",
      "4279/4279 [==============================] - 10s 2ms/step - loss: 0.0651 - accuracy: 0.9721\n",
      "1721/1721 [==============================] - 4s 3ms/step - loss: 0.3428 - accuracy: 0.8363\n",
      "4481/4481 [==============================] - 11s 2ms/step - loss: 0.1009 - accuracy: 0.9532\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.4211 - val_accuracy: 0.8477\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.4028 - val_accuracy: 0.8481\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 0.0107 - accuracy: 0.9971 - val_loss: 0.4261 - val_accuracy: 0.8451\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0104 - accuracy: 0.9973 - val_loss: 0.4196 - val_accuracy: 0.8484\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.6897 - val_accuracy: 0.7697\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 166ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 0.5288 - val_accuracy: 0.8173\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.5141 - val_accuracy: 0.8268\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 166ms/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.4320 - val_accuracy: 0.8425\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 164ms/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 0.5367 - val_accuracy: 0.8196\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.5879 - val_accuracy: 0.8033\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.6771 - val_accuracy: 0.7788\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 0.5700 - val_accuracy: 0.8162\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.5770 - val_accuracy: 0.8178\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 164ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.6320 - val_accuracy: 0.8016\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.4618 - val_accuracy: 0.8394\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.5932 - val_accuracy: 0.8193\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.4948 - val_accuracy: 0.8387\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 166ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.6291 - val_accuracy: 0.8158\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.6048 - val_accuracy: 0.8159\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.5861 - val_accuracy: 0.8211\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 164ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.6521 - val_accuracy: 0.8094\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 164ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.4921 - val_accuracy: 0.8389\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 166ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.6386 - val_accuracy: 0.8114\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 164ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.4237 - val_accuracy: 0.8509\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 164ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.6039 - val_accuracy: 0.8197\n",
      "4279/4279 [==============================] - 11s 3ms/step - loss: 0.0757 - accuracy: 0.9717\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.5321 - accuracy: 0.7570\n",
      "4481/4481 [==============================] - 12s 3ms/step - loss: 0.1324 - accuracy: 0.9486\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "    loss_complete, accuracy_complete, f1_complete, precision_complete, recall_complete = evaluation(global_model, xcomplete, ycomplete)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus, loss_complete])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus, accuracy_complete])\n",
    "    f1_it.append([f1_basic, f1_plus, f1_complete])\n",
    "    precision_it.append([precision_basic, precision_plus, precision_complete])\n",
    "    recall_it.append([recall_basic, recall_plus, recall_complete])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/id700.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.057443179190158844, 0.2938941717147827, 0.09973163902759552], [0.06505249440670013, 0.34281834959983826, 0.10086438804864883], [0.07566161453723907, 0.5321468114852905, 0.13242985308170319]]\n",
      "Accuracy for iterations:  [[0.9707192778587341, 0.8688331246376038, 0.94956374168396], [0.9721215963363647, 0.83626389503479, 0.9532325863838196], [0.9716760516166687, 0.7570115327835083, 0.9486151337623596]]\n",
      "F1 for iterations:  [[0.9706688853212286, 0.8649817140968488, 0.9494720777638193], [0.9720795342963164, 0.8293219364694641, 0.9531637020621871], [0.9716245405472854, 0.734246008100034, 0.9485102660927153]]\n",
      "Precision for iterations:  [[0.971532954468529, 0.8874553006598564, 0.9528482190249333], [0.9727807229073139, 0.8641774303355073, 0.9559134625704929], [0.9725716710212223, 0.8203151931332536, 0.9522984846048763]]\n",
      "Recall for iterations:  [[0.9707192731309708, 0.8688331032478384, 0.9495637132155487], [0.9721215928014257, 0.8362638959529173, 0.9532325677098954], [0.971676064156125, 0.7570115527137978, 0.9486151120535122]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Filt5B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part1.csv', low_memory=False)\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part2.csv', low_memory=False)\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part3.csv', low_memory=False)\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part4.csv', low_memory=False)\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part5.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'id701.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    # Calculate mean gradient for each layer\n",
    "    mean_grad = [tf.reduce_mean(layer_grads, axis=0) for layer_grads in zip(*grad_list)]\n",
    "    \n",
    "    return mean_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 178ms/step - loss: 0.3705 - accuracy: 0.9542 - val_loss: 2.2033 - val_accuracy: 0.5496\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 203ms/step - loss: 0.0624 - accuracy: 0.9916 - val_loss: 1.3871 - val_accuracy: 0.5527\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 201ms/step - loss: 0.0297 - accuracy: 0.9923 - val_loss: 0.8468 - val_accuracy: 0.5572\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 187ms/step - loss: 0.0261 - accuracy: 0.9923 - val_loss: 0.8293 - val_accuracy: 0.5610\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 179ms/step - loss: 0.0247 - accuracy: 0.9924 - val_loss: 0.7090 - val_accuracy: 0.5773\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 180ms/step - loss: 0.0344 - accuracy: 0.9907 - val_loss: 0.4736 - val_accuracy: 0.7157\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 185ms/step - loss: 0.0242 - accuracy: 0.9917 - val_loss: 0.5484 - val_accuracy: 0.6482\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 181ms/step - loss: 0.0221 - accuracy: 0.9924 - val_loss: 0.3592 - val_accuracy: 0.7456\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 189ms/step - loss: 0.0207 - accuracy: 0.9930 - val_loss: 0.4239 - val_accuracy: 0.7005\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 188ms/step - loss: 0.0201 - accuracy: 0.9930 - val_loss: 0.3218 - val_accuracy: 0.7730\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 179ms/step - loss: 0.0109 - accuracy: 0.9973 - val_loss: 4.9850 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 2.2349e-07 - accuracy: 1.0000 - val_loss: 5.3811 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 203ms/step - loss: 1.4589e-07 - accuracy: 1.0000 - val_loss: 5.4020 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 264ms/step - loss: 1.4297e-07 - accuracy: 1.0000 - val_loss: 5.4039 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 280ms/step - loss: 1.4244e-07 - accuracy: 1.0000 - val_loss: 5.4050 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 10s 308ms/step - loss: 4.6739 - accuracy: 0.4339 - val_loss: 0.0302 - val_accuracy: 0.9928\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 244ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 205ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 261ms/step - loss: 9.3123e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 283ms/step - loss: 5.3136e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 10s 310ms/step - loss: 1.4823 - accuracy: 0.7083 - val_loss: 1.0293 - val_accuracy: 0.6321\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 246ms/step - loss: 0.0422 - accuracy: 0.9943 - val_loss: 0.7781 - val_accuracy: 0.6367\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 205ms/step - loss: 0.0231 - accuracy: 0.9942 - val_loss: 0.7416 - val_accuracy: 0.6368\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 265ms/step - loss: 0.0214 - accuracy: 0.9942 - val_loss: 0.7362 - val_accuracy: 0.6368\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 272ms/step - loss: 0.0204 - accuracy: 0.9942 - val_loss: 0.7179 - val_accuracy: 0.6368\n",
      "4279/4279 [==============================] - 27s 6ms/step - loss: 0.1297 - accuracy: 0.9240\n",
      "1721/1721 [==============================] - 10s 6ms/step - loss: 0.2685 - accuracy: 0.8365\n",
      "4481/4481 [==============================] - 25s 6ms/step - loss: 0.1863 - accuracy: 0.8911\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 196ms/step - loss: 0.0211 - accuracy: 0.9935 - val_loss: 0.3652 - val_accuracy: 0.7709\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 197ms/step - loss: 0.0182 - accuracy: 0.9943 - val_loss: 0.5206 - val_accuracy: 0.6665\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 194ms/step - loss: 0.0173 - accuracy: 0.9945 - val_loss: 0.2973 - val_accuracy: 0.8234\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 184ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 0.3014 - val_accuracy: 0.8265\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 0.4471 - val_accuracy: 0.7521\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 213ms/step - loss: 0.0173 - accuracy: 0.9945 - val_loss: 0.5329 - val_accuracy: 0.7502\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 250ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 0.5002 - val_accuracy: 0.7757\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 275ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.4132 - val_accuracy: 0.8077\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 276ms/step - loss: 0.0152 - accuracy: 0.9955 - val_loss: 0.3594 - val_accuracy: 0.8289\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 271ms/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 0.3614 - val_accuracy: 0.8309\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 234ms/step - loss: 0.0198 - accuracy: 0.9925 - val_loss: 5.3688 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 295ms/step - loss: 1.3158e-07 - accuracy: 1.0000 - val_loss: 5.7389 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 290ms/step - loss: 9.3818e-08 - accuracy: 1.0000 - val_loss: 5.7579 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 281ms/step - loss: 9.2351e-08 - accuracy: 1.0000 - val_loss: 5.7591 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 274ms/step - loss: 9.2189e-08 - accuracy: 1.0000 - val_loss: 5.7595 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 213ms/step - loss: 7.8721 - accuracy: 0.3051 - val_loss: 0.4688 - val_accuracy: 0.8483\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 259ms/step - loss: 0.0815 - accuracy: 0.9676 - val_loss: 0.0107 - val_accuracy: 0.9957\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 275ms/step - loss: 4.7307e-04 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9969\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 295ms/step - loss: 3.4225e-04 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9973\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 277ms/step - loss: 3.0053e-04 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9975\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 218ms/step - loss: 2.0041 - accuracy: 0.7126 - val_loss: 0.5217 - val_accuracy: 0.7152\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 261ms/step - loss: 0.0184 - accuracy: 0.9949 - val_loss: 0.6931 - val_accuracy: 0.6918\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 273ms/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 0.5791 - val_accuracy: 0.7043\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 275ms/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.5998 - val_accuracy: 0.7017\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 281ms/step - loss: 0.0150 - accuracy: 0.9948 - val_loss: 0.5736 - val_accuracy: 0.7054\n",
      "4279/4279 [==============================] - 28s 7ms/step - loss: 0.0926 - accuracy: 0.9501\n",
      "1721/1721 [==============================] - 6s 4ms/step - loss: 0.2431 - accuracy: 0.8805\n",
      "4481/4481 [==============================] - 12s 3ms/step - loss: 0.1515 - accuracy: 0.9176\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 0.3532 - val_accuracy: 0.8023\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.4244 - val_accuracy: 0.7829\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 0.4137 - val_accuracy: 0.8025\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 150ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.3932 - val_accuracy: 0.8127\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 0.0143 - accuracy: 0.9960 - val_loss: 0.4554 - val_accuracy: 0.7878\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 166ms/step - loss: 0.0178 - accuracy: 0.9953 - val_loss: 0.5914 - val_accuracy: 0.7830\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0155 - accuracy: 0.9956 - val_loss: 0.3428 - val_accuracy: 0.8410\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.0145 - accuracy: 0.9955 - val_loss: 0.5206 - val_accuracy: 0.8006\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.5981 - val_accuracy: 0.7867\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 151ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 0.5387 - val_accuracy: 0.8039\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 0.0421 - accuracy: 0.9834 - val_loss: 4.6212 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 1.3600e-06 - accuracy: 1.0000 - val_loss: 5.0157 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 9.2134e-07 - accuracy: 1.0000 - val_loss: 5.0380 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 8.9892e-07 - accuracy: 1.0000 - val_loss: 5.0415 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 150ms/step - loss: 8.9259e-07 - accuracy: 1.0000 - val_loss: 5.0443 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 172ms/step - loss: 7.8422 - accuracy: 0.3086 - val_loss: 1.5651 - val_accuracy: 0.7134\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 170ms/step - loss: 0.6610 - accuracy: 0.8238 - val_loss: 0.0355 - val_accuracy: 0.9882\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9990\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 6.3217e-04 - accuracy: 1.0000 - val_loss: 7.7947e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 1.9367e-04 - accuracy: 1.0000 - val_loss: 2.8754e-04 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 188ms/step - loss: 1.4318 - accuracy: 0.7588 - val_loss: 0.3149 - val_accuracy: 0.7870\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 185ms/step - loss: 0.0195 - accuracy: 0.9942 - val_loss: 0.5860 - val_accuracy: 0.6944\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 183ms/step - loss: 0.0179 - accuracy: 0.9937 - val_loss: 0.5868 - val_accuracy: 0.6955\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0170 - accuracy: 0.9941 - val_loss: 0.5629 - val_accuracy: 0.6975\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.0166 - accuracy: 0.9941 - val_loss: 0.5920 - val_accuracy: 0.6961\n",
      "4279/4279 [==============================] - 10s 2ms/step - loss: 0.1028 - accuracy: 0.9420\n",
      "1721/1721 [==============================] - 4s 2ms/step - loss: 0.2445 - accuracy: 0.8834\n",
      "4481/4481 [==============================] - 11s 2ms/step - loss: 0.1730 - accuracy: 0.9093\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "    loss_complete, accuracy_complete, f1_complete, precision_complete, recall_complete = evaluation(global_model, xcomplete, ycomplete)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus, loss_complete])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus, accuracy_complete])\n",
    "    f1_it.append([f1_basic, f1_plus, f1_complete])\n",
    "    precision_it.append([precision_basic, precision_plus, precision_complete])\n",
    "    recall_it.append([recall_basic, recall_plus, recall_complete])\n",
    "\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/id701.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.12972553074359894, 0.26845505833625793, 0.18629196286201477], [0.0925874412059784, 0.24309733510017395, 0.1514696329832077], [0.10275402665138245, 0.24451933801174164, 0.1729889214038849]]\n",
      "Accuracy for iterations:  [[0.923982560634613, 0.8365000486373901, 0.8911271095275879], [0.9501227140426636, 0.8805129528045654, 0.9176321029663086], [0.9420374631881714, 0.88343745470047, 0.9093179106712341]]\n",
      "F1 for iterations:  [[0.9232563832924529, 0.8295778888827323, 0.889908856084678], [0.9498869503995601, 0.8775831881849809, 0.9171320298536756], [0.9416874732802485, 0.8806837182262405, 0.9086378332472831]]\n",
      "Precision for iterations:  [[0.9325674107935139, 0.8643866622617569, 0.9092398729715513], [0.9536519058631838, 0.8954091223603107, 0.9279618345403645], [0.9468958940466878, 0.8976967067608941, 0.9218783038238343]]\n",
      "Recall for iterations:  [[0.9239825878640918, 0.8365000363292887, 0.8911270916306873], [0.9501227029711649, 0.8805129695560561, 0.917632124099352], [0.9420374536211984, 0.8834374772941945, 0.9093179139144445]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Filt5C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part1.csv', low_memory=False)\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part2.csv', low_memory=False)\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part3.csv', low_memory=False)\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part4.csv', low_memory=False)\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part5.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'id702.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    # Calculate mean gradient for each layer\n",
    "    mean_grad = [tf.reduce_mean(layer_grads, axis=0) for layer_grads in zip(*grad_list)]\n",
    "    \n",
    "    return mean_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.5748 - accuracy: 0.7443 - val_loss: 1.5561 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.2592 - accuracy: 0.9027 - val_loss: 2.9254 - val_accuracy: 0.1332\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 163ms/step - loss: 0.0986 - accuracy: 0.9893 - val_loss: 4.1191 - val_accuracy: 0.1339\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 0.0616 - accuracy: 0.9893 - val_loss: 2.5636 - val_accuracy: 0.1343\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 0.0410 - accuracy: 0.9892 - val_loss: 1.4367 - val_accuracy: 0.1619\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 143ms/step - loss: 0.0237 - accuracy: 0.9950 - val_loss: 0.8711 - val_accuracy: 0.7271\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.0207 - accuracy: 0.9950 - val_loss: 0.6643 - val_accuracy: 0.7278\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 139ms/step - loss: 0.0202 - accuracy: 0.9950 - val_loss: 0.7180 - val_accuracy: 0.7278\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 138ms/step - loss: 0.0193 - accuracy: 0.9950 - val_loss: 0.6580 - val_accuracy: 0.7293\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.0188 - accuracy: 0.9950 - val_loss: 0.6398 - val_accuracy: 0.7298\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 148ms/step - loss: 0.0143 - accuracy: 0.9961 - val_loss: 2.5355 - val_accuracy: 0.4416\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 145ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 2.2600 - val_accuracy: 0.4414\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 145ms/step - loss: 0.0129 - accuracy: 0.9964 - val_loss: 2.1636 - val_accuracy: 0.4409\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 145ms/step - loss: 0.0128 - accuracy: 0.9967 - val_loss: 2.1152 - val_accuracy: 0.4389\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 146ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 2.2252 - val_accuracy: 0.4389\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 4s 147ms/step - loss: 2.1868 - accuracy: 0.5845 - val_loss: 0.0602 - val_accuracy: 0.9792\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 4s 152ms/step - loss: 0.0084 - accuracy: 0.9997 - val_loss: 0.0112 - val_accuracy: 0.9956\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 4s 151ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.0056 - val_accuracy: 0.9980\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 4s 151ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9998\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 4s 147ms/step - loss: 6.2418e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 11s 151ms/step - loss: 0.4935 - accuracy: 0.8934 - val_loss: 0.3961 - val_accuracy: 0.8274\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 11s 153ms/step - loss: 0.0238 - accuracy: 0.9926 - val_loss: 0.2725 - val_accuracy: 0.8340\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 11s 151ms/step - loss: 0.0219 - accuracy: 0.9930 - val_loss: 0.2451 - val_accuracy: 0.8470\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 11s 151ms/step - loss: 0.0208 - accuracy: 0.9931 - val_loss: 0.2310 - val_accuracy: 0.8552\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 11s 153ms/step - loss: 0.0199 - accuracy: 0.9934 - val_loss: 0.2184 - val_accuracy: 0.8647\n",
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.0828 - accuracy: 0.9872\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1571 - accuracy: 0.9554\n",
      "4481/4481 [==============================] - 14s 3ms/step - loss: 0.0933 - accuracy: 0.9804\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 157ms/step - loss: 0.0258 - accuracy: 0.9908 - val_loss: 0.7108 - val_accuracy: 0.6096\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 2s 154ms/step - loss: 0.0228 - accuracy: 0.9919 - val_loss: 0.8928 - val_accuracy: 0.4948\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 0.0215 - accuracy: 0.9925 - val_loss: 0.7268 - val_accuracy: 0.5996\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 2s 150ms/step - loss: 0.0205 - accuracy: 0.9928 - val_loss: 0.9022 - val_accuracy: 0.5028\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 0.0198 - accuracy: 0.9932 - val_loss: 0.9685 - val_accuracy: 0.4991\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 158ms/step - loss: 0.0150 - accuracy: 0.9955 - val_loss: 0.6867 - val_accuracy: 0.7399\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 170ms/step - loss: 0.0141 - accuracy: 0.9964 - val_loss: 0.8553 - val_accuracy: 0.7328\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 144ms/step - loss: 0.0146 - accuracy: 0.9964 - val_loss: 0.7132 - val_accuracy: 0.7399\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 143ms/step - loss: 0.0134 - accuracy: 0.9965 - val_loss: 0.7617 - val_accuracy: 0.7396\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 138ms/step - loss: 0.0130 - accuracy: 0.9967 - val_loss: 0.7313 - val_accuracy: 0.7429\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 170ms/step - loss: 0.0110 - accuracy: 0.9974 - val_loss: 1.6636 - val_accuracy: 0.5094\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 157ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 1.6556 - val_accuracy: 0.5210\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 176ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 1.9758 - val_accuracy: 0.5037\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 159ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 1.7137 - val_accuracy: 0.5382\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 147ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 1.4426 - val_accuracy: 0.5815\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 176ms/step - loss: 4.5842 - accuracy: 0.4092 - val_loss: 0.5509 - val_accuracy: 0.8661\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 171ms/step - loss: 0.2112 - accuracy: 0.9280 - val_loss: 0.0570 - val_accuracy: 0.9839\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 4s 159ms/step - loss: 0.0050 - accuracy: 0.9997 - val_loss: 0.0337 - val_accuracy: 0.9894\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 4s 157ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.0283 - val_accuracy: 0.9908\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 174ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0244 - val_accuracy: 0.9922\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 174ms/step - loss: 0.7027 - accuracy: 0.8807 - val_loss: 0.2601 - val_accuracy: 0.8722\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 13s 184ms/step - loss: 0.0184 - accuracy: 0.9946 - val_loss: 0.1960 - val_accuracy: 0.9008\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 13s 183ms/step - loss: 0.0173 - accuracy: 0.9947 - val_loss: 0.1765 - val_accuracy: 0.9052\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 12s 174ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 0.1682 - val_accuracy: 0.9077\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 12s 165ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.1666 - val_accuracy: 0.9090\n",
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.0609 - accuracy: 0.9891\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1570 - accuracy: 0.9431\n",
      "4481/4481 [==============================] - 14s 3ms/step - loss: 0.0673 - accuracy: 0.9843\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.0211 - accuracy: 0.9927 - val_loss: 0.9174 - val_accuracy: 0.5131\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 5s 311ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.8216 - val_accuracy: 0.5944\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 5s 286ms/step - loss: 0.0180 - accuracy: 0.9941 - val_loss: 0.9898 - val_accuracy: 0.5460\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 5s 316ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.7810 - val_accuracy: 0.6336\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 5s 315ms/step - loss: 0.0173 - accuracy: 0.9946 - val_loss: 0.9575 - val_accuracy: 0.5675\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 5s 347ms/step - loss: 0.0137 - accuracy: 0.9966 - val_loss: 0.7910 - val_accuracy: 0.7450\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 4s 295ms/step - loss: 0.0128 - accuracy: 0.9972 - val_loss: 0.8051 - val_accuracy: 0.7501\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 4s 312ms/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.9127 - val_accuracy: 0.7486\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.0120 - accuracy: 0.9972 - val_loss: 0.7320 - val_accuracy: 0.7631\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 4s 268ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 0.8342 - val_accuracy: 0.7551\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 8s 314ms/step - loss: 0.0104 - accuracy: 0.9975 - val_loss: 1.5425 - val_accuracy: 0.5576\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 8s 320ms/step - loss: 0.0099 - accuracy: 0.9975 - val_loss: 1.7240 - val_accuracy: 0.5488\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 8s 319ms/step - loss: 0.0101 - accuracy: 0.9975 - val_loss: 1.3154 - val_accuracy: 0.6153\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 9s 328ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 1.6609 - val_accuracy: 0.5650\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 10s 380ms/step - loss: 0.0098 - accuracy: 0.9975 - val_loss: 1.6895 - val_accuracy: 0.5719\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 11s 399ms/step - loss: 4.7577 - accuracy: 0.4873 - val_loss: 0.5900 - val_accuracy: 0.8748\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 10s 356ms/step - loss: 0.2069 - accuracy: 0.9363 - val_loss: 0.0168 - val_accuracy: 0.9944\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 11s 400ms/step - loss: 5.6983e-04 - accuracy: 0.9999 - val_loss: 0.0077 - val_accuracy: 0.9968\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 11s 396ms/step - loss: 2.7010e-04 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9972\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 12s 463ms/step - loss: 2.3122e-04 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9975\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 28s 394ms/step - loss: 1.0934 - accuracy: 0.8756 - val_loss: 0.2308 - val_accuracy: 0.9039\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 30s 435ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.1813 - val_accuracy: 0.9209\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 22s 319ms/step - loss: 0.0158 - accuracy: 0.9950 - val_loss: 0.1541 - val_accuracy: 0.9302\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 20s 289ms/step - loss: 0.0149 - accuracy: 0.9952 - val_loss: 0.1562 - val_accuracy: 0.9269\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 22s 318ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.1325 - val_accuracy: 0.9367\n",
      "4279/4279 [==============================] - 33s 8ms/step - loss: 0.0507 - accuracy: 0.9900\n",
      "1721/1721 [==============================] - 16s 9ms/step - loss: 0.1213 - accuracy: 0.9471\n",
      "4481/4481 [==============================] - 45s 10ms/step - loss: 0.0545 - accuracy: 0.9879\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "    loss_complete, accuracy_complete, f1_complete, precision_complete, recall_complete = evaluation(global_model, xcomplete, ycomplete)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus, loss_complete])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus, accuracy_complete])\n",
    "    f1_it.append([f1_basic, f1_plus, f1_complete])\n",
    "    precision_it.append([precision_basic, precision_plus, precision_complete])\n",
    "    recall_it.append([recall_basic, recall_plus, recall_complete])\n",
    "\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/id702.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.08284654468297958, 0.15706931054592133, 0.09326823055744171], [0.06087246164679527, 0.15701165795326233, 0.06732453405857086], [0.05067482963204384, 0.12131398916244507, 0.05448112636804581]]\n",
      "Accuracy for iterations:  [[0.9871526956558228, 0.9554057717323303, 0.9804420471191406], [0.9890955090522766, 0.9430901408195496, 0.9842643737792969], [0.9900376796722412, 0.9471408724784851, 0.9879401922225952]]\n",
      "F1 for iterations:  [[0.9871565102028913, 0.955312338388428, 0.9804419468335733], [0.9890998387839542, 0.9428067404328064, 0.9842643431643833], [0.990042161736056, 0.9468745067838977, 0.9879397635678289]]\n",
      "Precision for iterations:  [[0.9872243578805475, 0.9556615380304949, 0.9804547372047389], [0.9892309150472579, 0.944483742605825, 0.984269025597288], [0.990217253956467, 0.9486164158111176, 0.9880125896412548]]\n",
      "Recall for iterations:  [[0.9871527067691139, 0.9554057981544721, 0.9804420760415431], [0.9890955038125566, 0.9430901692944852, 0.9842643807238664], [0.9900376873411435, 0.9471408849814721, 0.9879402102267575]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
