{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Federated Learning for attack detection: 5 nodes sharing gradients: KRUM**\n",
    "\n",
    "IDs from this file = **idKRUMxy** (x = 0 if experiment with dataset, x = 1 if epochs & iterations, y being integer equal or greater than 0)\n",
    "\n",
    "In this file, experiments with different datasets, and number of epochs & iterations are done. The experiments are divided into sections, based on the elements being changed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static elements for all experiments (execute first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Disable warns\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data): \n",
    "\n",
    "    # Select the 'proto' and 'state' values that I want\n",
    "    data = data.loc[(data['proto'] == 'tcp') | (data['proto'] =='udp') | (data['proto'] =='icmp') | (data['proto'] =='arp') | (data['proto'] =='ipv6-icmp') | (data['proto'] =='igmp') | (data['proto'] =='rarp'), :]\n",
    "    data = data.loc[(data['state'] == 'RST') | (data['state'] =='REQ') | (data['state'] =='INT') | (data['state'] =='FIN') | (data['state'] =='CON') | (data['state'] =='ECO') | (data['state'] =='ACC') | (data['state'] == 'PAR'), :]\n",
    "\n",
    "    # Extracting labels \n",
    "    data_labels = data[['label']]\n",
    "\n",
    "    # Drop the invalid features and select interested data features\n",
    "    data_features=data[['proto','srcip','sport','dstip','dsport','spkts','dpkts','sbytes','dbytes','state','stime','ltime','dur']]\n",
    "\n",
    "    \"\"\"PREPROCESSING\"\"\"\n",
    "\n",
    "\n",
    "    # Preprocess IP and ports features\n",
    "    # IP Source Address\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "\n",
    "    # IP Destination Address\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "    # Ports\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "\n",
    "    # Convert all ports with 0 decimal, and HEX to DEC\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    # Convert field to int format\n",
    "    data_features['srcip'] = data_features['srcip'].astype(int)\n",
    "    data_features['sport'] = data_features['sport'].astype(int)\n",
    "    data_features['dstip'] = data_features['dstip'].astype(int)\n",
    "    data_features['dsport'] = data_features['dsport'].astype(int)\n",
    "\n",
    "    # Convert some fields to logarithmic\n",
    "    log1p_col = ['dur', 'sbytes', 'dbytes', 'spkts']\n",
    "\n",
    "    for col in log1p_col:\n",
    "        data_features[col] = data_features[col].apply(np.log1p)\n",
    "\n",
    "    # Create a complementary field of attack & Transform to One hot encoding - LABELS\n",
    "    normal=data_labels['label']\n",
    "    normal=normal.replace(1,2)\n",
    "    normal=normal.replace(0,1)\n",
    "    normal=normal.replace(2,0)\n",
    "\n",
    "    # Insert the new column in data labels\n",
    "    data_labels.insert(1, 'normal', normal)\n",
    "    data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "    data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "    # Transform to One hot encoding - FEATURES\n",
    "    data_features=pd.get_dummies(data_features)\n",
    "\n",
    "    # Value given for the missing columns\n",
    "    auxCol=0\n",
    "\n",
    "    # As we are using different datasets that might not have all representations, we are going to detect and add the missing columns \n",
    "    # The columns that can have types are: proto and state: need to check if all representations are done \n",
    "    state_cols = [col for col in data_features if col.startswith('state_')]\n",
    "    proto_cols = [col for col in data_features if col.startswith('proto_')]\n",
    "    \n",
    "    # Check if all columns are present\n",
    "    if 'state_PAR' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_PAR', auxCol, True)\n",
    "    if 'state_ACC' not in state_cols: \n",
    "        data_features.insert(data_features.shape[1], 'state_ACC', auxCol, True)\n",
    "    if 'state_ECO' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_ECO', auxCol, True)\n",
    "    if 'state_CON' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_CON', auxCol, True)\n",
    "    if 'state_FIN' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_FIN', auxCol, True)\n",
    "    if 'state_INT' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_INT', auxCol, True)\n",
    "    if 'state_REQ' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_REQ', auxCol, True)\n",
    "    if 'state_RST' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_RST', auxCol, True)\n",
    "    if 'proto_igmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_igmp', auxCol, True)\n",
    "    if 'proto_arp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_arp', auxCol, True)\n",
    "    if 'proto_icmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_icmp', auxCol, True)\n",
    "    if 'proto_udp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_udp', auxCol, True)\n",
    "    if 'proto_tcp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_tcp', auxCol, True)\n",
    "\n",
    "    # Normalize all data features\n",
    "    data_features = StandardScaler().fit_transform(data_features)\n",
    "\n",
    "    #Add dimension to data features\n",
    "    data_features = np.expand_dims(data_features, axis=2)\n",
    "    data_features = np.expand_dims(data_features, axis=3)\n",
    "\n",
    "    x = data_features\n",
    "    y = data_labels.to_numpy()\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building and definition\n",
    "def build_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(filters=32,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(1, 2), padding='same'))\n",
    "    model.add(layers.Conv2D(filters=64,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(1, 2), padding='same'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(Dense(444, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns values of loss, accuracy, f1, precision and recall of model evaluating with test dataset \n",
    "def evaluation(model, x, y): \n",
    "    loss, accuracy = model.evaluate(x, y)\n",
    "    y_pred = model.predict(x)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y = np.argmax(y, axis=1)\n",
    "    report = classification_report(y, y_pred, target_names=['normal', 'attack'], output_dict=True)\n",
    "    # Obtain f1, precision and recall from the report\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    return loss, accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16076/3457440085.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16076/3457440085.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_complete = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Complete.csv')\n"
     ]
    }
   ],
   "source": [
    "test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n",
    "test_plus = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test+.csv')\n",
    "test_complete = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)\n",
    "xcomplete, ycomplete = preprocessing(test_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments with datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Filt5A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part1.csv', low_memory=False)\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part2.csv', low_memory=False)\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part3.csv', low_memory=False)\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part4.csv', low_memory=False)\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part5.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idKRUM00.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list, num_mal = 0):\n",
    "    \n",
    "    num_to_consider = num_nodes - num_mal - 2\n",
    "\n",
    "    # Flatten gradients to compute distances\n",
    "    flat_grads = [tf.concat([tf.reshape(g, [-1]) for g in grad], axis=0).numpy() for grad in grad_list]\n",
    "\n",
    "    # Compute pairwise squared Euclidean distances\n",
    "    distances = np.zeros((num_nodes, num_nodes))\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(i + 1, num_nodes):\n",
    "            dist = np.sum((flat_grads[i] - flat_grads[j]) ** 2)\n",
    "            distances[i, j] = dist\n",
    "            distances[j, i] = dist\n",
    "\n",
    "    # Find the Krum gradient\n",
    "    krum_scores = []\n",
    "    for i in range(num_nodes):\n",
    "        sorted_distances = np.sort(distances[i])\n",
    "        score = np.sum(sorted_distances[:num_to_consider])\n",
    "        krum_scores.append(score)\n",
    "    \n",
    "    krum_index = np.argmin(krum_scores)\n",
    "    selected_grad = grad_list[krum_index]\n",
    "\n",
    "    return selected_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 342ms/step - loss: 0.3642 - accuracy: 0.9667 - val_loss: 1.8792 - val_accuracy: 0.6196\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 289ms/step - loss: 0.0594 - accuracy: 0.9916 - val_loss: 0.8933 - val_accuracy: 0.6202\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 279ms/step - loss: 0.0299 - accuracy: 0.9923 - val_loss: 0.7760 - val_accuracy: 0.6249\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 280ms/step - loss: 0.0272 - accuracy: 0.9923 - val_loss: 0.5877 - val_accuracy: 0.6559\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 246ms/step - loss: 0.0259 - accuracy: 0.9923 - val_loss: 0.7493 - val_accuracy: 0.6244\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 235ms/step - loss: 0.0419 - accuracy: 0.9897 - val_loss: 0.4992 - val_accuracy: 0.7400\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 236ms/step - loss: 0.0275 - accuracy: 0.9912 - val_loss: 0.5183 - val_accuracy: 0.6632\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 224ms/step - loss: 0.0247 - accuracy: 0.9914 - val_loss: 0.4427 - val_accuracy: 0.6861\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 215ms/step - loss: 0.0228 - accuracy: 0.9920 - val_loss: 0.4181 - val_accuracy: 0.7046\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 357ms/step - loss: 0.0210 - accuracy: 0.9929 - val_loss: 0.4148 - val_accuracy: 0.7053\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 13s 425ms/step - loss: 0.0204 - accuracy: 0.9932 - val_loss: 0.4123 - val_accuracy: 0.7182\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 12s 385ms/step - loss: 0.0180 - accuracy: 0.9941 - val_loss: 0.3050 - val_accuracy: 0.8005\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 344ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.4146 - val_accuracy: 0.7601\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 262ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.6784 - val_accuracy: 0.6999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 351ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.4200 - val_accuracy: 0.7886\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 396ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.3057 - val_accuracy: 0.8347\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 12s 397ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 0.5404 - val_accuracy: 0.7660\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 297ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.4006 - val_accuracy: 0.8148\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 245ms/step - loss: 0.0146 - accuracy: 0.9955 - val_loss: 0.4588 - val_accuracy: 0.8026\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 303ms/step - loss: 0.0144 - accuracy: 0.9956 - val_loss: 0.3708 - val_accuracy: 0.8319\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 15s 493ms/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 0.4438 - val_accuracy: 0.8102\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 15s 476ms/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 0.5461 - val_accuracy: 0.7793\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 17s 534ms/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 0.5406 - val_accuracy: 0.7850\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 14s 446ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.4882 - val_accuracy: 0.8023\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 18s 571ms/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.7125 - val_accuracy: 0.7431\n",
      "4279/4279 [==============================] - 48s 11ms/step - loss: 0.0888 - accuracy: 0.9640\n",
      "1721/1721 [==============================] - 18s 11ms/step - loss: 0.3737 - accuracy: 0.8403\n",
      "4481/4481 [==============================] - 47s 11ms/step - loss: 0.1483 - accuracy: 0.9347\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 18s 565ms/step - loss: 0.0155 - accuracy: 0.9955 - val_loss: 0.3306 - val_accuracy: 0.8417\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 15s 484ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.4936 - val_accuracy: 0.7929\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 13s 411ms/step - loss: 0.0138 - accuracy: 0.9961 - val_loss: 0.4117 - val_accuracy: 0.8198\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 356ms/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.5193 - val_accuracy: 0.7838\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 14s 452ms/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 0.4290 - val_accuracy: 0.8117\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 18s 571ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.5176 - val_accuracy: 0.8006\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 15s 476ms/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.5331 - val_accuracy: 0.7997\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 13s 424ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.4021 - val_accuracy: 0.8400\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 402ms/step - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.3986 - val_accuracy: 0.8411\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 356ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.3535 - val_accuracy: 0.8480\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 15s 488ms/step - loss: 0.0130 - accuracy: 0.9959 - val_loss: 0.5755 - val_accuracy: 0.7946\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 12s 391ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.4913 - val_accuracy: 0.8143\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 290ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.4384 - val_accuracy: 0.8314\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 360ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 0.3432 - val_accuracy: 0.8563\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 326ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 0.6282 - val_accuracy: 0.7832\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 15s 482ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.4292 - val_accuracy: 0.8341\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 355ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.4896 - val_accuracy: 0.8163\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 273ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.4570 - val_accuracy: 0.8308\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 247ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.4565 - val_accuracy: 0.8347\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 12s 388ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.3442 - val_accuracy: 0.8564\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 18s 583ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.5792 - val_accuracy: 0.8030\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 14s 464ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.5403 - val_accuracy: 0.8090\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 12s 403ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.4491 - val_accuracy: 0.8276\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 348ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.4214 - val_accuracy: 0.8402\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 13s 428ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.4263 - val_accuracy: 0.8383\n",
      "4279/4279 [==============================] - 52s 12ms/step - loss: 0.0571 - accuracy: 0.9732\n",
      "1721/1721 [==============================] - 24s 14ms/step - loss: 0.2969 - accuracy: 0.8621\n",
      "4481/4481 [==============================] - 42s 9ms/step - loss: 0.0962 - accuracy: 0.9568\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 13s 432ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.4422 - val_accuracy: 0.8279\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 13s 434ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 0.5213 - val_accuracy: 0.8015\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 358ms/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.4540 - val_accuracy: 0.8208\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 384ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.6177 - val_accuracy: 0.7759\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 15s 478ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.5491 - val_accuracy: 0.7948\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 17s 535ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.3452 - val_accuracy: 0.8526\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 13s 413ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.5298 - val_accuracy: 0.8087\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 12s 395ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.5845 - val_accuracy: 0.7956\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 345ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 0.5147 - val_accuracy: 0.8208\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 13s 428ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 0.6133 - val_accuracy: 0.7920\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 16s 523ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.5594 - val_accuracy: 0.8116\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 12s 373ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.5936 - val_accuracy: 0.7905\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 303ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.7171 - val_accuracy: 0.7730\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 248ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.5068 - val_accuracy: 0.8288\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 285ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.5838 - val_accuracy: 0.8105\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 15s 486ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 0.4676 - val_accuracy: 0.8378\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 12s 378ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 0.6199 - val_accuracy: 0.8072\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 281ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.5476 - val_accuracy: 0.8186\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 218ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.5045 - val_accuracy: 0.8330\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 324ms/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 0.3619 - val_accuracy: 0.8569\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 18s 570ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.4996 - val_accuracy: 0.8329\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 16s 514ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.3886 - val_accuracy: 0.8538\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 14s 460ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.2715 - val_accuracy: 0.8759\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 390ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.3201 - val_accuracy: 0.8652\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 12s 386ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.6557 - val_accuracy: 0.7986\n",
      "4279/4279 [==============================] - 46s 11ms/step - loss: 0.0817 - accuracy: 0.9693\n",
      "1721/1721 [==============================] - 22s 13ms/step - loss: 0.6474 - accuracy: 0.7406\n",
      "4481/4481 [==============================] - 40s 9ms/step - loss: 0.1580 - accuracy: 0.9428\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "    loss_complete, accuracy_complete, f1_complete, precision_complete, recall_complete = evaluation(global_model, xcomplete, ycomplete)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus, loss_complete])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus, accuracy_complete])\n",
    "    f1_it.append([f1_basic, f1_plus, f1_complete])\n",
    "    precision_it.append([precision_basic, precision_plus, precision_complete])\n",
    "    recall_it.append([recall_basic, recall_plus, recall_complete])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idKRUM00.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.08878409117460251, 0.37367090582847595, 0.14826644957065582], [0.05707963928580284, 0.296873539686203, 0.09621022641658783], [0.08165192604064941, 0.6474021077156067, 0.15797719359397888]]\n",
      "Accuracy for iterations:  [[0.9639633297920227, 0.8402600884437561, 0.9347139000892639], [0.9731733202934265, 0.8620940446853638, 0.9568177461624146], [0.9693023562431335, 0.7406452298164368, 0.9428328275680542]]\n",
      "F1 for iterations:  [[0.9638645940345658, 0.8335965860492922, 0.9344801079863494], [0.9731358370953441, 0.857684002050284, 0.9567667355664131], [0.9692349378527148, 0.7125105552563743, 0.9426773587612735]]\n",
      "Precision for iterations:  [[0.9656154245460951, 0.8680512788671989, 0.9410082055066445], [0.9737565088890403, 0.8826517217546718, 0.9589824408983635], [0.9705001595482861, 0.8138686114556182, 0.9476890554678995]]\n",
      "Recall for iterations:  [[0.9639633059686231, 0.8402601177068953, 0.934713920024552], [0.9731733325542669, 0.8620940201990845, 0.9568177221017096], [0.9693023459639487, 0.7406452081668241, 0.9428328299702167]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Filt5B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part1.csv', low_memory=False)\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part2.csv', low_memory=False)\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part3.csv', low_memory=False)\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part4.csv', low_memory=False)\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part5.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idKRUM01.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 18s 583ms/step - loss: 0.3610 - accuracy: 0.9093 - val_loss: 2.2652 - val_accuracy: 0.5512\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 14s 451ms/step - loss: 0.0586 - accuracy: 0.9916 - val_loss: 1.1078 - val_accuracy: 0.5527\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 14s 457ms/step - loss: 0.0294 - accuracy: 0.9922 - val_loss: 0.9290 - val_accuracy: 0.5569\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 367ms/step - loss: 0.0266 - accuracy: 0.9922 - val_loss: 0.7739 - val_accuracy: 0.5710\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 370ms/step - loss: 0.0255 - accuracy: 0.9921 - val_loss: 0.8235 - val_accuracy: 0.5605\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 359ms/step - loss: 0.0374 - accuracy: 0.9903 - val_loss: 0.5398 - val_accuracy: 0.6966\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 328ms/step - loss: 0.0258 - accuracy: 0.9914 - val_loss: 0.4068 - val_accuracy: 0.7266\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 325ms/step - loss: 0.0237 - accuracy: 0.9917 - val_loss: 0.4761 - val_accuracy: 0.6669\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 320ms/step - loss: 0.0218 - accuracy: 0.9927 - val_loss: 0.2685 - val_accuracy: 0.8403\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 14s 464ms/step - loss: 0.0205 - accuracy: 0.9929 - val_loss: 0.2471 - val_accuracy: 0.8510\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 13s 433ms/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 5.0445 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 365ms/step - loss: 2.3336e-07 - accuracy: 1.0000 - val_loss: 5.4695 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 296ms/step - loss: 1.4758e-07 - accuracy: 1.0000 - val_loss: 5.4919 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 277ms/step - loss: 1.4448e-07 - accuracy: 1.0000 - val_loss: 5.4939 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 12s 375ms/step - loss: 1.4401e-07 - accuracy: 1.0000 - val_loss: 5.4950 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 374ms/step - loss: 4.3532 - accuracy: 0.4614 - val_loss: 0.0279 - val_accuracy: 0.9953\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 335ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 284ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 242ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 316ms/step - loss: 7.2363e-04 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 17s 553ms/step - loss: 1.3174 - accuracy: 0.7249 - val_loss: 1.1206 - val_accuracy: 0.6344\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 15s 484ms/step - loss: 0.0356 - accuracy: 0.9938 - val_loss: 0.7979 - val_accuracy: 0.6368\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 13s 408ms/step - loss: 0.0229 - accuracy: 0.9939 - val_loss: 0.7509 - val_accuracy: 0.6368\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 384ms/step - loss: 0.0215 - accuracy: 0.9942 - val_loss: 0.7291 - val_accuracy: 0.6368\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 337ms/step - loss: 0.0205 - accuracy: 0.9942 - val_loss: 0.6798 - val_accuracy: 0.6368\n",
      "4279/4279 [==============================] - 39s 9ms/step - loss: 0.1294 - accuracy: 0.9241\n",
      "1721/1721 [==============================] - 17s 10ms/step - loss: 0.2261 - accuracy: 0.88650s - loss: 0\n",
      "4481/4481 [==============================] - 32s 7ms/step - loss: 0.1836 - accuracy: 0.8914\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 342ms/step - loss: 0.0213 - accuracy: 0.9928 - val_loss: 0.5113 - val_accuracy: 0.6546\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 310ms/step - loss: 0.0186 - accuracy: 0.9943 - val_loss: 0.4625 - val_accuracy: 0.6923\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 313ms/step - loss: 0.0170 - accuracy: 0.9948 - val_loss: 0.5107 - val_accuracy: 0.6936\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 322ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 0.3588 - val_accuracy: 0.7950\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 260ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.4487 - val_accuracy: 0.7548\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 226ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.4901 - val_accuracy: 0.7640\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 214ms/step - loss: 0.0157 - accuracy: 0.9953 - val_loss: 0.3329 - val_accuracy: 0.8287\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 204ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.5664 - val_accuracy: 0.7717\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 202ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.4979 - val_accuracy: 0.7962\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 276ms/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 0.6307 - val_accuracy: 0.7772\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 364ms/step - loss: 0.0118 - accuracy: 0.9954 - val_loss: 5.8124 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 315ms/step - loss: 4.3008e-08 - accuracy: 1.0000 - val_loss: 6.1674 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 241ms/step - loss: 3.0319e-08 - accuracy: 1.0000 - val_loss: 6.1855 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 231ms/step - loss: 2.9858e-08 - accuracy: 1.0000 - val_loss: 6.1865 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 281ms/step - loss: 2.9835e-08 - accuracy: 1.0000 - val_loss: 6.1868 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 359ms/step - loss: 7.5996 - accuracy: 0.3813 - val_loss: 0.2590 - val_accuracy: 0.9008\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 309ms/step - loss: 0.0304 - accuracy: 0.9846 - val_loss: 0.0048 - val_accuracy: 0.9975\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 254ms/step - loss: 2.6469e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9984\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 225ms/step - loss: 2.0699e-04 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9988\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 266ms/step - loss: 1.8001e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9989\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 14s 448ms/step - loss: 2.1208 - accuracy: 0.7212 - val_loss: 0.9006 - val_accuracy: 0.6729\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 12s 401ms/step - loss: 0.0226 - accuracy: 0.9951 - val_loss: 0.9837 - val_accuracy: 0.6650\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 328ms/step - loss: 0.0164 - accuracy: 0.9946 - val_loss: 0.7334 - val_accuracy: 0.6868\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 342ms/step - loss: 0.0157 - accuracy: 0.9946 - val_loss: 0.6650 - val_accuracy: 0.6943\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 284ms/step - loss: 0.0153 - accuracy: 0.9948 - val_loss: 0.6178 - val_accuracy: 0.6997\n",
      "4279/4279 [==============================] - 40s 9ms/step - loss: 0.0966 - accuracy: 0.9473\n",
      "1721/1721 [==============================] - 15s 9ms/step - loss: 0.2352 - accuracy: 0.8826\n",
      "4481/4481 [==============================] - 32s 7ms/step - loss: 0.1565 - accuracy: 0.9153\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 10s 336ms/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.4955 - val_accuracy: 0.7317\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 318ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.5224 - val_accuracy: 0.7323\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 308ms/step - loss: 0.0142 - accuracy: 0.9959 - val_loss: 0.3614 - val_accuracy: 0.8213\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 277ms/step - loss: 0.0139 - accuracy: 0.9960 - val_loss: 0.3696 - val_accuracy: 0.8200\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 229ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 0.4325 - val_accuracy: 0.7951\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 228ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.3564 - val_accuracy: 0.8425\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 214ms/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.6703 - val_accuracy: 0.7740\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 193ms/step - loss: 0.0144 - accuracy: 0.9958 - val_loss: 0.4759 - val_accuracy: 0.8228\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 233ms/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 0.6908 - val_accuracy: 0.7732\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 271ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.6194 - val_accuracy: 0.7938\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 15s 492ms/step - loss: 0.0221 - accuracy: 0.9919 - val_loss: 5.4644 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 288ms/step - loss: 1.4972e-07 - accuracy: 1.0000 - val_loss: 5.8342 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 225ms/step - loss: 1.0455e-07 - accuracy: 1.0000 - val_loss: 5.8534 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 295ms/step - loss: 1.0273e-07 - accuracy: 1.0000 - val_loss: 5.8547 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 280ms/step - loss: 1.0255e-07 - accuracy: 1.0000 - val_loss: 5.8552 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 387ms/step - loss: 8.7521 - accuracy: 0.3852 - val_loss: 0.9370 - val_accuracy: 0.8400\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 301ms/step - loss: 0.1993 - accuracy: 0.9461 - val_loss: 5.7614e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 228ms/step - loss: 6.1041e-05 - accuracy: 1.0000 - val_loss: 1.9767e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 395ms/step - loss: 4.3526e-05 - accuracy: 1.0000 - val_loss: 1.8489e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 13s 428ms/step - loss: 4.2232e-05 - accuracy: 1.0000 - val_loss: 1.8104e-04 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 14s 445ms/step - loss: 2.0730 - accuracy: 0.7205 - val_loss: 0.4836 - val_accuracy: 0.7241\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 281ms/step - loss: 0.0203 - accuracy: 0.9947 - val_loss: 0.5668 - val_accuracy: 0.7066\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 281ms/step - loss: 0.0161 - accuracy: 0.9944 - val_loss: 0.5802 - val_accuracy: 0.7046\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 361ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.5880 - val_accuracy: 0.7048\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 12s 399ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 0.5448 - val_accuracy: 0.7098\n",
      "4279/4279 [==============================] - 40s 9ms/step - loss: 0.0844 - accuracy: 0.9557\n",
      "1721/1721 [==============================] - 14s 8ms/step - loss: 0.1929 - accuracy: 0.9301\n",
      "4481/4481 [==============================] - 34s 8ms/step - loss: 0.1398 - accuracy: 0.9268\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "    loss_complete, accuracy_complete, f1_complete, precision_complete, recall_complete = evaluation(global_model, xcomplete, ycomplete)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus, loss_complete])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus, accuracy_complete])\n",
    "    f1_it.append([f1_basic, f1_plus, f1_complete])\n",
    "    precision_it.append([precision_basic, precision_plus, precision_complete])\n",
    "    recall_it.append([recall_basic, recall_plus, recall_complete])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idKRUM01.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.1294107586145401, 0.22612498700618744, 0.18356190621852875], [0.09662602841854095, 0.23518449068069458, 0.1565445512533188], [0.08443371206521988, 0.1928814947605133, 0.13982537388801575]]\n",
      "Accuracy for iterations:  [[0.9241140484809875, 0.8864709734916687, 0.8913781642913818], [0.9472669363021851, 0.8825655579566956, 0.9152536392211914], [0.9557246565818787, 0.9300661087036133, 0.926755428314209]]\n",
      "F1 for iterations:  [[0.9233918735333838, 0.8838986349720896, 0.8901692764377828], [0.9469940166524514, 0.8797686921800936, 0.9147101698666007], [0.955552926164441, 0.9293800076359917, 0.9264159913216581]]\n",
      "Precision for iterations:  [[0.9326584387033396, 0.9000277455110332, 0.9094021627378143], [0.951245544478366, 0.8969437182595985, 0.9261135945657125], [0.9584258577276722, 0.9344163489049463, 0.9347770819443417]]\n",
      "Recall for iterations:  [[0.924114055333197, 0.8864709728983506, 0.8913781919382852], [0.9472669373922697, 0.8825655743660539, 0.9152536461857166], [0.9557246779047007, 0.930066119305384, 0.9267554352754082]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Filt5C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part1.csv', low_memory=False)\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part2.csv', low_memory=False)\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part3.csv', low_memory=False)\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part4.csv', low_memory=False)\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part5.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idKRUM02.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.5476 - accuracy: 0.7475 - val_loss: 1.6460 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 199ms/step - loss: 0.2205 - accuracy: 0.9476 - val_loss: 3.6629 - val_accuracy: 0.1143\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 200ms/step - loss: 0.0977 - accuracy: 0.9883 - val_loss: 4.3456 - val_accuracy: 0.1322\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 198ms/step - loss: 0.0587 - accuracy: 0.9893 - val_loss: 2.5633 - val_accuracy: 0.1342\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 0.0373 - accuracy: 0.9901 - val_loss: 1.1930 - val_accuracy: 0.2259\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 222ms/step - loss: 0.0219 - accuracy: 0.9949 - val_loss: 0.8595 - val_accuracy: 0.7270\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 215ms/step - loss: 0.0202 - accuracy: 0.9950 - val_loss: 0.5374 - val_accuracy: 0.7288\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 196ms/step - loss: 0.0189 - accuracy: 0.9950 - val_loss: 0.5473 - val_accuracy: 0.7295\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 180ms/step - loss: 0.0183 - accuracy: 0.9950 - val_loss: 0.6839 - val_accuracy: 0.7275\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 203ms/step - loss: 0.0176 - accuracy: 0.9950 - val_loss: 0.5925 - val_accuracy: 0.7295\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.0141 - accuracy: 0.9966 - val_loss: 2.1990 - val_accuracy: 0.4419\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 182ms/step - loss: 0.0127 - accuracy: 0.9969 - val_loss: 2.0793 - val_accuracy: 0.4395\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 194ms/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 2.2486 - val_accuracy: 0.4374\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 191ms/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 1.8448 - val_accuracy: 0.4424\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 7s 274ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 2.2544 - val_accuracy: 0.4369\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 9s 342ms/step - loss: 2.4316 - accuracy: 0.5490 - val_loss: 0.0819 - val_accuracy: 0.9759\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 7s 243ms/step - loss: 0.0109 - accuracy: 0.9996 - val_loss: 0.0136 - val_accuracy: 0.9944\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 8s 290ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.0075 - val_accuracy: 0.9971\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 9s 319ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0042 - val_accuracy: 0.9982\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 8s 294ms/step - loss: 6.8609e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9997\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 21s 299ms/step - loss: 0.5165 - accuracy: 0.8897 - val_loss: 0.3702 - val_accuracy: 0.8274\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 19s 272ms/step - loss: 0.0240 - accuracy: 0.9927 - val_loss: 0.2555 - val_accuracy: 0.8415\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 28s 393ms/step - loss: 0.0215 - accuracy: 0.9934 - val_loss: 0.2378 - val_accuracy: 0.8530\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 26s 378ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 0.2256 - val_accuracy: 0.8613\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 25s 363ms/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 0.2009 - val_accuracy: 0.8773\n",
      "4279/4279 [==============================] - 47s 11ms/step - loss: 0.0751 - accuracy: 0.9873\n",
      "1721/1721 [==============================] - 16s 9ms/step - loss: 0.1553 - accuracy: 0.9606\n",
      "4481/4481 [==============================] - 41s 9ms/step - loss: 0.0832 - accuracy: 0.9828\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 4s 243ms/step - loss: 0.0252 - accuracy: 0.9901 - val_loss: 0.6753 - val_accuracy: 0.6228\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 4s 224ms/step - loss: 0.0228 - accuracy: 0.9918 - val_loss: 0.9855 - val_accuracy: 0.4209\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.0212 - accuracy: 0.9927 - val_loss: 1.1028 - val_accuracy: 0.3801\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 4s 220ms/step - loss: 0.0207 - accuracy: 0.9929 - val_loss: 1.0773 - val_accuracy: 0.4108\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 4s 222ms/step - loss: 0.0200 - accuracy: 0.9932 - val_loss: 0.9331 - val_accuracy: 0.4979\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 4s 270ms/step - loss: 0.0157 - accuracy: 0.9956 - val_loss: 0.7754 - val_accuracy: 0.7308\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 229ms/step - loss: 0.0150 - accuracy: 0.9963 - val_loss: 0.6194 - val_accuracy: 0.7428\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 222ms/step - loss: 0.0141 - accuracy: 0.9963 - val_loss: 0.6066 - val_accuracy: 0.7458\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 209ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.6653 - val_accuracy: 0.7422\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 205ms/step - loss: 0.0133 - accuracy: 0.9964 - val_loss: 0.7882 - val_accuracy: 0.7379\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 6s 230ms/step - loss: 0.0110 - accuracy: 0.9974 - val_loss: 2.2075 - val_accuracy: 0.4664\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 6s 217ms/step - loss: 0.0109 - accuracy: 0.9974 - val_loss: 1.4173 - val_accuracy: 0.5356\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 1.8408 - val_accuracy: 0.5117\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 7s 283ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 1.9368 - val_accuracy: 0.5123\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 9s 328ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 2.3395 - val_accuracy: 0.4935\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 7s 268ms/step - loss: 4.9481 - accuracy: 0.3856 - val_loss: 0.4968 - val_accuracy: 0.8168\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 8s 294ms/step - loss: 0.1607 - accuracy: 0.9423 - val_loss: 0.0366 - val_accuracy: 0.9885\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 9s 345ms/step - loss: 0.0040 - accuracy: 0.9998 - val_loss: 0.0206 - val_accuracy: 0.9919\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 9s 326ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0167 - val_accuracy: 0.9933\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 6s 240ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0139 - val_accuracy: 0.9941\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 24s 349ms/step - loss: 0.5253 - accuracy: 0.8973 - val_loss: 0.2862 - val_accuracy: 0.8607\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 25s 356ms/step - loss: 0.0187 - accuracy: 0.9947 - val_loss: 0.2075 - val_accuracy: 0.8921\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 28s 395ms/step - loss: 0.0176 - accuracy: 0.9949 - val_loss: 0.1835 - val_accuracy: 0.9011\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 30s 423ms/step - loss: 0.0167 - accuracy: 0.9950 - val_loss: 0.1767 - val_accuracy: 0.9007\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 26s 365ms/step - loss: 0.0160 - accuracy: 0.9952 - val_loss: 0.1636 - val_accuracy: 0.9077\n",
      "4279/4279 [==============================] - 53s 12ms/step - loss: 0.0610 - accuracy: 0.9895\n",
      "1721/1721 [==============================] - 17s 10ms/step - loss: 0.1221 - accuracy: 0.9645\n",
      "4481/4481 [==============================] - 39s 9ms/step - loss: 0.0606 - accuracy: 0.9887\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 4s 255ms/step - loss: 0.0229 - accuracy: 0.9925 - val_loss: 0.7187 - val_accuracy: 0.5955\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 4s 221ms/step - loss: 0.0196 - accuracy: 0.9934 - val_loss: 0.8749 - val_accuracy: 0.5343\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 4s 234ms/step - loss: 0.0182 - accuracy: 0.9940 - val_loss: 0.7960 - val_accuracy: 0.6001\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 217ms/step - loss: 0.0181 - accuracy: 0.9943 - val_loss: 0.8954 - val_accuracy: 0.5726\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 217ms/step - loss: 0.0174 - accuracy: 0.9942 - val_loss: 1.0795 - val_accuracy: 0.5170\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 237ms/step - loss: 0.0145 - accuracy: 0.9959 - val_loss: 0.8847 - val_accuracy: 0.7356\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 224ms/step - loss: 0.0133 - accuracy: 0.9968 - val_loss: 0.7081 - val_accuracy: 0.7505\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 195ms/step - loss: 0.0126 - accuracy: 0.9971 - val_loss: 0.7463 - val_accuracy: 0.7508\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 195ms/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.7353 - val_accuracy: 0.7550\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 197ms/step - loss: 0.0121 - accuracy: 0.9971 - val_loss: 0.8264 - val_accuracy: 0.7501\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 6s 215ms/step - loss: 0.0106 - accuracy: 0.9975 - val_loss: 1.5820 - val_accuracy: 0.5352\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.0102 - accuracy: 0.9975 - val_loss: 1.5658 - val_accuracy: 0.5451\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 7s 273ms/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 1.7675 - val_accuracy: 0.5340\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 8s 312ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 1.5425 - val_accuracy: 0.5810\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 8s 312ms/step - loss: 0.0094 - accuracy: 0.9975 - val_loss: 1.5308 - val_accuracy: 0.5825\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 10s 362ms/step - loss: 4.2168 - accuracy: 0.4706 - val_loss: 0.3175 - val_accuracy: 0.9009\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 9s 326ms/step - loss: 0.0827 - accuracy: 0.9713 - val_loss: 0.0190 - val_accuracy: 0.9909\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 9s 319ms/step - loss: 0.0035 - accuracy: 0.9999 - val_loss: 0.0093 - val_accuracy: 0.9959\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 6s 220ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 0.9971\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 9s 317ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9983\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 22s 318ms/step - loss: 0.5941 - accuracy: 0.9024 - val_loss: 0.2428 - val_accuracy: 0.8899\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 20s 290ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 0.1773 - val_accuracy: 0.9152\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 30s 422ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 0.1576 - val_accuracy: 0.9227\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 24s 338ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.1529 - val_accuracy: 0.9233\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 27s 390ms/step - loss: 0.0144 - accuracy: 0.9955 - val_loss: 0.1551 - val_accuracy: 0.9210\n",
      "4279/4279 [==============================] - 45s 11ms/step - loss: 0.0525 - accuracy: 0.9902\n",
      "1721/1721 [==============================] - 14s 8ms/step - loss: 0.0980 - accuracy: 0.9727\n",
      "4481/4481 [==============================] - 39s 9ms/step - loss: 0.0534 - accuracy: 0.9891\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "    loss_complete, accuracy_complete, f1_complete, precision_complete, recall_complete = evaluation(global_model, xcomplete, ycomplete)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus, loss_complete])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus, accuracy_complete])\n",
    "    f1_it.append([f1_basic, f1_plus, f1_complete])\n",
    "    precision_it.append([precision_basic, precision_plus, precision_complete])\n",
    "    recall_it.append([recall_basic, recall_plus, recall_complete])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idKRUM02.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.07510484009981155, 0.15525732934474945, 0.08319155871868134], [0.06100010126829147, 0.12212061882019043, 0.06060165911912918], [0.05247027054429054, 0.09796081483364105, 0.05343760922551155]]\n",
      "Accuracy for iterations:  [[0.9873133897781372, 0.9606190323829651, 0.982785701751709], [0.989467978477478, 0.9645426273345947, 0.9887214303016663], [0.990234911441803, 0.9727166891098022, 0.9891329407691956]]\n",
      "F1 for iterations:  [[0.9873178303106482, 0.9606038442324906, 0.9827856759477432], [0.9894729211773826, 0.9645320799718331, 0.9887208056204078], [0.9902391931011721, 0.9726951004082693, 0.9891323871495287]]\n",
      "Precision for iterations:  [[0.9874161155962561, 0.9606068016196768, 0.9827860172386974], [0.9896665365698087, 0.9645324642787586, 0.9888264897944212], [0.9904064503870083, 0.9727472144071837, 0.9892319900707868]]\n",
      "Recall for iterations:  [[0.9873133892313535, 0.9606190510789798, 0.9827856789124567], [0.9894679949750211, 0.9645426142556128, 0.9887214111837287], [0.9902348885448012, 0.9727167042069317, 0.9891329366878474]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
