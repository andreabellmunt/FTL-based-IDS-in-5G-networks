{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Federated Learning for attack classification: 7 nodes sharing gradients**\n",
    "\n",
    "IDs from this file = **idcat7xy** (x = 0 if experiment with dataset, x = 1 if epochs & iterations, y being integer equal or greater than 0)\n",
    "\n",
    "In this file, experiments with different datasets, and number of epochs & iterations are done. The experiments are divided into sections, based on the elements being changed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static elements for all experiments (execute first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Disable warns\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for test and training datasets (to be able to train and make predictions to evaluate)\n",
    "def preprocessing(data): \n",
    "\n",
    "    # Select the 'proto' and 'state' values that I want\n",
    "    data = data.loc[(data['proto'] == 'tcp') | (data['proto'] =='udp') | (data['proto'] =='icmp') | (data['proto'] =='arp') | (data['proto'] =='ipv6-icmp') | (data['proto'] =='igmp') | (data['proto'] =='rarp'), :]\n",
    "    data = data.loc[(data['state'] == 'RST') | (data['state'] =='REQ') | (data['state'] =='INT') | (data['state'] =='FIN') | (data['state'] =='CON') | (data['state'] =='ECO') | (data['state'] =='ACC') | (data['state'] == 'PAR'), :]\n",
    "\n",
    "    # Creating categories dataframe\n",
    "    data_labels = pd.DataFrame()\n",
    "\n",
    "    # Drop the invalid features and select interested data features\n",
    "    data_features=data[['proto','srcip','sport','dstip','dsport','spkts','dpkts','sbytes','dbytes','state','stime','ltime','dur']]\n",
    "\n",
    "    \"\"\"PREPROCESSING\"\"\"\n",
    "\n",
    "\n",
    "    # Preprocess IP and ports features\n",
    "    # IP Source Address\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "\n",
    "    # IP Destination Address\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "    # Ports\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "\n",
    "    # Convert all ports with 0 decimal, and HEX to DEC\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    # Convert field to int format\n",
    "    data_features['srcip'] = data_features['srcip'].astype(int)\n",
    "    data_features['sport'] = data_features['sport'].astype(int)\n",
    "    data_features['dstip'] = data_features['dstip'].astype(int)\n",
    "    data_features['dsport'] = data_features['dsport'].astype(int)\n",
    "\n",
    "    # Convert some fields to logarithmic\n",
    "    log1p_col = ['dur', 'sbytes', 'dbytes', 'spkts']\n",
    "\n",
    "    for col in log1p_col:\n",
    "        data_features[col] = data_features[col].apply(np.log1p)\n",
    "        \n",
    "    # Transform to One Hot Encoding the Categories - normal, dos, reconnaissance, generic, exploits, worms, fuzzers, analysis, backdoor, shellcode\n",
    "    data_labels.insert(0, 'dos', data['attack_cat'].replace('dos', 1).replace(['reconnaissance', 'generic', 'exploits', 'worms', 'fuzzers', 'analysis', 'backdoor', 'shellcode'], 0))\n",
    "    data_labels.insert(1, 'reconnaissance', data['attack_cat'].replace('reconnaissance', 1).replace([ 'dos', 'generic', 'exploits', 'worms', 'fuzzers', 'analysis', 'backdoor', 'shellcode'], 0))\n",
    "    data_labels.insert(2, 'generic', data['attack_cat'].replace('generic', 1).replace(['dos', 'reconnaissance', 'exploits', 'worms', 'fuzzers', 'analysis', 'backdoor', 'shellcode'], 0))\n",
    "    data_labels.insert(3, 'exploits', data['attack_cat'].replace('exploits', 1).replace([ 'dos', 'reconnaissance', 'generic', 'worms', 'fuzzers', 'analysis', 'backdoor', 'shellcode'], 0))\n",
    "    data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "    # Transform to One hot encoding - FEATURES\n",
    "    data_features=pd.get_dummies(data_features)\n",
    "\n",
    "    # Generate 2 new columns to fit with training\n",
    "    auxCol=data_features['sbytes']\n",
    "    auxCol=0\n",
    "\n",
    "      # As we are using different datasets that might not have all representations, we are going to detect and add the missing columns \n",
    "    # The columns that can have types are: proto and state: need to check if all representations are done \n",
    "    state_cols = [col for col in data_features if col.startswith('state_')]\n",
    "    proto_cols = [col for col in data_features if col.startswith('proto_')]\n",
    "    \n",
    "    # Check if all columns are present\n",
    "    if 'state_PAR' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_PAR', auxCol, True)\n",
    "    if 'state_ACC' not in state_cols: \n",
    "        data_features.insert(data_features.shape[1], 'state_ACC', auxCol, True)\n",
    "    if 'state_ECO' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_ECO', auxCol, True)\n",
    "    if 'state_CON' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_CON', auxCol, True)\n",
    "    if 'state_FIN' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_FIN', auxCol, True)\n",
    "    if 'state_INT' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_INT', auxCol, True)\n",
    "    if 'state_REQ' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_REQ', auxCol, True)\n",
    "    if 'state_RST' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_RST', auxCol, True)\n",
    "    if 'proto_igmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_igmp', auxCol, True)\n",
    "    if 'proto_arp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_arp', auxCol, True)\n",
    "    if 'proto_icmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_icmp', auxCol, True)\n",
    "    if 'proto_udp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_udp', auxCol, True)\n",
    "    if 'proto_tcp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_tcp', auxCol, True)\n",
    "\n",
    "    # Normalize all data features\n",
    "    data_features = StandardScaler().fit_transform(data_features)\n",
    "\n",
    "    #Add dimension to data features\n",
    "    data_features = np.expand_dims(data_features, axis=2)\n",
    "    data_features = np.expand_dims(data_features, axis=3)\n",
    "\n",
    "    x = data_features\n",
    "    y = data_labels.to_numpy()\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building and definition\n",
    "def build_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(Dense(108, input_shape=input_shape, activation='relu'))\n",
    "    model.add(layers.Conv2D(filters=16, kernel_size=(1, 2), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(1, 1), padding='same'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(Dense(108, activation='relu'))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns values of loss, accuracy, f1, precision and recall of model evaluating with test dataset \n",
    "def evaluation(model, x, y): \n",
    "    loss, accuracy = model.evaluate(x, y)\n",
    "    y_pred = model.predict(x)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y = np.argmax(y, axis=1)\n",
    "    report = classification_report(y, y_pred, labels = [i for i in range(4)], target_names=['dos', 'reconnaissance', 'generic', 'exploits'], output_dict=True)\n",
    "    # Obtain f1, precision and recall from the report\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    return loss, accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments with datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cat7A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat7A-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat7A-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat7A-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat7A-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat7A-Part5.csv')\n",
    "training6 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat7A-Part6.csv')\n",
    "training7 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat7A-Part7.csv')\n",
    "test_cat = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Categories.csv')\n",
    "test_cat_eq = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Categories_Eq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_nodes = 7\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idCAT700.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=1024)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    avg_grad = np.mean(grad_list, axis=0)\n",
    "    return avg_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)\n",
    "x6, y6 = preprocessing(training6)\n",
    "x7, y7 = preprocessing(training7)\n",
    "xc, yc = preprocessing(test_cat)\n",
    "xce, yce = preprocessing(test_cat_eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "22/22 [==============================] - 2s 80ms/step - loss: 0.5719 - accuracy: 0.9876 - val_loss: 1.4407 - val_accuracy: 0.1422\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 2s 71ms/step - loss: 0.1428 - accuracy: 0.9998 - val_loss: 1.4700 - val_accuracy: 0.1492\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 1s 66ms/step - loss: 0.0423 - accuracy: 0.9999 - val_loss: 1.5074 - val_accuracy: 0.1474\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 2s 71ms/step - loss: 0.0179 - accuracy: 0.9999 - val_loss: 1.5494 - val_accuracy: 0.1431\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 0.0095 - accuracy: 0.9999 - val_loss: 1.6003 - val_accuracy: 0.1415\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 3s 141ms/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 1.7346 - val_accuracy: 0.1411\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 1s 62ms/step - loss: 8.4549e-04 - accuracy: 1.0000 - val_loss: 1.8487 - val_accuracy: 0.1411\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 1s 57ms/step - loss: 3.7956e-04 - accuracy: 1.0000 - val_loss: 1.9707 - val_accuracy: 0.1411\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 1s 53ms/step - loss: 2.5264e-04 - accuracy: 1.0000 - val_loss: 2.1120 - val_accuracy: 0.1411\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 1.8067e-04 - accuracy: 1.0000 - val_loss: 2.2798 - val_accuracy: 0.1411\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 2s 112ms/step - loss: 3.9236e-05 - accuracy: 1.0000 - val_loss: 2.7963 - val_accuracy: 0.1411\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 2s 77ms/step - loss: 6.3397e-06 - accuracy: 1.0000 - val_loss: 3.2675 - val_accuracy: 0.1411\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 2s 103ms/step - loss: 3.0440e-06 - accuracy: 1.0000 - val_loss: 3.7024 - val_accuracy: 0.1411\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 2s 104ms/step - loss: 2.0228e-06 - accuracy: 1.0000 - val_loss: 4.1549 - val_accuracy: 0.1411\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 1.4988e-06 - accuracy: 1.0000 - val_loss: 4.6464 - val_accuracy: 0.1411\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 3s 146ms/step - loss: 1.0281e-06 - accuracy: 1.0000 - val_loss: 5.3869 - val_accuracy: 0.1413\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 5.2821e-07 - accuracy: 1.0000 - val_loss: 6.2251 - val_accuracy: 0.1413\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 2.9600e-07 - accuracy: 1.0000 - val_loss: 7.0427 - val_accuracy: 0.1413\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 1.7931e-07 - accuracy: 1.0000 - val_loss: 7.8398 - val_accuracy: 0.1413\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 1.3323e-07 - accuracy: 1.0000 - val_loss: 8.6382 - val_accuracy: 0.1411\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 2s 105ms/step - loss: 1.5770e-07 - accuracy: 1.0000 - val_loss: 9.3090 - val_accuracy: 0.1411\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 9.8542e-08 - accuracy: 1.0000 - val_loss: 10.0844 - val_accuracy: 0.1411\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 2s 76ms/step - loss: 7.5733e-08 - accuracy: 1.0000 - val_loss: 10.8507 - val_accuracy: 0.1411\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 1s 64ms/step - loss: 5.7239e-08 - accuracy: 1.0000 - val_loss: 11.5782 - val_accuracy: 0.1411\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 3.9734e-08 - accuracy: 1.0000 - val_loss: 12.2683 - val_accuracy: 0.1411\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 201ms/step - loss: 2.4259e-08 - accuracy: 1.0000 - val_loss: 12.9863 - val_accuracy: 0.1411\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 2.6056e-08 - accuracy: 1.0000 - val_loss: 13.5711 - val_accuracy: 0.1411\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 2.2947e-08 - accuracy: 1.0000 - val_loss: 14.1076 - val_accuracy: 0.1411\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 1.6426e-08 - accuracy: 1.0000 - val_loss: 14.5961 - val_accuracy: 0.1411\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 2s 113ms/step - loss: 1.4634e-08 - accuracy: 1.0000 - val_loss: 15.0300 - val_accuracy: 0.1411\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 171ms/step - loss: 1.9535e-08 - accuracy: 1.0000 - val_loss: 15.4376 - val_accuracy: 0.1411\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 1.6593e-08 - accuracy: 1.0000 - val_loss: 15.7538 - val_accuracy: 0.1411\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 2s 101ms/step - loss: 1.2011e-08 - accuracy: 1.0000 - val_loss: 16.0521 - val_accuracy: 0.1411\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 2s 78ms/step - loss: 1.1811e-08 - accuracy: 1.0000 - val_loss: 16.3036 - val_accuracy: 0.1411\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 2s 70ms/step - loss: 1.1314e-08 - accuracy: 1.0000 - val_loss: 16.5147 - val_accuracy: 0.1411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017/2017 [==============================] - 14s 7ms/step - loss: 2.6318 - accuracy: 0.8320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 4ms/step - loss: 9.4989 - accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 1.8660e-08 - accuracy: 1.0000 - val_loss: 16.1593 - val_accuracy: 0.1413\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 2.0242e-08 - accuracy: 1.0000 - val_loss: 16.3733 - val_accuracy: 0.1413\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 1.1730e-08 - accuracy: 1.0000 - val_loss: 16.5511 - val_accuracy: 0.1411\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 1.4488e-08 - accuracy: 1.0000 - val_loss: 16.7302 - val_accuracy: 0.1411\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 1.2658e-08 - accuracy: 1.0000 - val_loss: 16.8974 - val_accuracy: 0.1411\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 5s 213ms/step - loss: 3.9835e-07 - accuracy: 1.0000 - val_loss: 16.9612 - val_accuracy: 0.1411\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 3s 118ms/step - loss: 1.7753e-07 - accuracy: 1.0000 - val_loss: 17.1003 - val_accuracy: 0.1411\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 1.5495e-07 - accuracy: 1.0000 - val_loss: 17.1187 - val_accuracy: 0.1411\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 3s 117ms/step - loss: 1.1319e-07 - accuracy: 1.0000 - val_loss: 17.0803 - val_accuracy: 0.1411\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 3s 128ms/step - loss: 1.2553e-07 - accuracy: 1.0000 - val_loss: 17.3419 - val_accuracy: 0.1411\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 1.1174e-09 - accuracy: 1.0000 - val_loss: 17.3776 - val_accuracy: 0.1411\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 1s 51ms/step - loss: 9.5544e-10 - accuracy: 1.0000 - val_loss: 17.4597 - val_accuracy: 0.1411\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 1s 58ms/step - loss: 1.0580e-09 - accuracy: 1.0000 - val_loss: 17.5315 - val_accuracy: 0.1411\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 5.9918e-10 - accuracy: 1.0000 - val_loss: 17.5885 - val_accuracy: 0.1411\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 2s 73ms/step - loss: 8.9067e-10 - accuracy: 1.0000 - val_loss: 17.6302 - val_accuracy: 0.1411\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 3s 134ms/step - loss: 1.4952e-09 - accuracy: 1.0000 - val_loss: 17.7171 - val_accuracy: 0.1411\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 1.0850e-09 - accuracy: 1.0000 - val_loss: 17.7417 - val_accuracy: 0.1411\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 1.1876e-09 - accuracy: 1.0000 - val_loss: 17.7683 - val_accuracy: 0.1411\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 1.7975e-09 - accuracy: 1.0000 - val_loss: 17.8089 - val_accuracy: 0.1411\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 2s 74ms/step - loss: 1.0472e-09 - accuracy: 1.0000 - val_loss: 17.8337 - val_accuracy: 0.1411\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 3s 152ms/step - loss: 1.0256e-09 - accuracy: 1.0000 - val_loss: 17.6933 - val_accuracy: 0.1411\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 3s 141ms/step - loss: 1.9811e-09 - accuracy: 1.0000 - val_loss: 17.6992 - val_accuracy: 0.1411\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 8.6368e-10 - accuracy: 1.0000 - val_loss: 17.6987 - val_accuracy: 0.1411\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 1.0850e-09 - accuracy: 1.0000 - val_loss: 17.6956 - val_accuracy: 0.1411\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 1.0958e-09 - accuracy: 1.0000 - val_loss: 17.7121 - val_accuracy: 0.1411\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 3.8326e-10 - accuracy: 1.0000 - val_loss: 17.8941 - val_accuracy: 0.1411\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 3s 117ms/step - loss: 3.2388e-10 - accuracy: 1.0000 - val_loss: 17.9180 - val_accuracy: 0.1411\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 3.2388e-10 - accuracy: 1.0000 - val_loss: 17.9446 - val_accuracy: 0.1411\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 3.0769e-10 - accuracy: 1.0000 - val_loss: 17.9632 - val_accuracy: 0.1411\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 3.3468e-10 - accuracy: 1.0000 - val_loss: 17.9806 - val_accuracy: 0.1411\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 162ms/step - loss: 1.4952e-09 - accuracy: 1.0000 - val_loss: 18.0705 - val_accuracy: 0.1411\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 2s 103ms/step - loss: 7.0714e-10 - accuracy: 1.0000 - val_loss: 18.0972 - val_accuracy: 0.1411\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 2s 106ms/step - loss: 5.2360e-10 - accuracy: 1.0000 - val_loss: 18.1183 - val_accuracy: 0.1411\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 5.3440e-10 - accuracy: 1.0000 - val_loss: 18.1367 - val_accuracy: 0.1411\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 2s 78ms/step - loss: 6.2077e-10 - accuracy: 1.0000 - val_loss: 18.1600 - val_accuracy: 0.1411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017/2017 [==============================] - 11s 6ms/step - loss: 2.9080 - accuracy: 0.8320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 1s 8ms/step - loss: 10.4678 - accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "22/22 [==============================] - 3s 139ms/step - loss: 2.3697e-09 - accuracy: 1.0000 - val_loss: 17.6883 - val_accuracy: 0.1411\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 2s 75ms/step - loss: 1.8785e-09 - accuracy: 1.0000 - val_loss: 17.7279 - val_accuracy: 0.1411\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 2s 78ms/step - loss: 2.4615e-09 - accuracy: 1.0000 - val_loss: 17.7608 - val_accuracy: 0.1411\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 2s 78ms/step - loss: 3.1362e-09 - accuracy: 1.0000 - val_loss: 17.8111 - val_accuracy: 0.1411\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 2s 81ms/step - loss: 1.9595e-09 - accuracy: 1.0000 - val_loss: 17.8503 - val_accuracy: 0.1411\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 6.5969e-08 - accuracy: 1.0000 - val_loss: 17.6906 - val_accuracy: 0.1411\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 2s 69ms/step - loss: 4.6903e-08 - accuracy: 1.0000 - val_loss: 17.5801 - val_accuracy: 0.1411\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 2s 70ms/step - loss: 7.5296e-08 - accuracy: 1.0000 - val_loss: 17.4958 - val_accuracy: 0.1411\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 2s 70ms/step - loss: 5.2560e-08 - accuracy: 1.0000 - val_loss: 17.4298 - val_accuracy: 0.1411\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 1s 63ms/step - loss: 4.6946e-08 - accuracy: 1.0000 - val_loss: 17.4235 - val_accuracy: 0.1411\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 3.4007e-10 - accuracy: 1.0000 - val_loss: 17.4590 - val_accuracy: 0.1411\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 1s 66ms/step - loss: 4.6963e-10 - accuracy: 1.0000 - val_loss: 17.5433 - val_accuracy: 0.1411\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 4.2104e-10 - accuracy: 1.0000 - val_loss: 17.6159 - val_accuracy: 0.1411\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 1s 66ms/step - loss: 3.6706e-10 - accuracy: 1.0000 - val_loss: 17.6710 - val_accuracy: 0.1411\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 1s 56ms/step - loss: 3.5627e-10 - accuracy: 1.0000 - val_loss: 17.7192 - val_accuracy: 0.1411\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 2s 75ms/step - loss: 5.9378e-10 - accuracy: 1.0000 - val_loss: 17.7966 - val_accuracy: 0.1411\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 1s 56ms/step - loss: 5.1281e-10 - accuracy: 1.0000 - val_loss: 17.8257 - val_accuracy: 0.1411\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 1s 59ms/step - loss: 6.1537e-10 - accuracy: 1.0000 - val_loss: 17.8465 - val_accuracy: 0.1411\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 2s 71ms/step - loss: 5.1821e-10 - accuracy: 1.0000 - val_loss: 17.8724 - val_accuracy: 0.1411\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 4.6423e-10 - accuracy: 1.0000 - val_loss: 17.8950 - val_accuracy: 0.1411\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 2s 79ms/step - loss: 6.7475e-10 - accuracy: 1.0000 - val_loss: 17.7480 - val_accuracy: 0.1411\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 2s 71ms/step - loss: 7.2873e-10 - accuracy: 1.0000 - val_loss: 17.7536 - val_accuracy: 0.1411\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 1s 57ms/step - loss: 6.3696e-10 - accuracy: 1.0000 - val_loss: 17.7530 - val_accuracy: 0.1411\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 1s 65ms/step - loss: 7.0714e-10 - accuracy: 1.0000 - val_loss: 17.7581 - val_accuracy: 0.1411\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 1s 58ms/step - loss: 5.9918e-10 - accuracy: 1.0000 - val_loss: 17.7653 - val_accuracy: 0.1411\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 2.5371e-10 - accuracy: 1.0000 - val_loss: 17.9359 - val_accuracy: 0.1411\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 1s 62ms/step - loss: 2.5910e-10 - accuracy: 1.0000 - val_loss: 17.9599 - val_accuracy: 0.1411\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 1s 59ms/step - loss: 2.3211e-10 - accuracy: 1.0000 - val_loss: 17.9764 - val_accuracy: 0.1411\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 1s 66ms/step - loss: 2.5371e-10 - accuracy: 1.0000 - val_loss: 17.9925 - val_accuracy: 0.1411\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 1s 64ms/step - loss: 1.7274e-10 - accuracy: 1.0000 - val_loss: 18.0145 - val_accuracy: 0.1411\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 2s 72ms/step - loss: 3.2928e-10 - accuracy: 1.0000 - val_loss: 18.0924 - val_accuracy: 0.1411\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 1s 55ms/step - loss: 4.6963e-10 - accuracy: 1.0000 - val_loss: 18.1152 - val_accuracy: 0.1411\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 1s 58ms/step - loss: 8.3669e-10 - accuracy: 1.0000 - val_loss: 18.1461 - val_accuracy: 0.1411\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 1s 50ms/step - loss: 4.4264e-10 - accuracy: 1.0000 - val_loss: 18.1733 - val_accuracy: 0.1411\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 1s 55ms/step - loss: 3.7246e-10 - accuracy: 1.0000 - val_loss: 18.2013 - val_accuracy: 0.1411\n",
      "   1/2017 [..............................] - ETA: 0s - loss: 2.8630 - accuracy: 0.8438"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017/2017 [==============================] - 4s 2ms/step - loss: 2.9082 - accuracy: 0.8320\n",
      "  1/119 [..............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 1s 6ms/step - loss: 10.6234 - accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3:\n",
    "            x, y = x4, y4\n",
    "        elif node == 4:\n",
    "            x, y = x5, y5\n",
    "        elif node == 5:\n",
    "            x, y = x6, y6\n",
    "        elif node == 6:\n",
    "            x, y = x7, y7\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(y, predictions)\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xc, yc) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xce, yce)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idCAT700.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[2.6318321228027344, 9.498917579650879], [2.908022403717041, 10.467752456665039], [2.9081966876983643, 10.623394012451172]]\n",
      "Accuracy for iterations:  [[0.8320106863975525, 0.25], [0.8319796919822693, 0.25], [0.8319796919822693, 0.25]]\n",
      "F1 for iterations:  [[0.7557758326595134, 0.1], [0.7557013693602648, 0.1], [0.7557013693602648, 0.1]]\n",
      "Precision for iterations:  [[0.6981405187221714, 0.0625], [0.6922352459557739, 0.0625], [0.6922352459557739, 0.0625]]\n",
      "Recall for iterations:  [[0.8320106640213281, 0.25], [0.8319796639593279, 0.25], [0.8319796639593279, 0.25]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cat7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat7B-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat7B-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat7B-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat7B-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat7B-Part5.csv')\n",
    "training6 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat7B-Part6.csv')\n",
    "training7 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat7B-Part7.csv')\n",
    "test_cat = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Categories.csv')\n",
    "test_cat_eq = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Categories_Eq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_nodes = 7\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idCAT701.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=1024)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    avg_grad = np.mean(grad_list, axis=0)\n",
    "    return avg_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)\n",
    "x6, y6 = preprocessing(training6)\n",
    "x7, y7 = preprocessing(training7)\n",
    "xc, yc = preprocessing(test_cat)\n",
    "xce, yce = preprocessing(test_cat_eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 572ms/step - loss: 1.2653 - accuracy: 0.2374 - val_loss: 1.4474 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 1.2019 - accuracy: 0.3028 - val_loss: 1.4501 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.1457 - accuracy: 0.4944 - val_loss: 1.4531 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 1.0957 - accuracy: 0.5635 - val_loss: 1.4563 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0531 - accuracy: 0.5725 - val_loss: 1.4594 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 1.0220 - accuracy: 0.5718 - val_loss: 1.4631 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.9857 - accuracy: 0.5890 - val_loss: 1.4662 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.9561 - accuracy: 0.6078 - val_loss: 1.4692 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.9297 - accuracy: 0.6071 - val_loss: 1.4722 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.9078 - accuracy: 0.6123 - val_loss: 1.4752 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 386ms/step - loss: 0.9093 - accuracy: 0.6048 - val_loss: 1.4698 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.8908 - accuracy: 0.6116 - val_loss: 1.4717 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.8748 - accuracy: 0.6191 - val_loss: 1.4731 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.8610 - accuracy: 0.6176 - val_loss: 1.4742 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.8493 - accuracy: 0.6183 - val_loss: 1.4747 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 564ms/step - loss: 0.8420 - accuracy: 0.6116 - val_loss: 1.4819 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.8286 - accuracy: 0.6221 - val_loss: 1.4822 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.8173 - accuracy: 0.6311 - val_loss: 1.4823 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.8088 - accuracy: 0.6386 - val_loss: 1.4821 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.8018 - accuracy: 0.6506 - val_loss: 1.4818 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 526ms/step - loss: 0.8190 - accuracy: 0.6183 - val_loss: 1.4744 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.8076 - accuracy: 0.6289 - val_loss: 1.4725 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.7982 - accuracy: 0.6356 - val_loss: 1.4704 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.7909 - accuracy: 0.6409 - val_loss: 1.4684 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.7841 - accuracy: 0.6424 - val_loss: 1.4666 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 455ms/step - loss: 0.7892 - accuracy: 0.6386 - val_loss: 1.4678 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.7822 - accuracy: 0.6514 - val_loss: 1.4681 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.7758 - accuracy: 0.6521 - val_loss: 1.4679 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.7710 - accuracy: 0.6582 - val_loss: 1.4671 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.7656 - accuracy: 0.6551 - val_loss: 1.4656 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 439ms/step - loss: 0.7727 - accuracy: 0.6379 - val_loss: 1.4650 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7661 - accuracy: 0.6454 - val_loss: 1.4609 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.7618 - accuracy: 0.6454 - val_loss: 1.4577 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.7580 - accuracy: 0.6461 - val_loss: 1.4554 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.7543 - accuracy: 0.6499 - val_loss: 1.4545 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017/2017 [==============================] - 8s 4ms/step - loss: 1.3481 - accuracy: 0.5344\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 1.3169 - accuracy: 0.4958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 633ms/step - loss: 0.7574 - accuracy: 0.6544 - val_loss: 1.4539 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7508 - accuracy: 0.6574 - val_loss: 1.4556 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.7485 - accuracy: 0.6589 - val_loss: 1.4576 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.7445 - accuracy: 0.6619 - val_loss: 1.4580 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7412 - accuracy: 0.6672 - val_loss: 1.4572 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 563ms/step - loss: 0.7298 - accuracy: 0.6657 - val_loss: 1.4529 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.7257 - accuracy: 0.6642 - val_loss: 1.4520 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.7226 - accuracy: 0.6642 - val_loss: 1.4524 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7196 - accuracy: 0.6687 - val_loss: 1.4529 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.7176 - accuracy: 0.6642 - val_loss: 1.4514 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 576ms/step - loss: 0.7453 - accuracy: 0.6424 - val_loss: 1.4444 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.7391 - accuracy: 0.6469 - val_loss: 1.4414 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.7353 - accuracy: 0.6536 - val_loss: 1.4399 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.7320 - accuracy: 0.6582 - val_loss: 1.4400 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.7287 - accuracy: 0.6544 - val_loss: 1.4415 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 310ms/step - loss: 0.7383 - accuracy: 0.6469 - val_loss: 1.4515 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7302 - accuracy: 0.6491 - val_loss: 1.4549 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.7243 - accuracy: 0.6559 - val_loss: 1.4564 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.7201 - accuracy: 0.6679 - val_loss: 1.4566 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.7167 - accuracy: 0.6649 - val_loss: 1.4562 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 703ms/step - loss: 0.7345 - accuracy: 0.6551 - val_loss: 1.4465 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.7278 - accuracy: 0.6664 - val_loss: 1.4454 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.7235 - accuracy: 0.6649 - val_loss: 1.4434 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.7196 - accuracy: 0.6657 - val_loss: 1.4425 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.7177 - accuracy: 0.6694 - val_loss: 1.4428 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 579ms/step - loss: 0.7194 - accuracy: 0.6634 - val_loss: 1.4478 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.7130 - accuracy: 0.6687 - val_loss: 1.4486 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7081 - accuracy: 0.6679 - val_loss: 1.4487 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.7056 - accuracy: 0.6709 - val_loss: 1.4488 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.7027 - accuracy: 0.6717 - val_loss: 1.4483 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 443ms/step - loss: 0.7115 - accuracy: 0.6574 - val_loss: 1.4480 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7084 - accuracy: 0.6544 - val_loss: 1.4448 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.7057 - accuracy: 0.6597 - val_loss: 1.4454 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.7040 - accuracy: 0.6589 - val_loss: 1.4472 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7017 - accuracy: 0.6582 - val_loss: 1.4491 - val_accuracy: 0.0000e+00\n",
      "  44/2017 [..............................] - ETA: 4s - loss: 1.3703 - accuracy: 0.2784"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017/2017 [==============================] - 11s 5ms/step - loss: 1.3654 - accuracy: 0.2979 0s - loss: 1.3652 - accu\n",
      "119/119 [==============================] - 1s 9ms/step - loss: 1.2599 - accuracy: 0.5187\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 741ms/step - loss: 0.7138 - accuracy: 0.6747 - val_loss: 1.4519 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.7085 - accuracy: 0.6732 - val_loss: 1.4536 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.7054 - accuracy: 0.6672 - val_loss: 1.4539 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.7031 - accuracy: 0.6762 - val_loss: 1.4542 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.7002 - accuracy: 0.6777 - val_loss: 1.4540 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 2s 792ms/step - loss: 0.6907 - accuracy: 0.6702 - val_loss: 1.4494 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 0.6861 - accuracy: 0.6687 - val_loss: 1.4459 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.6835 - accuracy: 0.6702 - val_loss: 1.4422 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.6812 - accuracy: 0.6747 - val_loss: 1.4412 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.6796 - accuracy: 0.6777 - val_loss: 1.4411 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 2s 919ms/step - loss: 0.7106 - accuracy: 0.6529 - val_loss: 1.4313 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7024 - accuracy: 0.6529 - val_loss: 1.4292 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7012 - accuracy: 0.64 - 0s 47ms/step - loss: 0.6977 - accuracy: 0.6499 - val_loss: 1.4302 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.6946 - accuracy: 0.6476 - val_loss: 1.4314 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6905 - accuracy: 0.6491 - val_loss: 1.4323 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 426ms/step - loss: 0.6965 - accuracy: 0.6469 - val_loss: 1.4495 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6894 - accuracy: 0.6604 - val_loss: 1.4574 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6838 - accuracy: 0.6687 - val_loss: 1.4600 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.6815 - accuracy: 0.6769 - val_loss: 1.4584 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6775 - accuracy: 0.6829 - val_loss: 1.4552 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 268ms/step - loss: 0.7013 - accuracy: 0.6732 - val_loss: 1.4378 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6951 - accuracy: 0.6732 - val_loss: 1.4391 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6912 - accuracy: 0.6844 - val_loss: 1.4421 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6883 - accuracy: 0.6799 - val_loss: 1.4450 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6862 - accuracy: 0.6860 - val_loss: 1.4463 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.6819 - accuracy: 0.6807 - val_loss: 1.4559 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6757 - accuracy: 0.6829 - val_loss: 1.4519 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6715 - accuracy: 0.6769 - val_loss: 1.4467 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6695 - accuracy: 0.6807 - val_loss: 1.4412 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6662 - accuracy: 0.6792 - val_loss: 1.4383 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 441ms/step - loss: 0.6762 - accuracy: 0.6649 - val_loss: 1.4448 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6719 - accuracy: 0.6687 - val_loss: 1.4519 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6700 - accuracy: 0.6679 - val_loss: 1.4562 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6679 - accuracy: 0.6702 - val_loss: 1.4570 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6657 - accuracy: 0.6717 - val_loss: 1.4548 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017/2017 [==============================] - 12s 6ms/step - loss: 1.3681 - accuracy: 0.3018\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 1.1857 - accuracy: 0.5751\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3:\n",
    "            x, y = x4, y4\n",
    "        elif node == 4:\n",
    "            x, y = x5, y5\n",
    "        elif node == 5:\n",
    "            x, y = x6, y6\n",
    "        elif node == 6:\n",
    "            x, y = x7, y7\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(y, predictions)\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xc, yc) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xce, yce)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idCAT701.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[1.3481199741363525, 1.3168654441833496], [1.3654203414916992, 1.2598567008972168], [1.36812162399292, 1.1857095956802368]]\n",
      "Accuracy for iterations:  [[0.5344410538673401, 0.49578502774238586], [0.2978641092777252, 0.5187038779258728], [0.3018166124820709, 0.5750790238380432]]\n",
      "F1 for iterations:  [[0.644208241759206, 0.40919421074317874], [0.3872641646744735, 0.44868519200137996], [0.3877987778265896, 0.5446580550194253]]\n",
      "Precision for iterations:  [[0.8820651862225276, 0.362551262101792], [0.8909300855665555, 0.6353503975044406], [0.892385208165991, 0.6465010605536355]]\n",
      "Recall for iterations:  [[0.5344410688821377, 0.4957850368809273], [0.29786409572819145, 0.5187038988408852], [0.3018166036332073, 0.5750790305584826]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cat7C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat7C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat7C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat7C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat7C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat7C-Part5.csv')\n",
    "training6 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat7C-Part6.csv')\n",
    "training7 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat7C-Part7.csv')\n",
    "test_cat = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Categories.csv')\n",
    "test_cat_eq = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Categories_Eq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_nodes = 7\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idCAT702.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=1024)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    avg_grad = np.mean(grad_list, axis=0)\n",
    "    return avg_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)\n",
    "x6, y6 = preprocessing(training6)\n",
    "x7, y7 = preprocessing(training7)\n",
    "xc, yc = preprocessing(test_cat)\n",
    "xce, yce = preprocessing(test_cat_eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 2.0168 - accuracy: 0.0146 - val_loss: 1.4286 - val_accuracy: 0.0034\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1.9238 - accuracy: 0.0232 - val_loss: 1.4226 - val_accuracy: 0.0103\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 1.8365 - accuracy: 0.0378 - val_loss: 1.4168 - val_accuracy: 0.0137\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 1.7538 - accuracy: 0.0696 - val_loss: 1.4112 - val_accuracy: 0.0137\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 1.6764 - accuracy: 0.0988 - val_loss: 1.4059 - val_accuracy: 0.0205\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 741ms/step - loss: 1.6189 - accuracy: 0.1391 - val_loss: 1.3701 - val_accuracy: 0.5332\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 1.5554 - accuracy: 0.1568 - val_loss: 1.3687 - val_accuracy: 0.6545\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 1.4971 - accuracy: 0.1843 - val_loss: 1.3672 - val_accuracy: 0.7368\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 1.4425 - accuracy: 0.2267 - val_loss: 1.3659 - val_accuracy: 0.7368\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.3930 - accuracy: 0.2559 - val_loss: 1.3646 - val_accuracy: 0.7071\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 1.5503 - accuracy: 0.1229 - val_loss: 1.3956 - val_accuracy: 0.0685\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 1.4473 - accuracy: 0.2030 - val_loss: 1.3942 - val_accuracy: 0.0776\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 1.3535 - accuracy: 0.3991 - val_loss: 1.3931 - val_accuracy: 0.0662\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 1.2645 - accuracy: 0.4980 - val_loss: 1.3921 - val_accuracy: 0.0502\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.1839 - accuracy: 0.5941 - val_loss: 1.3911 - val_accuracy: 0.0479\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 0s 230ms/step - loss: 1.3932 - accuracy: 0.3156 - val_loss: 1.3995 - val_accuracy: 0.0479\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 1.3152 - accuracy: 0.3854 - val_loss: 1.3992 - val_accuracy: 0.0776\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 1.2423 - accuracy: 0.5037 - val_loss: 1.3989 - val_accuracy: 0.1164\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 1.1777 - accuracy: 0.5575 - val_loss: 1.3988 - val_accuracy: 0.1233\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.1172 - accuracy: 0.6078 - val_loss: 1.3987 - val_accuracy: 0.1301\n",
      "Epoch 1/5\n",
      "9/9 [==============================] - 1s 118ms/step - loss: 0.9968 - accuracy: 0.6344 - val_loss: 1.4083 - val_accuracy: 0.0264\n",
      "Epoch 2/5\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.7835 - accuracy: 0.7983 - val_loss: 1.4082 - val_accuracy: 0.0505\n",
      "Epoch 3/5\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.6522 - accuracy: 0.8070 - val_loss: 1.3994 - val_accuracy: 0.0599\n",
      "Epoch 4/5\n",
      "9/9 [==============================] - 1s 83ms/step - loss: 0.5753 - accuracy: 0.8098 - val_loss: 1.3822 - val_accuracy: 0.0621\n",
      "Epoch 5/5\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.5274 - accuracy: 0.8112 - val_loss: 1.3618 - val_accuracy: 0.0626\n",
      "Epoch 1/5\n",
      "6/6 [==============================] - 1s 128ms/step - loss: 0.9893 - accuracy: 0.6133 - val_loss: 1.3333 - val_accuracy: 0.0710\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 0s 75ms/step - loss: 0.7636 - accuracy: 0.6152 - val_loss: 1.2942 - val_accuracy: 0.3371\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 0s 69ms/step - loss: 0.5996 - accuracy: 0.7349 - val_loss: 1.2562 - val_accuracy: 0.6582\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 1s 99ms/step - loss: 0.4985 - accuracy: 0.8350 - val_loss: 1.2206 - val_accuracy: 0.6595\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 1s 107ms/step - loss: 0.4432 - accuracy: 0.8355 - val_loss: 1.1897 - val_accuracy: 0.6622\n",
      "Epoch 1/5\n",
      "25/25 [==============================] - 3s 125ms/step - loss: 0.4010 - accuracy: 0.8238 - val_loss: 1.1482 - val_accuracy: 0.9787\n",
      "Epoch 2/5\n",
      "25/25 [==============================] - 2s 99ms/step - loss: 0.1198 - accuracy: 0.9832 - val_loss: 0.9957 - val_accuracy: 0.9816\n",
      "Epoch 3/5\n",
      "25/25 [==============================] - 2s 92ms/step - loss: 0.0938 - accuracy: 0.9835 - val_loss: 0.9049 - val_accuracy: 0.9816\n",
      "Epoch 4/5\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 0.0860 - accuracy: 0.9835 - val_loss: 0.8299 - val_accuracy: 0.9824\n",
      "Epoch 5/5\n",
      "25/25 [==============================] - 2s 70ms/step - loss: 0.0815 - accuracy: 0.9837 - val_loss: 0.7548 - val_accuracy: 0.9825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017/2017 [==============================] - 6s 3ms/step - loss: 1.0601 - accuracy: 0.8978\n",
      "  1/119 [..............................] - ETA: 0s - loss: 0.8723 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0104s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 3ms/step - loss: 1.3039 - accuracy: 0.4926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2/2 [==============================] - 0s 200ms/step - loss: 2.3361 - accuracy: 0.5309 - val_loss: 1.8934 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 2.2309 - accuracy: 0.5464 - val_loss: 1.8644 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 2.1384 - accuracy: 0.5601 - val_loss: 1.8342 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 2.0510 - accuracy: 0.5765 - val_loss: 1.8036 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.9754 - accuracy: 0.5859 - val_loss: 1.7730 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 2.5269 - accuracy: 0.4024 - val_loss: 1.7280 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 2.4138 - accuracy: 0.4024 - val_loss: 1.6966 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 2.3002 - accuracy: 0.4030 - val_loss: 1.6656 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 2.1824 - accuracy: 0.4058 - val_loss: 1.6359 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 2.0766 - accuracy: 0.4070 - val_loss: 1.6068 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 434ms/step - loss: 0.7046 - accuracy: 0.8165 - val_loss: 1.5999 - val_accuracy: 0.0068\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.6731 - accuracy: 0.8176 - val_loss: 1.5662 - val_accuracy: 0.0114\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.6444 - accuracy: 0.8188 - val_loss: 1.5330 - val_accuracy: 0.0114\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.6211 - accuracy: 0.8199 - val_loss: 1.5009 - val_accuracy: 0.0228\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.5986 - accuracy: 0.8188 - val_loss: 1.4697 - val_accuracy: 0.0297\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 750ms/step - loss: 1.6801 - accuracy: 0.4191 - val_loss: 1.6040 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 1.5590 - accuracy: 0.4208 - val_loss: 1.5838 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.4439 - accuracy: 0.4265 - val_loss: 1.5642 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 1.3426 - accuracy: 0.4305 - val_loss: 1.5445 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 1.2470 - accuracy: 0.4351 - val_loss: 1.5254 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/5\n",
      "9/9 [==============================] - 2s 174ms/step - loss: 0.5992 - accuracy: 0.8143 - val_loss: 1.4357 - val_accuracy: 0.0156\n",
      "Epoch 2/5\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.5026 - accuracy: 0.8211 - val_loss: 1.3317 - val_accuracy: 0.0411\n",
      "Epoch 3/5\n",
      "9/9 [==============================] - 1s 132ms/step - loss: 0.4536 - accuracy: 0.8231 - val_loss: 1.2459 - val_accuracy: 0.0595\n",
      "Epoch 4/5\n",
      "9/9 [==============================] - 1s 113ms/step - loss: 0.4253 - accuracy: 0.8239 - val_loss: 1.2008 - val_accuracy: 0.0653\n",
      "Epoch 5/5\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.4044 - accuracy: 0.8245 - val_loss: 1.1691 - val_accuracy: 0.0671\n",
      "Epoch 1/5\n",
      "6/6 [==============================] - 1s 223ms/step - loss: 1.0353 - accuracy: 0.6439 - val_loss: 1.2043 - val_accuracy: 0.1682\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 1s 128ms/step - loss: 0.7262 - accuracy: 0.6439 - val_loss: 1.0390 - val_accuracy: 0.2989\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 1s 115ms/step - loss: 0.5091 - accuracy: 0.7741 - val_loss: 0.9044 - val_accuracy: 0.7453\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 1s 124ms/step - loss: 0.3979 - accuracy: 0.8660 - val_loss: 0.8077 - val_accuracy: 0.7406\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 1s 116ms/step - loss: 0.3505 - accuracy: 0.8702 - val_loss: 0.7420 - val_accuracy: 0.7426\n",
      "Epoch 1/5\n",
      "25/25 [==============================] - 4s 154ms/step - loss: 0.4774 - accuracy: 0.7967 - val_loss: 0.6779 - val_accuracy: 0.9820\n",
      "Epoch 2/5\n",
      "25/25 [==============================] - 2s 94ms/step - loss: 0.1140 - accuracy: 0.9836 - val_loss: 0.4254 - val_accuracy: 0.9825\n",
      "Epoch 3/5\n",
      "25/25 [==============================] - 2s 98ms/step - loss: 0.0894 - accuracy: 0.9837 - val_loss: 0.3429 - val_accuracy: 0.9825\n",
      "Epoch 4/5\n",
      "25/25 [==============================] - 2s 95ms/step - loss: 0.0815 - accuracy: 0.9837 - val_loss: 0.2847 - val_accuracy: 0.9825\n",
      "Epoch 5/5\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.0772 - accuracy: 0.9839 - val_loss: 0.2346 - val_accuracy: 0.9827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017/2017 [==============================] - 11s 6ms/step - loss: 0.8453 - accuracy: 0.9098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 1s 6ms/step - loss: 1.4476 - accuracy: 0.4939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 453ms/step - loss: 2.3768 - accuracy: 0.5155 - val_loss: 3.2254 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 2.2711 - accuracy: 0.5301 - val_loss: 3.1186 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 2.1730 - accuracy: 0.5473 - val_loss: 3.0119 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 2.0744 - accuracy: 0.5662 - val_loss: 2.9072 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 1.9830 - accuracy: 0.5790 - val_loss: 2.8050 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 2.4590 - accuracy: 0.4024 - val_loss: 2.4769 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 2.3374 - accuracy: 0.4024 - val_loss: 2.3313 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 2.2144 - accuracy: 0.4024 - val_loss: 2.1874 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 2.0943 - accuracy: 0.4047 - val_loss: 2.0488 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.9833 - accuracy: 0.4064 - val_loss: 1.9177 - val_accuracy: 0.0000e+00\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 343ms/step - loss: 0.7032 - accuracy: 0.8170 - val_loss: 2.2267 - val_accuracy: 0.0137\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.6700 - accuracy: 0.8170 - val_loss: 2.1152 - val_accuracy: 0.0251\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.6408 - accuracy: 0.8170 - val_loss: 2.0094 - val_accuracy: 0.0251\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.6159 - accuracy: 0.8193 - val_loss: 1.9097 - val_accuracy: 0.0274\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.5933 - accuracy: 0.8199 - val_loss: 1.8166 - val_accuracy: 0.0297\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 1.6324 - accuracy: 0.4208 - val_loss: 1.8506 - val_accuracy: 0.0023\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.4985 - accuracy: 0.4214 - val_loss: 1.7568 - val_accuracy: 0.0046\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 1.3759 - accuracy: 0.4254 - val_loss: 1.6696 - val_accuracy: 0.0091\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 1.2656 - accuracy: 0.4277 - val_loss: 1.5881 - val_accuracy: 0.0114\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 1.1658 - accuracy: 0.4357 - val_loss: 1.5120 - val_accuracy: 0.0205\n",
      "Epoch 1/5\n",
      "9/9 [==============================] - 2s 274ms/step - loss: 0.5311 - accuracy: 0.8143 - val_loss: 1.3721 - val_accuracy: 0.0532\n",
      "Epoch 2/5\n",
      "9/9 [==============================] - 1s 100ms/step - loss: 0.4333 - accuracy: 0.8245 - val_loss: 1.1816 - val_accuracy: 0.0796\n",
      "Epoch 3/5\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.3872 - accuracy: 0.8296 - val_loss: 1.0696 - val_accuracy: 0.0948\n",
      "Epoch 4/5\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 0.3661 - accuracy: 0.8387 - val_loss: 1.0452 - val_accuracy: 0.1059\n",
      "Epoch 5/5\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3512 - accuracy: 0.84 - 1s 91ms/step - loss: 0.3512 - accuracy: 0.8462 - val_loss: 1.0282 - val_accuracy: 0.1220\n",
      "Epoch 1/5\n",
      "6/6 [==============================] - 2s 284ms/step - loss: 1.0945 - accuracy: 0.7012 - val_loss: 1.3873 - val_accuracy: 0.2895\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 1s 95ms/step - loss: 0.7150 - accuracy: 0.6856 - val_loss: 0.8653 - val_accuracy: 0.3847\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 1s 111ms/step - loss: 0.4527 - accuracy: 0.7850 - val_loss: 0.5621 - val_accuracy: 0.8371\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 1s 94ms/step - loss: 0.3241 - accuracy: 0.9041 - val_loss: 0.4392 - val_accuracy: 0.8385\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.2795 - accuracy: 0.9079 - val_loss: 0.3927 - val_accuracy: 0.8304\n",
      "Epoch 1/5\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 0.5339 - accuracy: 0.7846 - val_loss: 0.3489 - val_accuracy: 0.9759\n",
      "Epoch 2/5\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 0.1102 - accuracy: 0.9836 - val_loss: 0.1474 - val_accuracy: 0.9830\n",
      "Epoch 3/5\n",
      "25/25 [==============================] - 2s 85ms/step - loss: 0.0850 - accuracy: 0.9839 - val_loss: 0.1202 - val_accuracy: 0.9825\n",
      "Epoch 4/5\n",
      "25/25 [==============================] - 2s 81ms/step - loss: 0.0776 - accuracy: 0.9840 - val_loss: 0.1096 - val_accuracy: 0.9829\n",
      "Epoch 5/5\n",
      "25/25 [==============================] - 2s 87ms/step - loss: 0.0733 - accuracy: 0.9842 - val_loss: 0.0977 - val_accuracy: 0.9830\n",
      "   1/2017 [..............................] - ETA: 0s - loss: 0.4854 - accuracy: 0.9062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017/2017 [==============================] - 8s 4ms/step - loss: 0.8514 - accuracy: 0.9115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 1.8647 - accuracy: 0.5045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3:\n",
    "            x, y = x4, y4\n",
    "        elif node == 4:\n",
    "            x, y = x5, y5\n",
    "        elif node == 5:\n",
    "            x, y = x6, y6\n",
    "        elif node == 6:\n",
    "            x, y = x7, y7\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(y, predictions)\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xc, yc) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xce, yce)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idCAT702.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[1.0600913763046265, 1.3038921356201172], [0.8453078866004944, 1.4476186037063599], [0.8513851165771484, 1.864727258682251]]\n",
      "Accuracy for iterations:  [[0.8977618217468262, 0.49262380599975586], [0.9097743034362793, 0.49394097924232483], [0.9115258455276489, 0.504478394985199]]\n",
      "F1 for iterations:  [[0.8803900154319717, 0.340209746720258], [0.8909246515695796, 0.3432699342301511], [0.8959708103565615, 0.36796612103987975]]\n",
      "Precision for iterations:  [[0.8775480551662516, 0.46375927497806435], [0.9290637761628321, 0.418975261728751], [0.9315069742871185, 0.43966165413533825]]\n",
      "Recall for iterations:  [[0.897761795523591, 0.49262381454162274], [0.9097743195486391, 0.493940990516333], [0.9115258230516461, 0.5044783983140148]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
