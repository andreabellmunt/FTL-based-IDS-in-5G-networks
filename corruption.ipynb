{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated Learning with one corrupted node \n",
    "Using one balanced and one unbalanced dataset with one corrupted node (5%, 25% and 50% corrupted samples) to test different aggregation functions and determine the more robust one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Disable warns\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data): \n",
    "\n",
    "    # Select the 'proto' and 'state' values that I want\n",
    "    data = data.loc[(data['proto'] == 'tcp') | (data['proto'] =='udp') | (data['proto'] =='icmp') | (data['proto'] =='arp') | (data['proto'] =='ipv6-icmp') | (data['proto'] =='igmp') | (data['proto'] =='rarp'), :]\n",
    "    data = data.loc[(data['state'] == 'RST') | (data['state'] =='REQ') | (data['state'] =='INT') | (data['state'] =='FIN') | (data['state'] =='CON') | (data['state'] =='ECO') | (data['state'] =='ACC') | (data['state'] == 'PAR'), :]\n",
    "\n",
    "    # Extracting labels \n",
    "    data_labels = data[['label']]\n",
    "\n",
    "    # Drop the invalid features and select interested data features\n",
    "    data_features=data[['proto','srcip','sport','dstip','dsport','spkts','dpkts','sbytes','dbytes','state','stime','ltime','dur']]\n",
    "\n",
    "    \"\"\"PREPROCESSING\"\"\"\n",
    "\n",
    "\n",
    "    # Preprocess IP and ports features\n",
    "    # IP Source Address\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "\n",
    "    # IP Destination Address\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "    # Ports\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "\n",
    "    # Convert all ports with 0 decimal, and HEX to DEC\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    # Convert field to int format\n",
    "    data_features['srcip'] = data_features['srcip'].astype(int)\n",
    "    data_features['sport'] = data_features['sport'].astype(int)\n",
    "    data_features['dstip'] = data_features['dstip'].astype(int)\n",
    "    data_features['dsport'] = data_features['dsport'].astype(int)\n",
    "\n",
    "    # Convert some fields to logarithmic\n",
    "    log1p_col = ['dur', 'sbytes', 'dbytes', 'spkts']\n",
    "\n",
    "    for col in log1p_col:\n",
    "        data_features[col] = data_features[col].apply(np.log1p)\n",
    "\n",
    "    # Create a complementary field of attack & Transform to One hot encoding - LABELS\n",
    "    normal=data_labels['label']\n",
    "    normal=normal.replace(1,2)\n",
    "    normal=normal.replace(0,1)\n",
    "    normal=normal.replace(2,0)\n",
    "\n",
    "    # Insert the new column in data labels\n",
    "    data_labels.insert(1, 'normal', normal)\n",
    "    data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "    data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "    # Transform to One hot encoding - FEATURES\n",
    "    data_features=pd.get_dummies(data_features)\n",
    "\n",
    "    # Value given for the missing columns\n",
    "    auxCol=0\n",
    "\n",
    "    # As we are using different datasets that might not have all representations, we are going to detect and add the missing columns \n",
    "    # The columns that can have types are: proto and state: need to check if all representations are done \n",
    "    state_cols = [col for col in data_features if col.startswith('state_')]\n",
    "    proto_cols = [col for col in data_features if col.startswith('proto_')]\n",
    "    \n",
    "    # Check if all columns are present\n",
    "    if 'state_PAR' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_PAR', auxCol, True)\n",
    "    if 'state_ACC' not in state_cols: \n",
    "        data_features.insert(data_features.shape[1], 'state_ACC', auxCol, True)\n",
    "    if 'state_ECO' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_ECO', auxCol, True)\n",
    "    if 'state_CON' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_CON', auxCol, True)\n",
    "    if 'state_FIN' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_FIN', auxCol, True)\n",
    "    if 'state_INT' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_INT', auxCol, True)\n",
    "    if 'state_REQ' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_REQ', auxCol, True)\n",
    "    if 'state_RST' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_RST', auxCol, True)\n",
    "    if 'proto_igmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_igmp', auxCol, True)\n",
    "    if 'proto_arp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_arp', auxCol, True)\n",
    "    if 'proto_icmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_icmp', auxCol, True)\n",
    "    if 'proto_udp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_udp', auxCol, True)\n",
    "    if 'proto_tcp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_tcp', auxCol, True)\n",
    "\n",
    "    # Normalize all data features\n",
    "    data_features = StandardScaler().fit_transform(data_features)\n",
    "\n",
    "    #Add dimension to data features\n",
    "    data_features = np.expand_dims(data_features, axis=2)\n",
    "    data_features = np.expand_dims(data_features, axis=3)\n",
    "\n",
    "    x = data_features\n",
    "    y = data_labels.to_numpy()\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building and definition\n",
    "def build_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(filters=32,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(1, 2), padding='same'))\n",
    "    model.add(layers.Conv2D(filters=64,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(1, 2), padding='same'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(Dense(444, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns values of loss, accuracy, f1, precision and recall of model evaluating with test dataset \n",
    "def evaluation(model, x, y): \n",
    "    loss, accuracy = model.evaluate(x, y)\n",
    "    y_pred = model.predict(x)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y = np.argmax(y, axis=1)\n",
    "    report = classification_report(y, y_pred, target_names=['normal', 'attack'], output_dict=True)\n",
    "    # Obtain f1, precision and recall from the report\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    return loss, accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AVERAGE 3 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    # Calculate mean gradient for each layer\n",
    "    mean_grad = [tf.reduce_mean(layer_grads, axis=0) for layer_grads in zip(*grad_list)]\n",
    "    \n",
    "    return mean_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3632/3457440085.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3632/3457440085.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_complete = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Complete.csv')\n"
     ]
    }
   ],
   "source": [
    "test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n",
    "test_plus = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test+.csv')\n",
    "test_complete = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)\n",
    "xcomplete, ycomplete = preprocessing(test_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3C 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_956/3517758634.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%13C-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_956/3517758634.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%13C-Part3.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%13C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%13C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%13C-Part3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "node_datasets = [training1, training2, training3]\n",
    "num_nodes = 3\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr53Cavg.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "51/51 [==============================] - 9s 168ms/step - loss: 0.3733 - accuracy: 0.8686 - val_loss: 0.1828 - val_accuracy: 0.9563\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 8s 160ms/step - loss: 0.1649 - accuracy: 0.9643 - val_loss: 0.1570 - val_accuracy: 0.9658\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 8s 165ms/step - loss: 0.1491 - accuracy: 0.9671 - val_loss: 0.1489 - val_accuracy: 0.9665\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 8s 164ms/step - loss: 0.1431 - accuracy: 0.9675 - val_loss: 0.1453 - val_accuracy: 0.9670\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 8s 163ms/step - loss: 0.1407 - accuracy: 0.9679 - val_loss: 0.1451 - val_accuracy: 0.9670\n",
      "Epoch 1/5\n",
      "51/51 [==============================] - 9s 174ms/step - loss: 0.0224 - accuracy: 0.9921 - val_loss: 0.2045 - val_accuracy: 0.9179\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 9s 175ms/step - loss: 0.0185 - accuracy: 0.9935 - val_loss: 0.2520 - val_accuracy: 0.8357\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 9s 172ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 0.4094 - val_accuracy: 0.7552\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 9s 171ms/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 0.2981 - val_accuracy: 0.8264\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 11s 207ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 0.2932 - val_accuracy: 0.8380\n",
      "Epoch 1/5\n",
      "51/51 [==============================] - 9s 172ms/step - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.3946 - val_accuracy: 0.8161\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 10s 187ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 0.2178 - val_accuracy: 0.8738\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 9s 175ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.3034 - val_accuracy: 0.8519\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 9s 178ms/step - loss: 0.0132 - accuracy: 0.9959 - val_loss: 0.4634 - val_accuracy: 0.8024\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 9s 181ms/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 0.3294 - val_accuracy: 0.8482\n",
      "4279/4279 [==============================] - 15s 3ms/step - loss: 0.1313 - accuracy: 0.9815\n",
      "1721/1721 [==============================] - 6s 4ms/step - loss: 0.2939 - accuracy: 0.9085\n",
      "Epoch 1/5\n",
      "51/51 [==============================] - 8s 165ms/step - loss: 0.1705 - accuracy: 0.9670 - val_loss: 0.1485 - val_accuracy: 0.9663\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 9s 171ms/step - loss: 0.1389 - accuracy: 0.9682 - val_loss: 0.1439 - val_accuracy: 0.9671\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 9s 183ms/step - loss: 0.1373 - accuracy: 0.9682 - val_loss: 0.1422 - val_accuracy: 0.9671\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 9s 185ms/step - loss: 0.1368 - accuracy: 0.9683 - val_loss: 0.1430 - val_accuracy: 0.9670\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 9s 184ms/step - loss: 0.1362 - accuracy: 0.9683 - val_loss: 0.1414 - val_accuracy: 0.9671\n",
      "Epoch 1/5\n",
      "51/51 [==============================] - 10s 193ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.3200 - val_accuracy: 0.8225\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 11s 208ms/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.3855 - val_accuracy: 0.8176\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 11s 211ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.3530 - val_accuracy: 0.8456\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 11s 214ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.4159 - val_accuracy: 0.8241\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 11s 215ms/step - loss: 0.0126 - accuracy: 0.9964 - val_loss: 0.7041 - val_accuracy: 0.7471\n",
      "Epoch 1/5\n",
      "51/51 [==============================] - 11s 217ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.4355 - val_accuracy: 0.8294\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 11s 207ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.4079 - val_accuracy: 0.8337\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 11s 212ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.3294 - val_accuracy: 0.8594\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 11s 211ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 0.4915 - val_accuracy: 0.8109\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 11s 214ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.4493 - val_accuracy: 0.8328\n",
      "4279/4279 [==============================] - 22s 5ms/step - loss: 0.2137 - accuracy: 0.9506\n",
      "1721/1721 [==============================] - 9s 5ms/step - loss: 0.4640 - accuracy: 0.8300\n",
      "Epoch 1/5\n",
      "51/51 [==============================] - 11s 214ms/step - loss: 0.1880 - accuracy: 0.9651 - val_loss: 0.1459 - val_accuracy: 0.9671\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 10s 205ms/step - loss: 0.1371 - accuracy: 0.9683 - val_loss: 0.1418 - val_accuracy: 0.9670\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 11s 212ms/step - loss: 0.1353 - accuracy: 0.9682 - val_loss: 0.1404 - val_accuracy: 0.9670\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 11s 210ms/step - loss: 0.1352 - accuracy: 0.9683 - val_loss: 0.1402 - val_accuracy: 0.9672\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 11s 214ms/step - loss: 0.1345 - accuracy: 0.9683 - val_loss: 0.1401 - val_accuracy: 0.9672\n",
      "Epoch 1/5\n",
      "51/51 [==============================] - 11s 213ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.3935 - val_accuracy: 0.8139\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 11s 214ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.3480 - val_accuracy: 0.8463\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 11s 213ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.3676 - val_accuracy: 0.8522\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 11s 212ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.4462 - val_accuracy: 0.8328\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 11s 211ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.5036 - val_accuracy: 0.8182\n",
      "Epoch 1/5\n",
      "51/51 [==============================] - 11s 215ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.3033 - val_accuracy: 0.8598\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 11s 211ms/step - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.4226 - val_accuracy: 0.8266\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 11s 218ms/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 0.4620 - val_accuracy: 0.8215\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 11s 213ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.5296 - val_accuracy: 0.8136\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 11s 213ms/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.5208 - val_accuracy: 0.8073\n",
      "4279/4279 [==============================] - 21s 5ms/step - loss: 0.2599 - accuracy: 0.9188\n",
      "1721/1721 [==============================] - 9s 5ms/step - loss: 0.6341 - accuracy: 0.7634\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        else:\n",
    "            x, y = x3, y3\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr53Cavg.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.13129368424415588, 0.29392746090888977], [0.21367402374744415, 0.4640328288078308], [0.25993427634239197, 0.6341381669044495]]\n",
      "Accuracy for iterations:  [[0.9815361499786377, 0.9085228443145752], [0.9505828619003296, 0.8299789428710938], [0.918840765953064, 0.7634418606758118]]\n",
      "F1 for iterations:  [[0.981547115873357, 0.90779772048695], [0.9504388438741762, 0.823371275255111], [0.9180986447905306, 0.7449847862228615]]\n",
      "Precision for iterations:  [[0.9819145017487854, 0.9110732237836993], [0.9522931983987097, 0.8535038895297559], [0.9267800594450063, 0.8119110396538817]]\n",
      "Recall for iterations:  [[0.9815361243390108, 0.908522851122575], [0.9505828391130328, 0.82997892901257], [0.918840749072424, 0.7634418368088353]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3C 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3796/1190975088.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%13C-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3796/1190975088.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%13C-Part3.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%13C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%13C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%13C-Part3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "node_datasets = [training1, training2, training3]\n",
    "num_nodes = 3\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr253Cavg.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "51/51 [==============================] - 9s 181ms/step - loss: 0.5087 - accuracy: 0.7875 - val_loss: 0.4147 - val_accuracy: 0.8653\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 11s 206ms/step - loss: 0.4059 - accuracy: 0.8672 - val_loss: 0.3999 - val_accuracy: 0.8674\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 11s 212ms/step - loss: 0.3952 - accuracy: 0.8682 - val_loss: 0.3925 - val_accuracy: 0.8682\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 12s 227ms/step - loss: 0.3912 - accuracy: 0.8685 - val_loss: 0.3905 - val_accuracy: 0.8684\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 11s 209ms/step - loss: 0.3898 - accuracy: 0.8687 - val_loss: 0.3904 - val_accuracy: 0.8686\n",
      "Epoch 1/5\n",
      "51/51 [==============================] - 10s 202ms/step - loss: 0.0336 - accuracy: 0.9910 - val_loss: 0.2968 - val_accuracy: 0.8210\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 10s 203ms/step - loss: 0.0212 - accuracy: 0.9919 - val_loss: 0.3161 - val_accuracy: 0.7573\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 10s 201ms/step - loss: 0.0198 - accuracy: 0.9931 - val_loss: 0.2075 - val_accuracy: 0.9116\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 10s 201ms/step - loss: 0.0186 - accuracy: 0.9936 - val_loss: 0.3946 - val_accuracy: 0.7163\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 10s 205ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 0.4267 - val_accuracy: 0.7237\n",
      "Epoch 1/5\n",
      "51/51 [==============================] - 9s 168ms/step - loss: 0.0153 - accuracy: 0.9946 - val_loss: 0.4800 - val_accuracy: 0.7381\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 9s 178ms/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.2999 - val_accuracy: 0.8274\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 9s 181ms/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.3355 - val_accuracy: 0.8269\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 9s 177ms/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.4645 - val_accuracy: 0.8007\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 9s 181ms/step - loss: 0.0134 - accuracy: 0.9956 - val_loss: 0.4886 - val_accuracy: 0.8012\n",
      "4279/4279 [==============================] - 15s 4ms/step - loss: 0.0603 - accuracy: 0.9876\n",
      "1721/1721 [==============================] - 7s 4ms/step - loss: 0.2340 - accuracy: 0.9195\n",
      "Epoch 1/5\n",
      "51/51 [==============================] - 8s 162ms/step - loss: 0.5819 - accuracy: 0.8559 - val_loss: 0.4145 - val_accuracy: 0.8686\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 8s 167ms/step - loss: 0.4002 - accuracy: 0.8692 - val_loss: 0.3961 - val_accuracy: 0.8693\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 9s 167ms/step - loss: 0.3925 - accuracy: 0.8695 - val_loss: 0.3925 - val_accuracy: 0.8694\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 8s 166ms/step - loss: 0.3902 - accuracy: 0.8696 - val_loss: 0.3912 - val_accuracy: 0.8694\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 9s 177ms/step - loss: 0.3894 - accuracy: 0.8696 - val_loss: 0.3899 - val_accuracy: 0.8694\n",
      "Epoch 1/5\n",
      "51/51 [==============================] - 8s 165ms/step - loss: 0.0255 - accuracy: 0.9945 - val_loss: 0.3820 - val_accuracy: 0.7730\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 9s 176ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.3641 - val_accuracy: 0.8061\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 9s 180ms/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 0.3325 - val_accuracy: 0.8338\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 9s 176ms/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 0.3399 - val_accuracy: 0.8389\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 9s 174ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.3700 - val_accuracy: 0.8314\n",
      "Epoch 1/5\n",
      "51/51 [==============================] - 8s 163ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.3526 - val_accuracy: 0.8391\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 9s 178ms/step - loss: 0.0124 - accuracy: 0.9962 - val_loss: 0.3089 - val_accuracy: 0.8541\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 9s 185ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.4103 - val_accuracy: 0.8357\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 9s 175ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.4633 - val_accuracy: 0.8182\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 9s 180ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.3431 - val_accuracy: 0.8519\n",
      "4279/4279 [==============================] - 18s 4ms/step - loss: 0.0659 - accuracy: 0.9834\n",
      "1721/1721 [==============================] - 7s 4ms/step - loss: 0.2324 - accuracy: 0.9114\n",
      "Epoch 1/5\n",
      "51/51 [==============================] - 8s 164ms/step - loss: 0.5574 - accuracy: 0.8569 - val_loss: 0.4034 - val_accuracy: 0.8686\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 8s 163ms/step - loss: 0.3950 - accuracy: 0.8692 - val_loss: 0.3936 - val_accuracy: 0.8690\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 8s 167ms/step - loss: 0.3904 - accuracy: 0.8695 - val_loss: 0.3926 - val_accuracy: 0.8692\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 9s 167ms/step - loss: 0.3889 - accuracy: 0.8695 - val_loss: 0.3906 - val_accuracy: 0.8693\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 9s 175ms/step - loss: 0.3878 - accuracy: 0.8696 - val_loss: 0.3899 - val_accuracy: 0.8694\n",
      "Epoch 1/5\n",
      "51/51 [==============================] - 9s 168ms/step - loss: 0.0233 - accuracy: 0.9951 - val_loss: 0.4070 - val_accuracy: 0.8032\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 9s 176ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.4105 - val_accuracy: 0.8167\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 9s 177ms/step - loss: 0.0127 - accuracy: 0.9964 - val_loss: 0.4813 - val_accuracy: 0.8042\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 9s 176ms/step - loss: 0.0126 - accuracy: 0.9964 - val_loss: 0.5052 - val_accuracy: 0.8024\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 9s 180ms/step - loss: 0.0125 - accuracy: 0.9964 - val_loss: 0.5187 - val_accuracy: 0.8085\n",
      "Epoch 1/5\n",
      "51/51 [==============================] - 8s 166ms/step - loss: 0.0117 - accuracy: 0.9966 - val_loss: 0.5115 - val_accuracy: 0.8130\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 9s 170ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.3648 - val_accuracy: 0.8482\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 9s 180ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.5234 - val_accuracy: 0.8072\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 9s 179ms/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 0.4411 - val_accuracy: 0.8363\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 9s 175ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.4938 - val_accuracy: 0.8179\n",
      "4279/4279 [==============================] - 17s 4ms/step - loss: 0.0801 - accuracy: 0.9840\n",
      "1721/1721 [==============================] - 7s 4ms/step - loss: 0.4589 - accuracy: 0.8010\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        else:\n",
    "            x, y = x3, y3\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr253Cavg.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.06029896065592766, 0.23395667970180511], [0.06586694717407227, 0.23241287469863892], [0.0801391676068306, 0.45889586210250854]]\n",
      "Accuracy for iterations:  [[0.9876128435134888, 0.9194579720497131], [0.9834350943565369, 0.911392867565155], [0.9839609861373901, 0.8010426759719849]]\n",
      "F1 for iterations:  [[0.9876179873106058, 0.9186358495776776], [0.9834448854405644, 0.9104962770279796], [0.9839582869405543, 0.7884540368927155]]\n",
      "Precision for iterations:  [[0.9877636771386369, 0.923821019409445], [0.9838040603809045, 0.9154707842555262], [0.983970662963597, 0.844334649351584]]\n",
      "Recall for iterations:  [[0.987612842910982, 0.9194579670130059], [0.9834350988927517, 0.9113928649277047], [0.9839609687691724, 0.8010426505849015]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3C 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3796/4238720402.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr50%13C-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3796/4238720402.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr50%13C-Part3.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr50%13C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr50%13C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr50%13C-Part3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "node_datasets = [training1, training2, training3]\n",
    "num_nodes = 3\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr503Cavg.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "51/51 [==============================] - 8s 163ms/step - loss: 0.6068 - accuracy: 0.7018 - val_loss: 0.5729 - val_accuracy: 0.7462\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 8s 151ms/step - loss: 0.5733 - accuracy: 0.7447 - val_loss: 0.5688 - val_accuracy: 0.7473\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 8s 159ms/step - loss: 0.5701 - accuracy: 0.7450 - val_loss: 0.5663 - val_accuracy: 0.7476\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 8s 163ms/step - loss: 0.5690 - accuracy: 0.7454 - val_loss: 0.5663 - val_accuracy: 0.7475\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 9s 182ms/step - loss: 0.5690 - accuracy: 0.7455 - val_loss: 0.5664 - val_accuracy: 0.7476\n",
      "Epoch 1/5\n",
      "51/51 [==============================] - 9s 169ms/step - loss: 0.0554 - accuracy: 0.9908 - val_loss: 0.4252 - val_accuracy: 0.6590\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 9s 184ms/step - loss: 0.0218 - accuracy: 0.9917 - val_loss: 0.3304 - val_accuracy: 0.7486\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 9s 183ms/step - loss: 0.0204 - accuracy: 0.9925 - val_loss: 0.3805 - val_accuracy: 0.6980\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 9s 175ms/step - loss: 0.0192 - accuracy: 0.9932 - val_loss: 0.3768 - val_accuracy: 0.7123\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 9s 182ms/step - loss: 0.0181 - accuracy: 0.9940 - val_loss: 0.3277 - val_accuracy: 0.7543\n",
      "Epoch 1/5\n",
      "51/51 [==============================] - 8s 165ms/step - loss: 0.0164 - accuracy: 0.9942 - val_loss: 0.3184 - val_accuracy: 0.7892\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 9s 178ms/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 0.3746 - val_accuracy: 0.7823\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 9s 184ms/step - loss: 0.0145 - accuracy: 0.9952 - val_loss: 0.3929 - val_accuracy: 0.7906\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 9s 178ms/step - loss: 0.0143 - accuracy: 0.9955 - val_loss: 0.3186 - val_accuracy: 0.8306\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 9s 178ms/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.4285 - val_accuracy: 0.8041\n",
      "4279/4279 [==============================] - 17s 4ms/step - loss: 0.0748 - accuracy: 0.9851\n",
      "1721/1721 [==============================] - 6s 4ms/step - loss: 0.2229 - accuracy: 0.9199\n",
      "Epoch 1/5\n",
      "51/51 [==============================] - 8s 166ms/step - loss: 0.9685 - accuracy: 0.7169 - val_loss: 0.6062 - val_accuracy: 0.7356\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 8s 161ms/step - loss: 0.5848 - accuracy: 0.7426 - val_loss: 0.5743 - val_accuracy: 0.7476\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 9s 170ms/step - loss: 0.5731 - accuracy: 0.7455 - val_loss: 0.5698 - val_accuracy: 0.7478\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 8s 162ms/step - loss: 0.5710 - accuracy: 0.7456 - val_loss: 0.5679 - val_accuracy: 0.7478\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 9s 183ms/step - loss: 0.5695 - accuracy: 0.7456 - val_loss: 0.5671 - val_accuracy: 0.7479\n",
      "Epoch 1/5\n",
      "51/51 [==============================] - 9s 169ms/step - loss: 0.0418 - accuracy: 0.9944 - val_loss: 0.3604 - val_accuracy: 0.7806\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 9s 181ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.3759 - val_accuracy: 0.7901\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 9s 180ms/step - loss: 0.0144 - accuracy: 0.9958 - val_loss: 0.3646 - val_accuracy: 0.8098\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 9s 176ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.3613 - val_accuracy: 0.8190\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 9s 177ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.3151 - val_accuracy: 0.8404\n",
      "Epoch 1/5\n",
      "51/51 [==============================] - 9s 167ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.4618 - val_accuracy: 0.8002\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 9s 181ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.3363 - val_accuracy: 0.8411\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 9s 181ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 0.5659 - val_accuracy: 0.7735\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 9s 178ms/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 0.5206 - val_accuracy: 0.7917\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 9s 178ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 0.4007 - val_accuracy: 0.8258\n",
      "4279/4279 [==============================] - 17s 4ms/step - loss: 0.1072 - accuracy: 0.9881\n",
      "1721/1721 [==============================] - 7s 4ms/step - loss: 0.3529 - accuracy: 0.8689: 0s -\n",
      "Epoch 1/5\n",
      "51/51 [==============================] - 9s 167ms/step - loss: 0.9604 - accuracy: 0.7230 - val_loss: 0.5852 - val_accuracy: 0.7362\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 10s 192ms/step - loss: 0.5764 - accuracy: 0.7440 - val_loss: 0.5709 - val_accuracy: 0.7474\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 9s 174ms/step - loss: 0.5714 - accuracy: 0.7454 - val_loss: 0.5677 - val_accuracy: 0.7476\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 9s 173ms/step - loss: 0.5694 - accuracy: 0.7455 - val_loss: 0.5671 - val_accuracy: 0.7474\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 9s 180ms/step - loss: 0.5683 - accuracy: 0.7454 - val_loss: 0.5655 - val_accuracy: 0.7476\n",
      "Epoch 1/5\n",
      "51/51 [==============================] - 9s 169ms/step - loss: 0.0413 - accuracy: 0.9949 - val_loss: 0.2870 - val_accuracy: 0.8396\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 9s 186ms/step - loss: 0.0138 - accuracy: 0.9961 - val_loss: 0.3388 - val_accuracy: 0.8244\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 10s 189ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 0.3686 - val_accuracy: 0.8278\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 9s 178ms/step - loss: 0.0130 - accuracy: 0.9962 - val_loss: 0.2825 - val_accuracy: 0.8595\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 9s 183ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.5757 - val_accuracy: 0.7794\n",
      "Epoch 1/5\n",
      "51/51 [==============================] - 9s 168ms/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 0.3633 - val_accuracy: 0.8468\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 9s 176ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.5403 - val_accuracy: 0.7939\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 11s 213ms/step - loss: 0.0116 - accuracy: 0.9965 - val_loss: 0.4205 - val_accuracy: 0.8319\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 17s 328ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 0.4052 - val_accuracy: 0.8372\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 15s 288ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.6173 - val_accuracy: 0.7749\n",
      "4279/4279 [==============================] - 23s 5ms/step - loss: 0.1737 - accuracy: 0.9780\n",
      "1721/1721 [==============================] - 9s 5ms/step - loss: 0.4773 - accuracy: 0.7984\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        else:\n",
    "            x, y = x3, y3\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr503Cavg.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.07479007542133331, 0.2228516787290573], [0.10720720887184143, 0.3528783619403839], [0.1736885905265808, 0.47727009654045105]]\n",
      "Accuracy for iterations:  [[0.985136866569519, 0.9198939204216003], [0.9881094694137573, 0.8688876032829285], [0.9779719114303589, 0.7984269261360168]]\n",
      "F1 for iterations:  [[0.9851443052890743, 0.919223630582906], [0.9881124299420956, 0.8653072885389217], [0.9779549154317135, 0.7853341121432225]]\n",
      "Precision for iterations:  [[0.9853745264525866, 0.9229680470935299], [0.9881581013337662, 0.8855111079149852], [0.9781830540609326, 0.8429088245423307]]\n",
      "Recall for iterations:  [[0.985136872242835, 0.9198939184770762], [0.988109497794268, 0.8688875971808472], [0.9779718951766047, 0.7984269418004796]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3G 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3796/2562238320.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%23G-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3796/2562238320.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%23G-Part3.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%23G-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%23G-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%23G-Part3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "node_datasets = [training1, training2, training3]\n",
    "num_nodes = 3\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr53Gavg.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20/20 [==============================] - 5s 247ms/step - loss: 0.5260 - accuracy: 0.9330 - val_loss: 1.5660 - val_accuracy: 0.1458\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 5s 229ms/step - loss: 0.1905 - accuracy: 0.9545 - val_loss: 1.2389 - val_accuracy: 0.1735\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 5s 231ms/step - loss: 0.0837 - accuracy: 0.9754 - val_loss: 0.6450 - val_accuracy: 0.7148\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 5s 250ms/step - loss: 0.0592 - accuracy: 0.9796 - val_loss: 0.5175 - val_accuracy: 0.7650\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 5s 236ms/step - loss: 0.0487 - accuracy: 0.9832 - val_loss: 0.4251 - val_accuracy: 0.8387\n",
      "Epoch 1/5\n",
      "54/54 [==============================] - 13s 244ms/step - loss: 0.1586 - accuracy: 0.9655 - val_loss: 0.1453 - val_accuracy: 0.9679\n",
      "Epoch 2/5\n",
      "54/54 [==============================] - 13s 243ms/step - loss: 0.1446 - accuracy: 0.9673 - val_loss: 0.1391 - val_accuracy: 0.9686\n",
      "Epoch 3/5\n",
      "54/54 [==============================] - 13s 245ms/step - loss: 0.1410 - accuracy: 0.9678 - val_loss: 0.1376 - val_accuracy: 0.9686\n",
      "Epoch 4/5\n",
      "54/54 [==============================] - 13s 242ms/step - loss: 0.1400 - accuracy: 0.9680 - val_loss: 0.1368 - val_accuracy: 0.9687\n",
      "Epoch 5/5\n",
      "54/54 [==============================] - 13s 241ms/step - loss: 0.1396 - accuracy: 0.9680 - val_loss: 0.1361 - val_accuracy: 0.9686\n",
      "Epoch 1/5\n",
      "79/79 [==============================] - 21s 263ms/step - loss: 0.0203 - accuracy: 0.9929 - val_loss: 0.1778 - val_accuracy: 0.8886\n",
      "Epoch 2/5\n",
      "79/79 [==============================] - 21s 266ms/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 0.1586 - val_accuracy: 0.9069\n",
      "Epoch 3/5\n",
      "79/79 [==============================] - 20s 257ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.4259 - val_accuracy: 0.8232\n",
      "Epoch 4/5\n",
      "79/79 [==============================] - 20s 254ms/step - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.3259 - val_accuracy: 0.8574\n",
      "Epoch 5/5\n",
      "79/79 [==============================] - 19s 242ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.3445 - val_accuracy: 0.8606\n",
      "4279/4279 [==============================] - 17s 4ms/step - loss: 0.3105 - accuracy: 0.8650\n",
      "1721/1721 [==============================] - 8s 5ms/step - loss: 0.4340 - accuracy: 0.8596\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 5s 244ms/step - loss: 0.0253 - accuracy: 0.9904 - val_loss: 0.4117 - val_accuracy: 0.7433\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 5s 228ms/step - loss: 0.0232 - accuracy: 0.9911 - val_loss: 0.3111 - val_accuracy: 0.8197\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 4s 223ms/step - loss: 0.0226 - accuracy: 0.9916 - val_loss: 0.1754 - val_accuracy: 0.9571\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 5s 232ms/step - loss: 0.0225 - accuracy: 0.9920 - val_loss: 0.3333 - val_accuracy: 0.7983\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 5s 229ms/step - loss: 0.0217 - accuracy: 0.9920 - val_loss: 0.2958 - val_accuracy: 0.8259\n",
      "Epoch 1/5\n",
      "54/54 [==============================] - 13s 249ms/step - loss: 0.1619 - accuracy: 0.9667 - val_loss: 0.1356 - val_accuracy: 0.9686\n",
      "Epoch 2/5\n",
      "54/54 [==============================] - 13s 246ms/step - loss: 0.1388 - accuracy: 0.9680 - val_loss: 0.1338 - val_accuracy: 0.9686\n",
      "Epoch 3/5\n",
      "54/54 [==============================] - 14s 252ms/step - loss: 0.1374 - accuracy: 0.9680 - val_loss: 0.1331 - val_accuracy: 0.9687\n",
      "Epoch 4/5\n",
      "54/54 [==============================] - 14s 251ms/step - loss: 0.1366 - accuracy: 0.9680 - val_loss: 0.1331 - val_accuracy: 0.9686\n",
      "Epoch 5/5\n",
      "54/54 [==============================] - 13s 241ms/step - loss: 0.1365 - accuracy: 0.9680 - val_loss: 0.1328 - val_accuracy: 0.9686\n",
      "Epoch 1/5\n",
      "79/79 [==============================] - 19s 239ms/step - loss: 0.0159 - accuracy: 0.9954 - val_loss: 0.2092 - val_accuracy: 0.8891\n",
      "Epoch 2/5\n",
      "79/79 [==============================] - 20s 248ms/step - loss: 0.0125 - accuracy: 0.9965 - val_loss: 0.2675 - val_accuracy: 0.8808\n",
      "Epoch 3/5\n",
      "79/79 [==============================] - 19s 237ms/step - loss: 0.0121 - accuracy: 0.9965 - val_loss: 0.2941 - val_accuracy: 0.8807\n",
      "Epoch 4/5\n",
      "79/79 [==============================] - 19s 239ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.2448 - val_accuracy: 0.9039\n",
      "Epoch 5/5\n",
      "79/79 [==============================] - 19s 240ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.2495 - val_accuracy: 0.9037\n",
      "4279/4279 [==============================] - 16s 4ms/step - loss: 0.3272 - accuracy: 0.8397 \n",
      "1721/1721 [==============================] - 7s 4ms/step - loss: 0.3997 - accuracy: 0.8563\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 5s 233ms/step - loss: 0.0221 - accuracy: 0.9917 - val_loss: 0.5567 - val_accuracy: 0.7122\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 4s 222ms/step - loss: 0.0206 - accuracy: 0.9923 - val_loss: 0.3338 - val_accuracy: 0.7993\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 5s 230ms/step - loss: 0.0197 - accuracy: 0.9924 - val_loss: 0.5102 - val_accuracy: 0.7531\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 4s 222ms/step - loss: 0.0195 - accuracy: 0.9927 - val_loss: 0.2925 - val_accuracy: 0.8244\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 4s 222ms/step - loss: 0.0192 - accuracy: 0.9927 - val_loss: 0.3489 - val_accuracy: 0.8098\n",
      "Epoch 1/5\n",
      "54/54 [==============================] - 13s 238ms/step - loss: 0.1589 - accuracy: 0.9669 - val_loss: 0.1333 - val_accuracy: 0.9686\n",
      "Epoch 2/5\n",
      "54/54 [==============================] - 13s 235ms/step - loss: 0.1366 - accuracy: 0.9680 - val_loss: 0.1319 - val_accuracy: 0.9687\n",
      "Epoch 3/5\n",
      "54/54 [==============================] - 13s 243ms/step - loss: 0.1359 - accuracy: 0.9680 - val_loss: 0.1318 - val_accuracy: 0.9687\n",
      "Epoch 4/5\n",
      "54/54 [==============================] - 13s 243ms/step - loss: 0.1355 - accuracy: 0.9680 - val_loss: 0.1324 - val_accuracy: 0.9686\n",
      "Epoch 5/5\n",
      "54/54 [==============================] - 13s 243ms/step - loss: 0.1353 - accuracy: 0.9680 - val_loss: 0.1321 - val_accuracy: 0.9687\n",
      "Epoch 1/5\n",
      "79/79 [==============================] - 19s 238ms/step - loss: 0.0142 - accuracy: 0.9960 - val_loss: 0.3089 - val_accuracy: 0.8715\n",
      "Epoch 2/5\n",
      "79/79 [==============================] - 19s 239ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.1750 - val_accuracy: 0.9182\n",
      "Epoch 3/5\n",
      "79/79 [==============================] - 20s 249ms/step - loss: 0.0104 - accuracy: 0.9971 - val_loss: 0.1834 - val_accuracy: 0.9211\n",
      "Epoch 4/5\n",
      "79/79 [==============================] - 20s 256ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.2312 - val_accuracy: 0.9090\n",
      "Epoch 5/5\n",
      "79/79 [==============================] - 20s 257ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.2724 - val_accuracy: 0.8985\n",
      "4279/4279 [==============================] - 16s 4ms/step - loss: 0.1823 - accuracy: 0.9736\n",
      "1721/1721 [==============================] - 8s 5ms/step - loss: 0.4158 - accuracy: 0.8287\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        else:\n",
    "            x, y = x3, y3\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr53Gavg.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.3104642331600189, 0.4340478181838989], [0.32722339034080505, 0.3996964395046234], [0.1822798252105713, 0.41584157943725586]]\n",
      "Accuracy for iterations:  [[0.8650486469268799, 0.8596236109733582], [0.8397119641304016, 0.8562995195388794], [0.9735750555992126, 0.8286710977554321]]\n",
      "F1 for iterations:  [[0.8625695297943645, 0.856015643855784], [0.8350657276233903, 0.8515486511560322], [0.9735519267354799, 0.8205135437845434]]\n",
      "Precision for iterations:  [[0.8816240653743856, 0.8739812836904703], [0.8671038802962394, 0.8773189481505456], [0.9738316774014399, 0.8608133572667405]]\n",
      "Recall for iterations:  [[0.8650486429635689, 0.8596236285693526], [0.839711940167694, 0.8562994986558163], [0.973575038709866, 0.8286710746203589]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3G 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3796/3341559854.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%23G-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3796/3341559854.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%23G-Part3.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%23G-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%23G-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%23G-Part3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "node_datasets = [training1, training2, training3]\n",
    "num_nodes = 3\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr253Gavg.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20/20 [==============================] - 5s 245ms/step - loss: 0.5533 - accuracy: 0.9321 - val_loss: 1.4477 - val_accuracy: 0.1457\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 5s 232ms/step - loss: 0.2214 - accuracy: 0.9325 - val_loss: 1.7663 - val_accuracy: 0.1462\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 5s 233ms/step - loss: 0.0931 - accuracy: 0.9742 - val_loss: 0.5407 - val_accuracy: 0.7873\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 5s 235ms/step - loss: 0.0585 - accuracy: 0.9816 - val_loss: 0.5089 - val_accuracy: 0.7737\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 5s 242ms/step - loss: 0.0476 - accuracy: 0.9834 - val_loss: 0.3371 - val_accuracy: 0.9068\n",
      "Epoch 1/5\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 0.4473 - accuracy: 0.8628 - val_loss: 0.4032 - val_accuracy: 0.8685\n",
      "Epoch 2/5\n",
      "54/54 [==============================] - 15s 270ms/step - loss: 0.3979 - accuracy: 0.8686 - val_loss: 0.3950 - val_accuracy: 0.8682\n",
      "Epoch 3/5\n",
      "54/54 [==============================] - 15s 269ms/step - loss: 0.3924 - accuracy: 0.8686 - val_loss: 0.3919 - val_accuracy: 0.8683\n",
      "Epoch 4/5\n",
      "54/54 [==============================] - 14s 267ms/step - loss: 0.3902 - accuracy: 0.8687 - val_loss: 0.3900 - val_accuracy: 0.8684\n",
      "Epoch 5/5\n",
      "54/54 [==============================] - 14s 265ms/step - loss: 0.3891 - accuracy: 0.8688 - val_loss: 0.3893 - val_accuracy: 0.8684\n",
      "Epoch 1/5\n",
      "79/79 [==============================] - 20s 250ms/step - loss: 0.0299 - accuracy: 0.9912 - val_loss: 0.2210 - val_accuracy: 0.8450\n",
      "Epoch 2/5\n",
      "79/79 [==============================] - 20s 259ms/step - loss: 0.0200 - accuracy: 0.9927 - val_loss: 0.2170 - val_accuracy: 0.8496\n",
      "Epoch 3/5\n",
      "79/79 [==============================] - 20s 258ms/step - loss: 0.0181 - accuracy: 0.9937 - val_loss: 0.2234 - val_accuracy: 0.8507\n",
      "Epoch 4/5\n",
      "79/79 [==============================] - 21s 263ms/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 0.2252 - val_accuracy: 0.8643\n",
      "Epoch 5/5\n",
      "79/79 [==============================] - 20s 259ms/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.2597 - val_accuracy: 0.8608\n",
      "4279/4279 [==============================] - 17s 4ms/step - loss: 0.0609 - accuracy: 0.9878\n",
      "1721/1721 [==============================] - 8s 5ms/step - loss: 0.1570 - accuracy: 0.9372\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 5s 269ms/step - loss: 0.0281 - accuracy: 0.9887 - val_loss: 0.2067 - val_accuracy: 0.9556\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 5s 274ms/step - loss: 0.0269 - accuracy: 0.9900 - val_loss: 0.2423 - val_accuracy: 0.9339\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 6s 280ms/step - loss: 0.0256 - accuracy: 0.9903 - val_loss: 0.1996 - val_accuracy: 0.9615\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 6s 279ms/step - loss: 0.0252 - accuracy: 0.9905 - val_loss: 0.2948 - val_accuracy: 0.8737\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 6s 275ms/step - loss: 0.0246 - accuracy: 0.9906 - val_loss: 0.3086 - val_accuracy: 0.8572\n",
      "Epoch 1/5\n",
      "54/54 [==============================] - 16s 306ms/step - loss: 0.5208 - accuracy: 0.8604 - val_loss: 0.4011 - val_accuracy: 0.8681\n",
      "Epoch 2/5\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 0.3945 - accuracy: 0.8687 - val_loss: 0.3917 - val_accuracy: 0.8684\n",
      "Epoch 3/5\n",
      "54/54 [==============================] - 13s 240ms/step - loss: 0.3903 - accuracy: 0.8688 - val_loss: 0.3901 - val_accuracy: 0.8683\n",
      "Epoch 4/5\n",
      "54/54 [==============================] - 13s 235ms/step - loss: 0.3889 - accuracy: 0.8689 - val_loss: 0.3886 - val_accuracy: 0.8685\n",
      "Epoch 5/5\n",
      "54/54 [==============================] - 13s 243ms/step - loss: 0.3880 - accuracy: 0.8692 - val_loss: 0.3879 - val_accuracy: 0.8697\n",
      "Epoch 1/5\n",
      "79/79 [==============================] - 20s 254ms/step - loss: 0.0246 - accuracy: 0.9940 - val_loss: 0.2413 - val_accuracy: 0.8453\n",
      "Epoch 2/5\n",
      "79/79 [==============================] - 20s 256ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.1914 - val_accuracy: 0.8864\n",
      "Epoch 3/5\n",
      "79/79 [==============================] - 21s 260ms/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.3036 - val_accuracy: 0.8527\n",
      "Epoch 4/5\n",
      "79/79 [==============================] - 21s 270ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.2844 - val_accuracy: 0.8694\n",
      "Epoch 5/5\n",
      "79/79 [==============================] - 20s 257ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.2550 - val_accuracy: 0.8856\n",
      "4279/4279 [==============================] - 17s 4ms/step - loss: 0.0998 - accuracy: 0.9873\n",
      "1721/1721 [==============================] - 7s 4ms/step - loss: 0.2868 - accuracy: 0.9021\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 5s 242ms/step - loss: 0.0265 - accuracy: 0.9890 - val_loss: 0.3048 - val_accuracy: 0.8477\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 4s 225ms/step - loss: 0.0243 - accuracy: 0.9912 - val_loss: 0.1726 - val_accuracy: 0.9696\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 5s 228ms/step - loss: 0.0238 - accuracy: 0.9913 - val_loss: 0.2763 - val_accuracy: 0.8702\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 4s 219ms/step - loss: 0.0229 - accuracy: 0.9917 - val_loss: 0.2576 - val_accuracy: 0.8872\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 4s 220ms/step - loss: 0.0226 - accuracy: 0.9917 - val_loss: 0.2988 - val_accuracy: 0.8314\n",
      "Epoch 1/5\n",
      "54/54 [==============================] - 13s 239ms/step - loss: 0.5287 - accuracy: 0.8605 - val_loss: 0.3980 - val_accuracy: 0.8687\n",
      "Epoch 2/5\n",
      "54/54 [==============================] - 13s 242ms/step - loss: 0.3931 - accuracy: 0.8690 - val_loss: 0.3906 - val_accuracy: 0.8688\n",
      "Epoch 3/5\n",
      "54/54 [==============================] - 13s 243ms/step - loss: 0.3896 - accuracy: 0.8692 - val_loss: 0.3885 - val_accuracy: 0.8691\n",
      "Epoch 4/5\n",
      "54/54 [==============================] - 13s 244ms/step - loss: 0.3883 - accuracy: 0.8695 - val_loss: 0.3894 - val_accuracy: 0.8697\n",
      "Epoch 5/5\n",
      "54/54 [==============================] - 13s 248ms/step - loss: 0.3878 - accuracy: 0.8696 - val_loss: 0.3875 - val_accuracy: 0.8699\n",
      "Epoch 1/5\n",
      "79/79 [==============================] - 20s 256ms/step - loss: 0.0215 - accuracy: 0.9950 - val_loss: 0.1689 - val_accuracy: 0.9024\n",
      "Epoch 2/5\n",
      "79/79 [==============================] - 20s 259ms/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 0.2737 - val_accuracy: 0.8673\n",
      "Epoch 3/5\n",
      "79/79 [==============================] - 20s 254ms/step - loss: 0.0130 - accuracy: 0.9959 - val_loss: 0.2357 - val_accuracy: 0.8896\n",
      "Epoch 4/5\n",
      "79/79 [==============================] - 20s 257ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 0.2676 - val_accuracy: 0.8854\n",
      "Epoch 5/5\n",
      "79/79 [==============================] - 20s 257ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.3103 - val_accuracy: 0.8783\n",
      "4279/4279 [==============================] - 21s 5ms/step - loss: 0.1565 - accuracy: 0.9864\n",
      "1721/1721 [==============================] - 9s 5ms/step - loss: 0.3756 - accuracy: 0.8682\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        else:\n",
    "            x, y = x3, y3\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr253Gavg.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.060935135930776596, 0.15702813863754272], [0.09976464509963989, 0.2867684066295624], [0.15649591386318207, 0.3756396770477295]]\n",
      "Accuracy for iterations:  [[0.9877881407737732, 0.9371866583824158], [0.9872987866401672, 0.90207439661026], [0.9864296317100525, 0.8681973218917847]]\n",
      "F1 for iterations:  [[0.9877931826222887, 0.9367851562505448], [0.9873033816435282, 0.9005431200450676], [0.9864313300484122, 0.8643057549560927]]\n",
      "Precision for iterations:  [[0.9879373458999762, 0.9393157774336919], [0.9874095350750886, 0.9101737793375498], [0.986443035436232, 0.886921073906556]]\n",
      "Recall for iterations:  [[0.9877881328697887, 0.9371866598851994], [0.9872987817347862, 0.9020744023832014], [0.9864296356890356, 0.8681973406960691]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3G 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3796/951321220.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr50%23G-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3796/951321220.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr50%23G-Part3.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr50%23G-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr50%23G-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr50%23G-Part3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "node_datasets = [training1, training2, training3]\n",
    "num_nodes = 3\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr503Gavg.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20/20 [==============================] - 5s 250ms/step - loss: 0.5215 - accuracy: 0.9168 - val_loss: 1.6026 - val_accuracy: 0.1469\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 5s 236ms/step - loss: 0.1918 - accuracy: 0.9485 - val_loss: 1.2337 - val_accuracy: 0.1804\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 5s 233ms/step - loss: 0.0811 - accuracy: 0.9772 - val_loss: 0.5493 - val_accuracy: 0.7746\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 5s 234ms/step - loss: 0.0549 - accuracy: 0.9805 - val_loss: 0.4581 - val_accuracy: 0.8127\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 5s 240ms/step - loss: 0.0465 - accuracy: 0.9844 - val_loss: 0.4765 - val_accuracy: 0.8006\n",
      "Epoch 1/5\n",
      "54/54 [==============================] - 14s 253ms/step - loss: 0.7051 - accuracy: 0.7324 - val_loss: 0.5756 - val_accuracy: 0.7452\n",
      "Epoch 2/5\n",
      "54/54 [==============================] - 15s 274ms/step - loss: 0.5740 - accuracy: 0.7457 - val_loss: 0.5715 - val_accuracy: 0.7458\n",
      "Epoch 3/5\n",
      "54/54 [==============================] - 17s 317ms/step - loss: 0.5720 - accuracy: 0.7456 - val_loss: 0.5699 - val_accuracy: 0.7458\n",
      "Epoch 4/5\n",
      "54/54 [==============================] - 15s 277ms/step - loss: 0.5707 - accuracy: 0.7456 - val_loss: 0.5690 - val_accuracy: 0.7459\n",
      "Epoch 5/5\n",
      "54/54 [==============================] - 14s 266ms/step - loss: 0.5699 - accuracy: 0.7457 - val_loss: 0.5696 - val_accuracy: 0.7463\n",
      "Epoch 1/5\n",
      "79/79 [==============================] - 21s 263ms/step - loss: 0.0475 - accuracy: 0.9908 - val_loss: 0.2338 - val_accuracy: 0.8379\n",
      "Epoch 2/5\n",
      "79/79 [==============================] - 19s 244ms/step - loss: 0.0211 - accuracy: 0.9920 - val_loss: 0.2192 - val_accuracy: 0.8452\n",
      "Epoch 3/5\n",
      "79/79 [==============================] - 19s 244ms/step - loss: 0.0190 - accuracy: 0.9933 - val_loss: 0.2046 - val_accuracy: 0.8658\n",
      "Epoch 4/5\n",
      "79/79 [==============================] - 19s 242ms/step - loss: 0.0171 - accuracy: 0.9941 - val_loss: 0.2048 - val_accuracy: 0.8694\n",
      "Epoch 5/5\n",
      "79/79 [==============================] - 20s 248ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.1998 - val_accuracy: 0.8811\n",
      "4279/4279 [==============================] - 20s 5ms/step - loss: 0.0558 - accuracy: 0.9883\n",
      "1721/1721 [==============================] - 8s 5ms/step - loss: 0.1168 - accuracy: 0.9602\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 5s 238ms/step - loss: 0.0277 - accuracy: 0.9894 - val_loss: 0.3348 - val_accuracy: 0.8640\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 5s 247ms/step - loss: 0.0259 - accuracy: 0.9901 - val_loss: 0.3457 - val_accuracy: 0.8260\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 5s 238ms/step - loss: 0.0251 - accuracy: 0.9906 - val_loss: 0.1890 - val_accuracy: 0.9607\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 5s 240ms/step - loss: 0.0246 - accuracy: 0.9909 - val_loss: 0.2258 - val_accuracy: 0.9251\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 5s 247ms/step - loss: 0.0240 - accuracy: 0.9912 - val_loss: 0.2914 - val_accuracy: 0.8605\n",
      "Epoch 1/5\n",
      "54/54 [==============================] - 14s 268ms/step - loss: 0.9210 - accuracy: 0.7168 - val_loss: 0.6007 - val_accuracy: 0.7390\n",
      "Epoch 2/5\n",
      "54/54 [==============================] - 14s 265ms/step - loss: 0.5821 - accuracy: 0.7444 - val_loss: 0.5722 - val_accuracy: 0.7464\n",
      "Epoch 3/5\n",
      "54/54 [==============================] - 14s 262ms/step - loss: 0.5726 - accuracy: 0.7458 - val_loss: 0.5699 - val_accuracy: 0.7465\n",
      "Epoch 4/5\n",
      "54/54 [==============================] - 15s 279ms/step - loss: 0.5705 - accuracy: 0.7461 - val_loss: 0.5682 - val_accuracy: 0.7465\n",
      "Epoch 5/5\n",
      "54/54 [==============================] - 15s 275ms/step - loss: 0.5692 - accuracy: 0.7461 - val_loss: 0.5679 - val_accuracy: 0.7465\n",
      "Epoch 1/5\n",
      "79/79 [==============================] - 20s 255ms/step - loss: 0.0382 - accuracy: 0.9941 - val_loss: 0.1639 - val_accuracy: 0.8966\n",
      "Epoch 2/5\n",
      "79/79 [==============================] - 21s 262ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.3108 - val_accuracy: 0.8267\n",
      "Epoch 3/5\n",
      "79/79 [==============================] - 21s 261ms/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.2166 - val_accuracy: 0.8844\n",
      "Epoch 4/5\n",
      "79/79 [==============================] - 20s 254ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.2954 - val_accuracy: 0.8579\n",
      "Epoch 5/5\n",
      "79/79 [==============================] - 21s 264ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.2452 - val_accuracy: 0.8834\n",
      "4279/4279 [==============================] - 23s 5ms/step - loss: 0.0627 - accuracy: 0.9891\n",
      "1721/1721 [==============================] - 9s 5ms/step - loss: 0.2061 - accuracy: 0.9224\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 5s 272ms/step - loss: 0.0257 - accuracy: 0.9898 - val_loss: 0.3876 - val_accuracy: 0.7478\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 5s 273ms/step - loss: 0.0238 - accuracy: 0.9909 - val_loss: 0.2216 - val_accuracy: 0.9246\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 5s 265ms/step - loss: 0.0230 - accuracy: 0.9915 - val_loss: 0.2845 - val_accuracy: 0.8446\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 5s 250ms/step - loss: 0.0225 - accuracy: 0.9919 - val_loss: 0.3422 - val_accuracy: 0.7893\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 5s 267ms/step - loss: 0.0222 - accuracy: 0.9916 - val_loss: 0.1389 - val_accuracy: 0.9756\n",
      "Epoch 1/5\n",
      "54/54 [==============================] - 15s 281ms/step - loss: 0.8910 - accuracy: 0.7251 - val_loss: 0.5834 - val_accuracy: 0.7446\n",
      "Epoch 2/5\n",
      "54/54 [==============================] - 15s 282ms/step - loss: 0.5758 - accuracy: 0.7458 - val_loss: 0.5720 - val_accuracy: 0.7466\n",
      "Epoch 3/5\n",
      "54/54 [==============================] - 15s 286ms/step - loss: 0.5707 - accuracy: 0.7461 - val_loss: 0.5689 - val_accuracy: 0.7466\n",
      "Epoch 4/5\n",
      "54/54 [==============================] - 15s 287ms/step - loss: 0.5689 - accuracy: 0.7462 - val_loss: 0.5676 - val_accuracy: 0.7467\n",
      "Epoch 5/5\n",
      "54/54 [==============================] - 15s 285ms/step - loss: 0.5680 - accuracy: 0.7463 - val_loss: 0.5669 - val_accuracy: 0.7466\n",
      "Epoch 1/5\n",
      "79/79 [==============================] - 20s 258ms/step - loss: 0.0362 - accuracy: 0.9950 - val_loss: 0.2137 - val_accuracy: 0.8789\n",
      "Epoch 2/5\n",
      "79/79 [==============================] - 21s 266ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 0.2067 - val_accuracy: 0.8937\n",
      "Epoch 3/5\n",
      "79/79 [==============================] - 21s 270ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.1721 - val_accuracy: 0.9058\n",
      "Epoch 4/5\n",
      "79/79 [==============================] - 21s 271ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 0.2203 - val_accuracy: 0.8975\n",
      "Epoch 5/5\n",
      "79/79 [==============================] - 22s 282ms/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 0.3070 - val_accuracy: 0.8760\n",
      "4279/4279 [==============================] - 22s 5ms/step - loss: 0.0947 - accuracy: 0.9890\n",
      "1721/1721 [==============================] - 9s 5ms/step - loss: 0.3455 - accuracy: 0.8677\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        else:\n",
    "            x, y = x3, y3\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr503Gavg.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.05575968325138092, 0.11677917838096619], [0.06265713274478912, 0.20614604651927948], [0.09469029307365417, 0.34547773003578186]]\n",
      "Accuracy for iterations:  [[0.9883213043212891, 0.9602376222610474], [0.9891027808189392, 0.9223642945289612], [0.9889713525772095, 0.8676705956459045]]\n",
      "F1 for iterations:  [[0.9883261113387183, 0.9601533630651375], [0.9891066536238714, 0.9215314952400294], [0.9889740519129036, 0.8636963260637445]]\n",
      "Precision for iterations:  [[0.9884684140142277, 0.9605227937723785], [0.9892063168439134, 0.9272031121527623], [0.9890192719638692, 0.886847151134282]]\n",
      "Recall for iterations:  [[0.988321306494493, 0.9602375935479184], [0.9891028075608402, 0.9223643101068081], [0.988971340091735, 0.8676705660103176]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORRUPTION WITH 5 NODES \n",
    "Trying aggregation functions with corrupted partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEDAVG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    # Calculate mean gradient for each layer\n",
    "    mean_grad = [tf.reduce_mean(layer_grads, axis=0) for layer_grads in zip(*grad_list)]\n",
    "    \n",
    "    return mean_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_21336/3836997398.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n"
     ]
    }
   ],
   "source": [
    "test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n",
    "test_plus = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test+.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5A 5% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3632/3687049449.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3632/3687049449.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3632/3687049449.py:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part4.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3632/3687049449.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr55Aavg.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 190ms/step - loss: 0.4766 - accuracy: 0.8151 - val_loss: 0.2719 - val_accuracy: 0.8733\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 176ms/step - loss: 0.1992 - accuracy: 0.9477 - val_loss: 0.1789 - val_accuracy: 0.9603\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 202ms/step - loss: 0.1656 - accuracy: 0.9651 - val_loss: 0.1630 - val_accuracy: 0.9632\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 193ms/step - loss: 0.1541 - accuracy: 0.9661 - val_loss: 0.1539 - val_accuracy: 0.9642\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 197ms/step - loss: 0.1469 - accuracy: 0.9674 - val_loss: 0.1490 - val_accuracy: 0.9655\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 218ms/step - loss: 0.0334 - accuracy: 0.9900 - val_loss: 0.5704 - val_accuracy: 0.6368\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 202ms/step - loss: 0.0235 - accuracy: 0.9912 - val_loss: 0.3290 - val_accuracy: 0.7542\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 215ms/step - loss: 0.0218 - accuracy: 0.9914 - val_loss: 0.3736 - val_accuracy: 0.6864\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 192ms/step - loss: 0.0206 - accuracy: 0.9924 - val_loss: 0.3092 - val_accuracy: 0.7617\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 203ms/step - loss: 0.0197 - accuracy: 0.9931 - val_loss: 0.3790 - val_accuracy: 0.7039\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 206ms/step - loss: 0.0200 - accuracy: 0.9925 - val_loss: 0.3723 - val_accuracy: 0.7158\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 226ms/step - loss: 0.0176 - accuracy: 0.9937 - val_loss: 0.2804 - val_accuracy: 0.8120\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 201ms/step - loss: 0.0171 - accuracy: 0.9939 - val_loss: 0.3643 - val_accuracy: 0.7591\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 255ms/step - loss: 0.0163 - accuracy: 0.9944 - val_loss: 0.4181 - val_accuracy: 0.7486\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 212ms/step - loss: 0.0155 - accuracy: 0.9950 - val_loss: 0.4119 - val_accuracy: 0.7697\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 249ms/step - loss: 0.0163 - accuracy: 0.9948 - val_loss: 0.2625 - val_accuracy: 0.8402\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 198ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.2407 - val_accuracy: 0.8546\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 230ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.2814 - val_accuracy: 0.8415\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 192ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.2600 - val_accuracy: 0.8511\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 220ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.4628 - val_accuracy: 0.7932\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 245ms/step - loss: 0.0173 - accuracy: 0.9950 - val_loss: 0.2747 - val_accuracy: 0.8431\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 205ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.3593 - val_accuracy: 0.8208\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 202ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 0.2911 - val_accuracy: 0.8449\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 201ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.4623 - val_accuracy: 0.7921\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 200ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 0.4470 - val_accuracy: 0.7955\n",
      "4279/4279 [==============================] - 19s 4ms/step - loss: 0.0573 - accuracy: 0.9712\n",
      "1721/1721 [==============================] - 9s 5ms/step - loss: 0.3753 - accuracy: 0.8189\n",
      "4481/4481 [==============================] - 22s 5ms/step - loss: 0.1010 - accuracy: 0.9490\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 245ms/step - loss: 0.2126 - accuracy: 0.9640 - val_loss: 0.1733 - val_accuracy: 0.9659\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 200ms/step - loss: 0.1529 - accuracy: 0.9683 - val_loss: 0.1514 - val_accuracy: 0.9661\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 240ms/step - loss: 0.1414 - accuracy: 0.9685 - val_loss: 0.1465 - val_accuracy: 0.9662\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 208ms/step - loss: 0.1388 - accuracy: 0.9686 - val_loss: 0.1442 - val_accuracy: 0.9662\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 220ms/step - loss: 0.1377 - accuracy: 0.9686 - val_loss: 0.1435 - val_accuracy: 0.9664\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 239ms/step - loss: 0.0225 - accuracy: 0.9935 - val_loss: 0.3471 - val_accuracy: 0.7723\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 213ms/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.3164 - val_accuracy: 0.8131\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 222ms/step - loss: 0.0155 - accuracy: 0.9954 - val_loss: 0.3362 - val_accuracy: 0.8179\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 220ms/step - loss: 0.0150 - accuracy: 0.9955 - val_loss: 0.3501 - val_accuracy: 0.8205\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 221ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.3023 - val_accuracy: 0.8459\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 239ms/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 0.4161 - val_accuracy: 0.8084\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 204ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.2967 - val_accuracy: 0.8510\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 213ms/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 0.5254 - val_accuracy: 0.7869\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 226ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.3445 - val_accuracy: 0.8452\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 202ms/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 0.3803 - val_accuracy: 0.8391\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 235ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.4530 - val_accuracy: 0.8158\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 212ms/step - loss: 0.0138 - accuracy: 0.9961 - val_loss: 0.3530 - val_accuracy: 0.8427\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 233ms/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 0.3393 - val_accuracy: 0.8455\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 188ms/step - loss: 0.0132 - accuracy: 0.9959 - val_loss: 0.5864 - val_accuracy: 0.7788\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 224ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 0.4063 - val_accuracy: 0.8323\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 246ms/step - loss: 0.0126 - accuracy: 0.9964 - val_loss: 0.3806 - val_accuracy: 0.8423\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 192ms/step - loss: 0.0109 - accuracy: 0.9967 - val_loss: 0.5116 - val_accuracy: 0.7976\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 231ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.5630 - val_accuracy: 0.7839\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 200ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.4100 - val_accuracy: 0.8340\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 236ms/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 0.3817 - val_accuracy: 0.8418\n",
      "4279/4279 [==============================] - 23s 5ms/step - loss: 0.0576 - accuracy: 0.9732\n",
      "1721/1721 [==============================] - 9s 5ms/step - loss: 0.4194 - accuracy: 0.7767\n",
      "4481/4481 [==============================] - 22s 5ms/step - loss: 0.1007 - accuracy: 0.9523\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 244ms/step - loss: 0.1952 - accuracy: 0.9651 - val_loss: 0.1578 - val_accuracy: 0.9657\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 227ms/step - loss: 0.1428 - accuracy: 0.9685 - val_loss: 0.1470 - val_accuracy: 0.9660\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 214ms/step - loss: 0.1382 - accuracy: 0.9687 - val_loss: 0.1442 - val_accuracy: 0.9662\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 245ms/step - loss: 0.1366 - accuracy: 0.9687 - val_loss: 0.1428 - val_accuracy: 0.9664\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 213ms/step - loss: 0.1359 - accuracy: 0.9687 - val_loss: 0.1423 - val_accuracy: 0.9664\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 244ms/step - loss: 0.0186 - accuracy: 0.9948 - val_loss: 0.3020 - val_accuracy: 0.8409\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 220ms/step - loss: 0.0138 - accuracy: 0.9961 - val_loss: 0.4597 - val_accuracy: 0.7958\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 229ms/step - loss: 0.0139 - accuracy: 0.9961 - val_loss: 0.5241 - val_accuracy: 0.7794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 221ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 0.3242 - val_accuracy: 0.8515\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 213ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.5452 - val_accuracy: 0.7854\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 233ms/step - loss: 0.0123 - accuracy: 0.9965 - val_loss: 0.5045 - val_accuracy: 0.8106\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 225ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.3967 - val_accuracy: 0.8402\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 253ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.5048 - val_accuracy: 0.8120\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 201ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.4192 - val_accuracy: 0.8405\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 224ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 0.3829 - val_accuracy: 0.8495\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 206ms/step - loss: 0.0122 - accuracy: 0.9962 - val_loss: 0.3814 - val_accuracy: 0.8447\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 239ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.5669 - val_accuracy: 0.8017\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 223ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 0.4715 - val_accuracy: 0.8303\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 253ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.4455 - val_accuracy: 0.8401\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 200ms/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 0.4856 - val_accuracy: 0.8263\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 208ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.4968 - val_accuracy: 0.8305\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 239ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.4191 - val_accuracy: 0.8467\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 203ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 0.5240 - val_accuracy: 0.8105\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 255ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.4232 - val_accuracy: 0.8445\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 204ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.3986 - val_accuracy: 0.8475\n",
      "4279/4279 [==============================] - 23s 5ms/step - loss: 0.0611 - accuracy: 0.9739\n",
      "1721/1721 [==============================] - 8s 5ms/step - loss: 0.3516 - accuracy: 0.8171\n",
      "4481/4481 [==============================] - 24s 5ms/step - loss: 0.1045 - accuracy: 0.9538\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "    loss_complete, accuracy_complete, f1_complete, precision_complete, recall_complete = evaluation(global_model, xcomplete, ycomplete)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus, loss_complete])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus, accuracy_complete])\n",
    "    f1_it.append([f1_basic, f1_plus, f1_complete])\n",
    "    precision_it.append([precision_basic, precision_plus, precision_complete])\n",
    "    recall_it.append([recall_basic, recall_plus, recall_complete])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr55Aavg.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.057268597185611725, 0.3753368854522705, 0.10097719728946686], [0.05764966458082199, 0.41941025853157043, 0.10066546499729156], [0.06108490750193596, 0.3515525162220001, 0.1044953316450119]]\n",
      "Accuracy for iterations:  [[0.9712086319923401, 0.8188984990119934, 0.9490266442298889], [0.973151445388794, 0.7767383456230164, 0.952339768409729], [0.9738671779632568, 0.8170820474624634, 0.9537696242332458]]\n",
      "F1 for iterations:  [[0.9711589716015901, 0.8093341715665523, 0.9489296911792579], [0.9731106298506226, 0.7590747621452839, 0.9522625656682077], [0.9738287441158313, 0.8071441568178996, 0.9537007975221027]]\n",
      "Precision for iterations:  [[0.97202735364702, 0.8547832333134442, 0.9524616779800035], [0.9738223143211889, 0.8306946500689956, 0.9552843739652934], [0.9745054735122656, 0.8542347118500215, 0.9564842558409361]]\n",
      "Recall for iterations:  [[0.9712086242659733, 0.8188984959674489, 0.9490266375576311], [0.973151421309416, 0.7767383564629805, 0.9523397666162141], [0.9738671886412107, 0.8170820315338225, 0.9537696433678131]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5B 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3632/2463029928.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part1.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3632/2463029928.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3632/2463029928.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3632/2463029928.py:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part4.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3632/2463029928.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr105Aavg.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 197ms/step - loss: 0.4756 - accuracy: 0.8252 - val_loss: 0.2809 - val_accuracy: 0.9237\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 198ms/step - loss: 0.2623 - accuracy: 0.9305 - val_loss: 0.2468 - val_accuracy: 0.9396\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 171ms/step - loss: 0.2411 - accuracy: 0.9403 - val_loss: 0.2325 - val_accuracy: 0.9421\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 204ms/step - loss: 0.2299 - accuracy: 0.9423 - val_loss: 0.2248 - val_accuracy: 0.9426\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 173ms/step - loss: 0.2237 - accuracy: 0.9427 - val_loss: 0.2218 - val_accuracy: 0.9426\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 216ms/step - loss: 0.0401 - accuracy: 0.9892 - val_loss: 0.4594 - val_accuracy: 0.7053\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 187ms/step - loss: 0.0238 - accuracy: 0.9905 - val_loss: 0.4849 - val_accuracy: 0.6429\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0225 - accuracy: 0.9915 - val_loss: 0.2749 - val_accuracy: 0.8324\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 150ms/step - loss: 0.0214 - accuracy: 0.9918 - val_loss: 0.3502 - val_accuracy: 0.7151\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.0206 - accuracy: 0.9924 - val_loss: 0.3571 - val_accuracy: 0.7105\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.0204 - accuracy: 0.9926 - val_loss: 0.2307 - val_accuracy: 0.8781\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 0.0179 - accuracy: 0.9937 - val_loss: 0.3689 - val_accuracy: 0.7381\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.0169 - accuracy: 0.9940 - val_loss: 0.4623 - val_accuracy: 0.7201\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 188ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 0.2539 - val_accuracy: 0.8392\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 179ms/step - loss: 0.0150 - accuracy: 0.9950 - val_loss: 0.2210 - val_accuracy: 0.8667\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 196ms/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 0.3849 - val_accuracy: 0.7980\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 203ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 0.7724 - val_accuracy: 0.6986\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 201ms/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.3353 - val_accuracy: 0.8260\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 199ms/step - loss: 0.0147 - accuracy: 0.9957 - val_loss: 0.4024 - val_accuracy: 0.8124\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 206ms/step - loss: 0.0143 - accuracy: 0.9957 - val_loss: 0.3141 - val_accuracy: 0.8397\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 205ms/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 0.5212 - val_accuracy: 0.7731\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 197ms/step - loss: 0.0128 - accuracy: 0.9956 - val_loss: 0.4439 - val_accuracy: 0.7999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 203ms/step - loss: 0.0122 - accuracy: 0.9962 - val_loss: 0.3825 - val_accuracy: 0.8230\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 195ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 0.2785 - val_accuracy: 0.8545\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 194ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.3911 - val_accuracy: 0.8235\n",
      "4279/4279 [==============================] - 25s 6ms/step - loss: 0.0463 - accuracy: 0.9748\n",
      "1721/1721 [==============================] - 11s 6ms/step - loss: 0.2961 - accuracy: 0.8715\n",
      "4481/4481 [==============================] - 25s 6ms/step - loss: 0.0810 - accuracy: 0.9605\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 4s 145ms/step - loss: 0.3478 - accuracy: 0.9362 - val_loss: 0.2466 - val_accuracy: 0.9424\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 133ms/step - loss: 0.2328 - accuracy: 0.9426 - val_loss: 0.2203 - val_accuracy: 0.9430\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 133ms/step - loss: 0.2220 - accuracy: 0.9429 - val_loss: 0.2174 - val_accuracy: 0.9431\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 130ms/step - loss: 0.2196 - accuracy: 0.9433 - val_loss: 0.2159 - val_accuracy: 0.9429\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 132ms/step - loss: 0.2179 - accuracy: 0.9433 - val_loss: 0.2154 - val_accuracy: 0.9431\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 0.0269 - accuracy: 0.9935 - val_loss: 0.4216 - val_accuracy: 0.7203\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 0.3726 - val_accuracy: 0.7746\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 133ms/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 0.3011 - val_accuracy: 0.8305\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 136ms/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 0.3293 - val_accuracy: 0.8256\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 134ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.3422 - val_accuracy: 0.8261\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 4s 135ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.5984 - val_accuracy: 0.7449\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 0.4572 - val_accuracy: 0.7984\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 144ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.3630 - val_accuracy: 0.8328\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.4138 - val_accuracy: 0.8218\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.4900 - val_accuracy: 0.8050\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 4s 134ms/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 0.3595 - val_accuracy: 0.8400\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 143ms/step - loss: 0.0134 - accuracy: 0.9961 - val_loss: 0.4040 - val_accuracy: 0.8273\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 137ms/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.5139 - val_accuracy: 0.7985\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 136ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.4557 - val_accuracy: 0.8173\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.2806 - val_accuracy: 0.8628\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 4s 137ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.3527 - val_accuracy: 0.8528\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 134ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.4411 - val_accuracy: 0.8197\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.4569 - val_accuracy: 0.8143\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 138ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.4441 - val_accuracy: 0.8164\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 136ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.4142 - val_accuracy: 0.8279\n",
      "4279/4279 [==============================] - 27s 6ms/step - loss: 0.0562 - accuracy: 0.9732\n",
      "1721/1721 [==============================] - 10s 6ms/step - loss: 0.3545 - accuracy: 0.8227\n",
      "4481/4481 [==============================] - 29s 7ms/step - loss: 0.0997 - accuracy: 0.9526\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 146ms/step - loss: 0.3391 - accuracy: 0.9369 - val_loss: 0.2353 - val_accuracy: 0.9420\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 145ms/step - loss: 0.2267 - accuracy: 0.9425 - val_loss: 0.2200 - val_accuracy: 0.9429\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 0.2204 - accuracy: 0.9430 - val_loss: 0.2161 - val_accuracy: 0.9433\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.2180 - accuracy: 0.9433 - val_loss: 0.2158 - val_accuracy: 0.9431\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.2171 - accuracy: 0.9434 - val_loss: 0.2150 - val_accuracy: 0.9434\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 150ms/step - loss: 0.0219 - accuracy: 0.9947 - val_loss: 0.3711 - val_accuracy: 0.7899\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 151ms/step - loss: 0.0144 - accuracy: 0.9958 - val_loss: 0.2387 - val_accuracy: 0.8699\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 144ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 0.4844 - val_accuracy: 0.7832\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.4098 - val_accuracy: 0.8228\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 144ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.4516 - val_accuracy: 0.8108\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 151ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.3937 - val_accuracy: 0.8321\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 145ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.4416 - val_accuracy: 0.8237\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.4860 - val_accuracy: 0.8182\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.4054 - val_accuracy: 0.8475\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 0.5123 - val_accuracy: 0.8160\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 146ms/step - loss: 0.0120 - accuracy: 0.9966 - val_loss: 0.4905 - val_accuracy: 0.8247\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 0.0116 - accuracy: 0.9965 - val_loss: 0.4988 - val_accuracy: 0.8242\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.3280 - val_accuracy: 0.8622\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 150ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.3450 - val_accuracy: 0.8620\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.4878 - val_accuracy: 0.8319\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 151ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 0.5092 - val_accuracy: 0.8287\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.3968 - val_accuracy: 0.8546\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.4044 - val_accuracy: 0.8534\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.4768 - val_accuracy: 0.8263\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 151ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.5080 - val_accuracy: 0.8217\n",
      "4279/4279 [==============================] - 39s 9ms/step - loss: 0.0697 - accuracy: 0.9721\n",
      "1721/1721 [==============================] - 14s 8ms/step - loss: 0.3469 - accuracy: 0.8180\n",
      "   1/4481 [..............................] - ETA: 0s - loss: 0.0502 - accuracy: 0.9688WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0017s vs `on_test_batch_end` time: 0.0025s). Check your callbacks.\n",
      "4481/4481 [==============================] - 33s 7ms/step - loss: 0.1199 - accuracy: 0.9481\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "    loss_complete, accuracy_complete, f1_complete, precision_complete, recall_complete = evaluation(global_model, xcomplete, ycomplete)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus, loss_complete])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus, accuracy_complete])\n",
    "    f1_it.append([f1_basic, f1_plus, f1_complete])\n",
    "    precision_it.append([precision_basic, precision_plus, precision_complete])\n",
    "    recall_it.append([recall_basic, recall_plus, recall_complete])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr105Aavg.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.04630370810627937, 0.2961485683917999, 0.08095862716436386], [0.05615843087434769, 0.354496031999588, 0.0996839851140976], [0.06967361271381378, 0.34686166048049927, 0.11991321295499802]]\n",
      "Accuracy for iterations:  [[0.9747874736785889, 0.8715214729309082, 0.9604726433753967], [0.9732463955879211, 0.8227493762969971, 0.9525769352912903], [0.9721288681030273, 0.818026602268219, 0.9481198787689209]]\n",
      "F1 for iterations:  [[0.974757759749822, 0.8680192371760987, 0.9604370790274662], [0.9732060844610915, 0.8137439255545337, 0.9525021677645069], [0.9720787442227808, 0.8081970449083345, 0.9480122187614385]]\n",
      "Precision for iterations:  [[0.9752270522777416, 0.8883265478611913, 0.962133143647721], [0.9739076775914974, 0.8572247322687857, 0.9554433831880542], [0.9730108896022659, 0.855030812765311, 0.9518625471736178]]\n",
      "Recall for iterations:  [[0.9747874609249467, 0.8715214706096055, 0.9604726265789676], [0.973246370037103, 0.822749400566737, 0.9525769169067232], [0.9721288965497094, 0.8180265930393082, 0.9481198864468608]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5B 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3632/3855986297.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3632/3855986297.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3632/3855986297.py:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part4.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3632/3855986297.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr255Aavg.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 151ms/step - loss: 0.4503 - accuracy: 0.8421 - val_loss: 0.2403 - val_accuracy: 0.8733\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 143ms/step - loss: 0.1548 - accuracy: 0.9588 - val_loss: 0.1204 - val_accuracy: 0.9766\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.1129 - accuracy: 0.9773 - val_loss: 0.1089 - val_accuracy: 0.9784\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 0.1032 - accuracy: 0.9792 - val_loss: 0.1059 - val_accuracy: 0.9787\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 0.0995 - accuracy: 0.9797 - val_loss: 0.0998 - val_accuracy: 0.9788\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 0.0315 - accuracy: 0.9900 - val_loss: 0.4291 - val_accuracy: 0.6994\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 143ms/step - loss: 0.0222 - accuracy: 0.9910 - val_loss: 0.3429 - val_accuracy: 0.7270\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.0211 - accuracy: 0.9921 - val_loss: 0.3265 - val_accuracy: 0.7396\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 146ms/step - loss: 0.0197 - accuracy: 0.9929 - val_loss: 0.3090 - val_accuracy: 0.7610\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 138ms/step - loss: 0.0191 - accuracy: 0.9934 - val_loss: 0.3342 - val_accuracy: 0.7545\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 146ms/step - loss: 0.0189 - accuracy: 0.9934 - val_loss: 0.4015 - val_accuracy: 0.7234\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 0.0170 - accuracy: 0.9939 - val_loss: 0.2621 - val_accuracy: 0.8257\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 145ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 0.3701 - val_accuracy: 0.7728\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 0.4767 - val_accuracy: 0.7498\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.4405 - val_accuracy: 0.7761\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 150ms/step - loss: 0.0156 - accuracy: 0.9950 - val_loss: 0.2372 - val_accuracy: 0.8564\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 0.0152 - accuracy: 0.9955 - val_loss: 0.2157 - val_accuracy: 0.8655\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 0.3102 - val_accuracy: 0.8383\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 150ms/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.3275 - val_accuracy: 0.8356\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.4543 - val_accuracy: 0.8024\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 0.0160 - accuracy: 0.9954 - val_loss: 0.3631 - val_accuracy: 0.8235\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 144ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 0.5638 - val_accuracy: 0.7626\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 0.4080 - val_accuracy: 0.8178\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 0.4025 - val_accuracy: 0.8199\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.2538 - val_accuracy: 0.8632\n",
      "4279/4279 [==============================] - 40s 9ms/step - loss: 0.0383 - accuracy: 0.9821\n",
      "1721/1721 [==============================] - 15s 9ms/step - loss: 0.2670 - accuracy: 0.8665\n",
      "4481/4481 [==============================] - 38s 9ms/step - loss: 0.0631 - accuracy: 0.9731\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.1246 - accuracy: 0.9791 - val_loss: 0.1033 - val_accuracy: 0.9793\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.0975 - accuracy: 0.9805 - val_loss: 0.0954 - val_accuracy: 0.9798\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.0916 - accuracy: 0.9806 - val_loss: 0.0939 - val_accuracy: 0.9798\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.0904 - accuracy: 0.9806 - val_loss: 0.0928 - val_accuracy: 0.9798\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 0.0893 - accuracy: 0.9806 - val_loss: 0.0925 - val_accuracy: 0.9797\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 181ms/step - loss: 0.0211 - accuracy: 0.9937 - val_loss: 0.2753 - val_accuracy: 0.8338\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.2613 - val_accuracy: 0.8495\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.3871 - val_accuracy: 0.7996\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 145ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.2702 - val_accuracy: 0.8534\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.3426 - val_accuracy: 0.8353\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.5865 - val_accuracy: 0.7522\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 0.4793 - val_accuracy: 0.7944\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 144ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.3819 - val_accuracy: 0.8335\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.3418 - val_accuracy: 0.8496\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.0125 - accuracy: 0.9962 - val_loss: 0.5410 - val_accuracy: 0.7931\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.4030 - val_accuracy: 0.8344\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 145ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.3197 - val_accuracy: 0.8529\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.4010 - val_accuracy: 0.8344\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.3976 - val_accuracy: 0.8391\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.4223 - val_accuracy: 0.8317\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.4860 - val_accuracy: 0.8157\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.5650 - val_accuracy: 0.7854\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 151ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.3441 - val_accuracy: 0.8527\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.4380 - val_accuracy: 0.8277\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.3533 - val_accuracy: 0.8500\n",
      "4279/4279 [==============================] - 37s 9ms/step - loss: 0.0534 - accuracy: 0.9747\n",
      "1721/1721 [==============================] - 9s 5ms/step - loss: 0.4717 - accuracy: 0.7648\n",
      "4481/4481 [==============================] - 18s 4ms/step - loss: 0.0978 - accuracy: 0.9544\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.1272 - accuracy: 0.9782 - val_loss: 0.1012 - val_accuracy: 0.9792\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 0.0940 - accuracy: 0.9805 - val_loss: 0.0948 - val_accuracy: 0.9798\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 0.0901 - accuracy: 0.9807 - val_loss: 0.0927 - val_accuracy: 0.9798\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 181ms/step - loss: 0.0888 - accuracy: 0.9807 - val_loss: 0.0918 - val_accuracy: 0.9798\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.0882 - accuracy: 0.9806 - val_loss: 0.0913 - val_accuracy: 0.9798\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 173ms/step - loss: 0.0163 - accuracy: 0.9952 - val_loss: 0.3491 - val_accuracy: 0.8246\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 151ms/step - loss: 0.0141 - accuracy: 0.9961 - val_loss: 0.4235 - val_accuracy: 0.8146\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 0.0130 - accuracy: 0.9962 - val_loss: 0.3599 - val_accuracy: 0.8421\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 145ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 0.3495 - val_accuracy: 0.8490\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.0125 - accuracy: 0.9964 - val_loss: 0.3663 - val_accuracy: 0.8484\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 0.3312 - val_accuracy: 0.8558\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 170ms/step - loss: 0.0116 - accuracy: 0.9967 - val_loss: 0.5117 - val_accuracy: 0.8085\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 0.0114 - accuracy: 0.9967 - val_loss: 0.4153 - val_accuracy: 0.8374\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 180ms/step - loss: 0.0109 - accuracy: 0.9967 - val_loss: 0.4173 - val_accuracy: 0.8423\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 175ms/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 0.4927 - val_accuracy: 0.8239\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.4715 - val_accuracy: 0.8252\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.4790 - val_accuracy: 0.8269\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.6272 - val_accuracy: 0.7931\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 179ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.3501 - val_accuracy: 0.8576\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 183ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.4492 - val_accuracy: 0.8368\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 151ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.4718 - val_accuracy: 0.8365\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.4546 - val_accuracy: 0.8400\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 171ms/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.4206 - val_accuracy: 0.8449\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.5706 - val_accuracy: 0.8070\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 172ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.4529 - val_accuracy: 0.8371\n",
      "4279/4279 [==============================] - 19s 4ms/step - loss: 0.0682 - accuracy: 0.9727\n",
      "1721/1721 [==============================] - 10s 6ms/step - loss: 0.5264 - accuracy: 0.7612\n",
      "4481/4481 [==============================] - 20s 4ms/step - loss: 0.1186 - accuracy: 0.9489\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "    loss_complete, accuracy_complete, f1_complete, precision_complete, recall_complete = evaluation(global_model, xcomplete, ycomplete)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus, loss_complete])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus, accuracy_complete])\n",
    "    f1_it.append([f1_basic, f1_plus, f1_complete])\n",
    "    precision_it.append([precision_basic, precision_plus, precision_complete])\n",
    "    recall_it.append([recall_basic, recall_plus, recall_complete])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr255Aavg.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.038302790373563766, 0.26699161529541016, 0.06310313194990158], [0.05338504537940025, 0.47174960374832153, 0.0978168398141861], [0.06824193894863129, 0.526358962059021, 0.11863312870264053]]\n",
      "Accuracy for iterations:  [[0.9821496605873108, 0.866526186466217, 0.9731322526931763], [0.9747143983840942, 0.7648223638534546, 0.9543625116348267], [0.9727351069450378, 0.7611894011497498, 0.9489429593086243]]\n",
      "F1 for iterations:  [[0.9821416331704106, 0.862501294144424, 0.9731255387637722], [0.9746795893900647, 0.7440076146052567, 0.9542961958400812], [0.9726884720031634, 0.739239173421521, 0.9488402715885467]]\n",
      "Precision for iterations:  [[0.9822282656806147, 0.8857129164601596, 0.9736063429562448], [0.9752887653650251, 0.8252473062361781, 0.9570148065656969], [0.9735495269555791, 0.8241365933145408, 0.952575202778001]]\n",
      "Recall for iterations:  [[0.9821496391948348, 0.8665261934171329, 0.9731322670870272], [0.9747144234421105, 0.7648223497783914, 0.9543625190940859], [0.9727351076572497, 0.7611894209111386, 0.9489429374550984]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5B 5% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3632/3503541895.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3632/3503541895.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_3632/3503541895.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr55Bavg.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3632/2913529406.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3632/2575831635.py\u001b[0m in \u001b[0;36mpreprocessing\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m# Ports\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mdata_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sport'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sport'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'0x'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m\"0x\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[0mdata_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dsport'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dsport'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'0x'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m\"0x\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\UX430\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4431\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4432\u001b[0m         \"\"\"\n\u001b[1;32m-> 4433\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4435\u001b[0m     def _reduce(\n",
      "\u001b[1;32mc:\\Users\\UX430\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1086\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1088\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1089\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\UX430\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1141\u001b[0m                 \u001b[1;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m                 \u001b[1;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1143\u001b[1;33m                 mapped = lib.map_infer(\n\u001b[0m\u001b[0;32m   1144\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\UX430\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3632/2575831635.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m# Ports\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mdata_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sport'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sport'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'0x'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m\"0x\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[0mdata_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dsport'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dsport'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'0x'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m\"0x\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.4760 - accuracy: 0.8449 - val_loss: 0.2409 - val_accuracy: 0.9336\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.1978 - accuracy: 0.9499 - val_loss: 0.1725 - val_accuracy: 0.9616\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.1666 - accuracy: 0.9646 - val_loss: 0.1585 - val_accuracy: 0.9646\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.1535 - accuracy: 0.9671 - val_loss: 0.1502 - val_accuracy: 0.9660\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.1464 - accuracy: 0.9676 - val_loss: 0.1467 - val_accuracy: 0.9658\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0344 - accuracy: 0.9901 - val_loss: 0.4782 - val_accuracy: 0.6849\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0227 - accuracy: 0.9915 - val_loss: 0.3628 - val_accuracy: 0.7081\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0212 - accuracy: 0.9924 - val_loss: 0.4268 - val_accuracy: 0.6687\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0202 - accuracy: 0.9929 - val_loss: 0.3253 - val_accuracy: 0.7425\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0191 - accuracy: 0.9938 - val_loss: 0.3766 - val_accuracy: 0.7227\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 186ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 4.9879 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 166ms/step - loss: 1.3970e-07 - accuracy: 1.0000 - val_loss: 5.3212 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 169ms/step - loss: 1.0400e-07 - accuracy: 1.0000 - val_loss: 5.3388 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 170ms/step - loss: 1.0241e-07 - accuracy: 1.0000 - val_loss: 5.3405 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 1.0212e-07 - accuracy: 1.0000 - val_loss: 5.3416 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 170ms/step - loss: 4.3514 - accuracy: 0.4950 - val_loss: 0.0197 - val_accuracy: 0.9954\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 178ms/step - loss: 4.8870e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 171ms/step - loss: 3.7354e-04 - accuracy: 1.0000 - val_loss: 9.7477e-04 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 195ms/step - loss: 2.9455e-04 - accuracy: 1.0000 - val_loss: 7.6120e-04 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 166ms/step - loss: 1.7240 - accuracy: 0.7016 - val_loss: 0.8968 - val_accuracy: 0.6291\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.0405 - accuracy: 0.9944 - val_loss: 0.6452 - val_accuracy: 0.6383\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 201ms/step - loss: 0.0222 - accuracy: 0.9942 - val_loss: 0.6087 - val_accuracy: 0.6385\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 173ms/step - loss: 0.0205 - accuracy: 0.9942 - val_loss: 0.6143 - val_accuracy: 0.6383\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0195 - accuracy: 0.9942 - val_loss: 0.6133 - val_accuracy: 0.6379\n",
      "4279/4279 [==============================] - 13s 3ms/step - loss: 0.1112 - accuracy: 0.9246\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.2568 - accuracy: 0.8308\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.1522 - accuracy: 0.9661 - val_loss: 0.1462 - val_accuracy: 0.9657\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 0.1416 - accuracy: 0.9675 - val_loss: 0.1427 - val_accuracy: 0.9660\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 151ms/step - loss: 0.1397 - accuracy: 0.9676 - val_loss: 0.1431 - val_accuracy: 0.9660\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 0.1383 - accuracy: 0.9676 - val_loss: 0.1416 - val_accuracy: 0.9660\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 0.1376 - accuracy: 0.9677 - val_loss: 0.1416 - val_accuracy: 0.9664\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.0234 - accuracy: 0.9928 - val_loss: 0.4163 - val_accuracy: 0.7033\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.0192 - accuracy: 0.9938 - val_loss: 0.4030 - val_accuracy: 0.7305\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.3277 - val_accuracy: 0.7852\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.1744 - val_accuracy: 0.8844\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0163 - accuracy: 0.9944 - val_loss: 0.2512 - val_accuracy: 0.8372\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.0163 - accuracy: 0.9929 - val_loss: 4.5307 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 5.3453e-07 - accuracy: 1.0000 - val_loss: 4.8680 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 3.9591e-07 - accuracy: 1.0000 - val_loss: 4.8864 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 3.8912e-07 - accuracy: 1.0000 - val_loss: 4.8887 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 169ms/step - loss: 3.8742e-07 - accuracy: 1.0000 - val_loss: 4.8903 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 4.3898 - accuracy: 0.4696 - val_loss: 0.1327 - val_accuracy: 0.9017\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 180ms/step - loss: 0.0221 - accuracy: 0.9939 - val_loss: 0.0048 - val_accuracy: 0.9995\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 9.3730e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 5.9676e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 4s 137ms/step - loss: 1.4795 - accuracy: 0.7320 - val_loss: 0.7220 - val_accuracy: 0.6674\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 0.0234 - accuracy: 0.9947 - val_loss: 0.4315 - val_accuracy: 0.7118\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 145ms/step - loss: 0.0165 - accuracy: 0.9944 - val_loss: 0.4764 - val_accuracy: 0.6995\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 0.5198 - val_accuracy: 0.6911\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 0.0159 - accuracy: 0.9946 - val_loss: 0.5025 - val_accuracy: 0.6962\n",
      "4279/4279 [==============================] - 28s 6ms/step - loss: 0.0874 - accuracy: 0.9471\n",
      "1721/1721 [==============================] - 11s 7ms/step - loss: 0.2411 - accuracy: 0.8625\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 4s 137ms/step - loss: 0.1422 - accuracy: 0.9677 - val_loss: 0.1410 - val_accuracy: 0.9658\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 135ms/step - loss: 0.1370 - accuracy: 0.9679 - val_loss: 0.1403 - val_accuracy: 0.9665\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 138ms/step - loss: 0.1359 - accuracy: 0.9684 - val_loss: 0.1403 - val_accuracy: 0.9664\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 132ms/step - loss: 0.1358 - accuracy: 0.9684 - val_loss: 0.1401 - val_accuracy: 0.9667\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 138ms/step - loss: 0.1353 - accuracy: 0.9685 - val_loss: 0.1397 - val_accuracy: 0.9667\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.0223 - accuracy: 0.9938 - val_loss: 0.2492 - val_accuracy: 0.8355\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 133ms/step - loss: 0.0179 - accuracy: 0.9947 - val_loss: 0.4135 - val_accuracy: 0.7575\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 135ms/step - loss: 0.0168 - accuracy: 0.9946 - val_loss: 0.3379 - val_accuracy: 0.8024\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 130ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 0.4164 - val_accuracy: 0.7849\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 134ms/step - loss: 0.0151 - accuracy: 0.9954 - val_loss: 0.2753 - val_accuracy: 0.8356\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.0321 - accuracy: 0.9862 - val_loss: 3.6012 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 143ms/step - loss: 5.3800e-06 - accuracy: 1.0000 - val_loss: 3.9445 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 166ms/step - loss: 3.9151e-06 - accuracy: 1.0000 - val_loss: 3.9706 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 3.7767e-06 - accuracy: 1.0000 - val_loss: 3.9815 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 150ms/step - loss: 3.6804e-06 - accuracy: 1.0000 - val_loss: 3.9929 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 4s 137ms/step - loss: 3.0162 - accuracy: 0.5492 - val_loss: 0.0874 - val_accuracy: 0.9728\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 138ms/step - loss: 0.0088 - accuracy: 0.9999 - val_loss: 0.0084 - val_accuracy: 0.9998\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 8.1452e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 151ms/step - loss: 4.8290e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.5317 - accuracy: 0.8589 - val_loss: 0.7667 - val_accuracy: 0.6944\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.0165 - accuracy: 0.9946 - val_loss: 0.4843 - val_accuracy: 0.7323\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 143ms/step - loss: 0.0153 - accuracy: 0.9946 - val_loss: 0.5553 - val_accuracy: 0.7211\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 150ms/step - loss: 0.0149 - accuracy: 0.9946 - val_loss: 0.5163 - val_accuracy: 0.7283\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 0.0146 - accuracy: 0.9947 - val_loss: 0.5064 - val_accuracy: 0.7315\n",
      "4279/4279 [==============================] - 18s 4ms/step - loss: 0.0776 - accuracy: 0.9562\n",
      "1721/1721 [==============================] - 9s 5ms/step - loss: 0.2283 - accuracy: 0.8849\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "    loss_complete, accuracy_complete, f1_complete, precision_complete, recall_complete = evaluation(global_model, xcomplete, ycomplete)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus, loss_complete])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus, accuracy_complete])\n",
    "    f1_it.append([f1_basic, f1_plus, f1_complete])\n",
    "    precision_it.append([precision_basic, precision_plus, precision_complete])\n",
    "    recall_it.append([recall_basic, recall_plus, recall_complete])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr55Bavg.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.11124108731746674, 0.2568061649799347], [0.08744512498378754, 0.24105194211006165], [0.07761744409799576, 0.22827744483947754]]\n",
      "Accuracy for iterations:  [[0.9245961308479309, 0.8307600021362305], [0.9471208453178406, 0.862529993057251], [0.9562432169914246, 0.8848906755447388]]\n",
      "F1 for iterations:  [[0.9238851317865417, 0.8231112554674732], [0.9468473069984635, 0.858249116698107], [0.9560772557703201, 0.8822572409757126]]\n",
      "Precision for iterations:  [[0.9330480634765211, 0.8607180094170204], [0.9510947077226397, 0.8822973812218775], [0.9588618004852771, 0.8985446903073606]]\n",
      "Recall for iterations:  [[0.9245961027199159, 0.8307600087190293], [0.9471208624265973, 0.8625299716631548], [0.9562432440328377, 0.8848906488410957]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5B 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16896/2097221778.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part1.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16896/2097221778.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16896/2097221778.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16896/2097221778.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr105Bavg.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 4s 138ms/step - loss: 0.4904 - accuracy: 0.8183 - val_loss: 0.2862 - val_accuracy: 0.9218\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.2706 - accuracy: 0.9273 - val_loss: 0.2487 - val_accuracy: 0.9396\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 138ms/step - loss: 0.2459 - accuracy: 0.9391 - val_loss: 0.2341 - val_accuracy: 0.9417\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 135ms/step - loss: 0.2323 - accuracy: 0.9412 - val_loss: 0.2234 - val_accuracy: 0.9429\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 137ms/step - loss: 0.2236 - accuracy: 0.9424 - val_loss: 0.2185 - val_accuracy: 0.9433\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.0379 - accuracy: 0.9899 - val_loss: 0.3268 - val_accuracy: 0.8140\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 143ms/step - loss: 0.0239 - accuracy: 0.9909 - val_loss: 0.3649 - val_accuracy: 0.7392\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 138ms/step - loss: 0.0224 - accuracy: 0.9918 - val_loss: 0.2432 - val_accuracy: 0.8682\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 136ms/step - loss: 0.0214 - accuracy: 0.9924 - val_loss: 0.2858 - val_accuracy: 0.8011\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 0.0207 - accuracy: 0.9928 - val_loss: 0.4167 - val_accuracy: 0.6899\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 4.1308 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 1.4399e-06 - accuracy: 1.0000 - val_loss: 4.4510 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 1.0753e-06 - accuracy: 1.0000 - val_loss: 4.4717 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 143ms/step - loss: 1.0500e-06 - accuracy: 1.0000 - val_loss: 4.4776 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 1.0358e-06 - accuracy: 1.0000 - val_loss: 4.4837 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 3.7130 - accuracy: 0.4824 - val_loss: 0.0165 - val_accuracy: 0.9975\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 151ms/step - loss: 7.1951e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 4.9142e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 3.1672e-04 - accuracy: 1.0000 - val_loss: 8.5004e-04 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 216ms/step - loss: 1.6130 - accuracy: 0.6911 - val_loss: 0.7662 - val_accuracy: 0.6345\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 199ms/step - loss: 0.0398 - accuracy: 0.9942 - val_loss: 0.5920 - val_accuracy: 0.6381\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 205ms/step - loss: 0.0231 - accuracy: 0.9942 - val_loss: 0.5676 - val_accuracy: 0.6384\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 197ms/step - loss: 0.0214 - accuracy: 0.9942 - val_loss: 0.5859 - val_accuracy: 0.6381\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 202ms/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 0.5825 - val_accuracy: 0.6378\n",
      "4279/4279 [==============================] - 32s 8ms/step - loss: 0.1147 - accuracy: 0.9250\n",
      "1721/1721 [==============================] - 14s 8ms/step - loss: 0.2322 - accuracy: 0.8733\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 215ms/step - loss: 0.2312 - accuracy: 0.9417 - val_loss: 0.2164 - val_accuracy: 0.9433\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 210ms/step - loss: 0.2190 - accuracy: 0.9425 - val_loss: 0.2146 - val_accuracy: 0.9433\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 203ms/step - loss: 0.2174 - accuracy: 0.9425 - val_loss: 0.2147 - val_accuracy: 0.9431\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 208ms/step - loss: 0.2166 - accuracy: 0.9426 - val_loss: 0.2154 - val_accuracy: 0.9431\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 206ms/step - loss: 0.2166 - accuracy: 0.9427 - val_loss: 0.2134 - val_accuracy: 0.9435\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 218ms/step - loss: 0.0248 - accuracy: 0.9929 - val_loss: 0.2844 - val_accuracy: 0.7975\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 208ms/step - loss: 0.0200 - accuracy: 0.9938 - val_loss: 0.3842 - val_accuracy: 0.7259\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 209ms/step - loss: 0.0189 - accuracy: 0.9940 - val_loss: 0.4059 - val_accuracy: 0.7301\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 195ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.3674 - val_accuracy: 0.7666\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 203ms/step - loss: 0.0171 - accuracy: 0.9944 - val_loss: 0.3887 - val_accuracy: 0.7736\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 0.0100 - accuracy: 0.9960 - val_loss: 4.0571 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 1.5012e-06 - accuracy: 1.0000 - val_loss: 4.3522 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 135ms/step - loss: 1.1577e-06 - accuracy: 1.0000 - val_loss: 4.3710 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 138ms/step - loss: 1.1327e-06 - accuracy: 1.0000 - val_loss: 4.3763 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 134ms/step - loss: 1.1194e-06 - accuracy: 1.0000 - val_loss: 4.3816 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 3.9911 - accuracy: 0.4603 - val_loss: 0.0820 - val_accuracy: 0.9800\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 143ms/step - loss: 9.3771e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 6.8118e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 5.3618e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 4s 145ms/step - loss: 1.3872 - accuracy: 0.7285 - val_loss: 0.6116 - val_accuracy: 0.6691\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.0255 - accuracy: 0.9946 - val_loss: 0.5478 - val_accuracy: 0.6747\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.4877 - val_accuracy: 0.6854\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.0172 - accuracy: 0.9943 - val_loss: 0.5066 - val_accuracy: 0.6816\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 144ms/step - loss: 0.0169 - accuracy: 0.9943 - val_loss: 0.5201 - val_accuracy: 0.6803\n",
      "4279/4279 [==============================] - 29s 7ms/step - loss: 0.0996 - accuracy: 0.9408\n",
      "1721/1721 [==============================] - 8s 5ms/step - loss: 0.2595 - accuracy: 0.8528\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.2317 - accuracy: 0.9421 - val_loss: 0.2152 - val_accuracy: 0.9431\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.2174 - accuracy: 0.9425 - val_loss: 0.2133 - val_accuracy: 0.9435\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 0.2162 - accuracy: 0.9429 - val_loss: 0.2129 - val_accuracy: 0.9435\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 164ms/step - loss: 0.2160 - accuracy: 0.9432 - val_loss: 0.2128 - val_accuracy: 0.9435\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.2156 - accuracy: 0.9432 - val_loss: 0.2136 - val_accuracy: 0.9435\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 172ms/step - loss: 0.0244 - accuracy: 0.9935 - val_loss: 0.3701 - val_accuracy: 0.7436\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.2791 - val_accuracy: 0.8070\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0175 - accuracy: 0.9946 - val_loss: 0.3513 - val_accuracy: 0.7834\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 170ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.3594 - val_accuracy: 0.7920\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 0.3541 - val_accuracy: 0.8048\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 180ms/step - loss: 0.0160 - accuracy: 0.9938 - val_loss: 3.5346 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 185ms/step - loss: 5.5548e-06 - accuracy: 1.0000 - val_loss: 3.8401 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 4.2033e-06 - accuracy: 1.0000 - val_loss: 3.8668 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 183ms/step - loss: 4.0325e-06 - accuracy: 1.0000 - val_loss: 3.8808 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 186ms/step - loss: 3.8983e-06 - accuracy: 1.0000 - val_loss: 3.8957 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 171ms/step - loss: 3.4538 - accuracy: 0.4767 - val_loss: 0.1314 - val_accuracy: 0.9696\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 189ms/step - loss: 0.0188 - accuracy: 0.9999 - val_loss: 0.0098 - val_accuracy: 0.9981\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 181ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 169ms/step - loss: 9.7945e-04 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 177ms/step - loss: 5.7254e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 0.7455 - accuracy: 0.8098 - val_loss: 0.7603 - val_accuracy: 0.6715\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0199 - accuracy: 0.9948 - val_loss: 0.6112 - val_accuracy: 0.6902\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 171ms/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 0.5381 - val_accuracy: 0.7050\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.5503 - val_accuracy: 0.7027\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 184ms/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 0.5323 - val_accuracy: 0.7085\n",
      "4279/4279 [==============================] - 15s 4ms/step - loss: 0.0941 - accuracy: 0.9484\n",
      "1721/1721 [==============================] - 6s 3ms/step - loss: 0.2622 - accuracy: 0.8647\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "    loss_complete, accuracy_complete, f1_complete, precision_complete, recall_complete = evaluation(global_model, xcomplete, ycomplete)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus, loss_complete])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus, accuracy_complete])\n",
    "    f1_it.append([f1_basic, f1_plus, f1_complete])\n",
    "    precision_it.append([precision_basic, precision_plus, precision_complete])\n",
    "    recall_it.append([recall_basic, recall_plus, recall_complete])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr105Bavg.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.11470375955104828, 0.23222364485263824], [0.09963300824165344, 0.259491503238678], [0.09414619952440262, 0.26222124695777893]]\n",
      "Accuracy for iterations:  [[0.9249832034111023, 0.8733197450637817], [0.9408031105995178, 0.8527936935424805], [0.9483625292778015, 0.8646552562713623]]\n",
      "F1 for iterations:  [[0.9242816503937178, 0.8698344379594948], [0.940434626040827, 0.8475370303696735], [0.948103720135536, 0.8604375955006761]]\n",
      "Precision for iterations:  [[0.9333531466382072, 0.8905279448236121], [0.9458517835799812, 0.8760728745656486], [0.9521770208609084, 0.8846596668569583]]\n",
      "Recall for iterations:  [[0.9249832013789476, 0.8733197703988956], [0.9408031201612668, 0.8527937222989174], [0.9483624996348126, 0.8646552350504977]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5B 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16896/3291834707.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part1.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16896/3291834707.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16896/3291834707.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16896/3291834707.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr255Bavg.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 145ms/step - loss: 0.5577 - accuracy: 0.7447 - val_loss: 0.4328 - val_accuracy: 0.8525\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.4210 - accuracy: 0.8598 - val_loss: 0.4024 - val_accuracy: 0.8689\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.4061 - accuracy: 0.8665 - val_loss: 0.3930 - val_accuracy: 0.8697\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 192ms/step - loss: 0.3973 - accuracy: 0.8676 - val_loss: 0.3893 - val_accuracy: 0.8705\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 194ms/step - loss: 0.3939 - accuracy: 0.8684 - val_loss: 0.3869 - val_accuracy: 0.8705\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 0.0492 - accuracy: 0.9897 - val_loss: 0.5851 - val_accuracy: 0.6476\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 345ms/step - loss: 0.0242 - accuracy: 0.9911 - val_loss: 0.4860 - val_accuracy: 0.6481\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 194ms/step - loss: 0.0224 - accuracy: 0.9916 - val_loss: 0.2838 - val_accuracy: 0.8049\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.0214 - accuracy: 0.9919 - val_loss: 0.3354 - val_accuracy: 0.7367\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.0204 - accuracy: 0.9929 - val_loss: 0.3569 - val_accuracy: 0.7147\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 33s 1s/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 4.3393 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 34s 1s/step - loss: 8.1073e-07 - accuracy: 1.0000 - val_loss: 4.6543 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 15s 495ms/step - loss: 6.1338e-07 - accuracy: 1.0000 - val_loss: 4.6729 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 269ms/step - loss: 6.0182e-07 - accuracy: 1.0000 - val_loss: 4.6768 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 252ms/step - loss: 5.9664e-07 - accuracy: 1.0000 - val_loss: 4.6804 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 233ms/step - loss: 3.9921 - accuracy: 0.4439 - val_loss: 0.0416 - val_accuracy: 0.9910\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 239ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 242ms/step - loss: 8.2845e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 242ms/step - loss: 4.7482e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 244ms/step - loss: 2.7109e-04 - accuracy: 1.0000 - val_loss: 7.3614e-04 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 238ms/step - loss: 1.6873 - accuracy: 0.6656 - val_loss: 0.5950 - val_accuracy: 0.6357\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 237ms/step - loss: 0.0463 - accuracy: 0.9942 - val_loss: 0.5529 - val_accuracy: 0.6383\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 231ms/step - loss: 0.0273 - accuracy: 0.9943 - val_loss: 0.7173 - val_accuracy: 0.6372\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 254ms/step - loss: 0.0236 - accuracy: 0.9943 - val_loss: 0.7108 - val_accuracy: 0.6370\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 242ms/step - loss: 0.0218 - accuracy: 0.9942 - val_loss: 0.6650 - val_accuracy: 0.6367\n",
      "   1/4279 [..............................] - ETA: 0s - loss: 0.1177 - accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0027s vs `on_test_batch_begin` time: 0.0150s). Check your callbacks.\n",
      "4279/4279 [==============================] - 21s 5ms/step - loss: 0.1333 - accuracy: 0.9240\n",
      "1721/1721 [==============================] - 8s 5ms/step - loss: 0.2549 - accuracy: 0.8540\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 9s 287ms/step - loss: 0.4263 - accuracy: 0.8653 - val_loss: 0.3926 - val_accuracy: 0.8703\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 248ms/step - loss: 0.3958 - accuracy: 0.8680 - val_loss: 0.3866 - val_accuracy: 0.8705\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 247ms/step - loss: 0.3920 - accuracy: 0.8683 - val_loss: 0.3850 - val_accuracy: 0.8705\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 239ms/step - loss: 0.3905 - accuracy: 0.8683 - val_loss: 0.3847 - val_accuracy: 0.8703\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 247ms/step - loss: 0.3898 - accuracy: 0.8683 - val_loss: 0.3840 - val_accuracy: 0.8705\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 0.0326 - accuracy: 0.9914 - val_loss: 0.2948 - val_accuracy: 0.8056\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 259ms/step - loss: 0.0213 - accuracy: 0.9927 - val_loss: 0.3075 - val_accuracy: 0.7594\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 239ms/step - loss: 0.0200 - accuracy: 0.9932 - val_loss: 0.2846 - val_accuracy: 0.7847\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 266ms/step - loss: 0.0191 - accuracy: 0.9936 - val_loss: 0.3235 - val_accuracy: 0.7595\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 273ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 0.3353 - val_accuracy: 0.7656\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 266ms/step - loss: 0.0115 - accuracy: 0.9956 - val_loss: 3.9290 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 248ms/step - loss: 2.0227e-06 - accuracy: 1.0000 - val_loss: 4.2359 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 257ms/step - loss: 1.5505e-06 - accuracy: 1.0000 - val_loss: 4.2560 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 254ms/step - loss: 1.5142e-06 - accuracy: 1.0000 - val_loss: 4.2619 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 246ms/step - loss: 1.4942e-06 - accuracy: 1.0000 - val_loss: 4.2679 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 9s 282ms/step - loss: 3.8304 - accuracy: 0.4373 - val_loss: 0.1467 - val_accuracy: 0.9003\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 238ms/step - loss: 0.0291 - accuracy: 0.9933 - val_loss: 0.0070 - val_accuracy: 0.9997\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 238ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 275ms/step - loss: 8.2876e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 250ms/step - loss: 1.1503 - accuracy: 0.7089 - val_loss: 0.5866 - val_accuracy: 0.6641\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 256ms/step - loss: 0.0332 - accuracy: 0.9938 - val_loss: 0.3427 - val_accuracy: 0.7590\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 258ms/step - loss: 0.0208 - accuracy: 0.9932 - val_loss: 0.4573 - val_accuracy: 0.6781\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 261ms/step - loss: 0.0191 - accuracy: 0.9941 - val_loss: 0.5085 - val_accuracy: 0.6705\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 260ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.5311 - val_accuracy: 0.6667\n",
      "4279/4279 [==============================] - 21s 5ms/step - loss: 0.1027 - accuracy: 0.9343\n",
      "1721/1721 [==============================] - 8s 5ms/step - loss: 0.2271 - accuracy: 0.8732\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 256ms/step - loss: 0.4304 - accuracy: 0.8664 - val_loss: 0.3926 - val_accuracy: 0.8701\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 250ms/step - loss: 0.3925 - accuracy: 0.8683 - val_loss: 0.3841 - val_accuracy: 0.8704\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 253ms/step - loss: 0.3902 - accuracy: 0.8682 - val_loss: 0.3836 - val_accuracy: 0.8705\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 255ms/step - loss: 0.3890 - accuracy: 0.8683 - val_loss: 0.3833 - val_accuracy: 0.8704\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 247ms/step - loss: 0.3889 - accuracy: 0.8683 - val_loss: 0.3831 - val_accuracy: 0.8705\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 265ms/step - loss: 0.0330 - accuracy: 0.9922 - val_loss: 0.3348 - val_accuracy: 0.7408\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 236ms/step - loss: 0.0195 - accuracy: 0.9935 - val_loss: 0.2385 - val_accuracy: 0.8384\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 0.0190 - accuracy: 0.9935 - val_loss: 0.2733 - val_accuracy: 0.8026\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 247ms/step - loss: 0.0178 - accuracy: 0.9939 - val_loss: 0.3207 - val_accuracy: 0.7897\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 235ms/step - loss: 0.0173 - accuracy: 0.9940 - val_loss: 0.3594 - val_accuracy: 0.7825\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 240ms/step - loss: 0.0238 - accuracy: 0.9900 - val_loss: 3.5579 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 228ms/step - loss: 6.8498e-06 - accuracy: 1.0000 - val_loss: 3.8838 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 237ms/step - loss: 5.0661e-06 - accuracy: 1.0000 - val_loss: 3.9106 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 4.8770e-06 - accuracy: 1.0000 - val_loss: 3.9231 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 237ms/step - loss: 4.7327e-06 - accuracy: 1.0000 - val_loss: 3.9361 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 237ms/step - loss: 3.3090 - accuracy: 0.4906 - val_loss: 0.1274 - val_accuracy: 0.9649\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 225ms/step - loss: 0.0206 - accuracy: 0.9997 - val_loss: 0.0147 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 235ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 235ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 228ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 240ms/step - loss: 0.3792 - accuracy: 0.8562 - val_loss: 0.7572 - val_accuracy: 0.6782\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 233ms/step - loss: 0.0192 - accuracy: 0.9942 - val_loss: 0.4603 - val_accuracy: 0.7244\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 235ms/step - loss: 0.0162 - accuracy: 0.9945 - val_loss: 0.5862 - val_accuracy: 0.6991\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 233ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.5073 - val_accuracy: 0.7242\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.4662 - val_accuracy: 0.7436\n",
      "4279/4279 [==============================] - 19s 5ms/step - loss: 0.0763 - accuracy: 0.9566\n",
      "1721/1721 [==============================] - 7s 4ms/step - loss: 0.2490 - accuracy: 0.8711\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "    loss_complete, accuracy_complete, f1_complete, precision_complete, recall_complete = evaluation(global_model, xcomplete, ycomplete)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus, loss_complete])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus, accuracy_complete])\n",
    "    f1_it.append([f1_basic, f1_plus, f1_complete])\n",
    "    precision_it.append([precision_basic, precision_plus, precision_complete])\n",
    "    recall_it.append([recall_basic, recall_plus, recall_complete])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr255Bavg.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.13327844440937042, 0.2549484968185425], [0.1026846170425415, 0.2271340936422348], [0.07630041986703873, 0.249038428068161]]\n",
      "Accuracy for iterations:  [[0.923982560634613, 0.8539562821388245], [0.9342954754829407, 0.8732107877731323], [0.9566011428833008, 0.8710673451423645]]\n",
      "F1 for iterations:  [[0.9232559208613232, 0.8489066584180305], [0.9338084600112092, 0.8697433202461109], [0.9564431931758209, 0.8673570867825495]]\n",
      "Precision for iterations:  [[0.932574827909274, 0.876227258613864], [0.9405867705057854, 0.8902485428821898], [0.9590661290639726, 0.8893179846143305]]\n",
      "Recall for iterations:  [[0.9239825878640918, 0.8539562595364383], [0.9342954804405621, 0.873210782532878], [0.956601127698735, 0.8710673545011989]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 1 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16896/591709827.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr55C1avg.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 208ms/step - loss: 0.6010 - accuracy: 0.7845 - val_loss: 0.4593 - val_accuracy: 0.7922\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 197ms/step - loss: 0.3526 - accuracy: 0.8733 - val_loss: 0.2495 - val_accuracy: 0.9253\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.2237 - accuracy: 0.9385 - val_loss: 0.2006 - val_accuracy: 0.9512\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 212ms/step - loss: 0.1972 - accuracy: 0.9572 - val_loss: 0.1820 - val_accuracy: 0.9609\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 200ms/step - loss: 0.1825 - accuracy: 0.9613 - val_loss: 0.1698 - val_accuracy: 0.9639\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 212ms/step - loss: 0.0397 - accuracy: 0.9905 - val_loss: 0.6318 - val_accuracy: 0.7277\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 193ms/step - loss: 0.0226 - accuracy: 0.9944 - val_loss: 0.9088 - val_accuracy: 0.7270\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 195ms/step - loss: 0.0211 - accuracy: 0.9950 - val_loss: 0.6602 - val_accuracy: 0.7272\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 210ms/step - loss: 0.0201 - accuracy: 0.9950 - val_loss: 0.5902 - val_accuracy: 0.7278\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 206ms/step - loss: 0.0193 - accuracy: 0.9950 - val_loss: 0.5878 - val_accuracy: 0.7283\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 6s 212ms/step - loss: 0.0143 - accuracy: 0.9961 - val_loss: 2.4561 - val_accuracy: 0.4423\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.0131 - accuracy: 0.9966 - val_loss: 2.4502 - val_accuracy: 0.4394\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 194ms/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 2.2043 - val_accuracy: 0.4399\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 2.4823 - val_accuracy: 0.4367\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 6s 213ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 2.3694 - val_accuracy: 0.4369\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 8s 279ms/step - loss: 2.0779 - accuracy: 0.5917 - val_loss: 0.0450 - val_accuracy: 0.9865\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 6s 216ms/step - loss: 0.0055 - accuracy: 0.9997 - val_loss: 0.0088 - val_accuracy: 0.9960\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 6s 215ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9987\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 6s 224ms/step - loss: 3.8642e-04 - accuracy: 1.0000 - val_loss: 5.7793e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 6s 223ms/step - loss: 1.0132e-04 - accuracy: 1.0000 - val_loss: 1.7755e-04 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 16s 233ms/step - loss: 0.7926 - accuracy: 0.8575 - val_loss: 0.3726 - val_accuracy: 0.8275\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 16s 226ms/step - loss: 0.0237 - accuracy: 0.9925 - val_loss: 0.2675 - val_accuracy: 0.8282\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 16s 225ms/step - loss: 0.0218 - accuracy: 0.9926 - val_loss: 0.2347 - val_accuracy: 0.8365\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 16s 231ms/step - loss: 0.0208 - accuracy: 0.9929 - val_loss: 0.2160 - val_accuracy: 0.8487\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 17s 242ms/step - loss: 0.0199 - accuracy: 0.9931 - val_loss: 0.2062 - val_accuracy: 0.8556\n",
      "4279/4279 [==============================] - 19s 4ms/step - loss: 0.0638 - accuracy: 0.9884\n",
      "1721/1721 [==============================] - 7s 4ms/step - loss: 0.1254 - accuracy: 0.9753\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 201ms/step - loss: 0.1822 - accuracy: 0.9624 - val_loss: 0.1611 - val_accuracy: 0.9658\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.1598 - accuracy: 0.9647 - val_loss: 0.1510 - val_accuracy: 0.9669\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 0.1544 - accuracy: 0.9654 - val_loss: 0.1467 - val_accuracy: 0.9674\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.1511 - accuracy: 0.9657 - val_loss: 0.1445 - val_accuracy: 0.9676\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.1491 - accuracy: 0.9658 - val_loss: 0.1431 - val_accuracy: 0.9671\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 196ms/step - loss: 0.0318 - accuracy: 0.9917 - val_loss: 0.6786 - val_accuracy: 0.7265\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 189ms/step - loss: 0.0175 - accuracy: 0.9951 - val_loss: 0.7501 - val_accuracy: 0.7267\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 194ms/step - loss: 0.0167 - accuracy: 0.9952 - val_loss: 0.5469 - val_accuracy: 0.7265\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 194ms/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 0.4740 - val_accuracy: 0.7254\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 201ms/step - loss: 0.0153 - accuracy: 0.9953 - val_loss: 0.5891 - val_accuracy: 0.7248\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 209ms/step - loss: 0.0117 - accuracy: 0.9971 - val_loss: 1.2905 - val_accuracy: 0.4485\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.0110 - accuracy: 0.9973 - val_loss: 1.7669 - val_accuracy: 0.4430\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.0111 - accuracy: 0.9972 - val_loss: 1.5256 - val_accuracy: 0.4566\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.0107 - accuracy: 0.9973 - val_loss: 1.8115 - val_accuracy: 0.4503\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 1.4649 - val_accuracy: 0.5051\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 6s 207ms/step - loss: 2.6873 - accuracy: 0.6257 - val_loss: 0.0897 - val_accuracy: 0.9590\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 6s 206ms/step - loss: 0.0128 - accuracy: 0.9976 - val_loss: 0.0054 - val_accuracy: 0.9971\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 6s 204ms/step - loss: 6.3796e-04 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9986\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 197ms/step - loss: 4.3666e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 0.9992\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 201ms/step - loss: 3.3342e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9995\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 15s 213ms/step - loss: 0.5611 - accuracy: 0.8957 - val_loss: 0.2585 - val_accuracy: 0.8669\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 15s 210ms/step - loss: 0.0183 - accuracy: 0.9937 - val_loss: 0.1916 - val_accuracy: 0.8984\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 14s 207ms/step - loss: 0.0174 - accuracy: 0.9938 - val_loss: 0.1883 - val_accuracy: 0.8911\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 14s 204ms/step - loss: 0.0167 - accuracy: 0.9941 - val_loss: 0.1620 - val_accuracy: 0.9037\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 14s 207ms/step - loss: 0.0162 - accuracy: 0.9944 - val_loss: 0.1678 - val_accuracy: 0.8969\n",
      "4279/4279 [==============================] - 16s 4ms/step - loss: 0.0716 - accuracy: 0.9865\n",
      "1721/1721 [==============================] - 6s 4ms/step - loss: 0.1566 - accuracy: 0.9511\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 0.1874 - accuracy: 0.9627 - val_loss: 0.1570 - val_accuracy: 0.9676\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 198ms/step - loss: 0.1574 - accuracy: 0.9655 - val_loss: 0.1482 - val_accuracy: 0.9678\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 198ms/step - loss: 0.1512 - accuracy: 0.9658 - val_loss: 0.1443 - val_accuracy: 0.9679\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 209ms/step - loss: 0.1481 - accuracy: 0.9658 - val_loss: 0.1429 - val_accuracy: 0.9680\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.1468 - accuracy: 0.9658 - val_loss: 0.1418 - val_accuracy: 0.9681\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 207ms/step - loss: 0.0256 - accuracy: 0.9936 - val_loss: 0.6448 - val_accuracy: 0.7268\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 204ms/step - loss: 0.0161 - accuracy: 0.9952 - val_loss: 0.8452 - val_accuracy: 0.7245\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 191ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.4974 - val_accuracy: 0.7316\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 191ms/step - loss: 0.0145 - accuracy: 0.9962 - val_loss: 0.5194 - val_accuracy: 0.7361\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 199ms/step - loss: 0.0137 - accuracy: 0.9962 - val_loss: 0.5931 - val_accuracy: 0.7390\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 6s 223ms/step - loss: 0.0115 - accuracy: 0.9972 - val_loss: 1.4705 - val_accuracy: 0.4750\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.0110 - accuracy: 0.9973 - val_loss: 1.7361 - val_accuracy: 0.4688\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 1.5389 - val_accuracy: 0.5046\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 1.3440 - val_accuracy: 0.5657\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.0098 - accuracy: 0.9975 - val_loss: 1.2533 - val_accuracy: 0.6048\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 6s 233ms/step - loss: 2.2735 - accuracy: 0.6851 - val_loss: 0.0410 - val_accuracy: 0.9874\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 6s 239ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9997\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 6s 204ms/step - loss: 1.4242e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 6s 212ms/step - loss: 1.1701e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 6s 206ms/step - loss: 1.0948e-04 - accuracy: 1.0000 - val_loss: 9.4467e-04 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 15s 215ms/step - loss: 0.4984 - accuracy: 0.9105 - val_loss: 0.2677 - val_accuracy: 0.8750\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 15s 209ms/step - loss: 0.0166 - accuracy: 0.9943 - val_loss: 0.1829 - val_accuracy: 0.9077\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 15s 212ms/step - loss: 0.0156 - accuracy: 0.9946 - val_loss: 0.1646 - val_accuracy: 0.9136\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 15s 211ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.1833 - val_accuracy: 0.9022\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 15s 208ms/step - loss: 0.0145 - accuracy: 0.9953 - val_loss: 0.1468 - val_accuracy: 0.9218\n",
      "4279/4279 [==============================] - 18s 4ms/step - loss: 0.1231 - accuracy: 0.9669\n",
      "1721/1721 [==============================] - 7s 4ms/step - loss: 0.2851 - accuracy: 0.8954\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "    loss_complete, accuracy_complete, f1_complete, precision_complete, recall_complete = evaluation(global_model, xcomplete, ycomplete)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus, loss_complete])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus, accuracy_complete])\n",
    "    f1_it.append([f1_basic, f1_plus, f1_complete])\n",
    "    precision_it.append([precision_basic, precision_plus, precision_complete])\n",
    "    recall_it.append([recall_basic, recall_plus, recall_complete])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr55C1avg.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.06380385905504227, 0.12535728514194489], [0.07164303958415985, 0.15664543211460114], [0.12308940291404724, 0.28510284423828125]]\n",
      "Accuracy for iterations:  [[0.9883724451065063, 0.9753324389457703], [0.9865245819091797, 0.951100766658783], [0.9668629169464111, 0.895371675491333]]\n",
      "F1 for iterations:  [[0.9883768370639537, 0.975381199566536], [0.9865325912208416, 0.9512753476524937], [0.9668897656867086, 0.8955566319421113]]\n",
      "Precision for iterations:  [[0.9884941803977767, 0.9761469231569462], [0.9868968713821396, 0.9559992520165418], [0.9690345154576933, 0.9154998776044775]]\n",
      "Recall for iterations:  [[0.9883724327324783, 0.9753324129913536], [0.9865245844167226, 0.9511007774467776], [0.9668628940372199, 0.8953716486231199]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 1 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16896/372464333.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr105C1avg.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.6154 - accuracy: 0.7681 - val_loss: 0.4970 - val_accuracy: 0.7811\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 216ms/step - loss: 0.4002 - accuracy: 0.8472 - val_loss: 0.3168 - val_accuracy: 0.9028\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 218ms/step - loss: 0.2936 - accuracy: 0.9172 - val_loss: 0.2823 - val_accuracy: 0.9271\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 203ms/step - loss: 0.2698 - accuracy: 0.9332 - val_loss: 0.2664 - val_accuracy: 0.9379\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 4s 220ms/step - loss: 0.2558 - accuracy: 0.9373 - val_loss: 0.2525 - val_accuracy: 0.9390\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 239ms/step - loss: 0.0486 - accuracy: 0.9908 - val_loss: 0.7414 - val_accuracy: 0.7270\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 206ms/step - loss: 0.0244 - accuracy: 0.9941 - val_loss: 0.8693 - val_accuracy: 0.7270\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 188ms/step - loss: 0.0217 - accuracy: 0.9951 - val_loss: 0.7607 - val_accuracy: 0.7270\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 201ms/step - loss: 0.0207 - accuracy: 0.9950 - val_loss: 0.5744 - val_accuracy: 0.7272\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 200ms/step - loss: 0.0200 - accuracy: 0.9950 - val_loss: 0.5555 - val_accuracy: 0.7280\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.0154 - accuracy: 0.9960 - val_loss: 2.6631 - val_accuracy: 0.4436\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.0140 - accuracy: 0.9962 - val_loss: 2.5621 - val_accuracy: 0.4409\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.0134 - accuracy: 0.9964 - val_loss: 2.0534 - val_accuracy: 0.4435\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.0127 - accuracy: 0.9967 - val_loss: 1.6363 - val_accuracy: 0.4434\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 194ms/step - loss: 0.0125 - accuracy: 0.9968 - val_loss: 2.1739 - val_accuracy: 0.4370\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 202ms/step - loss: 1.9033 - accuracy: 0.6043 - val_loss: 0.0327 - val_accuracy: 0.9872\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 6s 208ms/step - loss: 0.0045 - accuracy: 0.9998 - val_loss: 0.0071 - val_accuracy: 0.9971\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 198ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9984\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 199ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9996\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 196ms/step - loss: 7.1294e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 16s 231ms/step - loss: 0.4503 - accuracy: 0.8972 - val_loss: 0.3245 - val_accuracy: 0.8276\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 16s 232ms/step - loss: 0.0239 - accuracy: 0.9925 - val_loss: 0.2541 - val_accuracy: 0.8291\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 16s 228ms/step - loss: 0.0218 - accuracy: 0.9926 - val_loss: 0.2288 - val_accuracy: 0.8410\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 16s 226ms/step - loss: 0.0207 - accuracy: 0.9929 - val_loss: 0.2248 - val_accuracy: 0.8455\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 16s 228ms/step - loss: 0.0198 - accuracy: 0.9930 - val_loss: 0.1957 - val_accuracy: 0.8670\n",
      "4279/4279 [==============================] - 18s 4ms/step - loss: 0.0664 - accuracy: 0.9884\n",
      "1721/1721 [==============================] - 9s 5ms/step - loss: 0.1257 - accuracy: 0.9755\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 4s 270ms/step - loss: 0.2850 - accuracy: 0.9343 - val_loss: 0.2457 - val_accuracy: 0.9410\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 4s 224ms/step - loss: 0.2417 - accuracy: 0.9401 - val_loss: 0.2320 - val_accuracy: 0.9421\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 218ms/step - loss: 0.2315 - accuracy: 0.9407 - val_loss: 0.2263 - val_accuracy: 0.9424\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 4s 223ms/step - loss: 0.2278 - accuracy: 0.9410 - val_loss: 0.2233 - val_accuracy: 0.9428\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 4s 220ms/step - loss: 0.2254 - accuracy: 0.9411 - val_loss: 0.2219 - val_accuracy: 0.9426\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 232ms/step - loss: 0.0385 - accuracy: 0.9912 - val_loss: 0.7458 - val_accuracy: 0.7254\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 212ms/step - loss: 0.0183 - accuracy: 0.9951 - val_loss: 0.8565 - val_accuracy: 0.7265\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 219ms/step - loss: 0.0178 - accuracy: 0.9951 - val_loss: 0.6636 - val_accuracy: 0.7255\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 218ms/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 0.4669 - val_accuracy: 0.7258\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 226ms/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 0.4791 - val_accuracy: 0.7260\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 6s 225ms/step - loss: 0.0122 - accuracy: 0.9970 - val_loss: 1.6984 - val_accuracy: 0.4395\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 6s 229ms/step - loss: 0.0114 - accuracy: 0.9972 - val_loss: 1.7911 - val_accuracy: 0.4404\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 8s 306ms/step - loss: 0.0112 - accuracy: 0.9973 - val_loss: 2.0387 - val_accuracy: 0.4377\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 8s 320ms/step - loss: 0.0110 - accuracy: 0.9973 - val_loss: 1.7842 - val_accuracy: 0.4503\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 7s 271ms/step - loss: 0.0108 - accuracy: 0.9973 - val_loss: 1.7372 - val_accuracy: 0.4670\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 7s 260ms/step - loss: 3.1287 - accuracy: 0.5180 - val_loss: 0.2469 - val_accuracy: 0.9134\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 8s 282ms/step - loss: 0.0538 - accuracy: 0.9754 - val_loss: 0.0066 - val_accuracy: 0.9961\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 6s 235ms/step - loss: 5.0582e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9985\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 6s 236ms/step - loss: 3.0446e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 0.9988\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 7s 258ms/step - loss: 2.4677e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9993\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 18s 254ms/step - loss: 0.5797 - accuracy: 0.8959 - val_loss: 0.2546 - val_accuracy: 0.8540\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 20s 287ms/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 0.1954 - val_accuracy: 0.8857\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 18s 252ms/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 0.1849 - val_accuracy: 0.8852\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 20s 284ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.1631 - val_accuracy: 0.8951\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 17s 245ms/step - loss: 0.0167 - accuracy: 0.9944 - val_loss: 0.1659 - val_accuracy: 0.8906\n",
      "4279/4279 [==============================] - 24s 6ms/step - loss: 0.0544 - accuracy: 0.9898\n",
      "1721/1721 [==============================] - 9s 5ms/step - loss: 0.1096 - accuracy: 0.9761\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 4s 254ms/step - loss: 0.2896 - accuracy: 0.9374 - val_loss: 0.2381 - val_accuracy: 0.9426\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 4s 228ms/step - loss: 0.2367 - accuracy: 0.9414 - val_loss: 0.2268 - val_accuracy: 0.9428\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 217ms/step - loss: 0.2284 - accuracy: 0.9414 - val_loss: 0.2238 - val_accuracy: 0.9424\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 4s 223ms/step - loss: 0.2259 - accuracy: 0.9414 - val_loss: 0.2230 - val_accuracy: 0.9425\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 4s 232ms/step - loss: 0.2245 - accuracy: 0.9415 - val_loss: 0.2204 - val_accuracy: 0.9429\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 4s 291ms/step - loss: 0.0409 - accuracy: 0.9923 - val_loss: 0.5121 - val_accuracy: 0.7258\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 4s 255ms/step - loss: 0.0161 - accuracy: 0.9950 - val_loss: 0.7564 - val_accuracy: 0.7255\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 246ms/step - loss: 0.0160 - accuracy: 0.9957 - val_loss: 0.6915 - val_accuracy: 0.7239\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 4s 266ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.5433 - val_accuracy: 0.7281\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 4s 255ms/step - loss: 0.0141 - accuracy: 0.9962 - val_loss: 0.4914 - val_accuracy: 0.7340\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 7s 253ms/step - loss: 0.0117 - accuracy: 0.9973 - val_loss: 1.8215 - val_accuracy: 0.4412\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 7s 250ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 1.2963 - val_accuracy: 0.4996\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 7s 261ms/step - loss: 0.0106 - accuracy: 0.9973 - val_loss: 1.7453 - val_accuracy: 0.4759\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 7s 259ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 1.5411 - val_accuracy: 0.5171\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 7s 266ms/step - loss: 0.0098 - accuracy: 0.9975 - val_loss: 1.5853 - val_accuracy: 0.5381\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 7s 273ms/step - loss: 2.9354 - accuracy: 0.5882 - val_loss: 0.1717 - val_accuracy: 0.9263\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 7s 245ms/step - loss: 0.0257 - accuracy: 0.9866 - val_loss: 0.0013 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 7s 262ms/step - loss: 5.3169e-05 - accuracy: 1.0000 - val_loss: 6.2483e-04 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 7s 256ms/step - loss: 3.7384e-05 - accuracy: 1.0000 - val_loss: 5.7669e-04 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 8s 280ms/step - loss: 3.5498e-05 - accuracy: 1.0000 - val_loss: 5.5714e-04 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 19s 264ms/step - loss: 0.5756 - accuracy: 0.9066 - val_loss: 0.2589 - val_accuracy: 0.8680\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 19s 270ms/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 0.1799 - val_accuracy: 0.9042\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 20s 281ms/step - loss: 0.0165 - accuracy: 0.9943 - val_loss: 0.1703 - val_accuracy: 0.9034\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 19s 271ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 0.1745 - val_accuracy: 0.8970\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 18s 262ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.1442 - val_accuracy: 0.9151\n",
      "4279/4279 [==============================] - 21s 5ms/step - loss: 0.0517 - accuracy: 0.9900\n",
      "1721/1721 [==============================] - 8s 5ms/step - loss: 0.0858 - accuracy: 0.9846\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "    loss_complete, accuracy_complete, f1_complete, precision_complete, recall_complete = evaluation(global_model, xcomplete, ycomplete)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus, loss_complete])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus, accuracy_complete])\n",
    "    f1_it.append([f1_basic, f1_plus, f1_complete])\n",
    "    precision_it.append([precision_basic, precision_plus, precision_complete])\n",
    "    recall_it.append([recall_basic, recall_plus, recall_complete])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr105C1avg.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.06640256196260452, 0.1257031261920929], [0.0543942004442215, 0.10962170362472534], [0.051678989082574844, 0.08576647192239761]]\n",
      "Accuracy for iterations:  [[0.988379716873169, 0.9754777550697327], [0.9897966384887695, 0.976113498210907], [0.9899938702583313, 0.9845600724220276]]\n",
      "F1 for iterations:  [[0.9883839596066323, 0.975493552587857], [0.9898015906657185, 0.9761696717141854], [0.9899986226483048, 0.9845855778790374]]\n",
      "Precision for iterations:  [[0.9884906782301287, 0.9755687720040811], [0.9900111184654423, 0.9773419606883076], [0.9902001605974614, 0.9850820400334382]]\n",
      "Recall for iterations:  [[0.9883797364807619, 0.9754777301460438], [0.9897966636477841, 0.976113492697813], [0.9899938648514418, 0.9845600523141756]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 1 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_21336/2868219575.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr255C1avg.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 184ms/step - loss: 0.6350 - accuracy: 0.7102 - val_loss: 0.5472 - val_accuracy: 0.7394\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 207ms/step - loss: 0.4898 - accuracy: 0.8046 - val_loss: 0.4409 - val_accuracy: 0.8484\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 0.4400 - accuracy: 0.8509 - val_loss: 0.4209 - val_accuracy: 0.8651\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 197ms/step - loss: 0.4258 - accuracy: 0.8624 - val_loss: 0.4109 - val_accuracy: 0.8677\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 199ms/step - loss: 0.4166 - accuracy: 0.8637 - val_loss: 0.4042 - val_accuracy: 0.8683\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 180ms/step - loss: 0.0816 - accuracy: 0.9906 - val_loss: 0.5417 - val_accuracy: 0.7270\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 177ms/step - loss: 0.0281 - accuracy: 0.9937 - val_loss: 0.7455 - val_accuracy: 0.7270\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 175ms/step - loss: 0.0235 - accuracy: 0.9946 - val_loss: 0.9317 - val_accuracy: 0.7270\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 160ms/step - loss: 0.0220 - accuracy: 0.9951 - val_loss: 0.7417 - val_accuracy: 0.7270\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 162ms/step - loss: 0.0208 - accuracy: 0.9950 - val_loss: 0.5774 - val_accuracy: 0.7271\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 174ms/step - loss: 0.0155 - accuracy: 0.9960 - val_loss: 2.2878 - val_accuracy: 0.4442\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 171ms/step - loss: 0.0143 - accuracy: 0.9961 - val_loss: 2.0605 - val_accuracy: 0.4443\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 184ms/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 2.5908 - val_accuracy: 0.4398\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 6s 214ms/step - loss: 0.0130 - accuracy: 0.9967 - val_loss: 1.9786 - val_accuracy: 0.4452\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 186ms/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 1.6930 - val_accuracy: 0.4430\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 183ms/step - loss: 1.6557 - accuracy: 0.6418 - val_loss: 0.0351 - val_accuracy: 0.9872\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 173ms/step - loss: 0.0062 - accuracy: 0.9997 - val_loss: 0.0071 - val_accuracy: 0.9974\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 181ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9985\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 183ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9996\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 180ms/step - loss: 8.8626e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 13s 188ms/step - loss: 0.4790 - accuracy: 0.8958 - val_loss: 0.3721 - val_accuracy: 0.8275\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 13s 179ms/step - loss: 0.0243 - accuracy: 0.9926 - val_loss: 0.2526 - val_accuracy: 0.8401\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 13s 182ms/step - loss: 0.0217 - accuracy: 0.9928 - val_loss: 0.2241 - val_accuracy: 0.8544\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 13s 181ms/step - loss: 0.0205 - accuracy: 0.9928 - val_loss: 0.2071 - val_accuracy: 0.8640\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 13s 180ms/step - loss: 0.0195 - accuracy: 0.9931 - val_loss: 0.2150 - val_accuracy: 0.8580\n",
      "4279/4279 [==============================] - 13s 3ms/step - loss: 0.0730 - accuracy: 0.9883\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1369 - accuracy: 0.9682\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 177ms/step - loss: 0.5552 - accuracy: 0.8496 - val_loss: 0.4290 - val_accuracy: 0.8590\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 178ms/step - loss: 0.4244 - accuracy: 0.8629 - val_loss: 0.4096 - val_accuracy: 0.8691\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.4102 - accuracy: 0.8658 - val_loss: 0.3983 - val_accuracy: 0.8696\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 177ms/step - loss: 0.4036 - accuracy: 0.8664 - val_loss: 0.3952 - val_accuracy: 0.8698\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.4004 - accuracy: 0.8664 - val_loss: 0.3928 - val_accuracy: 0.8701\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 183ms/step - loss: 0.0652 - accuracy: 0.9910 - val_loss: 0.5423 - val_accuracy: 0.7242\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 168ms/step - loss: 0.0186 - accuracy: 0.9952 - val_loss: 0.6875 - val_accuracy: 0.7257\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 166ms/step - loss: 0.0177 - accuracy: 0.9952 - val_loss: 0.7359 - val_accuracy: 0.7252\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 161ms/step - loss: 0.0170 - accuracy: 0.9952 - val_loss: 0.5439 - val_accuracy: 0.7255\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 162ms/step - loss: 0.0161 - accuracy: 0.9953 - val_loss: 0.5265 - val_accuracy: 0.7249\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 177ms/step - loss: 0.0122 - accuracy: 0.9969 - val_loss: 1.6570 - val_accuracy: 0.4377\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 177ms/step - loss: 0.0115 - accuracy: 0.9972 - val_loss: 1.7427 - val_accuracy: 0.4384\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 171ms/step - loss: 0.0114 - accuracy: 0.9972 - val_loss: 1.5738 - val_accuracy: 0.4482\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 179ms/step - loss: 0.0109 - accuracy: 0.9972 - val_loss: 1.4229 - val_accuracy: 0.4774\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 172ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 1.8652 - val_accuracy: 0.4550\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 167ms/step - loss: 3.1330 - accuracy: 0.5338 - val_loss: 0.2735 - val_accuracy: 0.9160\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 174ms/step - loss: 0.0724 - accuracy: 0.9685 - val_loss: 0.0053 - val_accuracy: 0.9975\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 181ms/step - loss: 6.0083e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9990\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 192ms/step - loss: 3.5683e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9995\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 181ms/step - loss: 3.0177e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 13s 186ms/step - loss: 0.7061 - accuracy: 0.8860 - val_loss: 0.2218 - val_accuracy: 0.8750\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 14s 197ms/step - loss: 0.0191 - accuracy: 0.9941 - val_loss: 0.1959 - val_accuracy: 0.8849\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 13s 187ms/step - loss: 0.0178 - accuracy: 0.9943 - val_loss: 0.2023 - val_accuracy: 0.8726\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 12s 177ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.1665 - val_accuracy: 0.8922\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 13s 184ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.1577 - val_accuracy: 0.8960\n",
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.0797 - accuracy: 0.9850\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1811 - accuracy: 0.9388\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 0.5818 - accuracy: 0.8553 - val_loss: 0.4276 - val_accuracy: 0.8685\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 0.4236 - accuracy: 0.8632 - val_loss: 0.4122 - val_accuracy: 0.8687\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.4096 - accuracy: 0.8669 - val_loss: 0.4001 - val_accuracy: 0.8703\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 0.4034 - accuracy: 0.8671 - val_loss: 0.3973 - val_accuracy: 0.8704\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.4003 - accuracy: 0.8671 - val_loss: 0.3943 - val_accuracy: 0.8706\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 225ms/step - loss: 0.0806 - accuracy: 0.9937 - val_loss: 0.6263 - val_accuracy: 0.7214\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 173ms/step - loss: 0.0204 - accuracy: 0.9952 - val_loss: 0.6534 - val_accuracy: 0.7258\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 158ms/step - loss: 0.0175 - accuracy: 0.9950 - val_loss: 0.7566 - val_accuracy: 0.7252\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 191ms/step - loss: 0.0163 - accuracy: 0.9955 - val_loss: 0.6899 - val_accuracy: 0.7237\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 234ms/step - loss: 0.0154 - accuracy: 0.9955 - val_loss: 0.5541 - val_accuracy: 0.7248\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 181ms/step - loss: 0.0122 - accuracy: 0.9972 - val_loss: 1.8800 - val_accuracy: 0.4377\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 178ms/step - loss: 0.0110 - accuracy: 0.9973 - val_loss: 1.6584 - val_accuracy: 0.4474\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 1.3464 - val_accuracy: 0.5028\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 155ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 1.2736 - val_accuracy: 0.5578\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 148ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 2.0652 - val_accuracy: 0.4612\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 4s 157ms/step - loss: 3.4354 - accuracy: 0.5215 - val_loss: 0.3485 - val_accuracy: 0.9021\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 4s 155ms/step - loss: 0.1046 - accuracy: 0.9599 - val_loss: 0.0015 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 174ms/step - loss: 2.3530e-04 - accuracy: 1.0000 - val_loss: 4.3018e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 4s 158ms/step - loss: 1.3802e-04 - accuracy: 1.0000 - val_loss: 3.5872e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 6s 204ms/step - loss: 1.2294e-04 - accuracy: 1.0000 - val_loss: 3.2431e-04 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 14s 201ms/step - loss: 0.6291 - accuracy: 0.8979 - val_loss: 0.1892 - val_accuracy: 0.9057\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 14s 195ms/step - loss: 0.0180 - accuracy: 0.9946 - val_loss: 0.1763 - val_accuracy: 0.9011\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 14s 201ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.1694 - val_accuracy: 0.8978\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 14s 196ms/step - loss: 0.0162 - accuracy: 0.9948 - val_loss: 0.1530 - val_accuracy: 0.9038\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 12s 176ms/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 0.1374 - val_accuracy: 0.9151\n",
      "4279/4279 [==============================] - 10s 2ms/step - loss: 0.1110 - accuracy: 0.9744\n",
      "1721/1721 [==============================] - 4s 3ms/step - loss: 0.2670 - accuracy: 0.9006\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "    loss_complete, accuracy_complete, f1_complete, precision_complete, recall_complete = evaluation(global_model, xcomplete, ycomplete)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus, loss_complete])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus, accuracy_complete])\n",
    "    f1_it.append([f1_basic, f1_plus, f1_complete])\n",
    "    precision_it.append([precision_basic, precision_plus, precision_complete])\n",
    "    recall_it.append([recall_basic, recall_plus, recall_complete])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr255C1avg.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.07301006466150284, 0.13686226308345795], [0.07973063737154007, 0.1810533106327057], [0.11098721623420715, 0.2670384347438812]]\n",
      "Accuracy for iterations:  [[0.9883286356925964, 0.9682118892669678], [0.9850346446037292, 0.9388033151626587], [0.9744295477867126, 0.9005667567253113]]\n",
      "F1 for iterations:  [[0.9883327370084766, 0.9681764578223622], [0.9850441636705817, 0.9390300567638474], [0.9744505128900312, 0.9007852290323695]]\n",
      "Precision for iterations:  [[0.9884330080269008, 0.9682811247686117], [0.9854926668972157, 0.946286857250159], [0.9757355470526499, 0.9189210677814361]]\n",
      "Recall for iterations:  [[0.9883286102427766, 0.9682118724115382], [0.9850346197668643, 0.938803313231127], [0.9744295772590493, 0.9005667369032915]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 3 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_21336/927562370.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr55C3avg.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 168ms/step - loss: 0.5297 - accuracy: 0.7412 - val_loss: 1.7559 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 170ms/step - loss: 0.1924 - accuracy: 0.9607 - val_loss: 3.6784 - val_accuracy: 0.1332\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 0.0802 - accuracy: 0.9893 - val_loss: 3.6751 - val_accuracy: 0.1342\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0515 - accuracy: 0.9893 - val_loss: 1.8339 - val_accuracy: 0.1357\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 202ms/step - loss: 0.0374 - accuracy: 0.9899 - val_loss: 1.5210 - val_accuracy: 0.1622\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 230ms/step - loss: 0.0231 - accuracy: 0.9949 - val_loss: 0.8074 - val_accuracy: 0.7271\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 197ms/step - loss: 0.0208 - accuracy: 0.9949 - val_loss: 0.5096 - val_accuracy: 0.7351\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 192ms/step - loss: 0.0207 - accuracy: 0.9949 - val_loss: 0.7279 - val_accuracy: 0.7278\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 5s 345ms/step - loss: 0.0194 - accuracy: 0.9951 - val_loss: 0.4990 - val_accuracy: 0.7382\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 244ms/step - loss: 0.0197 - accuracy: 0.9950 - val_loss: 0.5134 - val_accuracy: 0.7360\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 6s 212ms/step - loss: 0.2402 - accuracy: 0.9391 - val_loss: 0.1866 - val_accuracy: 0.9606\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 210ms/step - loss: 0.1814 - accuracy: 0.9607 - val_loss: 0.1722 - val_accuracy: 0.9639\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 6s 221ms/step - loss: 0.1693 - accuracy: 0.9626 - val_loss: 0.1650 - val_accuracy: 0.9642\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 6s 220ms/step - loss: 0.1629 - accuracy: 0.9632 - val_loss: 0.1611 - val_accuracy: 0.9642\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 6s 221ms/step - loss: 0.1585 - accuracy: 0.9634 - val_loss: 0.1569 - val_accuracy: 0.9646\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 198ms/step - loss: 0.3551 - accuracy: 0.8636 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 190ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.3198e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 6s 214ms/step - loss: 4.4800e-04 - accuracy: 1.0000 - val_loss: 1.5714e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 6s 207ms/step - loss: 2.3705e-04 - accuracy: 1.0000 - val_loss: 9.1338e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 189ms/step - loss: 1.4259e-04 - accuracy: 1.0000 - val_loss: 5.7025e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 13s 188ms/step - loss: 0.8832 - accuracy: 0.8480 - val_loss: 0.3723 - val_accuracy: 0.8289\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 13s 192ms/step - loss: 0.0312 - accuracy: 0.9913 - val_loss: 0.2581 - val_accuracy: 0.8498\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 14s 201ms/step - loss: 0.0249 - accuracy: 0.9907 - val_loss: 0.2305 - val_accuracy: 0.8568\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 14s 196ms/step - loss: 0.0227 - accuracy: 0.9915 - val_loss: 0.2124 - val_accuracy: 0.8621\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 14s 195ms/step - loss: 0.0212 - accuracy: 0.9924 - val_loss: 0.2036 - val_accuracy: 0.8665\n",
      "4279/4279 [==============================] - 13s 3ms/step - loss: 0.1084 - accuracy: 0.9880\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1124 - accuracy: 0.9728\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 0.0245 - accuracy: 0.9912 - val_loss: 0.6338 - val_accuracy: 0.5818\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 0.0219 - accuracy: 0.9926 - val_loss: 0.5576 - val_accuracy: 0.6555\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 170ms/step - loss: 0.0208 - accuracy: 0.9930 - val_loss: 0.6398 - val_accuracy: 0.5888\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 181ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 0.7204 - val_accuracy: 0.5739\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 0.0184 - accuracy: 0.9938 - val_loss: 0.7047 - val_accuracy: 0.6035\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 181ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.6531 - val_accuracy: 0.7402\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 173ms/step - loss: 0.0135 - accuracy: 0.9964 - val_loss: 0.6942 - val_accuracy: 0.7410\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 168ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.5898 - val_accuracy: 0.7575\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 170ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.7759 - val_accuracy: 0.7413\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 178ms/step - loss: 0.0127 - accuracy: 0.9967 - val_loss: 0.6388 - val_accuracy: 0.7610\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 182ms/step - loss: 0.2522 - accuracy: 0.9524 - val_loss: 0.1784 - val_accuracy: 0.9639\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 170ms/step - loss: 0.1664 - accuracy: 0.9634 - val_loss: 0.1571 - val_accuracy: 0.9642\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 179ms/step - loss: 0.1544 - accuracy: 0.9636 - val_loss: 0.1527 - val_accuracy: 0.9642\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 179ms/step - loss: 0.1516 - accuracy: 0.9638 - val_loss: 0.1508 - val_accuracy: 0.9642\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 174ms/step - loss: 0.1504 - accuracy: 0.9638 - val_loss: 0.1495 - val_accuracy: 0.9646\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 183ms/step - loss: 0.5451 - accuracy: 0.8148 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 6s 206ms/step - loss: 6.3985e-04 - accuracy: 1.0000 - val_loss: 1.0485e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 189ms/step - loss: 1.4204e-04 - accuracy: 1.0000 - val_loss: 6.5234e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 187ms/step - loss: 9.8956e-05 - accuracy: 1.0000 - val_loss: 4.8167e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 185ms/step - loss: 7.2734e-05 - accuracy: 1.0000 - val_loss: 3.5307e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 13s 188ms/step - loss: 0.9436 - accuracy: 0.8374 - val_loss: 0.2665 - val_accuracy: 0.8700\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 13s 186ms/step - loss: 0.0236 - accuracy: 0.9934 - val_loss: 0.2062 - val_accuracy: 0.8921\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 13s 188ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 0.1835 - val_accuracy: 0.8956\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 13s 187ms/step - loss: 0.0182 - accuracy: 0.9944 - val_loss: 0.1795 - val_accuracy: 0.8953\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 13s 187ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.1735 - val_accuracy: 0.8991\n",
      "4279/4279 [==============================] - 14s 3ms/step - loss: 0.1162 - accuracy: 0.9890\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1426 - accuracy: 0.9530\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 218ms/step - loss: 0.0194 - accuracy: 0.9940 - val_loss: 0.8413 - val_accuracy: 0.5303\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0178 - accuracy: 0.9943 - val_loss: 0.8763 - val_accuracy: 0.5632\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 218ms/step - loss: 0.0170 - accuracy: 0.9946 - val_loss: 0.8555 - val_accuracy: 0.5894\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 4s 228ms/step - loss: 0.0165 - accuracy: 0.9946 - val_loss: 0.8369 - val_accuracy: 0.6017\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.0165 - accuracy: 0.9948 - val_loss: 0.8232 - val_accuracy: 0.6119\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 4s 275ms/step - loss: 0.0129 - accuracy: 0.9965 - val_loss: 0.7772 - val_accuracy: 0.7550\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 203ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 0.6729 - val_accuracy: 0.7666\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 191ms/step - loss: 0.0123 - accuracy: 0.9968 - val_loss: 1.0088 - val_accuracy: 0.7461\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 197ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.8823 - val_accuracy: 0.7548\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 218ms/step - loss: 0.0116 - accuracy: 0.9971 - val_loss: 0.9232 - val_accuracy: 0.7557\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 6s 228ms/step - loss: 0.2505 - accuracy: 0.9476 - val_loss: 0.1725 - val_accuracy: 0.9643\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 6s 221ms/step - loss: 0.1605 - accuracy: 0.9633 - val_loss: 0.1542 - val_accuracy: 0.9644\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 7s 251ms/step - loss: 0.1525 - accuracy: 0.9637 - val_loss: 0.1509 - val_accuracy: 0.9642\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 6s 246ms/step - loss: 0.1503 - accuracy: 0.9637 - val_loss: 0.1490 - val_accuracy: 0.9642\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 7s 285ms/step - loss: 0.1487 - accuracy: 0.9639 - val_loss: 0.1482 - val_accuracy: 0.9646\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 198ms/step - loss: 0.4401 - accuracy: 0.8433 - val_loss: 6.0441e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 186ms/step - loss: 3.1184e-04 - accuracy: 1.0000 - val_loss: 6.7926e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 199ms/step - loss: 9.7697e-05 - accuracy: 1.0000 - val_loss: 4.9452e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 194ms/step - loss: 7.8897e-05 - accuracy: 1.0000 - val_loss: 4.1915e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 201ms/step - loss: 6.6823e-05 - accuracy: 1.0000 - val_loss: 3.5225e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 16s 231ms/step - loss: 0.8261 - accuracy: 0.8535 - val_loss: 0.2426 - val_accuracy: 0.8906\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 13s 187ms/step - loss: 0.0198 - accuracy: 0.9940 - val_loss: 0.1899 - val_accuracy: 0.9095\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 11s 161ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.1819 - val_accuracy: 0.9072\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 12s 169ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.1592 - val_accuracy: 0.9166\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 15s 208ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.1546 - val_accuracy: 0.9192\n",
      "4279/4279 [==============================] - 13s 3ms/step - loss: 0.1181 - accuracy: 0.9901\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1680 - accuracy: 0.9472\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "    loss_complete, accuracy_complete, f1_complete, precision_complete, recall_complete = evaluation(global_model, xcomplete, ycomplete)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus, loss_complete])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus, accuracy_complete])\n",
    "    f1_it.append([f1_basic, f1_plus, f1_complete])\n",
    "    precision_it.append([precision_basic, precision_plus, precision_complete])\n",
    "    recall_it.append([recall_basic, recall_plus, recall_complete])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr55C3avg.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.1084146797657013, 0.1123688668012619], [0.1162383109331131, 0.1426282525062561], [0.11805704981088638, 0.16804981231689453]]\n",
      "Accuracy for iterations:  [[0.9879999160766602, 0.9727712273597717], [0.9890370965003967, 0.952953577041626], [0.9900742173194885, 0.9472498893737793]]\n",
      "F1 for iterations:  [[0.988003964019539, 0.9727450833085427], [0.9890408833630392, 0.9527551368789061], [0.9900774749113563, 0.9469688561753138]]\n",
      "Precision for iterations:  [[0.9880929627462135, 0.9728250915394179], [0.9891371143801229, 0.9540567725774562], [0.9901625178749895, 0.9488898335585798]]\n",
      "Recall for iterations:  [[0.9879999415700137, 0.9727711981399404], [0.9890370738262877, 0.9529535711690765], [0.9900742060825616, 0.9472498728474896]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 3 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_21336/4114672810.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr105C3avg.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 212ms/step - loss: 0.5324 - accuracy: 0.7423 - val_loss: 1.7323 - val_accuracy: 0.0233\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 182ms/step - loss: 0.1918 - accuracy: 0.9744 - val_loss: 3.9565 - val_accuracy: 0.1281\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 0.0867 - accuracy: 0.9892 - val_loss: 3.8688 - val_accuracy: 0.1339\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 0.0524 - accuracy: 0.9892 - val_loss: 1.6523 - val_accuracy: 0.1386\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 163ms/step - loss: 0.0364 - accuracy: 0.9891 - val_loss: 1.2198 - val_accuracy: 0.2383\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 184ms/step - loss: 0.0220 - accuracy: 0.9948 - val_loss: 0.8367 - val_accuracy: 0.7270\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 171ms/step - loss: 0.0195 - accuracy: 0.9950 - val_loss: 0.6023 - val_accuracy: 0.7283\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 159ms/step - loss: 0.0188 - accuracy: 0.9950 - val_loss: 0.6598 - val_accuracy: 0.7281\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 164ms/step - loss: 0.0180 - accuracy: 0.9950 - val_loss: 0.6554 - val_accuracy: 0.7284\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 161ms/step - loss: 0.0174 - accuracy: 0.9950 - val_loss: 0.5685 - val_accuracy: 0.7323\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 172ms/step - loss: 0.3627 - accuracy: 0.9147 - val_loss: 0.2729 - val_accuracy: 0.9328\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.2626 - accuracy: 0.9372 - val_loss: 0.2563 - val_accuracy: 0.9367\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 188ms/step - loss: 0.2497 - accuracy: 0.9384 - val_loss: 0.2489 - val_accuracy: 0.9374\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.2429 - accuracy: 0.9392 - val_loss: 0.2428 - val_accuracy: 0.9376\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 162ms/step - loss: 0.2378 - accuracy: 0.9394 - val_loss: 0.2387 - val_accuracy: 0.9380\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 0.2749 - accuracy: 0.8872 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 4s 162ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 5.6492e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 4s 162ms/step - loss: 7.2765e-04 - accuracy: 1.0000 - val_loss: 2.5842e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 4s 158ms/step - loss: 3.7052e-04 - accuracy: 1.0000 - val_loss: 1.4458e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 4s 156ms/step - loss: 2.1632e-04 - accuracy: 1.0000 - val_loss: 8.8571e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 177ms/step - loss: 0.7890 - accuracy: 0.8405 - val_loss: 0.3870 - val_accuracy: 0.8277\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 15s 220ms/step - loss: 0.0328 - accuracy: 0.9920 - val_loss: 0.2892 - val_accuracy: 0.8285\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 14s 206ms/step - loss: 0.0246 - accuracy: 0.9912 - val_loss: 0.2501 - val_accuracy: 0.8329\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 14s 200ms/step - loss: 0.0225 - accuracy: 0.9914 - val_loss: 0.2273 - val_accuracy: 0.8409\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 14s 193ms/step - loss: 0.0211 - accuracy: 0.9919 - val_loss: 0.2090 - val_accuracy: 0.8538\n",
      "4279/4279 [==============================] - 14s 3ms/step - loss: 0.0791 - accuracy: 0.9885\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1097 - accuracy: 0.9746\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 166ms/step - loss: 0.0286 - accuracy: 0.9892 - val_loss: 0.8898 - val_accuracy: 0.3131\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.0232 - accuracy: 0.9907 - val_loss: 0.7205 - val_accuracy: 0.5136\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 2s 156ms/step - loss: 0.0216 - accuracy: 0.9919 - val_loss: 0.7826 - val_accuracy: 0.4706\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 162ms/step - loss: 0.0206 - accuracy: 0.9927 - val_loss: 0.7543 - val_accuracy: 0.5206\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 161ms/step - loss: 0.0199 - accuracy: 0.9932 - val_loss: 0.8750 - val_accuracy: 0.4640\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 197ms/step - loss: 0.0145 - accuracy: 0.9959 - val_loss: 0.6386 - val_accuracy: 0.7351\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 161ms/step - loss: 0.0137 - accuracy: 0.9962 - val_loss: 0.4926 - val_accuracy: 0.7504\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 145ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.6833 - val_accuracy: 0.7384\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.0130 - accuracy: 0.9966 - val_loss: 0.6979 - val_accuracy: 0.7406\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 157ms/step - loss: 0.0130 - accuracy: 0.9966 - val_loss: 0.7084 - val_accuracy: 0.7430\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 156ms/step - loss: 0.4276 - accuracy: 0.9143 - val_loss: 0.2970 - val_accuracy: 0.9367\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 154ms/step - loss: 0.2628 - accuracy: 0.9383 - val_loss: 0.2490 - val_accuracy: 0.9377\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 149ms/step - loss: 0.2388 - accuracy: 0.9394 - val_loss: 0.2384 - val_accuracy: 0.9381\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 159ms/step - loss: 0.2330 - accuracy: 0.9397 - val_loss: 0.2352 - val_accuracy: 0.9381\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 159ms/step - loss: 0.2304 - accuracy: 0.9397 - val_loss: 0.2335 - val_accuracy: 0.9371\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 4s 159ms/step - loss: 0.2933 - accuracy: 0.8743 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 4s 152ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3713e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 4s 156ms/step - loss: 4.5854e-04 - accuracy: 1.0000 - val_loss: 1.7824e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 4s 156ms/step - loss: 2.7256e-04 - accuracy: 1.0000 - val_loss: 1.1501e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 171ms/step - loss: 1.8240e-04 - accuracy: 1.0000 - val_loss: 7.8962e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 165ms/step - loss: 0.8375 - accuracy: 0.8326 - val_loss: 0.3236 - val_accuracy: 0.8297\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 11s 161ms/step - loss: 0.0255 - accuracy: 0.9928 - val_loss: 0.2154 - val_accuracy: 0.8626\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 11s 162ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.1784 - val_accuracy: 0.8906\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 11s 162ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.1733 - val_accuracy: 0.8952\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 11s 162ms/step - loss: 0.0172 - accuracy: 0.9946 - val_loss: 0.1686 - val_accuracy: 0.9003\n",
      "4279/4279 [==============================] - 10s 2ms/step - loss: 0.1111 - accuracy: 0.9895\n",
      "1721/1721 [==============================] - 6s 3ms/step - loss: 0.1262 - accuracy: 0.9660: 0s - loss: 0.1262 - accuracy: 0.96\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.0206 - accuracy: 0.9934 - val_loss: 0.7357 - val_accuracy: 0.5371\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.8186 - val_accuracy: 0.5474\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 2s 150ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.8657 - val_accuracy: 0.5547\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.8777 - val_accuracy: 0.5634\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 2s 152ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.9334 - val_accuracy: 0.5638\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 161ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.7267 - val_accuracy: 0.7514\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.0125 - accuracy: 0.9968 - val_loss: 0.8461 - val_accuracy: 0.7452\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 158ms/step - loss: 0.0123 - accuracy: 0.9971 - val_loss: 0.8586 - val_accuracy: 0.7478\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 155ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.8841 - val_accuracy: 0.7494\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.0120 - accuracy: 0.9971 - val_loss: 0.9329 - val_accuracy: 0.7486\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 156ms/step - loss: 0.4388 - accuracy: 0.9110 - val_loss: 0.3022 - val_accuracy: 0.9360\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 154ms/step - loss: 0.2633 - accuracy: 0.9379 - val_loss: 0.2487 - val_accuracy: 0.9370\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 155ms/step - loss: 0.2370 - accuracy: 0.9389 - val_loss: 0.2370 - val_accuracy: 0.9371\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 156ms/step - loss: 0.2309 - accuracy: 0.9392 - val_loss: 0.2336 - val_accuracy: 0.9371\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 152ms/step - loss: 0.2285 - accuracy: 0.9390 - val_loss: 0.2318 - val_accuracy: 0.9372\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 4s 154ms/step - loss: 0.2791 - accuracy: 0.8780 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 4s 150ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.1110e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 4s 156ms/step - loss: 4.6370e-04 - accuracy: 1.0000 - val_loss: 1.8524e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 4s 157ms/step - loss: 2.9870e-04 - accuracy: 1.0000 - val_loss: 1.2237e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 167ms/step - loss: 2.0142e-04 - accuracy: 1.0000 - val_loss: 8.3771e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 167ms/step - loss: 0.7087 - accuracy: 0.8556 - val_loss: 0.2820 - val_accuracy: 0.8466\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 12s 168ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.1791 - val_accuracy: 0.8913\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 14s 196ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.1778 - val_accuracy: 0.8920\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 13s 186ms/step - loss: 0.0166 - accuracy: 0.9947 - val_loss: 0.1683 - val_accuracy: 0.9003\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 12s 171ms/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 0.1478 - val_accuracy: 0.9159\n",
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.1059 - accuracy: 0.9902 0s - loss: 0.1060 - accuracy: 0.99\n",
      "1721/1721 [==============================] - 6s 4ms/step - loss: 0.1465 - accuracy: 0.9479\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "    loss_complete, accuracy_complete, f1_complete, precision_complete, recall_complete = evaluation(global_model, xcomplete, ycomplete)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus, loss_complete])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus, accuracy_complete])\n",
    "    f1_it.append([f1_basic, f1_plus, f1_complete])\n",
    "    precision_it.append([precision_basic, precision_plus, precision_complete])\n",
    "    recall_it.append([recall_basic, recall_plus, recall_complete])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr105C3avg.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.07911981642246246, 0.10972201079130173], [0.11108022183179855, 0.12621992826461792], [0.10594591498374939, 0.14654435217380524]]\n",
      "Accuracy for iterations:  [[0.9884600639343262, 0.9746421575546265], [0.989482581615448, 0.9660139679908752], [0.9902129769325256, 0.9479401111602783]]\n",
      "F1 for iterations:  [[0.9884641874354215, 0.9746253145543056], [0.9894866514296236, 0.9659476699492876], [0.9902162674857102, 0.9476694014296102]]\n",
      "Precision for iterations:  [[0.9885660727407686, 0.9746612204195951], [0.9896081802206068, 0.9662745375191877], [0.9903052955349512, 0.9495162369660378]]\n",
      "Recall for iterations:  [[0.9884600777118817, 0.9746421565065756], [0.9894826024715884, 0.9660139504468502], [0.9902129772999503, 0.9479401293322677]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 3 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_21336/512859027.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr255C3avg.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 181ms/step - loss: 0.5393 - accuracy: 0.7489 - val_loss: 1.6758 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 0.2027 - accuracy: 0.9544 - val_loss: 3.6085 - val_accuracy: 0.1320\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0847 - accuracy: 0.9892 - val_loss: 4.0488 - val_accuracy: 0.1337\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 0.0519 - accuracy: 0.9894 - val_loss: 2.0923 - val_accuracy: 0.1343\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 206ms/step - loss: 0.0370 - accuracy: 0.9903 - val_loss: 1.6371 - val_accuracy: 0.1401\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 212ms/step - loss: 0.0219 - accuracy: 0.9950 - val_loss: 0.8711 - val_accuracy: 0.7271\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 219ms/step - loss: 0.0203 - accuracy: 0.9950 - val_loss: 0.6223 - val_accuracy: 0.7294\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 185ms/step - loss: 0.0195 - accuracy: 0.9950 - val_loss: 0.7629 - val_accuracy: 0.7275\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 170ms/step - loss: 0.0189 - accuracy: 0.9950 - val_loss: 0.6572 - val_accuracy: 0.7283\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 172ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.5615 - val_accuracy: 0.7307\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 178ms/step - loss: 0.6814 - accuracy: 0.8284 - val_loss: 0.4621 - val_accuracy: 0.8586\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 187ms/step - loss: 0.4393 - accuracy: 0.8621 - val_loss: 0.4274 - val_accuracy: 0.8631\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 168ms/step - loss: 0.4229 - accuracy: 0.8641 - val_loss: 0.4172 - val_accuracy: 0.8635\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 183ms/step - loss: 0.4153 - accuracy: 0.8647 - val_loss: 0.4132 - val_accuracy: 0.8648\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 185ms/step - loss: 0.4107 - accuracy: 0.8654 - val_loss: 0.4088 - val_accuracy: 0.8651\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 6s 209ms/step - loss: 0.1994 - accuracy: 0.9256 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 175ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2715e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 4.2659e-04 - accuracy: 1.0000 - val_loss: 1.7053e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 173ms/step - loss: 2.5153e-04 - accuracy: 1.0000 - val_loss: 1.0910e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 184ms/step - loss: 1.6586e-04 - accuracy: 1.0000 - val_loss: 7.3649e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 15s 214ms/step - loss: 0.7972 - accuracy: 0.8453 - val_loss: 0.4424 - val_accuracy: 0.8277\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 15s 216ms/step - loss: 0.0342 - accuracy: 0.9919 - val_loss: 0.3176 - val_accuracy: 0.8279\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 15s 212ms/step - loss: 0.0253 - accuracy: 0.9919 - val_loss: 0.2509 - val_accuracy: 0.8323\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 15s 208ms/step - loss: 0.0228 - accuracy: 0.9915 - val_loss: 0.2372 - val_accuracy: 0.8364\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 14s 203ms/step - loss: 0.0213 - accuracy: 0.9920 - val_loss: 0.2045 - val_accuracy: 0.8576\n",
      "4279/4279 [==============================] - 15s 3ms/step - loss: 0.0854 - accuracy: 0.9879\n",
      "1721/1721 [==============================] - 14s 8ms/step - loss: 0.1233 - accuracy: 0.9722\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 6s 362ms/step - loss: 0.0304 - accuracy: 0.9890 - val_loss: 0.6837 - val_accuracy: 0.5475\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 5s 326ms/step - loss: 0.0243 - accuracy: 0.9903 - val_loss: 0.8217 - val_accuracy: 0.4209\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 5s 288ms/step - loss: 0.0221 - accuracy: 0.9919 - val_loss: 0.6621 - val_accuracy: 0.5958\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 5s 282ms/step - loss: 0.0211 - accuracy: 0.9921 - val_loss: 0.7667 - val_accuracy: 0.5050\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 0.0200 - accuracy: 0.9927 - val_loss: 0.7843 - val_accuracy: 0.5108\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 6s 400ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.7377 - val_accuracy: 0.7283\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.0144 - accuracy: 0.9961 - val_loss: 0.6855 - val_accuracy: 0.7328\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 5s 339ms/step - loss: 0.0141 - accuracy: 0.9962 - val_loss: 0.8307 - val_accuracy: 0.7300\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 5s 339ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.7994 - val_accuracy: 0.7314\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 5s 325ms/step - loss: 0.0137 - accuracy: 0.9965 - val_loss: 0.7753 - val_accuracy: 0.7333\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 336ms/step - loss: 0.8308 - accuracy: 0.8163 - val_loss: 0.5129 - val_accuracy: 0.8592\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 6s 233ms/step - loss: 0.4479 - accuracy: 0.8615 - val_loss: 0.4277 - val_accuracy: 0.8643\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 9s 330ms/step - loss: 0.4159 - accuracy: 0.8659 - val_loss: 0.4135 - val_accuracy: 0.8649\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 9s 346ms/step - loss: 0.4073 - accuracy: 0.8658 - val_loss: 0.4084 - val_accuracy: 0.8647\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 8s 326ms/step - loss: 0.4029 - accuracy: 0.8657 - val_loss: 0.4053 - val_accuracy: 0.8643\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 10s 358ms/step - loss: 0.3422 - accuracy: 0.8581 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 7s 274ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.3284e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 7s 248ms/step - loss: 3.8807e-04 - accuracy: 1.0000 - val_loss: 1.1994e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 9s 330ms/step - loss: 1.7278e-04 - accuracy: 1.0000 - val_loss: 6.4806e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 10s 377ms/step - loss: 1.0078e-04 - accuracy: 1.0000 - val_loss: 4.0374e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 24s 342ms/step - loss: 1.0503 - accuracy: 0.8036 - val_loss: 0.3417 - val_accuracy: 0.8286\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 23s 328ms/step - loss: 0.0309 - accuracy: 0.9929 - val_loss: 0.2337 - val_accuracy: 0.8482\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 24s 340ms/step - loss: 0.0217 - accuracy: 0.9936 - val_loss: 0.2001 - val_accuracy: 0.8708\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 22s 320ms/step - loss: 0.0192 - accuracy: 0.9941 - val_loss: 0.1757 - val_accuracy: 0.8915\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 17s 248ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.1893 - val_accuracy: 0.8863\n",
      "4279/4279 [==============================] - 21s 5ms/step - loss: 0.0968 - accuracy: 0.9889\n",
      "1721/1721 [==============================] - 16s 9ms/step - loss: 0.1369 - accuracy: 0.9630\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 5s 340ms/step - loss: 0.0206 - accuracy: 0.9932 - val_loss: 0.7193 - val_accuracy: 0.5644\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 5s 335ms/step - loss: 0.0189 - accuracy: 0.9937 - val_loss: 0.8442 - val_accuracy: 0.5371\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 5s 316ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 1.0348 - val_accuracy: 0.4892\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 5s 324ms/step - loss: 0.0175 - accuracy: 0.9941 - val_loss: 0.8742 - val_accuracy: 0.5659\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 5s 311ms/step - loss: 0.0171 - accuracy: 0.9944 - val_loss: 0.8505 - val_accuracy: 0.5937\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 5s 354ms/step - loss: 0.0138 - accuracy: 0.9962 - val_loss: 0.7529 - val_accuracy: 0.7462\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 4s 258ms/step - loss: 0.0130 - accuracy: 0.9970 - val_loss: 0.8292 - val_accuracy: 0.7446\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 243ms/step - loss: 0.0124 - accuracy: 0.9967 - val_loss: 0.7802 - val_accuracy: 0.7532\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 215ms/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.8835 - val_accuracy: 0.7463\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 4s 258ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 0.8176 - val_accuracy: 0.7529\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 353ms/step - loss: 0.8833 - accuracy: 0.8125 - val_loss: 0.5505 - val_accuracy: 0.8479\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 8s 316ms/step - loss: 0.4630 - accuracy: 0.8575 - val_loss: 0.4302 - val_accuracy: 0.8629\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 9s 328ms/step - loss: 0.4121 - accuracy: 0.8654 - val_loss: 0.4107 - val_accuracy: 0.8639\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 8s 319ms/step - loss: 0.4019 - accuracy: 0.8657 - val_loss: 0.4051 - val_accuracy: 0.8640\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 8s 312ms/step - loss: 0.3982 - accuracy: 0.8657 - val_loss: 0.4031 - val_accuracy: 0.8640\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 9s 349ms/step - loss: 0.3258 - accuracy: 0.8552 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 9s 336ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.8281e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 9s 324ms/step - loss: 3.1193e-04 - accuracy: 1.0000 - val_loss: 8.7859e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 9s 340ms/step - loss: 1.0835e-04 - accuracy: 1.0000 - val_loss: 3.1469e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 9s 328ms/step - loss: 4.1622e-05 - accuracy: 1.0000 - val_loss: 1.3216e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 25s 359ms/step - loss: 1.0030 - accuracy: 0.8176 - val_loss: 0.1944 - val_accuracy: 0.8873\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 25s 362ms/step - loss: 0.0226 - accuracy: 0.9937 - val_loss: 0.1861 - val_accuracy: 0.8726\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 22s 316ms/step - loss: 0.0187 - accuracy: 0.9943 - val_loss: 0.1984 - val_accuracy: 0.8737\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 17s 244ms/step - loss: 0.0175 - accuracy: 0.9946 - val_loss: 0.1735 - val_accuracy: 0.8942\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 18s 258ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.1823 - val_accuracy: 0.8911\n",
      "4279/4279 [==============================] - 30s 7ms/step - loss: 0.1229 - accuracy: 0.9891\n",
      "1721/1721 [==============================] - 12s 7ms/step - loss: 0.1541 - accuracy: 0.9476\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "    loss_complete, accuracy_complete, f1_complete, precision_complete, recall_complete = evaluation(global_model, xcomplete, ycomplete)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus, loss_complete])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus, accuracy_complete])\n",
    "    f1_it.append([f1_basic, f1_plus, f1_complete])\n",
    "    precision_it.append([precision_basic, precision_plus, precision_complete])\n",
    "    recall_it.append([recall_basic, recall_plus, recall_complete])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr255C3avg.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.08544706553220749, 0.12328588217496872], [0.09680859744548798, 0.13693860173225403], [0.12291232496500015, 0.15408408641815186]]\n",
      "Accuracy for iterations:  [[0.9878538846969604, 0.9722262620925903], [0.9889128804206848, 0.9629804491996765], [0.9890589714050293, 0.9475768208503723]]\n",
      "F1 for iterations:  [[0.9878578666501733, 0.9722010170737153], [0.988916709205785, 0.9628907034001225], [0.9890627905095888, 0.9472986746263102]]\n",
      "Precision for iterations:  [[0.9879434565329552, 0.9722715522619876], [0.9890099785924518, 0.9633804123844554], [0.9891592171717783, 0.949208839513966]]\n",
      "Recall for iterations:  [[0.9878538666043414, 0.9722262588098525], [0.9889129101054661, 0.9629804548426942], [0.9890589850711385, 0.9475768364455424]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
