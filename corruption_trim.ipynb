{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated Learning with one corrupted node: trimmed mean\n",
    "Using one balanced and one unbalanced dataset with one corrupted node (5%, 25% and 50% corrupted samples) to test different aggregation functions and determine the more robust one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Disable warns\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data): \n",
    "\n",
    "    # Select the 'proto' and 'state' values that I want\n",
    "    data = data.loc[(data['proto'] == 'tcp') | (data['proto'] =='udp') | (data['proto'] =='icmp') | (data['proto'] =='arp') | (data['proto'] =='ipv6-icmp') | (data['proto'] =='igmp') | (data['proto'] =='rarp'), :]\n",
    "    data = data.loc[(data['state'] == 'RST') | (data['state'] =='REQ') | (data['state'] =='INT') | (data['state'] =='FIN') | (data['state'] =='CON') | (data['state'] =='ECO') | (data['state'] =='ACC') | (data['state'] == 'PAR'), :]\n",
    "\n",
    "    # Extracting labels \n",
    "    data_labels = data[['label']]\n",
    "\n",
    "    # Drop the invalid features and select interested data features\n",
    "    data_features=data[['proto','srcip','sport','dstip','dsport','spkts','dpkts','sbytes','dbytes','state','stime','ltime','dur']]\n",
    "\n",
    "    \"\"\"PREPROCESSING\"\"\"\n",
    "\n",
    "\n",
    "    # Preprocess IP and ports features\n",
    "    # IP Source Address\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "\n",
    "    # IP Destination Address\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "    # Ports\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "\n",
    "    # Convert all ports with 0 decimal, and HEX to DEC\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    # Convert field to int format\n",
    "    data_features['srcip'] = data_features['srcip'].astype(int)\n",
    "    data_features['sport'] = data_features['sport'].astype(int)\n",
    "    data_features['dstip'] = data_features['dstip'].astype(int)\n",
    "    data_features['dsport'] = data_features['dsport'].astype(int)\n",
    "\n",
    "    # Convert some fields to logarithmic\n",
    "    log1p_col = ['dur', 'sbytes', 'dbytes', 'spkts']\n",
    "\n",
    "    for col in log1p_col:\n",
    "        data_features[col] = data_features[col].apply(np.log1p)\n",
    "\n",
    "    # Create a complementary field of attack & Transform to One hot encoding - LABELS\n",
    "    normal=data_labels['label']\n",
    "    normal=normal.replace(1,2)\n",
    "    normal=normal.replace(0,1)\n",
    "    normal=normal.replace(2,0)\n",
    "\n",
    "    # Insert the new column in data labels\n",
    "    data_labels.insert(1, 'normal', normal)\n",
    "    data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "    data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "    # Transform to One hot encoding - FEATURES\n",
    "    data_features=pd.get_dummies(data_features)\n",
    "\n",
    "    # Value given for the missing columns\n",
    "    auxCol=0\n",
    "\n",
    "    # As we are using different datasets that might not have all representations, we are going to detect and add the missing columns \n",
    "    # The columns that can have types are: proto and state: need to check if all representations are done \n",
    "    state_cols = [col for col in data_features if col.startswith('state_')]\n",
    "    proto_cols = [col for col in data_features if col.startswith('proto_')]\n",
    "    \n",
    "    # Check if all columns are present\n",
    "    if 'state_PAR' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_PAR', auxCol, True)\n",
    "    if 'state_ACC' not in state_cols: \n",
    "        data_features.insert(data_features.shape[1], 'state_ACC', auxCol, True)\n",
    "    if 'state_ECO' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_ECO', auxCol, True)\n",
    "    if 'state_CON' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_CON', auxCol, True)\n",
    "    if 'state_FIN' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_FIN', auxCol, True)\n",
    "    if 'state_INT' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_INT', auxCol, True)\n",
    "    if 'state_REQ' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_REQ', auxCol, True)\n",
    "    if 'state_RST' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_RST', auxCol, True)\n",
    "    if 'proto_igmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_igmp', auxCol, True)\n",
    "    if 'proto_arp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_arp', auxCol, True)\n",
    "    if 'proto_icmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_icmp', auxCol, True)\n",
    "    if 'proto_udp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_udp', auxCol, True)\n",
    "    if 'proto_tcp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_tcp', auxCol, True)\n",
    "\n",
    "    # Normalize all data features\n",
    "    data_features = StandardScaler().fit_transform(data_features)\n",
    "\n",
    "    #Add dimension to data features\n",
    "    data_features = np.expand_dims(data_features, axis=2)\n",
    "    data_features = np.expand_dims(data_features, axis=3)\n",
    "\n",
    "    x = data_features\n",
    "    y = data_labels.to_numpy()\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building and definition\n",
    "def build_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(filters=32,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(1, 1), padding='same'))\n",
    "    model.add(layers.Conv2D(filters=64,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(1, 1), padding='same'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(Dense(444, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns values of loss, accuracy, f1, precision and recall of model evaluating with test dataset \n",
    "def evaluation(model, x, y): \n",
    "    loss, accuracy = model.evaluate(x, y)\n",
    "    y_pred = model.predict(x)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y = np.argmax(y, axis=1)\n",
    "    report = classification_report(y, y_pred, target_names=['normal', 'attack'], output_dict=True)\n",
    "    # Obtain f1, precision and recall from the report\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    return loss, accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list, trim_num = 1):\n",
    "    # Calculate 20% trimmed mean -> stay with 3 closer nodes \n",
    "    # Initialize the list to store trimmed mean gradients\n",
    "    trim_mean_grad = []\n",
    "    \n",
    "    # Iterate over the gradients coordinate-wise\n",
    "    for layer_grads in zip(*grad_list):\n",
    "        # Stack gradients for the current layer to shape (num_nodes, ...)\n",
    "        stacked_grads = tf.stack(layer_grads, axis=0)\n",
    "\n",
    "        # Sort the gradients along the node axis\n",
    "        sorted_grads = tf.sort(stacked_grads, axis=0)\n",
    "\n",
    "        # Trim the top and bottom trim_count gradients\n",
    "        trimmed_grads = sorted_grads[trim_num:num_nodes - trim_num]\n",
    "\n",
    "        # Calculate the mean of the remaining gradients\n",
    "        trimmed_mean = tf.reduce_mean(trimmed_grads, axis=0)\n",
    "\n",
    "        # Append the trimmed mean gradient for the current layer\n",
    "        trim_mean_grad.append(trimmed_mean)\n",
    "    \n",
    "    \n",
    "    return trim_mean_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_12168/3836997398.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n"
     ]
    }
   ],
   "source": [
    "test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n",
    "test_plus = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test+.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5A 5% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_12168/3687049449.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_12168/3687049449.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_12168/3687049449.py:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part4.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_12168/3687049449.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr55Atrim.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 4s 144ms/step - loss: 0.4719 - accuracy: 0.8668 - val_loss: 0.2438 - val_accuracy: 0.9240\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 151ms/step - loss: 0.1922 - accuracy: 0.9522 - val_loss: 0.1810 - val_accuracy: 0.9600\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 0.1672 - accuracy: 0.9643 - val_loss: 0.1626 - val_accuracy: 0.9629\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.1533 - accuracy: 0.9668 - val_loss: 0.1532 - val_accuracy: 0.9651\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.1459 - accuracy: 0.9676 - val_loss: 0.1484 - val_accuracy: 0.9657\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 146ms/step - loss: 0.0351 - accuracy: 0.9898 - val_loss: 0.5027 - val_accuracy: 0.6757\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.0236 - accuracy: 0.9908 - val_loss: 0.3351 - val_accuracy: 0.7642\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 0.0221 - accuracy: 0.9917 - val_loss: 0.3736 - val_accuracy: 0.7019\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 0.0213 - accuracy: 0.9923 - val_loss: 0.3790 - val_accuracy: 0.6912\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.0201 - accuracy: 0.9930 - val_loss: 0.3326 - val_accuracy: 0.7464\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.0207 - accuracy: 0.9922 - val_loss: 0.3869 - val_accuracy: 0.7103\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0177 - accuracy: 0.9938 - val_loss: 0.3019 - val_accuracy: 0.7913\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 145ms/step - loss: 0.0164 - accuracy: 0.9943 - val_loss: 0.2705 - val_accuracy: 0.8292\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 0.0156 - accuracy: 0.9948 - val_loss: 0.4528 - val_accuracy: 0.7494\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 143ms/step - loss: 0.0151 - accuracy: 0.9950 - val_loss: 0.3182 - val_accuracy: 0.8199\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 4s 143ms/step - loss: 0.0156 - accuracy: 0.9950 - val_loss: 0.3635 - val_accuracy: 0.8053\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.2907 - val_accuracy: 0.8397\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 0.0149 - accuracy: 0.9952 - val_loss: 0.2586 - val_accuracy: 0.8526\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.0149 - accuracy: 0.9950 - val_loss: 0.5478 - val_accuracy: 0.7662\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.3822 - val_accuracy: 0.8204\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.4146 - val_accuracy: 0.8026\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.3903 - val_accuracy: 0.8187\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.2769 - val_accuracy: 0.8513\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.4374 - val_accuracy: 0.8078\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 164ms/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 0.2773 - val_accuracy: 0.8561\n",
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.0423 - accuracy: 0.9789\n",
      "1721/1721 [==============================] - 4s 3ms/step - loss: 0.2617 - accuracy: 0.8806\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.1950 - accuracy: 0.9662 - val_loss: 0.1625 - val_accuracy: 0.9653\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.1464 - accuracy: 0.9680 - val_loss: 0.1485 - val_accuracy: 0.9660\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.1409 - accuracy: 0.9685 - val_loss: 0.1458 - val_accuracy: 0.9658\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.1388 - accuracy: 0.9686 - val_loss: 0.1442 - val_accuracy: 0.9662\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.1378 - accuracy: 0.9686 - val_loss: 0.1440 - val_accuracy: 0.9662\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.0219 - accuracy: 0.9936 - val_loss: 0.3614 - val_accuracy: 0.7589\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.0157 - accuracy: 0.9955 - val_loss: 0.3545 - val_accuracy: 0.7958\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 171ms/step - loss: 0.0148 - accuracy: 0.9955 - val_loss: 0.3095 - val_accuracy: 0.8309\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.3209 - val_accuracy: 0.8328\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.3314 - val_accuracy: 0.8363\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 0.3742 - val_accuracy: 0.8232\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 0.3896 - val_accuracy: 0.8255\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.6103 - val_accuracy: 0.7626\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 0.0125 - accuracy: 0.9964 - val_loss: 0.5811 - val_accuracy: 0.7793\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 151ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 0.4966 - val_accuracy: 0.8094\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.3816 - val_accuracy: 0.8402\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.4089 - val_accuracy: 0.8342\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.6548 - val_accuracy: 0.7611\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.5419 - val_accuracy: 0.8031\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.4660 - val_accuracy: 0.8274\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.0124 - accuracy: 0.9965 - val_loss: 0.4093 - val_accuracy: 0.8378\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.4512 - val_accuracy: 0.8291\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.4415 - val_accuracy: 0.8311\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.4063 - val_accuracy: 0.8418\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.6460 - val_accuracy: 0.7696\n",
      "4279/4279 [==============================] - 11s 3ms/step - loss: 0.0880 - accuracy: 0.9674\n",
      "1721/1721 [==============================] - 4s 3ms/step - loss: 0.5494 - accuracy: 0.7500\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.2254 - accuracy: 0.9643 - val_loss: 0.1759 - val_accuracy: 0.9653\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.1471 - accuracy: 0.9679 - val_loss: 0.1507 - val_accuracy: 0.9657\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.1396 - accuracy: 0.9685 - val_loss: 0.1469 - val_accuracy: 0.9661\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.1373 - accuracy: 0.9686 - val_loss: 0.1446 - val_accuracy: 0.9660\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.1365 - accuracy: 0.9686 - val_loss: 0.1434 - val_accuracy: 0.9663\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.0187 - accuracy: 0.9947 - val_loss: 0.3103 - val_accuracy: 0.8253\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0139 - accuracy: 0.9962 - val_loss: 0.3703 - val_accuracy: 0.8196\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 151ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.3398 - val_accuracy: 0.8378\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 0.3943 - val_accuracy: 0.8296\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 0.0124 - accuracy: 0.9965 - val_loss: 0.3502 - val_accuracy: 0.8428\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 0.5625 - val_accuracy: 0.7748\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.4067 - val_accuracy: 0.8367\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.5953 - val_accuracy: 0.7817\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.4616 - val_accuracy: 0.8277\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.5919 - val_accuracy: 0.8023\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.3817 - val_accuracy: 0.8474\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.4180 - val_accuracy: 0.8417\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 169ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.5041 - val_accuracy: 0.8300\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 166ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.4613 - val_accuracy: 0.8361\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 0.4754 - val_accuracy: 0.8392\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.7142 - val_accuracy: 0.7893\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.3592 - val_accuracy: 0.8595\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.5965 - val_accuracy: 0.8050\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.5710 - val_accuracy: 0.8181\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.4379 - val_accuracy: 0.8427\n",
      "4279/4279 [==============================] - 11s 3ms/step - loss: 0.0628 - accuracy: 0.9729\n",
      "1721/1721 [==============================] - 4s 3ms/step - loss: 0.3404 - accuracy: 0.8288\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr55Atrim.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.042285747826099396, 0.2616843283176422], [0.08800294250249863, 0.54937344789505], [0.06275994330644608, 0.3403714597225189]]\n",
      "Accuracy for iterations:  [[0.9788775444030762, 0.8806401491165161], [0.967410683631897, 0.7499818205833435], [0.972859263420105, 0.828798234462738]]\n",
      "F1 for iterations:  [[0.9788615259035282, 0.8777836036028267], [0.9673305136426964, 0.7251205814396124], [0.9728185377982685, 0.8206576736913368]]\n",
      "Precision for iterations:  [[0.979084447975743, 0.8949858527993769], [0.9688303261334784, 0.8169439479915453], [0.9735154730730012, 0.8608948198651091]]\n",
      "Recall for iterations:  [[0.9788775599637735, 0.88064012206641], [0.9674106751584913, 0.7499818353556638], [0.9728592713780713, 0.8287982271307128]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5B 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_12168/2463029928.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part1.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_12168/2463029928.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_12168/2463029928.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_12168/2463029928.py:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part4.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_12168/2463029928.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr105Atrim.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 164ms/step - loss: 0.4948 - accuracy: 0.8260 - val_loss: 0.2943 - val_accuracy: 0.9043\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.2646 - accuracy: 0.9289 - val_loss: 0.2453 - val_accuracy: 0.9402\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.2428 - accuracy: 0.9406 - val_loss: 0.2341 - val_accuracy: 0.9414\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.2318 - accuracy: 0.9418 - val_loss: 0.2255 - val_accuracy: 0.9426\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.2252 - accuracy: 0.9425 - val_loss: 0.2207 - val_accuracy: 0.9428\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0373 - accuracy: 0.9897 - val_loss: 0.4601 - val_accuracy: 0.7144\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0236 - accuracy: 0.9905 - val_loss: 0.4199 - val_accuracy: 0.6780\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0222 - accuracy: 0.9915 - val_loss: 0.3179 - val_accuracy: 0.7668\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.0215 - accuracy: 0.9919 - val_loss: 0.3643 - val_accuracy: 0.7041\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0204 - accuracy: 0.9928 - val_loss: 0.3777 - val_accuracy: 0.7037\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0211 - accuracy: 0.9921 - val_loss: 0.5480 - val_accuracy: 0.6407\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0183 - accuracy: 0.9935 - val_loss: 0.2744 - val_accuracy: 0.8081\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.0173 - accuracy: 0.9941 - val_loss: 0.2313 - val_accuracy: 0.8628\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.0165 - accuracy: 0.9943 - val_loss: 0.2873 - val_accuracy: 0.8109\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 0.2501 - val_accuracy: 0.8413\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.3444 - val_accuracy: 0.8018\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.3565 - val_accuracy: 0.8061\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.0151 - accuracy: 0.9954 - val_loss: 0.3123 - val_accuracy: 0.8317\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 0.3994 - val_accuracy: 0.8074\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.2528 - val_accuracy: 0.8524\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0174 - accuracy: 0.9951 - val_loss: 0.4434 - val_accuracy: 0.7922\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 164ms/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 0.3940 - val_accuracy: 0.8125\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.5235 - val_accuracy: 0.7766\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.4769 - val_accuracy: 0.7944\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.4199 - val_accuracy: 0.8157\n",
      "4279/4279 [==============================] - 11s 3ms/step - loss: 0.0503 - accuracy: 0.9730\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.3206 - accuracy: 0.8474\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.3617 - accuracy: 0.9350 - val_loss: 0.2553 - val_accuracy: 0.9424\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.2373 - accuracy: 0.9427 - val_loss: 0.2232 - val_accuracy: 0.9427\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.2234 - accuracy: 0.9431 - val_loss: 0.2179 - val_accuracy: 0.9431\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.2205 - accuracy: 0.9433 - val_loss: 0.2163 - val_accuracy: 0.9431\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.2187 - accuracy: 0.9433 - val_loss: 0.2165 - val_accuracy: 0.9429\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0294 - accuracy: 0.9928 - val_loss: 0.4415 - val_accuracy: 0.7096\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.0173 - accuracy: 0.9947 - val_loss: 0.3718 - val_accuracy: 0.7678\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 0.3426 - val_accuracy: 0.8000\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0156 - accuracy: 0.9952 - val_loss: 0.3846 - val_accuracy: 0.7936\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 0.4550 - val_accuracy: 0.7752\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0160 - accuracy: 0.9952 - val_loss: 0.3692 - val_accuracy: 0.8136\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 0.4150 - val_accuracy: 0.8068\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.4070 - val_accuracy: 0.8193\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 0.5954 - val_accuracy: 0.7747\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.5833 - val_accuracy: 0.7887\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.0140 - accuracy: 0.9960 - val_loss: 0.3801 - val_accuracy: 0.8365\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.4179 - val_accuracy: 0.8274\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.3360 - val_accuracy: 0.8453\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 0.4290 - val_accuracy: 0.8292\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.5505 - val_accuracy: 0.7918\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.5778 - val_accuracy: 0.7806\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 0.3592 - val_accuracy: 0.8488\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.4092 - val_accuracy: 0.8294\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.5007 - val_accuracy: 0.7989\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.4788 - val_accuracy: 0.8099\n",
      "4279/4279 [==============================] - 11s 3ms/step - loss: 0.0685 - accuracy: 0.9711\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.3882 - accuracy: 0.8078\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.3319 - accuracy: 0.9367 - val_loss: 0.2368 - val_accuracy: 0.9421\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 0.2269 - accuracy: 0.9427 - val_loss: 0.2197 - val_accuracy: 0.9429\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.2206 - accuracy: 0.9428 - val_loss: 0.2162 - val_accuracy: 0.9433\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 0.2183 - accuracy: 0.9429 - val_loss: 0.2158 - val_accuracy: 0.9435\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.2172 - accuracy: 0.9434 - val_loss: 0.2152 - val_accuracy: 0.9432\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.0236 - accuracy: 0.9940 - val_loss: 0.3027 - val_accuracy: 0.8218\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 0.3695 - val_accuracy: 0.8160\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.0141 - accuracy: 0.9960 - val_loss: 0.3052 - val_accuracy: 0.8527\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 145ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.4222 - val_accuracy: 0.8167\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.4037 - val_accuracy: 0.8317\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 0.3965 - val_accuracy: 0.8389\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 150ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.2367 - val_accuracy: 0.8755\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.4710 - val_accuracy: 0.8210\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 0.0117 - accuracy: 0.9967 - val_loss: 0.4447 - val_accuracy: 0.8327\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 150ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.4229 - val_accuracy: 0.8370\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.5836 - val_accuracy: 0.7969\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 0.4106 - val_accuracy: 0.8409\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 150ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.4342 - val_accuracy: 0.8356\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 151ms/step - loss: 0.0119 - accuracy: 0.9965 - val_loss: 0.3621 - val_accuracy: 0.8546\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.6202 - val_accuracy: 0.7874\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0133 - accuracy: 0.9962 - val_loss: 0.4330 - val_accuracy: 0.8413\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.3984 - val_accuracy: 0.8448\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.4701 - val_accuracy: 0.8291\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.5463 - val_accuracy: 0.8075\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.5246 - val_accuracy: 0.8061\n",
      "4279/4279 [==============================] - 11s 3ms/step - loss: 0.0767 - accuracy: 0.9700\n",
      "1721/1721 [==============================] - 6s 4ms/step - loss: 0.3717 - accuracy: 0.8056\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr105Atrim.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.05028942599892616, 0.3205834925174713], [0.06852910667657852, 0.38822370767593384], [0.076668880879879, 0.37169456481933594]]\n",
      "Accuracy for iterations:  [[0.9730053544044495, 0.8474169969558716], [0.9710990786552429, 0.8078362345695496], [0.9700326919555664, 0.8056201338768005]]\n",
      "F1 for iterations:  [[0.972967334914303, 0.841549289072722], [0.9710459029564532, 0.7964318949359777], [0.9699702812954014, 0.7937612346782192]]\n",
      "Precision for iterations:  [[0.9735953007015596, 0.8728276569160942], [0.9720083999680239, 0.8484449321571627], [0.9711383790561191, 0.8475302701275563]]\n",
      "Recall for iterations:  [[0.9730053463437436, 0.8474169875753833], [0.971099068041719, 0.8078362275666643], [0.9700327207923106, 0.80562014095764]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5B 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_12168/3855986297.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_12168/3855986297.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_12168/3855986297.py:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part4.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_12168/3855986297.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr255Atrim.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.4922 - accuracy: 0.8231 - val_loss: 0.2886 - val_accuracy: 0.8563\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.1797 - accuracy: 0.9435 - val_loss: 0.1261 - val_accuracy: 0.9748\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.1197 - accuracy: 0.9768 - val_loss: 0.1135 - val_accuracy: 0.9779\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.1084 - accuracy: 0.9783 - val_loss: 0.1067 - val_accuracy: 0.9774\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.1011 - accuracy: 0.9788 - val_loss: 0.1009 - val_accuracy: 0.9787\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 0.0295 - accuracy: 0.9899 - val_loss: 0.4507 - val_accuracy: 0.7028\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0228 - accuracy: 0.9909 - val_loss: 0.2226 - val_accuracy: 0.8975\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.0215 - accuracy: 0.9918 - val_loss: 0.3202 - val_accuracy: 0.7581\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.0199 - accuracy: 0.9925 - val_loss: 0.2835 - val_accuracy: 0.8020\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0190 - accuracy: 0.9931 - val_loss: 0.3494 - val_accuracy: 0.7282\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.0198 - accuracy: 0.9927 - val_loss: 0.2977 - val_accuracy: 0.7814\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.0176 - accuracy: 0.9937 - val_loss: 0.3778 - val_accuracy: 0.7249\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.0168 - accuracy: 0.9940 - val_loss: 0.3426 - val_accuracy: 0.7695\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.0160 - accuracy: 0.9944 - val_loss: 0.3277 - val_accuracy: 0.7854\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.0156 - accuracy: 0.9950 - val_loss: 0.2900 - val_accuracy: 0.8184\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.0164 - accuracy: 0.9946 - val_loss: 0.4064 - val_accuracy: 0.7665\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 166ms/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.3180 - val_accuracy: 0.8104\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 0.2943 - val_accuracy: 0.8273\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.3147 - val_accuracy: 0.8258\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.3154 - val_accuracy: 0.8297\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.0181 - accuracy: 0.9948 - val_loss: 0.4024 - val_accuracy: 0.7807\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.2226 - val_accuracy: 0.8684\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 0.3434 - val_accuracy: 0.8177\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.2321 - val_accuracy: 0.8655\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.0119 - accuracy: 0.9965 - val_loss: 0.2394 - val_accuracy: 0.8636\n",
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.0355 - accuracy: 0.9872\n",
      "1721/1721 [==============================] - 6s 3ms/step - loss: 0.2418 - accuracy: 0.8914\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 0.1257 - accuracy: 0.9786 - val_loss: 0.1051 - val_accuracy: 0.9797\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.0987 - accuracy: 0.9805 - val_loss: 0.0967 - val_accuracy: 0.9798\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.0926 - accuracy: 0.9806 - val_loss: 0.0946 - val_accuracy: 0.9798\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 170ms/step - loss: 0.0912 - accuracy: 0.9806 - val_loss: 0.0934 - val_accuracy: 0.9798\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.0905 - accuracy: 0.9807 - val_loss: 0.0929 - val_accuracy: 0.9798\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.0213 - accuracy: 0.9934 - val_loss: 0.2949 - val_accuracy: 0.8090\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0164 - accuracy: 0.9950 - val_loss: 0.2568 - val_accuracy: 0.8463\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 0.2501 - val_accuracy: 0.8523\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 0.2803 - val_accuracy: 0.8448\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.3742 - val_accuracy: 0.8139\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.3768 - val_accuracy: 0.8170\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.5498 - val_accuracy: 0.7693\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 0.3767 - val_accuracy: 0.8315\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.3541 - val_accuracy: 0.8423\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 0.0128 - accuracy: 0.9964 - val_loss: 0.3101 - val_accuracy: 0.8578\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0140 - accuracy: 0.9961 - val_loss: 0.4885 - val_accuracy: 0.8045\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.5169 - val_accuracy: 0.7945\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 0.4662 - val_accuracy: 0.8132\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.5296 - val_accuracy: 0.7981\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0138 - accuracy: 0.9962 - val_loss: 0.4173 - val_accuracy: 0.8299\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0128 - accuracy: 0.9965 - val_loss: 0.4720 - val_accuracy: 0.8101\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.4654 - val_accuracy: 0.8114\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.3478 - val_accuracy: 0.8475\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.4293 - val_accuracy: 0.8227\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.4102 - val_accuracy: 0.8299\n",
      "4279/4279 [==============================] - 13s 3ms/step - loss: 0.0609 - accuracy: 0.9728\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.5760 - accuracy: 0.7192\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.1278 - accuracy: 0.9772 - val_loss: 0.1048 - val_accuracy: 0.9792\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0969 - accuracy: 0.9804 - val_loss: 0.0963 - val_accuracy: 0.9799\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 0.0916 - accuracy: 0.9807 - val_loss: 0.0939 - val_accuracy: 0.9798\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.0904 - accuracy: 0.9807 - val_loss: 0.0927 - val_accuracy: 0.9798\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 0.0893 - accuracy: 0.9807 - val_loss: 0.0918 - val_accuracy: 0.9798\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.3343 - val_accuracy: 0.8239\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.0140 - accuracy: 0.9960 - val_loss: 0.2730 - val_accuracy: 0.8616\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.4233 - val_accuracy: 0.8131\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0133 - accuracy: 0.9964 - val_loss: 0.4160 - val_accuracy: 0.8226\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.0132 - accuracy: 0.9965 - val_loss: 0.3614 - val_accuracy: 0.8437\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.0127 - accuracy: 0.9965 - val_loss: 0.4113 - val_accuracy: 0.8336\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0120 - accuracy: 0.9967 - val_loss: 0.4280 - val_accuracy: 0.8339\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.4345 - val_accuracy: 0.8312\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.4243 - val_accuracy: 0.8420\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.5038 - val_accuracy: 0.8185\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0126 - accuracy: 0.9964 - val_loss: 0.4495 - val_accuracy: 0.8302\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.0119 - accuracy: 0.9965 - val_loss: 0.4664 - val_accuracy: 0.8292\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.0119 - accuracy: 0.9966 - val_loss: 0.5391 - val_accuracy: 0.8079\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.0116 - accuracy: 0.9965 - val_loss: 0.5319 - val_accuracy: 0.8147\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.4925 - val_accuracy: 0.8237\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.5584 - val_accuracy: 0.8068\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.4655 - val_accuracy: 0.8303\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.5079 - val_accuracy: 0.8176\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.4131 - val_accuracy: 0.8428\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.6579 - val_accuracy: 0.7815\n",
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.0947 - accuracy: 0.9665 0s - loss: 0.0948 - accuracy: 0.96\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.8303 - accuracy: 0.6866\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr255Atrim.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.03547447919845581, 0.24176229536533356], [0.06090780347585678, 0.5759752988815308], [0.09472198039293289, 0.8302773833274841]]\n",
      "Accuracy for iterations:  [[0.98721843957901, 0.8914117813110352], [0.9727716445922852, 0.7192472815513611], [0.9665049910545349, 0.6865509152412415]]\n",
      "F1 for iterations:  [[0.9872179163877111, 0.8891381357650477], [0.9727271160510258, 0.6836903376510435], [0.9664137908651006, 0.6358010262225898]]\n",
      "Precision for iterations:  [[0.9872183662570505, 0.9036799999619477], [0.9735276561088202, 0.8023977883403604], [0.968161154710334, 0.7898784531411435]]\n",
      "Recall for iterations:  [[0.9872184405036665, 0.8914117561578144], [0.9727716263986678, 0.7192472571387052], [0.9665050103713225, 0.6865508973334302]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5B 5% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_12308/3503541895.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_12308/3503541895.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_12308/3503541895.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr55Btrim.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 179ms/step - loss: 0.4804 - accuracy: 0.8230 - val_loss: 0.2525 - val_accuracy: 0.9144\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 178ms/step - loss: 0.2023 - accuracy: 0.9473 - val_loss: 0.1742 - val_accuracy: 0.9605\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 0.1699 - accuracy: 0.9635 - val_loss: 0.1602 - val_accuracy: 0.9642\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 193ms/step - loss: 0.1549 - accuracy: 0.9659 - val_loss: 0.1512 - val_accuracy: 0.9658\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 188ms/step - loss: 0.1470 - accuracy: 0.9674 - val_loss: 0.1466 - val_accuracy: 0.9660 loss: 0.147\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 171ms/step - loss: 0.0357 - accuracy: 0.9899 - val_loss: 0.4334 - val_accuracy: 0.7160\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 0.0233 - accuracy: 0.9907 - val_loss: 0.3948 - val_accuracy: 0.6877\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 178ms/step - loss: 0.0217 - accuracy: 0.9920 - val_loss: 0.2892 - val_accuracy: 0.7871\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 209ms/step - loss: 0.0207 - accuracy: 0.9925 - val_loss: 0.3421 - val_accuracy: 0.7157\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 316ms/step - loss: 0.0194 - accuracy: 0.9932 - val_loss: 0.2780 - val_accuracy: 0.7905\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 364ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 4.4305 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 342ms/step - loss: 5.5917e-07 - accuracy: 1.0000 - val_loss: 4.7624 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 298ms/step - loss: 4.1689e-07 - accuracy: 1.0000 - val_loss: 4.7812 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 245ms/step - loss: 4.0943e-07 - accuracy: 1.0000 - val_loss: 4.7845 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 329ms/step - loss: 4.0665e-07 - accuracy: 1.0000 - val_loss: 4.7874 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 378ms/step - loss: 4.3898 - accuracy: 0.4004 - val_loss: 0.0470 - val_accuracy: 0.9906\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 355ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 335ms/step - loss: 5.3812e-04 - accuracy: 1.0000 - val_loss: 4.8266e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 250ms/step - loss: 2.5127e-04 - accuracy: 1.0000 - val_loss: 2.5267e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 324ms/step - loss: 1.3470e-04 - accuracy: 1.0000 - val_loss: 1.4822e-04 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 370ms/step - loss: 2.0751 - accuracy: 0.6319 - val_loss: 0.6150 - val_accuracy: 0.6356\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 348ms/step - loss: 0.0414 - accuracy: 0.9943 - val_loss: 0.6127 - val_accuracy: 0.6378\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 322ms/step - loss: 0.0234 - accuracy: 0.9943 - val_loss: 0.6054 - val_accuracy: 0.6383\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 253ms/step - loss: 0.0213 - accuracy: 0.9943 - val_loss: 0.6281 - val_accuracy: 0.6379\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 326ms/step - loss: 0.0201 - accuracy: 0.9943 - val_loss: 0.6182 - val_accuracy: 0.6376\n",
      "   1/4279 [..............................] - ETA: 30s - loss: 0.1099 - accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_test_batch_end` time: 0.0050s). Check your callbacks.\n",
      "4279/4279 [==============================] - 38s 9ms/step - loss: 0.1224 - accuracy: 0.9243\n",
      "   1/1721 [..............................] - ETA: 0s - loss: 0.6672 - accuracy: 0.6875WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_test_batch_end` time: 0.0040s). Check your callbacks.\n",
      "1721/1721 [==============================] - 13s 7ms/step - loss: 0.2528 - accuracy: 0.8514\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 267ms/step - loss: 0.1517 - accuracy: 0.9658 - val_loss: 0.1451 - val_accuracy: 0.9660\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 237ms/step - loss: 0.1408 - accuracy: 0.9676 - val_loss: 0.1425 - val_accuracy: 0.9658\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 246ms/step - loss: 0.1387 - accuracy: 0.9676 - val_loss: 0.1415 - val_accuracy: 0.9660\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 238ms/step - loss: 0.1376 - accuracy: 0.9679 - val_loss: 0.1414 - val_accuracy: 0.9663\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 235ms/step - loss: 0.1368 - accuracy: 0.9681 - val_loss: 0.1411 - val_accuracy: 0.9665\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 246ms/step - loss: 0.0231 - accuracy: 0.9932 - val_loss: 0.2395 - val_accuracy: 0.8529\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 260ms/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 0.2961 - val_accuracy: 0.7865\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 233ms/step - loss: 0.0185 - accuracy: 0.9939 - val_loss: 0.2903 - val_accuracy: 0.7969\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 236ms/step - loss: 0.0177 - accuracy: 0.9938 - val_loss: 0.2837 - val_accuracy: 0.8066\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 250ms/step - loss: 0.0168 - accuracy: 0.9946 - val_loss: 0.3495 - val_accuracy: 0.7921\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 386ms/step - loss: 0.0197 - accuracy: 0.9921 - val_loss: 3.9808 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 354ms/step - loss: 2.2120e-06 - accuracy: 1.0000 - val_loss: 4.3451 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 350ms/step - loss: 1.5780e-06 - accuracy: 1.0000 - val_loss: 4.3683 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 266ms/step - loss: 1.5365e-06 - accuracy: 1.0000 - val_loss: 4.3747 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 235ms/step - loss: 1.5146e-06 - accuracy: 1.0000 - val_loss: 4.3808 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 398ms/step - loss: 4.3311 - accuracy: 0.4421 - val_loss: 0.1799 - val_accuracy: 0.8957\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 357ms/step - loss: 0.0232 - accuracy: 0.9896 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 364ms/step - loss: 3.7497e-04 - accuracy: 1.0000 - val_loss: 7.7350e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 332ms/step - loss: 2.0670e-04 - accuracy: 1.0000 - val_loss: 5.0413e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 263ms/step - loss: 1.3991e-04 - accuracy: 1.0000 - val_loss: 3.4374e-04 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 397ms/step - loss: 1.4039 - accuracy: 0.7336 - val_loss: 0.6774 - val_accuracy: 0.6796\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 12s 372ms/step - loss: 0.0232 - accuracy: 0.9946 - val_loss: 0.4353 - val_accuracy: 0.7110\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 368ms/step - loss: 0.0168 - accuracy: 0.9943 - val_loss: 0.4870 - val_accuracy: 0.6989\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 303ms/step - loss: 0.0164 - accuracy: 0.9943 - val_loss: 0.5080 - val_accuracy: 0.6961\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 203ms/step - loss: 0.0161 - accuracy: 0.9943 - val_loss: 0.5138 - val_accuracy: 0.6964\n",
      "4279/4279 [==============================] - 32s 8ms/step - loss: 0.0895 - accuracy: 0.9445\n",
      "1721/1721 [==============================] - 12s 7ms/step - loss: 0.2435 - accuracy: 0.8602\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 200ms/step - loss: 0.1447 - accuracy: 0.9674 - val_loss: 0.1416 - val_accuracy: 0.9664\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 199ms/step - loss: 0.1374 - accuracy: 0.9681 - val_loss: 0.1413 - val_accuracy: 0.9665\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 195ms/step - loss: 0.1361 - accuracy: 0.9681 - val_loss: 0.1401 - val_accuracy: 0.9664\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 191ms/step - loss: 0.1355 - accuracy: 0.9683 - val_loss: 0.1397 - val_accuracy: 0.9667\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 203ms/step - loss: 0.1349 - accuracy: 0.9685 - val_loss: 0.1393 - val_accuracy: 0.9667\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 183ms/step - loss: 0.0214 - accuracy: 0.9941 - val_loss: 0.3044 - val_accuracy: 0.7927\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 212ms/step - loss: 0.0175 - accuracy: 0.9948 - val_loss: 0.2889 - val_accuracy: 0.8083\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 207ms/step - loss: 0.0161 - accuracy: 0.9948 - val_loss: 0.3173 - val_accuracy: 0.8068\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 194ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 0.2608 - val_accuracy: 0.8321\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 195ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.3580 - val_accuracy: 0.8088\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 10s 324ms/step - loss: 0.0441 - accuracy: 0.9811 - val_loss: 3.2952 - val_accuracy: 0.5795\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 293ms/step - loss: 1.2324e-05 - accuracy: 1.0000 - val_loss: 3.6660 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 303ms/step - loss: 8.6986e-06 - accuracy: 1.0000 - val_loss: 3.7043 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 299ms/step - loss: 8.1691e-06 - accuracy: 1.0000 - val_loss: 3.7274 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 249ms/step - loss: 7.7441e-06 - accuracy: 1.0000 - val_loss: 3.7518 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 345ms/step - loss: 3.1872 - accuracy: 0.5609 - val_loss: 0.0571 - val_accuracy: 0.9792\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 324ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 355ms/step - loss: 3.1443e-04 - accuracy: 1.0000 - val_loss: 4.3345e-04 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 366ms/step - loss: 6.4425e-05 - accuracy: 1.0000 - val_loss: 8.5235e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 304ms/step - loss: 2.4517e-05 - accuracy: 1.0000 - val_loss: 3.9871e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 13s 413ms/step - loss: 0.9796 - accuracy: 0.8089 - val_loss: 1.1128 - val_accuracy: 0.6616\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 12s 397ms/step - loss: 0.0189 - accuracy: 0.9952 - val_loss: 0.5695 - val_accuracy: 0.7278\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 13s 430ms/step - loss: 0.0153 - accuracy: 0.9949 - val_loss: 0.5954 - val_accuracy: 0.7229\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 385ms/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 0.5247 - val_accuracy: 0.7430\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 289ms/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 0.4972 - val_accuracy: 0.7513\n",
      "4279/4279 [==============================] - 43s 10ms/step - loss: 0.0749 - accuracy: 0.9594\n",
      "1721/1721 [==============================] - 16s 10ms/step - loss: 0.2723 - accuracy: 0.8637\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr55Btrim.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.12244821339845657, 0.2528262138366699], [0.08950452506542206, 0.24348971247673035], [0.07490818202495575, 0.27225756645202637]]\n",
      "Accuracy for iterations:  [[0.924260139465332, 0.8514131903648376], [0.9445280432701111, 0.8602412343025208], [0.9593692421913147, 0.8637470006942749]]\n",
      "F1 for iterations:  [[0.9235397984106394, 0.8459784484330178], [0.944217950472414, 0.8557242476851611], [0.959231231785833, 0.8594891071087266]]\n",
      "Precision for iterations:  [[0.9328015488315454, 0.8754066001815818], [0.9489238365189864, 0.8809455090187539], [0.9616180683113731, 0.8837468987190035]]\n",
      "Recall for iterations:  [[0.9242601302988693, 0.8514132093293614], [0.9445280317859125, 0.8602412264767856], [0.9593692482982267, 0.8637470028336846]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5B 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_12308/2097221778.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part1.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_12308/2097221778.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_12308/2097221778.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_12308/2097221778.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr105Btrim.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 253ms/step - loss: 0.4764 - accuracy: 0.8579 - val_loss: 0.2773 - val_accuracy: 0.9208\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 198ms/step - loss: 0.2672 - accuracy: 0.9289 - val_loss: 0.2492 - val_accuracy: 0.9397\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 209ms/step - loss: 0.2447 - accuracy: 0.9394 - val_loss: 0.2319 - val_accuracy: 0.9415\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 221ms/step - loss: 0.2310 - accuracy: 0.9418 - val_loss: 0.2224 - val_accuracy: 0.9431\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 242ms/step - loss: 0.2236 - accuracy: 0.9424 - val_loss: 0.2177 - val_accuracy: 0.9433\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 226ms/step - loss: 0.0369 - accuracy: 0.9902 - val_loss: 0.4042 - val_accuracy: 0.7557\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 217ms/step - loss: 0.0237 - accuracy: 0.9911 - val_loss: 0.3248 - val_accuracy: 0.7816\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 208ms/step - loss: 0.0223 - accuracy: 0.9917 - val_loss: 0.3500 - val_accuracy: 0.7418\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 208ms/step - loss: 0.0215 - accuracy: 0.9926 - val_loss: 0.3328 - val_accuracy: 0.7475\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 254ms/step - loss: 0.0205 - accuracy: 0.9930 - val_loss: 0.2134 - val_accuracy: 0.8898\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 394ms/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 4.3261 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 360ms/step - loss: 8.4817e-07 - accuracy: 1.0000 - val_loss: 4.6952 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 12s 402ms/step - loss: 6.0585e-07 - accuracy: 1.0000 - val_loss: 4.7163 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 290ms/step - loss: 5.9399e-07 - accuracy: 1.0000 - val_loss: 4.7199 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 278ms/step - loss: 5.8967e-07 - accuracy: 1.0000 - val_loss: 4.7229 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 14s 454ms/step - loss: 3.6794 - accuracy: 0.5175 - val_loss: 0.0210 - val_accuracy: 0.9986\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 12s 387ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 12s 382ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 290ms/step - loss: 9.0065e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 285ms/step - loss: 5.4893e-04 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 399ms/step - loss: 1.2655 - accuracy: 0.7322 - val_loss: 0.9075 - val_accuracy: 0.6345\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 366ms/step - loss: 0.0355 - accuracy: 0.9943 - val_loss: 0.6873 - val_accuracy: 0.6379\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 364ms/step - loss: 0.0231 - accuracy: 0.9942 - val_loss: 0.6384 - val_accuracy: 0.6383\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 272ms/step - loss: 0.0218 - accuracy: 0.9942 - val_loss: 0.6242 - val_accuracy: 0.6381\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 352ms/step - loss: 0.0209 - accuracy: 0.9942 - val_loss: 0.6092 - val_accuracy: 0.6381\n",
      "4279/4279 [==============================] - 38s 9ms/step - loss: 0.1222 - accuracy: 0.9255\n",
      "1721/1721 [==============================] - 12s 7ms/step - loss: 0.2281 - accuracy: 0.8877\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 245ms/step - loss: 0.2302 - accuracy: 0.9416 - val_loss: 0.2167 - val_accuracy: 0.9433\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 202ms/step - loss: 0.2191 - accuracy: 0.9425 - val_loss: 0.2154 - val_accuracy: 0.9433\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 211ms/step - loss: 0.2176 - accuracy: 0.9426 - val_loss: 0.2138 - val_accuracy: 0.9433\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 185ms/step - loss: 0.2166 - accuracy: 0.9425 - val_loss: 0.2143 - val_accuracy: 0.9433\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 203ms/step - loss: 0.2167 - accuracy: 0.9427 - val_loss: 0.2135 - val_accuracy: 0.9433\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 249ms/step - loss: 0.0257 - accuracy: 0.9930 - val_loss: 0.3747 - val_accuracy: 0.7118\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 254ms/step - loss: 0.0203 - accuracy: 0.9932 - val_loss: 0.2685 - val_accuracy: 0.8083\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 196ms/step - loss: 0.0191 - accuracy: 0.9938 - val_loss: 0.3438 - val_accuracy: 0.7587\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 200ms/step - loss: 0.0182 - accuracy: 0.9940 - val_loss: 0.2589 - val_accuracy: 0.8195\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 201ms/step - loss: 0.0174 - accuracy: 0.9941 - val_loss: 0.2959 - val_accuracy: 0.8066\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 376ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 4.3115 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 339ms/step - loss: 6.6590e-07 - accuracy: 1.0000 - val_loss: 4.6119 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 298ms/step - loss: 5.1037e-07 - accuracy: 1.0000 - val_loss: 4.6298 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 254ms/step - loss: 5.0138e-07 - accuracy: 1.0000 - val_loss: 4.6337 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 209ms/step - loss: 4.9730e-07 - accuracy: 1.0000 - val_loss: 4.6372 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 352ms/step - loss: 3.8336 - accuracy: 0.5097 - val_loss: 0.0433 - val_accuracy: 0.9884\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 354ms/step - loss: 0.0060 - accuracy: 0.9999 - val_loss: 0.0038 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 347ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 317ms/step - loss: 6.6328e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 247ms/step - loss: 4.5370e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 377ms/step - loss: 1.1534 - accuracy: 0.7468 - val_loss: 0.6032 - val_accuracy: 0.6624\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 12s 382ms/step - loss: 0.0316 - accuracy: 0.9948 - val_loss: 0.4601 - val_accuracy: 0.6896\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 365ms/step - loss: 0.0202 - accuracy: 0.9947 - val_loss: 0.4449 - val_accuracy: 0.6939\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 330ms/step - loss: 0.0189 - accuracy: 0.9947 - val_loss: 0.4874 - val_accuracy: 0.6790\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 261ms/step - loss: 0.0181 - accuracy: 0.9947 - val_loss: 0.5062 - val_accuracy: 0.6745\n",
      "4279/4279 [==============================] - 42s 10ms/step - loss: 0.1018 - accuracy: 0.9414\n",
      "1721/1721 [==============================] - 15s 9ms/step - loss: 0.2820 - accuracy: 0.8346\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 261ms/step - loss: 0.2286 - accuracy: 0.9420 - val_loss: 0.2144 - val_accuracy: 0.9434\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 248ms/step - loss: 0.2172 - accuracy: 0.9427 - val_loss: 0.2136 - val_accuracy: 0.9435\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 247ms/step - loss: 0.2161 - accuracy: 0.9430 - val_loss: 0.2133 - val_accuracy: 0.9435\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 236ms/step - loss: 0.2159 - accuracy: 0.9431 - val_loss: 0.2129 - val_accuracy: 0.9436\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 238ms/step - loss: 0.2163 - accuracy: 0.9432 - val_loss: 0.2123 - val_accuracy: 0.9439\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 227ms/step - loss: 0.0245 - accuracy: 0.9936 - val_loss: 0.4093 - val_accuracy: 0.7178\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 211ms/step - loss: 0.0186 - accuracy: 0.9945 - val_loss: 0.2818 - val_accuracy: 0.8005\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 203ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.3710 - val_accuracy: 0.7681\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 183ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 0.3064 - val_accuracy: 0.8074\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 195ms/step - loss: 0.0166 - accuracy: 0.9943 - val_loss: 0.2867 - val_accuracy: 0.8189\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 361ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 4.0598 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 350ms/step - loss: 1.4187e-06 - accuracy: 1.0000 - val_loss: 4.3816 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 345ms/step - loss: 1.0804e-06 - accuracy: 1.0000 - val_loss: 4.4027 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 313ms/step - loss: 1.0551e-06 - accuracy: 1.0000 - val_loss: 4.4091 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 213ms/step - loss: 1.0403e-06 - accuracy: 1.0000 - val_loss: 4.4155 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 10s 326ms/step - loss: 3.4981 - accuracy: 0.5289 - val_loss: 0.0894 - val_accuracy: 0.9772\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 317ms/step - loss: 0.0117 - accuracy: 0.9998 - val_loss: 0.0151 - val_accuracy: 0.9976\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 317ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 0.9989\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 272ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 0.9992\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 197ms/step - loss: 9.4035e-04 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9995\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 10s 319ms/step - loss: 0.6466 - accuracy: 0.8279 - val_loss: 0.8672 - val_accuracy: 0.6652\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 301ms/step - loss: 0.0193 - accuracy: 0.9950 - val_loss: 0.5998 - val_accuracy: 0.6971\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 328ms/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.5464 - val_accuracy: 0.7090\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 306ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.5556 - val_accuracy: 0.7072\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 244ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.5262 - val_accuracy: 0.7152\n",
      "4279/4279 [==============================] - 42s 10ms/step - loss: 0.0924 - accuracy: 0.9511\n",
      "1721/1721 [==============================] - 10s 6ms/step - loss: 0.3041 - accuracy: 0.8382\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr105Btrim.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.122221939265728, 0.2280646115541458], [0.10179457068443298, 0.28196805715560913], [0.09244326502084732, 0.30414462089538574]]\n",
      "Accuracy for iterations:  [[0.9255455732345581, 0.8877425193786621], [0.941372811794281, 0.8346290588378906], [0.9510868191719055, 0.838207483291626]]\n",
      "F1 for iterations:  [[0.9248587934917004, 0.8852297838198837], [0.9410112177452631, 0.8272093187585741], [0.9508598994241823, 0.8312715046375951]]\n",
      "Precision for iterations:  [[0.9337771859800958, 0.9011270863559564], [0.9463667913714228, 0.8648585340365701], [0.9545341635122602, 0.8668976370039558]]\n",
      "Recall for iterations:  [[0.9255455899967864, 0.8877424980018891], [0.941372812527389, 0.8346290779626535], [0.9510867977446025, 0.8382075128968974]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5B 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16296/3291834707.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part1.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16296/3291834707.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16296/3291834707.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16296/3291834707.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr255Btrim.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.5489 - accuracy: 0.7542 - val_loss: 0.4311 - val_accuracy: 0.8559\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 0.4217 - accuracy: 0.8586 - val_loss: 0.4032 - val_accuracy: 0.8683\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 0.4051 - accuracy: 0.8662 - val_loss: 0.3924 - val_accuracy: 0.8700\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 150ms/step - loss: 0.3975 - accuracy: 0.8679 - val_loss: 0.3886 - val_accuracy: 0.8704\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.3936 - accuracy: 0.8683 - val_loss: 0.3887 - val_accuracy: 0.8705\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.0505 - accuracy: 0.9895 - val_loss: 0.5217 - val_accuracy: 0.6561\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0241 - accuracy: 0.9908 - val_loss: 0.4075 - val_accuracy: 0.6819\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.0223 - accuracy: 0.9916 - val_loss: 0.3445 - val_accuracy: 0.7299\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 0.0215 - accuracy: 0.9921 - val_loss: 0.4119 - val_accuracy: 0.6817\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0207 - accuracy: 0.9925 - val_loss: 0.3586 - val_accuracy: 0.7140\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 150ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 4.3050 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 9.7667e-07 - accuracy: 1.0000 - val_loss: 4.6076 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 7.4905e-07 - accuracy: 1.0000 - val_loss: 4.6257 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 7.3499e-07 - accuracy: 1.0000 - val_loss: 4.6298 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 7.2846e-07 - accuracy: 1.0000 - val_loss: 4.6335 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 3.7518 - accuracy: 0.4761 - val_loss: 0.0255 - val_accuracy: 0.9946\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 6.2100e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 166ms/step - loss: 3.3243e-04 - accuracy: 1.0000 - val_loss: 6.5973e-04 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 1.7389e-04 - accuracy: 1.0000 - val_loss: 3.0869e-04 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 1.7648 - accuracy: 0.6662 - val_loss: 0.6190 - val_accuracy: 0.6353\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0521 - accuracy: 0.9942 - val_loss: 0.5644 - val_accuracy: 0.6370\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.0284 - accuracy: 0.9942 - val_loss: 0.5958 - val_accuracy: 0.6374\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0244 - accuracy: 0.9942 - val_loss: 0.6586 - val_accuracy: 0.6368\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0224 - accuracy: 0.9942 - val_loss: 0.6594 - val_accuracy: 0.6367\n",
      "4279/4279 [==============================] - 22s 5ms/step - loss: 0.1272 - accuracy: 0.9239\n",
      "1721/1721 [==============================] - 9s 5ms/step - loss: 0.2506 - accuracy: 0.8515\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 186ms/step - loss: 0.4212 - accuracy: 0.8666 - val_loss: 0.3912 - val_accuracy: 0.8702\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.3938 - accuracy: 0.8682 - val_loss: 0.3853 - val_accuracy: 0.8705\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.3909 - accuracy: 0.8683 - val_loss: 0.3847 - val_accuracy: 0.8705\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.3899 - accuracy: 0.8683 - val_loss: 0.3840 - val_accuracy: 0.8705\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.3892 - accuracy: 0.8684 - val_loss: 0.3842 - val_accuracy: 0.8705\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0336 - accuracy: 0.9918 - val_loss: 0.3259 - val_accuracy: 0.7229\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.2931 - val_accuracy: 0.7639\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.3414 - val_accuracy: 0.7385\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 0.0192 - accuracy: 0.9938 - val_loss: 0.3979 - val_accuracy: 0.7236\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 170ms/step - loss: 0.0186 - accuracy: 0.9937 - val_loss: 0.4734 - val_accuracy: 0.7149\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 4.1372 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 1.3921e-06 - accuracy: 1.0000 - val_loss: 4.4328 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 1.0762e-06 - accuracy: 1.0000 - val_loss: 4.4521 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 1.0524e-06 - accuracy: 1.0000 - val_loss: 4.4581 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 1.0386e-06 - accuracy: 1.0000 - val_loss: 4.4638 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 175ms/step - loss: 3.9173 - accuracy: 0.4415 - val_loss: 0.1032 - val_accuracy: 0.9475\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 181ms/step - loss: 0.0168 - accuracy: 0.9980 - val_loss: 0.0022 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 187ms/step - loss: 9.4538e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 201ms/step - loss: 6.2685e-04 - accuracy: 1.0000 - val_loss: 8.9799e-04 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 211ms/step - loss: 4.7516e-04 - accuracy: 1.0000 - val_loss: 6.8377e-04 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 248ms/step - loss: 1.2863 - accuracy: 0.7047 - val_loss: 0.5110 - val_accuracy: 0.6922\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 219ms/step - loss: 0.0310 - accuracy: 0.9943 - val_loss: 0.3519 - val_accuracy: 0.7477\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 208ms/step - loss: 0.0197 - accuracy: 0.9936 - val_loss: 0.4602 - val_accuracy: 0.6892\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 179ms/step - loss: 0.0186 - accuracy: 0.9944 - val_loss: 0.5197 - val_accuracy: 0.6803\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.5252 - val_accuracy: 0.6793\n",
      "4279/4279 [==============================] - 18s 4ms/step - loss: 0.0943 - accuracy: 0.9385\n",
      "1721/1721 [==============================] - 7s 4ms/step - loss: 0.2078 - accuracy: 0.9015\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.4370 - accuracy: 0.8672 - val_loss: 0.3903 - val_accuracy: 0.8704\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.3925 - accuracy: 0.8683 - val_loss: 0.3841 - val_accuracy: 0.8705\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.3898 - accuracy: 0.8684 - val_loss: 0.3838 - val_accuracy: 0.8705\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.3893 - accuracy: 0.8683 - val_loss: 0.3831 - val_accuracy: 0.8705\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.3886 - accuracy: 0.8684 - val_loss: 0.3843 - val_accuracy: 0.8705\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0347 - accuracy: 0.9921 - val_loss: 0.3153 - val_accuracy: 0.7473\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.0195 - accuracy: 0.9932 - val_loss: 0.3488 - val_accuracy: 0.7475\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0184 - accuracy: 0.9938 - val_loss: 0.3055 - val_accuracy: 0.7852\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 171ms/step - loss: 0.0176 - accuracy: 0.9940 - val_loss: 0.3265 - val_accuracy: 0.7878\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 170ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.2799 - val_accuracy: 0.8127\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0260 - accuracy: 0.9897 - val_loss: 3.4838 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 170ms/step - loss: 8.6319e-06 - accuracy: 1.0000 - val_loss: 3.8056 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 198ms/step - loss: 6.4521e-06 - accuracy: 1.0000 - val_loss: 3.8328 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 207ms/step - loss: 6.1966e-06 - accuracy: 1.0000 - val_loss: 3.8460 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 208ms/step - loss: 6.0021e-06 - accuracy: 1.0000 - val_loss: 3.8601 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 226ms/step - loss: 3.8104 - accuracy: 0.4211 - val_loss: 0.1728 - val_accuracy: 0.8915\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 210ms/step - loss: 0.0303 - accuracy: 0.9935 - val_loss: 0.0069 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 202ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 218ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 176ms/step - loss: 7.5872e-04 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 178ms/step - loss: 0.7564 - accuracy: 0.7738 - val_loss: 0.6243 - val_accuracy: 0.6878\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 205ms/step - loss: 0.0218 - accuracy: 0.9945 - val_loss: 0.4327 - val_accuracy: 0.7203\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 230ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.5366 - val_accuracy: 0.6959\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 233ms/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 0.5270 - val_accuracy: 0.6973\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 240ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.5341 - val_accuracy: 0.6963\n",
      "4279/4279 [==============================] - 21s 5ms/step - loss: 0.0869 - accuracy: 0.9469\n",
      "1721/1721 [==============================] - 8s 5ms/step - loss: 0.2302 - accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr255Btrim.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.12718556821346283, 0.2506321370601654], [0.09431221336126328, 0.20777417719364166], [0.08693456649780273, 0.2302439659833908]]\n",
      "Accuracy for iterations:  [[0.9239314794540405, 0.8514677286148071], [0.9384732246398926, 0.9015294909477234], [0.9468725323677063, 0.8750090599060059]]\n",
      "F1 for iterations:  [[0.9232044215951977, 0.8462135463954481], [0.9380632083276941, 0.8997971859796177], [0.9465919401131463, 0.8716070442680398]]\n",
      "Precision for iterations:  [[0.9325202875460346, 0.8742504965436585], [0.9439814188043357, 0.9113137972507154], [0.9509623857296089, 0.8920751366213381]]\n",
      "Recall for iterations:  [[0.9239314616261065, 0.8514677032623701], [0.9384732244587922, 0.9015294630531134], [0.9468725349849543, 0.8750090823221681]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 1 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16296/591709827.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr55C1trim.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 207ms/step - loss: 0.6056 - accuracy: 0.7805 - val_loss: 0.4711 - val_accuracy: 0.7837\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.3646 - accuracy: 0.8595 - val_loss: 0.2521 - val_accuracy: 0.9267\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 0.2224 - accuracy: 0.9405 - val_loss: 0.1963 - val_accuracy: 0.9553\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 0.1947 - accuracy: 0.9583 - val_loss: 0.1804 - val_accuracy: 0.9615\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.1819 - accuracy: 0.9621 - val_loss: 0.1696 - val_accuracy: 0.9645\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 212ms/step - loss: 0.0416 - accuracy: 0.9903 - val_loss: 0.6089 - val_accuracy: 0.7274\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 196ms/step - loss: 0.0239 - accuracy: 0.9936 - val_loss: 0.8258 - val_accuracy: 0.7270\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 194ms/step - loss: 0.0215 - accuracy: 0.9950 - val_loss: 0.7282 - val_accuracy: 0.7270\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 196ms/step - loss: 0.0202 - accuracy: 0.9950 - val_loss: 0.5804 - val_accuracy: 0.7278\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 197ms/step - loss: 0.0194 - accuracy: 0.9950 - val_loss: 0.5486 - val_accuracy: 0.7287\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 209ms/step - loss: 0.0149 - accuracy: 0.9961 - val_loss: 1.9821 - val_accuracy: 0.4446\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.0145 - accuracy: 0.9962 - val_loss: 2.2859 - val_accuracy: 0.4438\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.0130 - accuracy: 0.9967 - val_loss: 1.8380 - val_accuracy: 0.4434\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 197ms/step - loss: 0.0128 - accuracy: 0.9967 - val_loss: 2.1548 - val_accuracy: 0.4386\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.0121 - accuracy: 0.9972 - val_loss: 1.7690 - val_accuracy: 0.4391\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 6s 223ms/step - loss: 2.0043 - accuracy: 0.6007 - val_loss: 0.0465 - val_accuracy: 0.9867\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 6s 211ms/step - loss: 0.0059 - accuracy: 0.9997 - val_loss: 0.0090 - val_accuracy: 0.9958\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 6s 208ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9976\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 6s 213ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9982\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 6s 211ms/step - loss: 7.4196e-04 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9988\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 15s 217ms/step - loss: 0.4821 - accuracy: 0.8930 - val_loss: 0.3525 - val_accuracy: 0.8276\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 15s 218ms/step - loss: 0.0237 - accuracy: 0.9925 - val_loss: 0.2589 - val_accuracy: 0.8297\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 15s 217ms/step - loss: 0.0216 - accuracy: 0.9926 - val_loss: 0.2333 - val_accuracy: 0.8391\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 15s 217ms/step - loss: 0.0206 - accuracy: 0.9929 - val_loss: 0.2113 - val_accuracy: 0.8532\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 15s 217ms/step - loss: 0.0198 - accuracy: 0.9930 - val_loss: 0.2053 - val_accuracy: 0.8576\n",
      "4279/4279 [==============================] - 27s 6ms/step - loss: 0.0627 - accuracy: 0.9875\n",
      "1721/1721 [==============================] - 11s 6ms/step - loss: 0.1246 - accuracy: 0.9750\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 214ms/step - loss: 0.1825 - accuracy: 0.9606 - val_loss: 0.1598 - val_accuracy: 0.9663\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 198ms/step - loss: 0.1595 - accuracy: 0.9650 - val_loss: 0.1502 - val_accuracy: 0.9669\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 203ms/step - loss: 0.1536 - accuracy: 0.9655 - val_loss: 0.1463 - val_accuracy: 0.9671\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 212ms/step - loss: 0.1504 - accuracy: 0.9656 - val_loss: 0.1441 - val_accuracy: 0.9678\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 207ms/step - loss: 0.1488 - accuracy: 0.9657 - val_loss: 0.1425 - val_accuracy: 0.9680\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 221ms/step - loss: 0.0286 - accuracy: 0.9919 - val_loss: 0.7553 - val_accuracy: 0.7257\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 196ms/step - loss: 0.0179 - accuracy: 0.9950 - val_loss: 0.7860 - val_accuracy: 0.7260\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 203ms/step - loss: 0.0163 - accuracy: 0.9952 - val_loss: 0.4379 - val_accuracy: 0.7270\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 203ms/step - loss: 0.0160 - accuracy: 0.9954 - val_loss: 0.4100 - val_accuracy: 0.7281\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 192ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.6485 - val_accuracy: 0.7235\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 6s 215ms/step - loss: 0.0116 - accuracy: 0.9972 - val_loss: 1.3542 - val_accuracy: 0.4486\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.0112 - accuracy: 0.9972 - val_loss: 1.6647 - val_accuracy: 0.4445\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 203ms/step - loss: 0.0109 - accuracy: 0.9973 - val_loss: 1.3064 - val_accuracy: 0.4831\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 210ms/step - loss: 0.0107 - accuracy: 0.9973 - val_loss: 1.2333 - val_accuracy: 0.5155\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 204ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 1.5410 - val_accuracy: 0.4772\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 6s 219ms/step - loss: 3.0086 - accuracy: 0.5506 - val_loss: 0.2721 - val_accuracy: 0.9154\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 6s 211ms/step - loss: 0.0842 - accuracy: 0.9641 - val_loss: 0.0075 - val_accuracy: 0.9965\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 6s 210ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9991\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 6s 214ms/step - loss: 8.5840e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9996\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 6s 211ms/step - loss: 6.5476e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 15s 218ms/step - loss: 0.5712 - accuracy: 0.8884 - val_loss: 0.2105 - val_accuracy: 0.8872\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 15s 215ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 0.1956 - val_accuracy: 0.8901\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 15s 217ms/step - loss: 0.0176 - accuracy: 0.9940 - val_loss: 0.1692 - val_accuracy: 0.9014\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 15s 218ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 0.1705 - val_accuracy: 0.8948\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 15s 218ms/step - loss: 0.0166 - accuracy: 0.9944 - val_loss: 0.1385 - val_accuracy: 0.9182\n",
      "4279/4279 [==============================] - 28s 7ms/step - loss: 0.0677 - accuracy: 0.9874\n",
      "1721/1721 [==============================] - 11s 6ms/step - loss: 0.1550 - accuracy: 0.9530\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 4s 221ms/step - loss: 0.1776 - accuracy: 0.9628 - val_loss: 0.1523 - val_accuracy: 0.9678\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 215ms/step - loss: 0.1537 - accuracy: 0.9658 - val_loss: 0.1459 - val_accuracy: 0.9678\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 208ms/step - loss: 0.1492 - accuracy: 0.9657 - val_loss: 0.1424 - val_accuracy: 0.9678\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 206ms/step - loss: 0.1470 - accuracy: 0.9657 - val_loss: 0.1414 - val_accuracy: 0.9680\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 213ms/step - loss: 0.1463 - accuracy: 0.9659 - val_loss: 0.1406 - val_accuracy: 0.9680\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 221ms/step - loss: 0.0310 - accuracy: 0.9931 - val_loss: 0.6759 - val_accuracy: 0.7248\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 195ms/step - loss: 0.0158 - accuracy: 0.9952 - val_loss: 0.7817 - val_accuracy: 0.7260\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 207ms/step - loss: 0.0152 - accuracy: 0.9955 - val_loss: 0.6296 - val_accuracy: 0.7238\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 199ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.5750 - val_accuracy: 0.7261\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 203ms/step - loss: 0.0139 - accuracy: 0.9961 - val_loss: 0.5391 - val_accuracy: 0.7331\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 6s 225ms/step - loss: 0.0114 - accuracy: 0.9973 - val_loss: 1.2548 - val_accuracy: 0.4924\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 210ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 1.4310 - val_accuracy: 0.5025\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 6s 213ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 1.7181 - val_accuracy: 0.4867\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 210ms/step - loss: 0.0100 - accuracy: 0.9975 - val_loss: 1.8173 - val_accuracy: 0.4935\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 6s 216ms/step - loss: 0.0101 - accuracy: 0.9975 - val_loss: 1.8231 - val_accuracy: 0.5032\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 6s 228ms/step - loss: 2.4193 - accuracy: 0.6466 - val_loss: 0.0581 - val_accuracy: 0.9851\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 6s 217ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 9.6682e-04 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 6s 220ms/step - loss: 1.8840e-04 - accuracy: 1.0000 - val_loss: 5.5477e-04 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 6s 219ms/step - loss: 1.4154e-04 - accuracy: 1.0000 - val_loss: 4.8228e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 6s 214ms/step - loss: 1.2470e-04 - accuracy: 1.0000 - val_loss: 4.3031e-04 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 16s 226ms/step - loss: 0.4553 - accuracy: 0.9183 - val_loss: 0.2184 - val_accuracy: 0.9009\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 16s 225ms/step - loss: 0.0173 - accuracy: 0.9940 - val_loss: 0.1757 - val_accuracy: 0.9143\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 16s 224ms/step - loss: 0.0162 - accuracy: 0.9944 - val_loss: 0.1594 - val_accuracy: 0.9176\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 16s 222ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.1702 - val_accuracy: 0.9077\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 16s 222ms/step - loss: 0.0150 - accuracy: 0.9950 - val_loss: 0.1317 - val_accuracy: 0.9291\n",
      "4279/4279 [==============================] - 33s 8ms/step - loss: 0.0827 - accuracy: 0.9822\n",
      "1721/1721 [==============================] - 12s 7ms/step - loss: 0.1578 - accuracy: 0.9506\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr55C1trim.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.062733955681324, 0.12458465248346329], [0.06769371032714844, 0.15497343242168427], [0.08265060186386108, 0.15783391892910004]]\n",
      "Accuracy for iterations:  [[0.9875178933143616, 0.975023627281189], [0.9873718023300171, 0.9530262351036072], [0.9821934700012207, 0.950610339641571]]\n",
      "F1 for iterations:  [[0.987521807169782, 0.9750497780067887], [0.9873789847612794, 0.9531916411137277], [0.9822060764648011, 0.9507851310990553]]\n",
      "Precision for iterations:  [[0.9875986220703395, 0.9752430062115834], [0.9876991976496031, 0.9575644361152994], [0.9828387569128129, 0.9552772476117818]]\n",
      "Recall for iterations:  [[0.9875178941832948, 0.9750236140376372], [0.9873718192176225, 0.9530262297464216], [0.9821934616845365, 0.9506103320496985]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 1 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16296/372464333.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr105C1trim.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 4s 229ms/step - loss: 0.6243 - accuracy: 0.6882 - val_loss: 0.5144 - val_accuracy: 0.7838\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 10s 615ms/step - loss: 0.4160 - accuracy: 0.8354 - val_loss: 0.3155 - val_accuracy: 0.9043\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 5s 295ms/step - loss: 0.2934 - accuracy: 0.9173 - val_loss: 0.2806 - val_accuracy: 0.9293\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 4s 252ms/step - loss: 0.2688 - accuracy: 0.9344 - val_loss: 0.2662 - val_accuracy: 0.9383\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 4s 243ms/step - loss: 0.2572 - accuracy: 0.9382 - val_loss: 0.2556 - val_accuracy: 0.9394\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 232ms/step - loss: 0.0562 - accuracy: 0.9903 - val_loss: 0.6054 - val_accuracy: 0.7271\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 239ms/step - loss: 0.0287 - accuracy: 0.9936 - val_loss: 0.7423 - val_accuracy: 0.7270\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 240ms/step - loss: 0.0242 - accuracy: 0.9940 - val_loss: 0.7954 - val_accuracy: 0.7270\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 247ms/step - loss: 0.0216 - accuracy: 0.9950 - val_loss: 0.6374 - val_accuracy: 0.7271\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 243ms/step - loss: 0.0206 - accuracy: 0.9950 - val_loss: 0.6105 - val_accuracy: 0.7272\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 6s 243ms/step - loss: 0.0152 - accuracy: 0.9960 - val_loss: 2.3602 - val_accuracy: 0.4443\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 6s 240ms/step - loss: 0.0138 - accuracy: 0.9961 - val_loss: 2.0985 - val_accuracy: 0.4433\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 6s 222ms/step - loss: 0.0132 - accuracy: 0.9964 - val_loss: 1.7758 - val_accuracy: 0.4438\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 6s 239ms/step - loss: 0.0126 - accuracy: 0.9967 - val_loss: 2.0980 - val_accuracy: 0.4384\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 6s 222ms/step - loss: 0.0121 - accuracy: 0.9972 - val_loss: 1.9229 - val_accuracy: 0.4379\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 6s 229ms/step - loss: 2.0071 - accuracy: 0.6242 - val_loss: 0.0285 - val_accuracy: 0.9887\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 6s 222ms/step - loss: 0.0036 - accuracy: 0.9999 - val_loss: 0.0053 - val_accuracy: 0.9979\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 6s 229ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9995\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 6s 227ms/step - loss: 7.5965e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 6s 229ms/step - loss: 4.5108e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 19s 278ms/step - loss: 0.5535 - accuracy: 0.8895 - val_loss: 0.3801 - val_accuracy: 0.8274\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 21s 303ms/step - loss: 0.0241 - accuracy: 0.9927 - val_loss: 0.2626 - val_accuracy: 0.8416\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 20s 285ms/step - loss: 0.0216 - accuracy: 0.9927 - val_loss: 0.2392 - val_accuracy: 0.8513\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 19s 270ms/step - loss: 0.0204 - accuracy: 0.9931 - val_loss: 0.2089 - val_accuracy: 0.8686\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 18s 262ms/step - loss: 0.0194 - accuracy: 0.9933 - val_loss: 0.2148 - val_accuracy: 0.8626\n",
      "4279/4279 [==============================] - 23s 5ms/step - loss: 0.0805 - accuracy: 0.9871\n",
      "1721/1721 [==============================] - 8s 5ms/step - loss: 0.1540 - accuracy: 0.9524\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 4s 262ms/step - loss: 0.2872 - accuracy: 0.9315 - val_loss: 0.2477 - val_accuracy: 0.9415\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 4s 248ms/step - loss: 0.2426 - accuracy: 0.9403 - val_loss: 0.2325 - val_accuracy: 0.9421\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 4s 260ms/step - loss: 0.2321 - accuracy: 0.9407 - val_loss: 0.2274 - val_accuracy: 0.9424\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 5s 286ms/step - loss: 0.2281 - accuracy: 0.9409 - val_loss: 0.2238 - val_accuracy: 0.9426\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 5s 292ms/step - loss: 0.2257 - accuracy: 0.9409 - val_loss: 0.2222 - val_accuracy: 0.9426\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 4s 317ms/step - loss: 0.0381 - accuracy: 0.9912 - val_loss: 0.7060 - val_accuracy: 0.7252\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 231ms/step - loss: 0.0176 - accuracy: 0.9953 - val_loss: 0.7659 - val_accuracy: 0.7267\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 4s 253ms/step - loss: 0.0171 - accuracy: 0.9952 - val_loss: 0.6311 - val_accuracy: 0.7251\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 246ms/step - loss: 0.0159 - accuracy: 0.9952 - val_loss: 0.4552 - val_accuracy: 0.7257\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 243ms/step - loss: 0.0153 - accuracy: 0.9953 - val_loss: 0.5633 - val_accuracy: 0.7252\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 8s 299ms/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 1.5263 - val_accuracy: 0.4427\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 6s 234ms/step - loss: 0.0112 - accuracy: 0.9972 - val_loss: 1.5954 - val_accuracy: 0.4544\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 6s 236ms/step - loss: 0.0110 - accuracy: 0.9973 - val_loss: 1.2652 - val_accuracy: 0.5006\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 8s 291ms/step - loss: 0.0106 - accuracy: 0.9973 - val_loss: 1.2917 - val_accuracy: 0.5490\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 8s 318ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 1.1209 - val_accuracy: 0.6041\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 9s 331ms/step - loss: 3.0518 - accuracy: 0.5447 - val_loss: 0.1448 - val_accuracy: 0.9288\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 8s 291ms/step - loss: 0.0269 - accuracy: 0.9878 - val_loss: 0.0026 - val_accuracy: 0.9992\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 9s 323ms/step - loss: 4.5868e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 8s 291ms/step - loss: 3.2975e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 8s 292ms/step - loss: 2.9439e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 20s 282ms/step - loss: 0.7142 - accuracy: 0.8828 - val_loss: 0.2075 - val_accuracy: 0.8983\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 21s 300ms/step - loss: 0.0185 - accuracy: 0.9939 - val_loss: 0.2044 - val_accuracy: 0.8908\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 24s 339ms/step - loss: 0.0176 - accuracy: 0.9941 - val_loss: 0.1863 - val_accuracy: 0.8935\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 22s 320ms/step - loss: 0.0168 - accuracy: 0.9943 - val_loss: 0.1596 - val_accuracy: 0.9062\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 22s 315ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 0.1736 - val_accuracy: 0.8942\n",
      "4279/4279 [==============================] - 27s 6ms/step - loss: 0.0548 - accuracy: 0.9902\n",
      "1721/1721 [==============================] - 10s 6ms/step - loss: 0.1029 - accuracy: 0.9817\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 4s 268ms/step - loss: 0.2931 - accuracy: 0.9349 - val_loss: 0.2394 - val_accuracy: 0.9428\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 4s 274ms/step - loss: 0.2368 - accuracy: 0.9413 - val_loss: 0.2283 - val_accuracy: 0.9428\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 5s 321ms/step - loss: 0.2284 - accuracy: 0.9414 - val_loss: 0.2248 - val_accuracy: 0.9424\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 5s 342ms/step - loss: 0.2253 - accuracy: 0.9413 - val_loss: 0.2218 - val_accuracy: 0.9428\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 5s 321ms/step - loss: 0.2240 - accuracy: 0.9414 - val_loss: 0.2205 - val_accuracy: 0.9429\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 4s 312ms/step - loss: 0.0366 - accuracy: 0.9921 - val_loss: 0.6995 - val_accuracy: 0.7218\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 5s 322ms/step - loss: 0.0157 - accuracy: 0.9953 - val_loss: 0.7480 - val_accuracy: 0.7254\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 5s 327ms/step - loss: 0.0155 - accuracy: 0.9957 - val_loss: 0.5887 - val_accuracy: 0.7229\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 4s 320ms/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.5545 - val_accuracy: 0.7270\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 4s 289ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.4790 - val_accuracy: 0.7392\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 8s 295ms/step - loss: 0.0112 - accuracy: 0.9971 - val_loss: 1.5146 - val_accuracy: 0.4707\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 9s 336ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 1.3775 - val_accuracy: 0.5098\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 7s 282ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 1.6682 - val_accuracy: 0.5026\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 8s 306ms/step - loss: 0.0099 - accuracy: 0.9975 - val_loss: 1.8136 - val_accuracy: 0.5067\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 7s 271ms/step - loss: 0.0099 - accuracy: 0.9975 - val_loss: 1.6616 - val_accuracy: 0.5408\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 8s 283ms/step - loss: 3.1606 - accuracy: 0.5507 - val_loss: 0.2126 - val_accuracy: 0.9263\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 7s 275ms/step - loss: 0.0542 - accuracy: 0.9756 - val_loss: 7.0360e-04 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 8s 283ms/step - loss: 2.9392e-04 - accuracy: 1.0000 - val_loss: 2.5219e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 7s 268ms/step - loss: 1.8664e-04 - accuracy: 1.0000 - val_loss: 2.0951e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 7s 267ms/step - loss: 1.6336e-04 - accuracy: 1.0000 - val_loss: 1.8515e-04 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 19s 271ms/step - loss: 0.6935 - accuracy: 0.8932 - val_loss: 0.1693 - val_accuracy: 0.9176\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 19s 274ms/step - loss: 0.0167 - accuracy: 0.9944 - val_loss: 0.1794 - val_accuracy: 0.9067\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 19s 268ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.1748 - val_accuracy: 0.9037\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 19s 265ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.1542 - val_accuracy: 0.9136\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 19s 268ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.1363 - val_accuracy: 0.9249\n",
      "4279/4279 [==============================] - 23s 5ms/step - loss: 0.0783 - accuracy: 0.9848\n",
      "1721/1721 [==============================] - 9s 5ms/step - loss: 0.2025 - accuracy: 0.9285\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr105C1trim.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.08047237247228622, 0.15403608977794647], [0.05477147549390793, 0.10293388366699219], [0.0783243402838707, 0.20254896581172943]]\n",
      "Accuracy for iterations:  [[0.9870796799659729, 0.9523723125457764], [0.990234911441803, 0.9816718697547913], [0.9847862720489502, 0.9284676313400269]]\n",
      "F1 for iterations:  [[0.9870829419179444, 0.9521742472039973], [0.9902394206199777, 0.9817068548328882], [0.9847960923824791, 0.928724059622684]]\n",
      "Precision for iterations:  [[0.9871314968459036, 0.9534397207559683], [0.9904291343131405, 0.9824032818165005], [0.98525858467648, 0.9384855711664822]]\n",
      "Recall for iterations:  [[0.9870796692862778, 0.952372302550316], [0.9902348885448012, 0.9816718738647098], [0.9847862923252213, 0.9284676306037928]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 1 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16296/2868219575.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr255C1trim.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 4s 251ms/step - loss: 0.6313 - accuracy: 0.7003 - val_loss: 0.5432 - val_accuracy: 0.7077\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 4s 248ms/step - loss: 0.4903 - accuracy: 0.7938 - val_loss: 0.4393 - val_accuracy: 0.8516\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 4s 243ms/step - loss: 0.4341 - accuracy: 0.8548 - val_loss: 0.4181 - val_accuracy: 0.8648\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 4s 249ms/step - loss: 0.4210 - accuracy: 0.8630 - val_loss: 0.4070 - val_accuracy: 0.8681\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.4132 - accuracy: 0.8647 - val_loss: 0.4011 - val_accuracy: 0.8686\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 4s 253ms/step - loss: 0.0767 - accuracy: 0.9907 - val_loss: 0.4384 - val_accuracy: 0.7274\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 4s 255ms/step - loss: 0.0307 - accuracy: 0.9936 - val_loss: 0.9639 - val_accuracy: 0.7258\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 225ms/step - loss: 0.0251 - accuracy: 0.9938 - val_loss: 0.8468 - val_accuracy: 0.7268\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 225ms/step - loss: 0.0220 - accuracy: 0.9945 - val_loss: 0.7623 - val_accuracy: 0.7267\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 223ms/step - loss: 0.0204 - accuracy: 0.9950 - val_loss: 0.5817 - val_accuracy: 0.7270\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 6s 240ms/step - loss: 0.0154 - accuracy: 0.9962 - val_loss: 2.2216 - val_accuracy: 0.4436\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 6s 240ms/step - loss: 0.0137 - accuracy: 0.9962 - val_loss: 2.3370 - val_accuracy: 0.4423\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 6s 241ms/step - loss: 0.0129 - accuracy: 0.9965 - val_loss: 1.9959 - val_accuracy: 0.4378\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 6s 247ms/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 2.5511 - val_accuracy: 0.4398\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 6s 235ms/step - loss: 0.0126 - accuracy: 0.9970 - val_loss: 2.0351 - val_accuracy: 0.4396\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 7s 250ms/step - loss: 1.7195 - accuracy: 0.6700 - val_loss: 0.0336 - val_accuracy: 0.9892\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 7s 249ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.0042 - val_accuracy: 0.9983\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 7s 245ms/step - loss: 8.4923e-04 - accuracy: 0.9999 - val_loss: 0.0026 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 7s 251ms/step - loss: 5.5789e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 7s 247ms/step - loss: 3.6341e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 18s 259ms/step - loss: 0.5114 - accuracy: 0.8883 - val_loss: 0.3400 - val_accuracy: 0.8282\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 18s 257ms/step - loss: 0.0246 - accuracy: 0.9926 - val_loss: 0.2592 - val_accuracy: 0.8304\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 17s 248ms/step - loss: 0.0219 - accuracy: 0.9928 - val_loss: 0.2297 - val_accuracy: 0.8385\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 18s 256ms/step - loss: 0.0207 - accuracy: 0.9930 - val_loss: 0.2119 - val_accuracy: 0.8502\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 20s 287ms/step - loss: 0.0199 - accuracy: 0.9931 - val_loss: 0.1994 - val_accuracy: 0.8594\n",
      "4279/4279 [==============================] - 17s 4ms/step - loss: 0.0634 - accuracy: 0.9894\n",
      "1721/1721 [==============================] - 7s 4ms/step - loss: 0.1136 - accuracy: 0.9835\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 4s 241ms/step - loss: 0.5391 - accuracy: 0.8499 - val_loss: 0.4178 - val_accuracy: 0.8616\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.4212 - accuracy: 0.8647 - val_loss: 0.4092 - val_accuracy: 0.8693\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.4079 - accuracy: 0.8665 - val_loss: 0.3978 - val_accuracy: 0.8699\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 4s 232ms/step - loss: 0.4027 - accuracy: 0.8664 - val_loss: 0.3947 - val_accuracy: 0.8698\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 4s 241ms/step - loss: 0.3994 - accuracy: 0.8665 - val_loss: 0.3920 - val_accuracy: 0.8698\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 240ms/step - loss: 0.0603 - accuracy: 0.9911 - val_loss: 0.6568 - val_accuracy: 0.7257\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 236ms/step - loss: 0.0188 - accuracy: 0.9951 - val_loss: 0.8354 - val_accuracy: 0.7258\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 235ms/step - loss: 0.0184 - accuracy: 0.9951 - val_loss: 0.7770 - val_accuracy: 0.7257\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 237ms/step - loss: 0.0173 - accuracy: 0.9952 - val_loss: 0.5549 - val_accuracy: 0.7258\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 235ms/step - loss: 0.0166 - accuracy: 0.9952 - val_loss: 0.5365 - val_accuracy: 0.7251\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 6s 235ms/step - loss: 0.0129 - accuracy: 0.9968 - val_loss: 1.3804 - val_accuracy: 0.4423\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 6s 233ms/step - loss: 0.0123 - accuracy: 0.9968 - val_loss: 1.9834 - val_accuracy: 0.4376\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 6s 226ms/step - loss: 0.0116 - accuracy: 0.9972 - val_loss: 1.4293 - val_accuracy: 0.4413\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 6s 236ms/step - loss: 0.0112 - accuracy: 0.9973 - val_loss: 1.9289 - val_accuracy: 0.4367\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 6s 232ms/step - loss: 0.0114 - accuracy: 0.9972 - val_loss: 1.1743 - val_accuracy: 0.4924\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 7s 254ms/step - loss: 2.3776 - accuracy: 0.5847 - val_loss: 0.1158 - val_accuracy: 0.9320\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 7s 254ms/step - loss: 0.0254 - accuracy: 0.9926 - val_loss: 0.0034 - val_accuracy: 0.9990\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 7s 245ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 7s 246ms/step - loss: 7.7097e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 7s 246ms/step - loss: 5.8304e-04 - accuracy: 1.0000 - val_loss: 9.2515e-04 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 18s 251ms/step - loss: 0.6316 - accuracy: 0.8738 - val_loss: 0.2118 - val_accuracy: 0.8654\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 18s 254ms/step - loss: 0.0194 - accuracy: 0.9940 - val_loss: 0.1902 - val_accuracy: 0.8814\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 18s 262ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.1736 - val_accuracy: 0.8900\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 17s 249ms/step - loss: 0.0180 - accuracy: 0.9941 - val_loss: 0.1908 - val_accuracy: 0.8713\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 17s 248ms/step - loss: 0.0175 - accuracy: 0.9941 - val_loss: 0.1659 - val_accuracy: 0.8883\n",
      "4279/4279 [==============================] - 17s 4ms/step - loss: 0.0807 - accuracy: 0.9849\n",
      "1721/1721 [==============================] - 9s 5ms/step - loss: 0.1987 - accuracy: 0.9307\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 4s 257ms/step - loss: 0.5418 - accuracy: 0.8601 - val_loss: 0.4138 - val_accuracy: 0.8693\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 4s 279ms/step - loss: 0.4186 - accuracy: 0.8666 - val_loss: 0.4054 - val_accuracy: 0.8698\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 4s 281ms/step - loss: 0.4039 - accuracy: 0.8669 - val_loss: 0.3955 - val_accuracy: 0.8704\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 5s 312ms/step - loss: 0.3994 - accuracy: 0.8670 - val_loss: 0.3927 - val_accuracy: 0.8704\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 5s 323ms/step - loss: 0.3971 - accuracy: 0.8670 - val_loss: 0.3906 - val_accuracy: 0.8706\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 4s 316ms/step - loss: 0.0726 - accuracy: 0.9926 - val_loss: 0.6018 - val_accuracy: 0.7255\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 4s 306ms/step - loss: 0.0181 - accuracy: 0.9950 - val_loss: 0.7578 - val_accuracy: 0.7257\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 4s 307ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.7907 - val_accuracy: 0.7254\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 4s 297ms/step - loss: 0.0160 - accuracy: 0.9954 - val_loss: 0.5950 - val_accuracy: 0.7255\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 4s 306ms/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 0.5592 - val_accuracy: 0.7245\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 7s 251ms/step - loss: 0.0117 - accuracy: 0.9973 - val_loss: 1.4765 - val_accuracy: 0.4379\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 6s 243ms/step - loss: 0.0112 - accuracy: 0.9972 - val_loss: 1.7133 - val_accuracy: 0.4379\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 7s 262ms/step - loss: 0.0116 - accuracy: 0.9972 - val_loss: 1.6228 - val_accuracy: 0.4454\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 8s 314ms/step - loss: 0.0107 - accuracy: 0.9973 - val_loss: 1.2126 - val_accuracy: 0.5005\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 8s 299ms/step - loss: 0.0105 - accuracy: 0.9973 - val_loss: 1.8040 - val_accuracy: 0.4587\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 9s 341ms/step - loss: 2.3537 - accuracy: 0.5916 - val_loss: 0.1592 - val_accuracy: 0.9256\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 10s 360ms/step - loss: 0.0451 - accuracy: 0.9821 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 9s 316ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.0037e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 8s 308ms/step - loss: 6.1374e-04 - accuracy: 1.0000 - val_loss: 3.6201e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 9s 332ms/step - loss: 3.9421e-04 - accuracy: 1.0000 - val_loss: 2.3602e-04 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 19s 275ms/step - loss: 0.4545 - accuracy: 0.9021 - val_loss: 0.1852 - val_accuracy: 0.8892\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 17s 241ms/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 0.1726 - val_accuracy: 0.8919\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 17s 247ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 0.1640 - val_accuracy: 0.8932\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 29s 419ms/step - loss: 0.0163 - accuracy: 0.9945 - val_loss: 0.1506 - val_accuracy: 0.9018\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 30s 432ms/step - loss: 0.0158 - accuracy: 0.9948 - val_loss: 0.1712 - val_accuracy: 0.8885\n",
      "4279/4279 [==============================] - 53s 12ms/step - loss: 0.1418 - accuracy: 0.9606\n",
      "1721/1721 [==============================] - 22s 13ms/step - loss: 0.3787 - accuracy: 0.8611\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr255C1trim.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.06338245421648026, 0.113584503531456], [0.08071856200695038, 0.1986856460571289], [0.1418112963438034, 0.37868085503578186]]\n",
      "Accuracy for iterations:  [[0.9894095659255981, 0.9835428595542908], [0.9849250912666321, 0.9306837320327759], [0.960567057132721, 0.8610586524009705]]\n",
      "F1 for iterations:  [[0.9894140573340214, 0.9835571912352438], [0.9849347229392563, 0.9309352354185929], [0.9605953312486784, 0.8607222475195819]]\n",
      "Precision for iterations:  [[0.9895667626532325, 0.9836851099430577], [0.9853897561861975, 0.9401315485917465], [0.9636055899126356, 0.8944473410099415]]\n",
      "Recall for iterations:  [[0.9894095649887522, 0.9835428322313449], [0.9849250635426101, 0.930683717212817], [0.9605670630167402, 0.8610586354719174]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 3 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16296/927562370.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr55C3trim.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16296/2913529406.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mx3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16296/2575831635.py\u001b[0m in \u001b[0;36mpreprocessing\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# IP Destination Address\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mdata_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dstip'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dstip'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mdata_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dstip'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dstip'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\":\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mdata_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dstip'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dstip'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\UX430\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4431\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4432\u001b[0m         \"\"\"\n\u001b[1;32m-> 4433\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4435\u001b[0m     def _reduce(\n",
      "\u001b[1;32mc:\\Users\\UX430\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1086\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1088\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1089\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\UX430\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1141\u001b[0m                 \u001b[1;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m                 \u001b[1;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1143\u001b[1;33m                 mapped = lib.map_infer(\n\u001b[0m\u001b[0;32m   1144\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\UX430\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16296/2575831635.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# IP Destination Address\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mdata_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dstip'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dstip'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mdata_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dstip'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dstip'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\":\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mdata_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dstip'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dstip'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 168ms/step - loss: 0.5297 - accuracy: 0.7412 - val_loss: 1.7559 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 170ms/step - loss: 0.1924 - accuracy: 0.9607 - val_loss: 3.6784 - val_accuracy: 0.1332\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 0.0802 - accuracy: 0.9893 - val_loss: 3.6751 - val_accuracy: 0.1342\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0515 - accuracy: 0.9893 - val_loss: 1.8339 - val_accuracy: 0.1357\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 202ms/step - loss: 0.0374 - accuracy: 0.9899 - val_loss: 1.5210 - val_accuracy: 0.1622\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 230ms/step - loss: 0.0231 - accuracy: 0.9949 - val_loss: 0.8074 - val_accuracy: 0.7271\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 197ms/step - loss: 0.0208 - accuracy: 0.9949 - val_loss: 0.5096 - val_accuracy: 0.7351\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 192ms/step - loss: 0.0207 - accuracy: 0.9949 - val_loss: 0.7279 - val_accuracy: 0.7278\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 5s 345ms/step - loss: 0.0194 - accuracy: 0.9951 - val_loss: 0.4990 - val_accuracy: 0.7382\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 244ms/step - loss: 0.0197 - accuracy: 0.9950 - val_loss: 0.5134 - val_accuracy: 0.7360\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 6s 212ms/step - loss: 0.2402 - accuracy: 0.9391 - val_loss: 0.1866 - val_accuracy: 0.9606\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 210ms/step - loss: 0.1814 - accuracy: 0.9607 - val_loss: 0.1722 - val_accuracy: 0.9639\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 6s 221ms/step - loss: 0.1693 - accuracy: 0.9626 - val_loss: 0.1650 - val_accuracy: 0.9642\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 6s 220ms/step - loss: 0.1629 - accuracy: 0.9632 - val_loss: 0.1611 - val_accuracy: 0.9642\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 6s 221ms/step - loss: 0.1585 - accuracy: 0.9634 - val_loss: 0.1569 - val_accuracy: 0.9646\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 198ms/step - loss: 0.3551 - accuracy: 0.8636 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 190ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.3198e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 6s 214ms/step - loss: 4.4800e-04 - accuracy: 1.0000 - val_loss: 1.5714e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 6s 207ms/step - loss: 2.3705e-04 - accuracy: 1.0000 - val_loss: 9.1338e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 189ms/step - loss: 1.4259e-04 - accuracy: 1.0000 - val_loss: 5.7025e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 13s 188ms/step - loss: 0.8832 - accuracy: 0.8480 - val_loss: 0.3723 - val_accuracy: 0.8289\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 13s 192ms/step - loss: 0.0312 - accuracy: 0.9913 - val_loss: 0.2581 - val_accuracy: 0.8498\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 14s 201ms/step - loss: 0.0249 - accuracy: 0.9907 - val_loss: 0.2305 - val_accuracy: 0.8568\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 14s 196ms/step - loss: 0.0227 - accuracy: 0.9915 - val_loss: 0.2124 - val_accuracy: 0.8621\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 14s 195ms/step - loss: 0.0212 - accuracy: 0.9924 - val_loss: 0.2036 - val_accuracy: 0.8665\n",
      "4279/4279 [==============================] - 13s 3ms/step - loss: 0.1084 - accuracy: 0.9880\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1124 - accuracy: 0.9728\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 0.0245 - accuracy: 0.9912 - val_loss: 0.6338 - val_accuracy: 0.5818\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 0.0219 - accuracy: 0.9926 - val_loss: 0.5576 - val_accuracy: 0.6555\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 170ms/step - loss: 0.0208 - accuracy: 0.9930 - val_loss: 0.6398 - val_accuracy: 0.5888\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 181ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 0.7204 - val_accuracy: 0.5739\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 0.0184 - accuracy: 0.9938 - val_loss: 0.7047 - val_accuracy: 0.6035\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 181ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.6531 - val_accuracy: 0.7402\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 173ms/step - loss: 0.0135 - accuracy: 0.9964 - val_loss: 0.6942 - val_accuracy: 0.7410\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 168ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.5898 - val_accuracy: 0.7575\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 170ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.7759 - val_accuracy: 0.7413\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 178ms/step - loss: 0.0127 - accuracy: 0.9967 - val_loss: 0.6388 - val_accuracy: 0.7610\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 182ms/step - loss: 0.2522 - accuracy: 0.9524 - val_loss: 0.1784 - val_accuracy: 0.9639\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 170ms/step - loss: 0.1664 - accuracy: 0.9634 - val_loss: 0.1571 - val_accuracy: 0.9642\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 179ms/step - loss: 0.1544 - accuracy: 0.9636 - val_loss: 0.1527 - val_accuracy: 0.9642\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 179ms/step - loss: 0.1516 - accuracy: 0.9638 - val_loss: 0.1508 - val_accuracy: 0.9642\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 174ms/step - loss: 0.1504 - accuracy: 0.9638 - val_loss: 0.1495 - val_accuracy: 0.9646\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 183ms/step - loss: 0.5451 - accuracy: 0.8148 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 6s 206ms/step - loss: 6.3985e-04 - accuracy: 1.0000 - val_loss: 1.0485e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 189ms/step - loss: 1.4204e-04 - accuracy: 1.0000 - val_loss: 6.5234e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 187ms/step - loss: 9.8956e-05 - accuracy: 1.0000 - val_loss: 4.8167e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 185ms/step - loss: 7.2734e-05 - accuracy: 1.0000 - val_loss: 3.5307e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 13s 188ms/step - loss: 0.9436 - accuracy: 0.8374 - val_loss: 0.2665 - val_accuracy: 0.8700\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 13s 186ms/step - loss: 0.0236 - accuracy: 0.9934 - val_loss: 0.2062 - val_accuracy: 0.8921\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 13s 188ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 0.1835 - val_accuracy: 0.8956\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 13s 187ms/step - loss: 0.0182 - accuracy: 0.9944 - val_loss: 0.1795 - val_accuracy: 0.8953\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 13s 187ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.1735 - val_accuracy: 0.8991\n",
      "4279/4279 [==============================] - 14s 3ms/step - loss: 0.1162 - accuracy: 0.9890\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1426 - accuracy: 0.9530\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 218ms/step - loss: 0.0194 - accuracy: 0.9940 - val_loss: 0.8413 - val_accuracy: 0.5303\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0178 - accuracy: 0.9943 - val_loss: 0.8763 - val_accuracy: 0.5632\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 218ms/step - loss: 0.0170 - accuracy: 0.9946 - val_loss: 0.8555 - val_accuracy: 0.5894\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 4s 228ms/step - loss: 0.0165 - accuracy: 0.9946 - val_loss: 0.8369 - val_accuracy: 0.6017\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.0165 - accuracy: 0.9948 - val_loss: 0.8232 - val_accuracy: 0.6119\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 4s 275ms/step - loss: 0.0129 - accuracy: 0.9965 - val_loss: 0.7772 - val_accuracy: 0.7550\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 203ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 0.6729 - val_accuracy: 0.7666\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 191ms/step - loss: 0.0123 - accuracy: 0.9968 - val_loss: 1.0088 - val_accuracy: 0.7461\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 197ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.8823 - val_accuracy: 0.7548\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 218ms/step - loss: 0.0116 - accuracy: 0.9971 - val_loss: 0.9232 - val_accuracy: 0.7557\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 6s 228ms/step - loss: 0.2505 - accuracy: 0.9476 - val_loss: 0.1725 - val_accuracy: 0.9643\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 6s 221ms/step - loss: 0.1605 - accuracy: 0.9633 - val_loss: 0.1542 - val_accuracy: 0.9644\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 7s 251ms/step - loss: 0.1525 - accuracy: 0.9637 - val_loss: 0.1509 - val_accuracy: 0.9642\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 6s 246ms/step - loss: 0.1503 - accuracy: 0.9637 - val_loss: 0.1490 - val_accuracy: 0.9642\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 7s 285ms/step - loss: 0.1487 - accuracy: 0.9639 - val_loss: 0.1482 - val_accuracy: 0.9646\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 198ms/step - loss: 0.4401 - accuracy: 0.8433 - val_loss: 6.0441e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 186ms/step - loss: 3.1184e-04 - accuracy: 1.0000 - val_loss: 6.7926e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 199ms/step - loss: 9.7697e-05 - accuracy: 1.0000 - val_loss: 4.9452e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 194ms/step - loss: 7.8897e-05 - accuracy: 1.0000 - val_loss: 4.1915e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 201ms/step - loss: 6.6823e-05 - accuracy: 1.0000 - val_loss: 3.5225e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 16s 231ms/step - loss: 0.8261 - accuracy: 0.8535 - val_loss: 0.2426 - val_accuracy: 0.8906\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 13s 187ms/step - loss: 0.0198 - accuracy: 0.9940 - val_loss: 0.1899 - val_accuracy: 0.9095\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 11s 161ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.1819 - val_accuracy: 0.9072\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 12s 169ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.1592 - val_accuracy: 0.9166\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 15s 208ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.1546 - val_accuracy: 0.9192\n",
      "4279/4279 [==============================] - 13s 3ms/step - loss: 0.1181 - accuracy: 0.9901\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1680 - accuracy: 0.9472\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr55C3trim.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.1084146797657013, 0.1123688668012619], [0.1162383109331131, 0.1426282525062561], [0.11805704981088638, 0.16804981231689453]]\n",
      "Accuracy for iterations:  [[0.9879999160766602, 0.9727712273597717], [0.9890370965003967, 0.952953577041626], [0.9900742173194885, 0.9472498893737793]]\n",
      "F1 for iterations:  [[0.988003964019539, 0.9727450833085427], [0.9890408833630392, 0.9527551368789061], [0.9900774749113563, 0.9469688561753138]]\n",
      "Precision for iterations:  [[0.9880929627462135, 0.9728250915394179], [0.9891371143801229, 0.9540567725774562], [0.9901625178749895, 0.9488898335585798]]\n",
      "Recall for iterations:  [[0.9879999415700137, 0.9727711981399404], [0.9890370738262877, 0.9529535711690765], [0.9900742060825616, 0.9472498728474896]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 3 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_21336/4114672810.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr105C3trim.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 212ms/step - loss: 0.5324 - accuracy: 0.7423 - val_loss: 1.7323 - val_accuracy: 0.0233\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 182ms/step - loss: 0.1918 - accuracy: 0.9744 - val_loss: 3.9565 - val_accuracy: 0.1281\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 0.0867 - accuracy: 0.9892 - val_loss: 3.8688 - val_accuracy: 0.1339\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 0.0524 - accuracy: 0.9892 - val_loss: 1.6523 - val_accuracy: 0.1386\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 163ms/step - loss: 0.0364 - accuracy: 0.9891 - val_loss: 1.2198 - val_accuracy: 0.2383\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 184ms/step - loss: 0.0220 - accuracy: 0.9948 - val_loss: 0.8367 - val_accuracy: 0.7270\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 171ms/step - loss: 0.0195 - accuracy: 0.9950 - val_loss: 0.6023 - val_accuracy: 0.7283\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 159ms/step - loss: 0.0188 - accuracy: 0.9950 - val_loss: 0.6598 - val_accuracy: 0.7281\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 164ms/step - loss: 0.0180 - accuracy: 0.9950 - val_loss: 0.6554 - val_accuracy: 0.7284\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 161ms/step - loss: 0.0174 - accuracy: 0.9950 - val_loss: 0.5685 - val_accuracy: 0.7323\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 172ms/step - loss: 0.3627 - accuracy: 0.9147 - val_loss: 0.2729 - val_accuracy: 0.9328\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.2626 - accuracy: 0.9372 - val_loss: 0.2563 - val_accuracy: 0.9367\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 188ms/step - loss: 0.2497 - accuracy: 0.9384 - val_loss: 0.2489 - val_accuracy: 0.9374\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.2429 - accuracy: 0.9392 - val_loss: 0.2428 - val_accuracy: 0.9376\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 162ms/step - loss: 0.2378 - accuracy: 0.9394 - val_loss: 0.2387 - val_accuracy: 0.9380\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 0.2749 - accuracy: 0.8872 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 4s 162ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 5.6492e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 4s 162ms/step - loss: 7.2765e-04 - accuracy: 1.0000 - val_loss: 2.5842e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 4s 158ms/step - loss: 3.7052e-04 - accuracy: 1.0000 - val_loss: 1.4458e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 4s 156ms/step - loss: 2.1632e-04 - accuracy: 1.0000 - val_loss: 8.8571e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 177ms/step - loss: 0.7890 - accuracy: 0.8405 - val_loss: 0.3870 - val_accuracy: 0.8277\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 15s 220ms/step - loss: 0.0328 - accuracy: 0.9920 - val_loss: 0.2892 - val_accuracy: 0.8285\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 14s 206ms/step - loss: 0.0246 - accuracy: 0.9912 - val_loss: 0.2501 - val_accuracy: 0.8329\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 14s 200ms/step - loss: 0.0225 - accuracy: 0.9914 - val_loss: 0.2273 - val_accuracy: 0.8409\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 14s 193ms/step - loss: 0.0211 - accuracy: 0.9919 - val_loss: 0.2090 - val_accuracy: 0.8538\n",
      "4279/4279 [==============================] - 14s 3ms/step - loss: 0.0791 - accuracy: 0.9885\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1097 - accuracy: 0.9746\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 166ms/step - loss: 0.0286 - accuracy: 0.9892 - val_loss: 0.8898 - val_accuracy: 0.3131\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.0232 - accuracy: 0.9907 - val_loss: 0.7205 - val_accuracy: 0.5136\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 2s 156ms/step - loss: 0.0216 - accuracy: 0.9919 - val_loss: 0.7826 - val_accuracy: 0.4706\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 162ms/step - loss: 0.0206 - accuracy: 0.9927 - val_loss: 0.7543 - val_accuracy: 0.5206\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 161ms/step - loss: 0.0199 - accuracy: 0.9932 - val_loss: 0.8750 - val_accuracy: 0.4640\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 197ms/step - loss: 0.0145 - accuracy: 0.9959 - val_loss: 0.6386 - val_accuracy: 0.7351\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 161ms/step - loss: 0.0137 - accuracy: 0.9962 - val_loss: 0.4926 - val_accuracy: 0.7504\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 145ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.6833 - val_accuracy: 0.7384\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.0130 - accuracy: 0.9966 - val_loss: 0.6979 - val_accuracy: 0.7406\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 157ms/step - loss: 0.0130 - accuracy: 0.9966 - val_loss: 0.7084 - val_accuracy: 0.7430\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 156ms/step - loss: 0.4276 - accuracy: 0.9143 - val_loss: 0.2970 - val_accuracy: 0.9367\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 154ms/step - loss: 0.2628 - accuracy: 0.9383 - val_loss: 0.2490 - val_accuracy: 0.9377\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 149ms/step - loss: 0.2388 - accuracy: 0.9394 - val_loss: 0.2384 - val_accuracy: 0.9381\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 159ms/step - loss: 0.2330 - accuracy: 0.9397 - val_loss: 0.2352 - val_accuracy: 0.9381\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 159ms/step - loss: 0.2304 - accuracy: 0.9397 - val_loss: 0.2335 - val_accuracy: 0.9371\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 4s 159ms/step - loss: 0.2933 - accuracy: 0.8743 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 4s 152ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3713e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 4s 156ms/step - loss: 4.5854e-04 - accuracy: 1.0000 - val_loss: 1.7824e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 4s 156ms/step - loss: 2.7256e-04 - accuracy: 1.0000 - val_loss: 1.1501e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 171ms/step - loss: 1.8240e-04 - accuracy: 1.0000 - val_loss: 7.8962e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 165ms/step - loss: 0.8375 - accuracy: 0.8326 - val_loss: 0.3236 - val_accuracy: 0.8297\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 11s 161ms/step - loss: 0.0255 - accuracy: 0.9928 - val_loss: 0.2154 - val_accuracy: 0.8626\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 11s 162ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.1784 - val_accuracy: 0.8906\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 11s 162ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.1733 - val_accuracy: 0.8952\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 11s 162ms/step - loss: 0.0172 - accuracy: 0.9946 - val_loss: 0.1686 - val_accuracy: 0.9003\n",
      "4279/4279 [==============================] - 10s 2ms/step - loss: 0.1111 - accuracy: 0.9895\n",
      "1721/1721 [==============================] - 6s 3ms/step - loss: 0.1262 - accuracy: 0.9660: 0s - loss: 0.1262 - accuracy: 0.96\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.0206 - accuracy: 0.9934 - val_loss: 0.7357 - val_accuracy: 0.5371\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.8186 - val_accuracy: 0.5474\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 2s 150ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.8657 - val_accuracy: 0.5547\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.8777 - val_accuracy: 0.5634\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 2s 152ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.9334 - val_accuracy: 0.5638\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 161ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.7267 - val_accuracy: 0.7514\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.0125 - accuracy: 0.9968 - val_loss: 0.8461 - val_accuracy: 0.7452\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 158ms/step - loss: 0.0123 - accuracy: 0.9971 - val_loss: 0.8586 - val_accuracy: 0.7478\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 155ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.8841 - val_accuracy: 0.7494\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.0120 - accuracy: 0.9971 - val_loss: 0.9329 - val_accuracy: 0.7486\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 156ms/step - loss: 0.4388 - accuracy: 0.9110 - val_loss: 0.3022 - val_accuracy: 0.9360\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 154ms/step - loss: 0.2633 - accuracy: 0.9379 - val_loss: 0.2487 - val_accuracy: 0.9370\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 155ms/step - loss: 0.2370 - accuracy: 0.9389 - val_loss: 0.2370 - val_accuracy: 0.9371\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 156ms/step - loss: 0.2309 - accuracy: 0.9392 - val_loss: 0.2336 - val_accuracy: 0.9371\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 152ms/step - loss: 0.2285 - accuracy: 0.9390 - val_loss: 0.2318 - val_accuracy: 0.9372\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 4s 154ms/step - loss: 0.2791 - accuracy: 0.8780 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 4s 150ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.1110e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 4s 156ms/step - loss: 4.6370e-04 - accuracy: 1.0000 - val_loss: 1.8524e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 4s 157ms/step - loss: 2.9870e-04 - accuracy: 1.0000 - val_loss: 1.2237e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 167ms/step - loss: 2.0142e-04 - accuracy: 1.0000 - val_loss: 8.3771e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 167ms/step - loss: 0.7087 - accuracy: 0.8556 - val_loss: 0.2820 - val_accuracy: 0.8466\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 12s 168ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.1791 - val_accuracy: 0.8913\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 14s 196ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.1778 - val_accuracy: 0.8920\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 13s 186ms/step - loss: 0.0166 - accuracy: 0.9947 - val_loss: 0.1683 - val_accuracy: 0.9003\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 12s 171ms/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 0.1478 - val_accuracy: 0.9159\n",
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.1059 - accuracy: 0.9902 0s - loss: 0.1060 - accuracy: 0.99\n",
      "1721/1721 [==============================] - 6s 4ms/step - loss: 0.1465 - accuracy: 0.9479\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr105C3trim.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.07911981642246246, 0.10972201079130173], [0.11108022183179855, 0.12621992826461792], [0.10594591498374939, 0.14654435217380524]]\n",
      "Accuracy for iterations:  [[0.9884600639343262, 0.9746421575546265], [0.989482581615448, 0.9660139679908752], [0.9902129769325256, 0.9479401111602783]]\n",
      "F1 for iterations:  [[0.9884641874354215, 0.9746253145543056], [0.9894866514296236, 0.9659476699492876], [0.9902162674857102, 0.9476694014296102]]\n",
      "Precision for iterations:  [[0.9885660727407686, 0.9746612204195951], [0.9896081802206068, 0.9662745375191877], [0.9903052955349512, 0.9495162369660378]]\n",
      "Recall for iterations:  [[0.9884600777118817, 0.9746421565065756], [0.9894826024715884, 0.9660139504468502], [0.9902129772999503, 0.9479401293322677]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 3 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_21336/512859027.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr255C3trim.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 181ms/step - loss: 0.5393 - accuracy: 0.7489 - val_loss: 1.6758 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 0.2027 - accuracy: 0.9544 - val_loss: 3.6085 - val_accuracy: 0.1320\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0847 - accuracy: 0.9892 - val_loss: 4.0488 - val_accuracy: 0.1337\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 0.0519 - accuracy: 0.9894 - val_loss: 2.0923 - val_accuracy: 0.1343\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 206ms/step - loss: 0.0370 - accuracy: 0.9903 - val_loss: 1.6371 - val_accuracy: 0.1401\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 212ms/step - loss: 0.0219 - accuracy: 0.9950 - val_loss: 0.8711 - val_accuracy: 0.7271\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 219ms/step - loss: 0.0203 - accuracy: 0.9950 - val_loss: 0.6223 - val_accuracy: 0.7294\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 185ms/step - loss: 0.0195 - accuracy: 0.9950 - val_loss: 0.7629 - val_accuracy: 0.7275\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 170ms/step - loss: 0.0189 - accuracy: 0.9950 - val_loss: 0.6572 - val_accuracy: 0.7283\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 172ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.5615 - val_accuracy: 0.7307\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 178ms/step - loss: 0.6814 - accuracy: 0.8284 - val_loss: 0.4621 - val_accuracy: 0.8586\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 187ms/step - loss: 0.4393 - accuracy: 0.8621 - val_loss: 0.4274 - val_accuracy: 0.8631\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 168ms/step - loss: 0.4229 - accuracy: 0.8641 - val_loss: 0.4172 - val_accuracy: 0.8635\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 183ms/step - loss: 0.4153 - accuracy: 0.8647 - val_loss: 0.4132 - val_accuracy: 0.8648\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 185ms/step - loss: 0.4107 - accuracy: 0.8654 - val_loss: 0.4088 - val_accuracy: 0.8651\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 6s 209ms/step - loss: 0.1994 - accuracy: 0.9256 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 175ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2715e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 4.2659e-04 - accuracy: 1.0000 - val_loss: 1.7053e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 173ms/step - loss: 2.5153e-04 - accuracy: 1.0000 - val_loss: 1.0910e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 184ms/step - loss: 1.6586e-04 - accuracy: 1.0000 - val_loss: 7.3649e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 15s 214ms/step - loss: 0.7972 - accuracy: 0.8453 - val_loss: 0.4424 - val_accuracy: 0.8277\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 15s 216ms/step - loss: 0.0342 - accuracy: 0.9919 - val_loss: 0.3176 - val_accuracy: 0.8279\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 15s 212ms/step - loss: 0.0253 - accuracy: 0.9919 - val_loss: 0.2509 - val_accuracy: 0.8323\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 15s 208ms/step - loss: 0.0228 - accuracy: 0.9915 - val_loss: 0.2372 - val_accuracy: 0.8364\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 14s 203ms/step - loss: 0.0213 - accuracy: 0.9920 - val_loss: 0.2045 - val_accuracy: 0.8576\n",
      "4279/4279 [==============================] - 15s 3ms/step - loss: 0.0854 - accuracy: 0.9879\n",
      "1721/1721 [==============================] - 14s 8ms/step - loss: 0.1233 - accuracy: 0.9722\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 6s 362ms/step - loss: 0.0304 - accuracy: 0.9890 - val_loss: 0.6837 - val_accuracy: 0.5475\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 5s 326ms/step - loss: 0.0243 - accuracy: 0.9903 - val_loss: 0.8217 - val_accuracy: 0.4209\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 5s 288ms/step - loss: 0.0221 - accuracy: 0.9919 - val_loss: 0.6621 - val_accuracy: 0.5958\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 5s 282ms/step - loss: 0.0211 - accuracy: 0.9921 - val_loss: 0.7667 - val_accuracy: 0.5050\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 0.0200 - accuracy: 0.9927 - val_loss: 0.7843 - val_accuracy: 0.5108\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 6s 400ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.7377 - val_accuracy: 0.7283\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.0144 - accuracy: 0.9961 - val_loss: 0.6855 - val_accuracy: 0.7328\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 5s 339ms/step - loss: 0.0141 - accuracy: 0.9962 - val_loss: 0.8307 - val_accuracy: 0.7300\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 5s 339ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.7994 - val_accuracy: 0.7314\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 5s 325ms/step - loss: 0.0137 - accuracy: 0.9965 - val_loss: 0.7753 - val_accuracy: 0.7333\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 336ms/step - loss: 0.8308 - accuracy: 0.8163 - val_loss: 0.5129 - val_accuracy: 0.8592\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 6s 233ms/step - loss: 0.4479 - accuracy: 0.8615 - val_loss: 0.4277 - val_accuracy: 0.8643\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 9s 330ms/step - loss: 0.4159 - accuracy: 0.8659 - val_loss: 0.4135 - val_accuracy: 0.8649\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 9s 346ms/step - loss: 0.4073 - accuracy: 0.8658 - val_loss: 0.4084 - val_accuracy: 0.8647\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 8s 326ms/step - loss: 0.4029 - accuracy: 0.8657 - val_loss: 0.4053 - val_accuracy: 0.8643\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 10s 358ms/step - loss: 0.3422 - accuracy: 0.8581 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 7s 274ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.3284e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 7s 248ms/step - loss: 3.8807e-04 - accuracy: 1.0000 - val_loss: 1.1994e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 9s 330ms/step - loss: 1.7278e-04 - accuracy: 1.0000 - val_loss: 6.4806e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 10s 377ms/step - loss: 1.0078e-04 - accuracy: 1.0000 - val_loss: 4.0374e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 24s 342ms/step - loss: 1.0503 - accuracy: 0.8036 - val_loss: 0.3417 - val_accuracy: 0.8286\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 23s 328ms/step - loss: 0.0309 - accuracy: 0.9929 - val_loss: 0.2337 - val_accuracy: 0.8482\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 24s 340ms/step - loss: 0.0217 - accuracy: 0.9936 - val_loss: 0.2001 - val_accuracy: 0.8708\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 22s 320ms/step - loss: 0.0192 - accuracy: 0.9941 - val_loss: 0.1757 - val_accuracy: 0.8915\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 17s 248ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.1893 - val_accuracy: 0.8863\n",
      "4279/4279 [==============================] - 21s 5ms/step - loss: 0.0968 - accuracy: 0.9889\n",
      "1721/1721 [==============================] - 16s 9ms/step - loss: 0.1369 - accuracy: 0.9630\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 5s 340ms/step - loss: 0.0206 - accuracy: 0.9932 - val_loss: 0.7193 - val_accuracy: 0.5644\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 5s 335ms/step - loss: 0.0189 - accuracy: 0.9937 - val_loss: 0.8442 - val_accuracy: 0.5371\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 5s 316ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 1.0348 - val_accuracy: 0.4892\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 5s 324ms/step - loss: 0.0175 - accuracy: 0.9941 - val_loss: 0.8742 - val_accuracy: 0.5659\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 5s 311ms/step - loss: 0.0171 - accuracy: 0.9944 - val_loss: 0.8505 - val_accuracy: 0.5937\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 5s 354ms/step - loss: 0.0138 - accuracy: 0.9962 - val_loss: 0.7529 - val_accuracy: 0.7462\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 4s 258ms/step - loss: 0.0130 - accuracy: 0.9970 - val_loss: 0.8292 - val_accuracy: 0.7446\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 243ms/step - loss: 0.0124 - accuracy: 0.9967 - val_loss: 0.7802 - val_accuracy: 0.7532\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 215ms/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.8835 - val_accuracy: 0.7463\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 4s 258ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 0.8176 - val_accuracy: 0.7529\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 353ms/step - loss: 0.8833 - accuracy: 0.8125 - val_loss: 0.5505 - val_accuracy: 0.8479\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 8s 316ms/step - loss: 0.4630 - accuracy: 0.8575 - val_loss: 0.4302 - val_accuracy: 0.8629\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 9s 328ms/step - loss: 0.4121 - accuracy: 0.8654 - val_loss: 0.4107 - val_accuracy: 0.8639\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 8s 319ms/step - loss: 0.4019 - accuracy: 0.8657 - val_loss: 0.4051 - val_accuracy: 0.8640\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 8s 312ms/step - loss: 0.3982 - accuracy: 0.8657 - val_loss: 0.4031 - val_accuracy: 0.8640\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 9s 349ms/step - loss: 0.3258 - accuracy: 0.8552 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 9s 336ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.8281e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 9s 324ms/step - loss: 3.1193e-04 - accuracy: 1.0000 - val_loss: 8.7859e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 9s 340ms/step - loss: 1.0835e-04 - accuracy: 1.0000 - val_loss: 3.1469e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 9s 328ms/step - loss: 4.1622e-05 - accuracy: 1.0000 - val_loss: 1.3216e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 25s 359ms/step - loss: 1.0030 - accuracy: 0.8176 - val_loss: 0.1944 - val_accuracy: 0.8873\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 25s 362ms/step - loss: 0.0226 - accuracy: 0.9937 - val_loss: 0.1861 - val_accuracy: 0.8726\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 22s 316ms/step - loss: 0.0187 - accuracy: 0.9943 - val_loss: 0.1984 - val_accuracy: 0.8737\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 17s 244ms/step - loss: 0.0175 - accuracy: 0.9946 - val_loss: 0.1735 - val_accuracy: 0.8942\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 18s 258ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.1823 - val_accuracy: 0.8911\n",
      "4279/4279 [==============================] - 30s 7ms/step - loss: 0.1229 - accuracy: 0.9891\n",
      "1721/1721 [==============================] - 12s 7ms/step - loss: 0.1541 - accuracy: 0.9476\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr255C3trim.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 181ms/step - loss: 0.5393 - accuracy: 0.7489 - val_loss: 1.6758 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 0.2027 - accuracy: 0.9544 - val_loss: 3.6085 - val_accuracy: 0.1320\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0847 - accuracy: 0.9892 - val_loss: 4.0488 - val_accuracy: 0.1337\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 0.0519 - accuracy: 0.9894 - val_loss: 2.0923 - val_accuracy: 0.1343\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 206ms/step - loss: 0.0370 - accuracy: 0.9903 - val_loss: 1.6371 - val_accuracy: 0.1401\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 212ms/step - loss: 0.0219 - accuracy: 0.9950 - val_loss: 0.8711 - val_accuracy: 0.7271\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 219ms/step - loss: 0.0203 - accuracy: 0.9950 - val_loss: 0.6223 - val_accuracy: 0.7294\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 185ms/step - loss: 0.0195 - accuracy: 0.9950 - val_loss: 0.7629 - val_accuracy: 0.7275\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 170ms/step - loss: 0.0189 - accuracy: 0.9950 - val_loss: 0.6572 - val_accuracy: 0.7283\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 172ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.5615 - val_accuracy: 0.7307\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 178ms/step - loss: 0.6814 - accuracy: 0.8284 - val_loss: 0.4621 - val_accuracy: 0.8586\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 187ms/step - loss: 0.4393 - accuracy: 0.8621 - val_loss: 0.4274 - val_accuracy: 0.8631\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 168ms/step - loss: 0.4229 - accuracy: 0.8641 - val_loss: 0.4172 - val_accuracy: 0.8635\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 183ms/step - loss: 0.4153 - accuracy: 0.8647 - val_loss: 0.4132 - val_accuracy: 0.8648\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 185ms/step - loss: 0.4107 - accuracy: 0.8654 - val_loss: 0.4088 - val_accuracy: 0.8651\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 6s 209ms/step - loss: 0.1994 - accuracy: 0.9256 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 175ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2715e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 4.2659e-04 - accuracy: 1.0000 - val_loss: 1.7053e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 173ms/step - loss: 2.5153e-04 - accuracy: 1.0000 - val_loss: 1.0910e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 184ms/step - loss: 1.6586e-04 - accuracy: 1.0000 - val_loss: 7.3649e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 15s 214ms/step - loss: 0.7972 - accuracy: 0.8453 - val_loss: 0.4424 - val_accuracy: 0.8277\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 15s 216ms/step - loss: 0.0342 - accuracy: 0.9919 - val_loss: 0.3176 - val_accuracy: 0.8279\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 15s 212ms/step - loss: 0.0253 - accuracy: 0.9919 - val_loss: 0.2509 - val_accuracy: 0.8323\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 15s 208ms/step - loss: 0.0228 - accuracy: 0.9915 - val_loss: 0.2372 - val_accuracy: 0.8364\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 14s 203ms/step - loss: 0.0213 - accuracy: 0.9920 - val_loss: 0.2045 - val_accuracy: 0.8576\n",
      "4279/4279 [==============================] - 15s 3ms/step - loss: 0.0854 - accuracy: 0.9879\n",
      "1721/1721 [==============================] - 14s 8ms/step - loss: 0.1233 - accuracy: 0.9722\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 6s 362ms/step - loss: 0.0304 - accuracy: 0.9890 - val_loss: 0.6837 - val_accuracy: 0.5475\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 5s 326ms/step - loss: 0.0243 - accuracy: 0.9903 - val_loss: 0.8217 - val_accuracy: 0.4209\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 5s 288ms/step - loss: 0.0221 - accuracy: 0.9919 - val_loss: 0.6621 - val_accuracy: 0.5958\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 5s 282ms/step - loss: 0.0211 - accuracy: 0.9921 - val_loss: 0.7667 - val_accuracy: 0.5050\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 0.0200 - accuracy: 0.9927 - val_loss: 0.7843 - val_accuracy: 0.5108\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 6s 400ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.7377 - val_accuracy: 0.7283\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.0144 - accuracy: 0.9961 - val_loss: 0.6855 - val_accuracy: 0.7328\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 5s 339ms/step - loss: 0.0141 - accuracy: 0.9962 - val_loss: 0.8307 - val_accuracy: 0.7300\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 5s 339ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.7994 - val_accuracy: 0.7314\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 5s 325ms/step - loss: 0.0137 - accuracy: 0.9965 - val_loss: 0.7753 - val_accuracy: 0.7333\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 336ms/step - loss: 0.8308 - accuracy: 0.8163 - val_loss: 0.5129 - val_accuracy: 0.8592\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 6s 233ms/step - loss: 0.4479 - accuracy: 0.8615 - val_loss: 0.4277 - val_accuracy: 0.8643\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 9s 330ms/step - loss: 0.4159 - accuracy: 0.8659 - val_loss: 0.4135 - val_accuracy: 0.8649\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 9s 346ms/step - loss: 0.4073 - accuracy: 0.8658 - val_loss: 0.4084 - val_accuracy: 0.8647\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 8s 326ms/step - loss: 0.4029 - accuracy: 0.8657 - val_loss: 0.4053 - val_accuracy: 0.8643\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 10s 358ms/step - loss: 0.3422 - accuracy: 0.8581 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 7s 274ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.3284e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 7s 248ms/step - loss: 3.8807e-04 - accuracy: 1.0000 - val_loss: 1.1994e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 9s 330ms/step - loss: 1.7278e-04 - accuracy: 1.0000 - val_loss: 6.4806e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 10s 377ms/step - loss: 1.0078e-04 - accuracy: 1.0000 - val_loss: 4.0374e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 24s 342ms/step - loss: 1.0503 - accuracy: 0.8036 - val_loss: 0.3417 - val_accuracy: 0.8286\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 23s 328ms/step - loss: 0.0309 - accuracy: 0.9929 - val_loss: 0.2337 - val_accuracy: 0.8482\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 24s 340ms/step - loss: 0.0217 - accuracy: 0.9936 - val_loss: 0.2001 - val_accuracy: 0.8708\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 22s 320ms/step - loss: 0.0192 - accuracy: 0.9941 - val_loss: 0.1757 - val_accuracy: 0.8915\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 17s 248ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.1893 - val_accuracy: 0.8863\n",
      "4279/4279 [==============================] - 21s 5ms/step - loss: 0.0968 - accuracy: 0.9889\n",
      "1721/1721 [==============================] - 16s 9ms/step - loss: 0.1369 - accuracy: 0.9630\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 5s 340ms/step - loss: 0.0206 - accuracy: 0.9932 - val_loss: 0.7193 - val_accuracy: 0.5644\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 5s 335ms/step - loss: 0.0189 - accuracy: 0.9937 - val_loss: 0.8442 - val_accuracy: 0.5371\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 5s 316ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 1.0348 - val_accuracy: 0.4892\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 5s 324ms/step - loss: 0.0175 - accuracy: 0.9941 - val_loss: 0.8742 - val_accuracy: 0.5659\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 5s 311ms/step - loss: 0.0171 - accuracy: 0.9944 - val_loss: 0.8505 - val_accuracy: 0.5937\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 5s 354ms/step - loss: 0.0138 - accuracy: 0.9962 - val_loss: 0.7529 - val_accuracy: 0.7462\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 4s 258ms/step - loss: 0.0130 - accuracy: 0.9970 - val_loss: 0.8292 - val_accuracy: 0.7446\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 243ms/step - loss: 0.0124 - accuracy: 0.9967 - val_loss: 0.7802 - val_accuracy: 0.7532\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 215ms/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.8835 - val_accuracy: 0.7463\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 4s 258ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 0.8176 - val_accuracy: 0.7529\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 353ms/step - loss: 0.8833 - accuracy: 0.8125 - val_loss: 0.5505 - val_accuracy: 0.8479\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 8s 316ms/step - loss: 0.4630 - accuracy: 0.8575 - val_loss: 0.4302 - val_accuracy: 0.8629\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 9s 328ms/step - loss: 0.4121 - accuracy: 0.8654 - val_loss: 0.4107 - val_accuracy: 0.8639\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 8s 319ms/step - loss: 0.4019 - accuracy: 0.8657 - val_loss: 0.4051 - val_accuracy: 0.8640\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 8s 312ms/step - loss: 0.3982 - accuracy: 0.8657 - val_loss: 0.4031 - val_accuracy: 0.8640\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 9s 349ms/step - loss: 0.3258 - accuracy: 0.8552 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 9s 336ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.8281e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 9s 324ms/step - loss: 3.1193e-04 - accuracy: 1.0000 - val_loss: 8.7859e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 9s 340ms/step - loss: 1.0835e-04 - accuracy: 1.0000 - val_loss: 3.1469e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 9s 328ms/step - loss: 4.1622e-05 - accuracy: 1.0000 - val_loss: 1.3216e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 25s 359ms/step - loss: 1.0030 - accuracy: 0.8176 - val_loss: 0.1944 - val_accuracy: 0.8873\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 25s 362ms/step - loss: 0.0226 - accuracy: 0.9937 - val_loss: 0.1861 - val_accuracy: 0.8726\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 22s 316ms/step - loss: 0.0187 - accuracy: 0.9943 - val_loss: 0.1984 - val_accuracy: 0.8737\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 17s 244ms/step - loss: 0.0175 - accuracy: 0.9946 - val_loss: 0.1735 - val_accuracy: 0.8942\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 18s 258ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.1823 - val_accuracy: 0.8911\n",
      "4279/4279 [==============================] - 30s 7ms/step - loss: 0.1229 - accuracy: 0.9891\n",
      "1721/1721 [==============================] - 12s 7ms/step - loss: 0.1541 - accuracy: 0.9476\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr255C3trim.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.08544706553220749, 0.12328588217496872], [0.09680859744548798, 0.13693860173225403], [0.12291232496500015, 0.15408408641815186]]\n",
      "Accuracy for iterations:  [[0.9878538846969604, 0.9722262620925903], [0.9889128804206848, 0.9629804491996765], [0.9890589714050293, 0.9475768208503723]]\n",
      "F1 for iterations:  [[0.9878578666501733, 0.9722010170737153], [0.988916709205785, 0.9628907034001225], [0.9890627905095888, 0.9472986746263102]]\n",
      "Precision for iterations:  [[0.9879434565329552, 0.9722715522619876], [0.9890099785924518, 0.9633804123844554], [0.9891592171717783, 0.949208839513966]]\n",
      "Recall for iterations:  [[0.9878538666043414, 0.9722262588098525], [0.9889129101054661, 0.9629804548426942], [0.9890589850711385, 0.9475768364455424]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
