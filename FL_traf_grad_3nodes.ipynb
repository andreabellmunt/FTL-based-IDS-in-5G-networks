{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Federated Learning for attack detection: 3 nodes sharing gradients**\n",
    "\n",
    "IDs from this file = **id6xy** (x = 0 if experiment with dataset, x = 1 if epochs & iterations, y being integer equal or greater than 0)\n",
    "\n",
    "In this file, experiments with different datasets, and number of epochs & iterations are done. The experiments are divided into sections, based on the elements being changed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static elements for all experiments (execute first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Disable warns\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data): \n",
    "\n",
    "    # Select the 'proto' and 'state' values that I want\n",
    "    data = data.loc[(data['proto'] == 'tcp') | (data['proto'] =='udp') | (data['proto'] =='icmp') | (data['proto'] =='arp') | (data['proto'] =='ipv6-icmp') | (data['proto'] =='igmp') | (data['proto'] =='rarp'), :]\n",
    "    data = data.loc[(data['state'] == 'RST') | (data['state'] =='REQ') | (data['state'] =='INT') | (data['state'] =='FIN') | (data['state'] =='CON') | (data['state'] =='ECO') | (data['state'] =='ACC') | (data['state'] == 'PAR'), :]\n",
    "\n",
    "    # Extracting labels \n",
    "    data_labels = data[['label']]\n",
    "\n",
    "    # Drop the invalid features and select interested data features\n",
    "    data_features=data[['proto','srcip','sport','dstip','dsport','spkts','dpkts','sbytes','dbytes','state','stime','ltime','dur']]\n",
    "\n",
    "    \"\"\"PREPROCESSING\"\"\"\n",
    "\n",
    "\n",
    "    # Preprocess IP and ports features\n",
    "    # IP Source Address\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "\n",
    "    # IP Destination Address\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "    # Ports\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "\n",
    "    # Convert all ports with 0 decimal, and HEX to DEC\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    # Convert field to int format\n",
    "    data_features['srcip'] = data_features['srcip'].astype(int)\n",
    "    data_features['sport'] = data_features['sport'].astype(int)\n",
    "    data_features['dstip'] = data_features['dstip'].astype(int)\n",
    "    data_features['dsport'] = data_features['dsport'].astype(int)\n",
    "\n",
    "    # Convert some fields to logarithmic\n",
    "    log1p_col = ['dur', 'sbytes', 'dbytes', 'spkts']\n",
    "\n",
    "    for col in log1p_col:\n",
    "        data_features[col] = data_features[col].apply(np.log1p)\n",
    "\n",
    "    # Create a complementary field of attack & Transform to One hot encoding - LABELS\n",
    "    normal=data_labels['label']\n",
    "    normal=normal.replace(1,2)\n",
    "    normal=normal.replace(0,1)\n",
    "    normal=normal.replace(2,0)\n",
    "\n",
    "    # Insert the new column in data labels\n",
    "    data_labels.insert(1, 'normal', normal)\n",
    "    data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "    data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "    # Transform to One hot encoding - FEATURES\n",
    "    data_features=pd.get_dummies(data_features)\n",
    "\n",
    "    # Value given for the missing columns\n",
    "    auxCol=0\n",
    "\n",
    "    # As we are using different datasets that might not have all representations, we are going to detect and add the missing columns \n",
    "    # The columns that can have types are: proto and state: need to check if all representations are done \n",
    "    state_cols = [col for col in data_features if col.startswith('state_')]\n",
    "    proto_cols = [col for col in data_features if col.startswith('proto_')]\n",
    "    \n",
    "    # Check if all columns are present\n",
    "    if 'state_PAR' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_PAR', auxCol, True)\n",
    "    if 'state_ACC' not in state_cols: \n",
    "        data_features.insert(data_features.shape[1], 'state_ACC', auxCol, True)\n",
    "    if 'state_ECO' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_ECO', auxCol, True)\n",
    "    if 'state_CON' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_CON', auxCol, True)\n",
    "    if 'state_FIN' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_FIN', auxCol, True)\n",
    "    if 'state_INT' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_INT', auxCol, True)\n",
    "    if 'state_REQ' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_REQ', auxCol, True)\n",
    "    if 'state_RST' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_RST', auxCol, True)\n",
    "    if 'proto_igmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_igmp', auxCol, True)\n",
    "    if 'proto_arp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_arp', auxCol, True)\n",
    "    if 'proto_icmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_icmp', auxCol, True)\n",
    "    if 'proto_udp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_udp', auxCol, True)\n",
    "    if 'proto_tcp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_tcp', auxCol, True)\n",
    "\n",
    "    # Normalize all data features\n",
    "    data_features = StandardScaler().fit_transform(data_features)\n",
    "\n",
    "    #Add dimension to data features\n",
    "    data_features = np.expand_dims(data_features, axis=2)\n",
    "    data_features = np.expand_dims(data_features, axis=3)\n",
    "\n",
    "    x = data_features\n",
    "    y = data_labels.to_numpy()\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building and definition\n",
    "def build_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(filters=32,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(1, 1), padding='same'))\n",
    "    model.add(layers.Conv2D(filters=64,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(1, 1), padding='same'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(Dense(444, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns values of loss, accuracy, f1, precision and recall of model evaluating with test dataset \n",
    "def evaluation(model, x, y): \n",
    "    loss, accuracy = model.evaluate(x, y)\n",
    "    y_pred = model.predict(x)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y = np.argmax(y, axis=1)\n",
    "    report = classification_report(y, y_pred, target_names=['normal', 'attack'], output_dict=True)\n",
    "    # Obtain f1, precision and recall from the report\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    return loss, accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments with datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 3A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_11172/797642493.py:2: DtypeWarning: Columns (2,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3A-Part1.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_11172/797642493.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3A-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_11172/797642493.py:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3A-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_11172/797642493.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3A-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3A-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3A-Part3.csv')\n",
    "test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n",
    "test_plus = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test+.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "node_datasets = [training1, training2, training3]\n",
    "num_nodes = 3\n",
    "global_updates = 10\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'id600.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    avg_grad = np.mean(grad_list, axis=0)\n",
    "    return avg_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "54/54 [==============================] - 45s 826ms/step - loss: 0.2711 - accuracy: 0.9490 - val_loss: 2.6933 - val_accuracy: 0.4715\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 44s 817ms/step - loss: 0.0351 - accuracy: 0.9920 - val_loss: 0.9535 - val_accuracy: 0.4829\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0263 - accuracy: 0.9923 - val_loss: 0.8317 - val_accuracy: 0.5034\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 67s 1s/step - loss: 0.0241 - accuracy: 0.9923 - val_loss: 0.7612 - val_accuracy: 0.5034\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 73s 1s/step - loss: 0.0225 - accuracy: 0.9926 - val_loss: 0.6078 - val_accuracy: 0.5825\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 74s 1s/step - loss: 0.0209 - accuracy: 0.9932 - val_loss: 0.5200 - val_accuracy: 0.6525\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0193 - accuracy: 0.9937 - val_loss: 0.6459 - val_accuracy: 0.5728\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 66s 1s/step - loss: 0.0181 - accuracy: 0.9940 - val_loss: 0.7053 - val_accuracy: 0.5801\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 66s 1s/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 0.6353 - val_accuracy: 0.6221\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 66s 1s/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.4882 - val_accuracy: 0.6950\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0160 - accuracy: 0.9950 - val_loss: 0.7388 - val_accuracy: 0.6290\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 0.5530 - val_accuracy: 0.6918\n",
      "Epoch 13/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 0.6000 - val_accuracy: 0.6863\n",
      "Epoch 14/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 1.0376 - val_accuracy: 0.5828\n",
      "Epoch 15/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0146 - accuracy: 0.9959 - val_loss: 0.6080 - val_accuracy: 0.6988\n",
      "Epoch 1/15\n",
      "53/53 [==============================] - 65s 1s/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.1089 - val_accuracy: 0.9464\n",
      "Epoch 2/15\n",
      "53/53 [==============================] - 58s 1s/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.1255 - val_accuracy: 0.9387\n",
      "Epoch 3/15\n",
      "53/53 [==============================] - 57s 1s/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 0.0957 - val_accuracy: 0.9548\n",
      "Epoch 4/15\n",
      "53/53 [==============================] - 62s 1s/step - loss: 0.0140 - accuracy: 0.9960 - val_loss: 0.0889 - val_accuracy: 0.9600\n",
      "Epoch 5/15\n",
      "53/53 [==============================] - 61s 1s/step - loss: 0.0133 - accuracy: 0.9962 - val_loss: 0.1434 - val_accuracy: 0.9346\n",
      "Epoch 6/15\n",
      "53/53 [==============================] - 67s 1s/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 0.1500 - val_accuracy: 0.9331\n",
      "Epoch 7/15\n",
      "53/53 [==============================] - 67s 1s/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.1215 - val_accuracy: 0.9452\n",
      "Epoch 8/15\n",
      "53/53 [==============================] - 61s 1s/step - loss: 0.0130 - accuracy: 0.9962 - val_loss: 0.1099 - val_accuracy: 0.9520\n",
      "Epoch 9/15\n",
      "53/53 [==============================] - 62s 1s/step - loss: 0.0128 - accuracy: 0.9964 - val_loss: 0.1599 - val_accuracy: 0.9349\n",
      "Epoch 10/15\n",
      "53/53 [==============================] - 60s 1s/step - loss: 0.0126 - accuracy: 0.9964 - val_loss: 0.1048 - val_accuracy: 0.9565\n",
      "Epoch 11/15\n",
      "53/53 [==============================] - 63s 1s/step - loss: 0.0130 - accuracy: 0.9962 - val_loss: 0.1237 - val_accuracy: 0.9481\n",
      "Epoch 12/15\n",
      "53/53 [==============================] - 58s 1s/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 0.1176 - val_accuracy: 0.9519\n",
      "Epoch 13/15\n",
      "53/53 [==============================] - 61s 1s/step - loss: 0.0119 - accuracy: 0.9965 - val_loss: 0.0978 - val_accuracy: 0.9623\n",
      "Epoch 14/15\n",
      "53/53 [==============================] - 64s 1s/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.0635 - val_accuracy: 0.9763\n",
      "Epoch 15/15\n",
      "53/53 [==============================] - 58s 1s/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 0.1076 - val_accuracy: 0.9585\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.3453 - val_accuracy: 0.8624\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.3819 - val_accuracy: 0.8501\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.3114 - val_accuracy: 0.8743\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 57s 1s/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.6038 - val_accuracy: 0.7549\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 55s 1s/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 0.3594 - val_accuracy: 0.8547\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 53s 975ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.4700 - val_accuracy: 0.8134\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 55s 1s/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.4759 - val_accuracy: 0.8088\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.2265 - val_accuracy: 0.8979\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 56s 1s/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.7027 - val_accuracy: 0.7332\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 53s 985ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.3229 - val_accuracy: 0.8668\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.2617 - val_accuracy: 0.8892\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.4222 - val_accuracy: 0.8373\n",
      "Epoch 13/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 0.3877 - val_accuracy: 0.8433\n",
      "Epoch 14/15\n",
      "54/54 [==============================] - 55s 1s/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.3831 - val_accuracy: 0.8463\n",
      "Epoch 15/15\n",
      "54/54 [==============================] - 54s 1s/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.3165 - val_accuracy: 0.8713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279/4279 [==============================] - 75s 18ms/step - loss: 0.2730 - accuracy: 0.8311\n",
      "1721/1721 [==============================] - 33s 19ms/step - loss: 0.7674 - accuracy: 0.7600\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 65s 1s/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 1.0450 - val_accuracy: 0.6792\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 1.2379 - val_accuracy: 0.6414\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 1.0654 - val_accuracy: 0.6791\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.9996 - val_accuracy: 0.6823\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 66s 1s/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.9091 - val_accuracy: 0.6864\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 1.1720 - val_accuracy: 0.6570\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 66s 1s/step - loss: 0.0084 - accuracy: 0.9975 - val_loss: 0.9783 - val_accuracy: 0.6853\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 1.2465 - val_accuracy: 0.6578\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 65s 1s/step - loss: 0.0084 - accuracy: 0.9975 - val_loss: 0.8749 - val_accuracy: 0.6893\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 65s 1s/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 1.0599 - val_accuracy: 0.6742\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 1.3735 - val_accuracy: 0.6105\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 1.4010 - val_accuracy: 0.6180\n",
      "Epoch 13/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 1.3373 - val_accuracy: 0.6400\n",
      "Epoch 14/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 1.5672 - val_accuracy: 0.6095\n",
      "Epoch 15/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 1.4092 - val_accuracy: 0.6197\n",
      "Epoch 1/15\n",
      "53/53 [==============================] - 66s 1s/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.1266 - val_accuracy: 0.9529\n",
      "Epoch 2/15\n",
      "53/53 [==============================] - 60s 1s/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 0.0899 - val_accuracy: 0.9670\n",
      "Epoch 3/15\n",
      "53/53 [==============================] - 59s 1s/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.1716 - val_accuracy: 0.9403\n",
      "Epoch 4/15\n",
      "53/53 [==============================] - 61s 1s/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.2088 - val_accuracy: 0.9325\n",
      "Epoch 5/15\n",
      "53/53 [==============================] - 60s 1s/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.1683 - val_accuracy: 0.9430\n",
      "Epoch 6/15\n",
      "53/53 [==============================] - 56s 1s/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.1213 - val_accuracy: 0.9564\n",
      "Epoch 7/15\n",
      "53/53 [==============================] - 55s 1s/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.0959 - val_accuracy: 0.9669\n",
      "Epoch 8/15\n",
      "53/53 [==============================] - 59s 1s/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.0961 - val_accuracy: 0.9660\n",
      "Epoch 9/15\n",
      "53/53 [==============================] - 55s 1s/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.1020 - val_accuracy: 0.9632\n",
      "Epoch 10/15\n",
      "53/53 [==============================] - 57s 1s/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.1624 - val_accuracy: 0.9448\n",
      "Epoch 11/15\n",
      "53/53 [==============================] - 54s 1s/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.1321 - val_accuracy: 0.9529\n",
      "Epoch 12/15\n",
      "53/53 [==============================] - 58s 1s/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.1158 - val_accuracy: 0.9598\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 81s 1s/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.5739 - val_accuracy: 0.8302\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.5902 - val_accuracy: 0.8087\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.4251 - val_accuracy: 0.8574\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 56s 1s/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.6966 - val_accuracy: 0.8117\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 54s 996ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.3393 - val_accuracy: 0.8878\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 57s 1s/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.4213 - val_accuracy: 0.8628\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 55s 1s/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.5508 - val_accuracy: 0.8328\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.3788 - val_accuracy: 0.8741\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 57s 1s/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.3761 - val_accuracy: 0.8733\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 57s 1s/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.3491 - val_accuracy: 0.8798\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 56s 1s/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.5021 - val_accuracy: 0.8349\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 57s 1s/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.5620 - val_accuracy: 0.8250\n",
      "Epoch 13/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.4564 - val_accuracy: 0.8561\n",
      "Epoch 14/15\n",
      "54/54 [==============================] - 56s 1s/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.4153 - val_accuracy: 0.8618\n",
      "Epoch 15/15\n",
      "54/54 [==============================] - 57s 1s/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.3400 - val_accuracy: 0.8820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279/4279 [==============================] - 89s 21ms/step - loss: 1.4864 - accuracy: 0.5937\n",
      "1721/1721 [==============================] - 40s 23ms/step - loss: 1.9885 - accuracy: 0.6568\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 1.1086 - val_accuracy: 0.6766\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 1.0684 - val_accuracy: 0.6767\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 1.3797 - val_accuracy: 0.6431\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 1.2886 - val_accuracy: 0.6520\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 66s 1s/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 1.2460 - val_accuracy: 0.6559\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 65s 1s/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 1.5426 - val_accuracy: 0.6312\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 1.3085 - val_accuracy: 0.6438\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 65s 1s/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 1.5035 - val_accuracy: 0.6197\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 67s 1s/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 1.0635 - val_accuracy: 0.6763\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 1.3645 - val_accuracy: 0.6435\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 1.1007 - val_accuracy: 0.6645\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 67s 1s/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 1.1260 - val_accuracy: 0.6681\n",
      "Epoch 13/15\n",
      "54/54 [==============================] - 66s 1s/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 1.0516 - val_accuracy: 0.6723\n",
      "Epoch 14/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 1.1643 - val_accuracy: 0.6572\n",
      "Epoch 15/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 1.3536 - val_accuracy: 0.6343\n",
      "Epoch 1/15\n",
      "53/53 [==============================] - 70s 1s/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.1613 - val_accuracy: 0.9473\n",
      "Epoch 2/15\n",
      "53/53 [==============================] - 57s 1s/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.1165 - val_accuracy: 0.9598\n",
      "Epoch 3/15\n",
      "53/53 [==============================] - 56s 1s/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.1191 - val_accuracy: 0.9597\n",
      "Epoch 4/15\n",
      "53/53 [==============================] - 57s 1s/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.1207 - val_accuracy: 0.9583\n",
      "Epoch 5/15\n",
      "53/53 [==============================] - 60s 1s/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.1345 - val_accuracy: 0.9549\n",
      "Epoch 6/15\n",
      "53/53 [==============================] - 55s 1s/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.1202 - val_accuracy: 0.9602\n",
      "Epoch 7/15\n",
      "53/53 [==============================] - 50s 952ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.1471 - val_accuracy: 0.9510\n",
      "Epoch 8/15\n",
      "53/53 [==============================] - 55s 1s/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.1374 - val_accuracy: 0.9540\n",
      "Epoch 9/15\n",
      "53/53 [==============================] - 57s 1s/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.0940 - val_accuracy: 0.9704\n",
      "Epoch 10/15\n",
      "53/53 [==============================] - 57s 1s/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.1329 - val_accuracy: 0.9549\n",
      "Epoch 11/15\n",
      "53/53 [==============================] - 58s 1s/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.1627 - val_accuracy: 0.9480\n",
      "Epoch 12/15\n",
      "53/53 [==============================] - 62s 1s/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.1367 - val_accuracy: 0.9552\n",
      "Epoch 13/15\n",
      "53/53 [==============================] - 63s 1s/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.1025 - val_accuracy: 0.9666\n",
      "Epoch 14/15\n",
      "53/53 [==============================] - 60s 1s/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.2207 - val_accuracy: 0.9349\n",
      "Epoch 15/15\n",
      "53/53 [==============================] - 52s 988ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.1060 - val_accuracy: 0.9660\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 56s 1s/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.3686 - val_accuracy: 0.8874\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.3869 - val_accuracy: 0.8742\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.4549 - val_accuracy: 0.8615\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.5128 - val_accuracy: 0.8450\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.3767 - val_accuracy: 0.8828\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.5182 - val_accuracy: 0.8483\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 54s 1s/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.5090 - val_accuracy: 0.8475\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 50s 932ms/step - loss: 0.0061 - accuracy: 0.9978 - val_loss: 0.4458 - val_accuracy: 0.8636\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 57s 1s/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.3522 - val_accuracy: 0.8887\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.5548 - val_accuracy: 0.8436\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.5203 - val_accuracy: 0.8445\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.3420 - val_accuracy: 0.8902\n",
      "Epoch 13/15\n",
      "54/54 [==============================] - 65s 1s/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.5756 - val_accuracy: 0.8320\n",
      "Epoch 14/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.4645 - val_accuracy: 0.8611\n",
      "Epoch 15/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.3769 - val_accuracy: 0.8877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279/4279 [==============================] - 90s 21ms/step - loss: 3.0596 - accuracy: 0.5879\n",
      "1721/1721 [==============================] - 38s 22ms/step - loss: 2.3411 - accuracy: 0.7279\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 69s 1s/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 1.0697 - val_accuracy: 0.6852\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 66s 1s/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 1.4257 - val_accuracy: 0.6326\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 1.0749 - val_accuracy: 0.6821\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 1.8403 - val_accuracy: 0.5693\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.9212 - val_accuracy: 0.6994\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 1.2931 - val_accuracy: 0.6464\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 1.0558 - val_accuracy: 0.6752\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 67s 1s/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.7532 - val_accuracy: 0.7237\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 1.4182 - val_accuracy: 0.6327\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 1.1667 - val_accuracy: 0.6650\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 1.2255 - val_accuracy: 0.6576\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 55s 1s/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 1.4268 - val_accuracy: 0.6282\n",
      "Epoch 13/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 1.7671 - val_accuracy: 0.5996\n",
      "Epoch 14/15\n",
      "54/54 [==============================] - 56s 1s/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 1.3877 - val_accuracy: 0.6303\n",
      "Epoch 15/15\n",
      "54/54 [==============================] - 56s 1s/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 1.2329 - val_accuracy: 0.6519\n",
      "Epoch 1/15\n",
      "53/53 [==============================] - 65s 1s/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.1348 - val_accuracy: 0.9569\n",
      "Epoch 2/15\n",
      "53/53 [==============================] - 55s 1s/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.1878 - val_accuracy: 0.9410\n",
      "Epoch 3/15\n",
      "53/53 [==============================] - 61s 1s/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.1327 - val_accuracy: 0.9573\n",
      "Epoch 4/15\n",
      "53/53 [==============================] - 54s 1s/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.1025 - val_accuracy: 0.9676\n",
      "Epoch 5/15\n",
      "53/53 [==============================] - 59s 1s/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.1495 - val_accuracy: 0.9532\n",
      "Epoch 6/15\n",
      "53/53 [==============================] - 62s 1s/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.1079 - val_accuracy: 0.9659\n",
      "Epoch 7/15\n",
      "53/53 [==============================] - 61s 1s/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.1081 - val_accuracy: 0.9669\n",
      "Epoch 8/15\n",
      "53/53 [==============================] - 55s 1s/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.1377 - val_accuracy: 0.9564\n",
      "Epoch 9/15\n",
      "53/53 [==============================] - 55s 1s/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.1645 - val_accuracy: 0.9490\n",
      "Epoch 10/15\n",
      "53/53 [==============================] - 55s 1s/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.1346 - val_accuracy: 0.9572\n",
      "Epoch 11/15\n",
      "53/53 [==============================] - 51s 962ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.1667 - val_accuracy: 0.9484\n",
      "Epoch 12/15\n",
      "53/53 [==============================] - 52s 986ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.2163 - val_accuracy: 0.9366\n",
      "Epoch 13/15\n",
      "53/53 [==============================] - 61s 1s/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.2107 - val_accuracy: 0.9385\n",
      "Epoch 14/15\n",
      "53/53 [==============================] - 59s 1s/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.1506 - val_accuracy: 0.9524\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.5244 - val_accuracy: 0.8558\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 53s 980ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.5077 - val_accuracy: 0.8529\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.4017 - val_accuracy: 0.8791\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 0.4938 - val_accuracy: 0.8557\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.4342 - val_accuracy: 0.8668\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.4761 - val_accuracy: 0.8620\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.4806 - val_accuracy: 0.8576\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.5630 - val_accuracy: 0.8472\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 65s 1s/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.5581 - val_accuracy: 0.8449\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.5598 - val_accuracy: 0.8416\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.4922 - val_accuracy: 0.8541\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.4828 - val_accuracy: 0.8632\n",
      "Epoch 13/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.4105 - val_accuracy: 0.8818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279/4279 [==============================] - 92s 21ms/step - loss: 4.0307 - accuracy: 0.5835\n",
      "1721/1721 [==============================] - 39s 23ms/step - loss: 2.9348 - accuracy: 0.7581\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 67s 1s/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 1.1519 - val_accuracy: 0.6807\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.9271 - val_accuracy: 0.6896\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 1.5905 - val_accuracy: 0.6225\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 1.0153 - val_accuracy: 0.6852\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 53s 988ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 1.4976 - val_accuracy: 0.6240\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 1.2035 - val_accuracy: 0.6683\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 1.3805 - val_accuracy: 0.6257\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 1.1638 - val_accuracy: 0.6697\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 1.4389 - val_accuracy: 0.6309\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.9548 - val_accuracy: 0.6877\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 1.0056 - val_accuracy: 0.6849\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 1.3801 - val_accuracy: 0.6267\n",
      "Epoch 1/15\n",
      "53/53 [==============================] - 61s 1s/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.1686 - val_accuracy: 0.9499\n",
      "Epoch 2/15\n",
      "53/53 [==============================] - 59s 1s/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.1380 - val_accuracy: 0.9585\n",
      "Epoch 3/15\n",
      "53/53 [==============================] - 54s 1s/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.1844 - val_accuracy: 0.9474\n",
      "Epoch 4/15\n",
      "53/53 [==============================] - 58s 1s/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.1432 - val_accuracy: 0.9565\n",
      "Epoch 5/15\n",
      "53/53 [==============================] - 59s 1s/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.1861 - val_accuracy: 0.9465\n",
      "Epoch 6/15\n",
      "53/53 [==============================] - 61s 1s/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.1559 - val_accuracy: 0.9540\n",
      "Epoch 7/15\n",
      "53/53 [==============================] - 55s 1s/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.1328 - val_accuracy: 0.9606\n",
      "Epoch 8/15\n",
      "53/53 [==============================] - 57s 1s/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.1863 - val_accuracy: 0.9479\n",
      "Epoch 9/15\n",
      "53/53 [==============================] - 59s 1s/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.1923 - val_accuracy: 0.9458\n",
      "Epoch 10/15\n",
      "53/53 [==============================] - 56s 1s/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.1456 - val_accuracy: 0.9578\n",
      "Epoch 11/15\n",
      "53/53 [==============================] - 51s 966ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.1569 - val_accuracy: 0.9559\n",
      "Epoch 12/15\n",
      "53/53 [==============================] - 59s 1s/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.1977 - val_accuracy: 0.9443\n",
      "Epoch 13/15\n",
      "53/53 [==============================] - 57s 1s/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.2201 - val_accuracy: 0.9425\n",
      "Epoch 14/15\n",
      "53/53 [==============================] - 55s 1s/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.1136 - val_accuracy: 0.9737\n",
      "Epoch 15/15\n",
      "53/53 [==============================] - 59s 1s/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 0.1817 - val_accuracy: 0.9490\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 66s 1s/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 0.5501 - val_accuracy: 0.8476\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 57s 1s/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.5421 - val_accuracy: 0.8574\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.4539 - val_accuracy: 0.8729\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.4827 - val_accuracy: 0.8718\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.4676 - val_accuracy: 0.8672\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.6499 - val_accuracy: 0.8262\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.6011 - val_accuracy: 0.8458\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.4862 - val_accuracy: 0.8714\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.5582 - val_accuracy: 0.8521\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0045 - accuracy: 0.9983 - val_loss: 0.4755 - val_accuracy: 0.8689\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.5867 - val_accuracy: 0.8461\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.6068 - val_accuracy: 0.8447\n",
      "Epoch 13/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.6323 - val_accuracy: 0.8427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279/4279 [==============================] - 88s 21ms/step - loss: 4.7947 - accuracy: 0.5807\n",
      "1721/1721 [==============================] - 32s 18ms/step - loss: 3.5389 - accuracy: 0.7778\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 57s 1s/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 1.0258 - val_accuracy: 0.6995\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 1.3952 - val_accuracy: 0.6456\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 1.2805 - val_accuracy: 0.6340\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 1.5252 - val_accuracy: 0.6285\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 1.1205 - val_accuracy: 0.6616\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 66s 1s/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 1.1643 - val_accuracy: 0.6761\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 1.2665 - val_accuracy: 0.6421\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 1.4117 - val_accuracy: 0.6306\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 1.1662 - val_accuracy: 0.6699\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 1.5288 - val_accuracy: 0.6214\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 1.5122 - val_accuracy: 0.6200\n",
      "Epoch 1/15\n",
      "53/53 [==============================] - 65s 1s/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.1694 - val_accuracy: 0.9533\n",
      "Epoch 2/15\n",
      "53/53 [==============================] - 58s 1s/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.1597 - val_accuracy: 0.9566\n",
      "Epoch 3/15\n",
      "53/53 [==============================] - 58s 1s/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.2100 - val_accuracy: 0.9432\n",
      "Epoch 4/15\n",
      "53/53 [==============================] - 52s 984ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.1518 - val_accuracy: 0.9573\n",
      "Epoch 5/15\n",
      "53/53 [==============================] - 52s 981ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.1398 - val_accuracy: 0.9623\n",
      "Epoch 6/15\n",
      "53/53 [==============================] - 52s 987ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.1518 - val_accuracy: 0.9586\n",
      "Epoch 7/15\n",
      "53/53 [==============================] - 52s 973ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.1651 - val_accuracy: 0.9546\n",
      "Epoch 8/15\n",
      "53/53 [==============================] - 54s 1s/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.1554 - val_accuracy: 0.9583\n",
      "Epoch 9/15\n",
      "53/53 [==============================] - 58s 1s/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.1647 - val_accuracy: 0.9563\n",
      "Epoch 10/15\n",
      "53/53 [==============================] - 62s 1s/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.1576 - val_accuracy: 0.9575\n",
      "Epoch 11/15\n",
      "53/53 [==============================] - 56s 1s/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.1657 - val_accuracy: 0.9563\n",
      "Epoch 12/15\n",
      "53/53 [==============================] - 54s 1s/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.1837 - val_accuracy: 0.9506\n",
      "Epoch 13/15\n",
      "53/53 [==============================] - 57s 1s/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.1771 - val_accuracy: 0.9516\n",
      "Epoch 14/15\n",
      "53/53 [==============================] - 60s 1s/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.1375 - val_accuracy: 0.9649\n",
      "Epoch 15/15\n",
      "53/53 [==============================] - 54s 1s/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.1677 - val_accuracy: 0.9562\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.5384 - val_accuracy: 0.8697\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.6327 - val_accuracy: 0.8299\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 57s 1s/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.5921 - val_accuracy: 0.8528\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 52s 969ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.6799 - val_accuracy: 0.8379\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 53s 982ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.4610 - val_accuracy: 0.8753\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 55s 1s/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.4317 - val_accuracy: 0.8819\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 55s 1s/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.6549 - val_accuracy: 0.8338\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.4483 - val_accuracy: 0.8763\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.7082 - val_accuracy: 0.8220\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.6737 - val_accuracy: 0.8263\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.5108 - val_accuracy: 0.8698\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.5017 - val_accuracy: 0.8725\n",
      "Epoch 13/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0040 - accuracy: 0.9985 - val_loss: 0.3991 - val_accuracy: 0.8968\n",
      "Epoch 14/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.5185 - val_accuracy: 0.8607\n",
      "Epoch 15/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.6571 - val_accuracy: 0.8418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279/4279 [==============================] - 89s 21ms/step - loss: 6.1694 - accuracy: 0.5651\n",
      "1721/1721 [==============================] - 35s 21ms/step - loss: 3.8523 - accuracy: 0.8460\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 1.1780 - val_accuracy: 0.6802\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 1.5061 - val_accuracy: 0.6344\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.7997 - val_accuracy: 0.7153\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 65s 1s/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 1.2456 - val_accuracy: 0.6573\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 1.4318 - val_accuracy: 0.6305\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 64s 1s/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 1.5648 - val_accuracy: 0.6360\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 1.5364 - val_accuracy: 0.6374\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 1.5161 - val_accuracy: 0.6442\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 62s 1s/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 1.4628 - val_accuracy: 0.6273\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 65s 1s/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 1.3378 - val_accuracy: 0.6603\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 1.3187 - val_accuracy: 0.6617\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 56s 1s/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 1.4231 - val_accuracy: 0.6422\n",
      "Epoch 13/15\n",
      "54/54 [==============================] - 57s 1s/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 1.4182 - val_accuracy: 0.6364\n",
      "Epoch 1/15\n",
      "53/53 [==============================] - 57s 1s/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.1662 - val_accuracy: 0.9575\n",
      "Epoch 2/15\n",
      "53/53 [==============================] - 61s 1s/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.1940 - val_accuracy: 0.9491\n",
      "Epoch 3/15\n",
      "53/53 [==============================] - 61s 1s/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.1462 - val_accuracy: 0.9639\n",
      "Epoch 4/15\n",
      "53/53 [==============================] - 60s 1s/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.2071 - val_accuracy: 0.9461\n",
      "Epoch 5/15\n",
      "53/53 [==============================] - 58s 1s/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.1879 - val_accuracy: 0.9502\n",
      "Epoch 6/15\n",
      "53/53 [==============================] - 57s 1s/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.2083 - val_accuracy: 0.9458\n",
      "Epoch 7/15\n",
      "53/53 [==============================] - 61s 1s/step - loss: 0.0040 - accuracy: 0.9985 - val_loss: 0.1890 - val_accuracy: 0.9505\n",
      "Epoch 8/15\n",
      "53/53 [==============================] - 50s 938ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.1361 - val_accuracy: 0.9674\n",
      "Epoch 9/15\n",
      "53/53 [==============================] - 47s 888ms/step - loss: 0.0039 - accuracy: 0.9985 - val_loss: 0.2602 - val_accuracy: 0.9377\n",
      "Epoch 10/15\n",
      "53/53 [==============================] - 53s 1s/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.1946 - val_accuracy: 0.9493\n",
      "Epoch 11/15\n",
      "53/53 [==============================] - 54s 1s/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.1708 - val_accuracy: 0.9566\n",
      "Epoch 12/15\n",
      "53/53 [==============================] - 52s 987ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 0.1979 - val_accuracy: 0.9506\n",
      "Epoch 13/15\n",
      "53/53 [==============================] - 55s 1s/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.1750 - val_accuracy: 0.9555\n",
      "Epoch 14/15\n",
      "53/53 [==============================] - 62s 1s/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 0.1866 - val_accuracy: 0.9529\n",
      "Epoch 15/15\n",
      "53/53 [==============================] - 60s 1s/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.1805 - val_accuracy: 0.9560\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 69s 1s/step - loss: 0.0047 - accuracy: 0.9983 - val_loss: 0.5548 - val_accuracy: 0.8567\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 54s 1s/step - loss: 0.0040 - accuracy: 0.9985 - val_loss: 0.5726 - val_accuracy: 0.8567\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.6174 - val_accuracy: 0.8406\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 0.4135 - val_accuracy: 0.8844\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.4766 - val_accuracy: 0.8747\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 57s 1s/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.4627 - val_accuracy: 0.8735\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.4820 - val_accuracy: 0.8696\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.4896 - val_accuracy: 0.8671\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.5512 - val_accuracy: 0.8575\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 0.6361 - val_accuracy: 0.8404\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.6354 - val_accuracy: 0.8374\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.5037 - val_accuracy: 0.8670\n",
      "Epoch 13/15\n",
      "54/54 [==============================] - 57s 1s/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.6459 - val_accuracy: 0.8442\n",
      "Epoch 14/15\n",
      "54/54 [==============================] - 60s 1s/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.4828 - val_accuracy: 0.8714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279/4279 [==============================] - 84s 20ms/step - loss: 5.8845 - accuracy: 0.5639\n",
      "1721/1721 [==============================] - 37s 21ms/step - loss: 3.5904 - accuracy: 0.8709\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 67s 1s/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 1.1590 - val_accuracy: 0.6676\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 1.2250 - val_accuracy: 0.6723\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 57s 1s/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 1.1033 - val_accuracy: 0.6749\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 1.2572 - val_accuracy: 0.6530\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 66s 1s/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 1.2383 - val_accuracy: 0.6441\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 63s 1s/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 1.2809 - val_accuracy: 0.6451\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 68s 1s/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 1.3605 - val_accuracy: 0.6482\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 66s 1s/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 1.4312 - val_accuracy: 0.6264\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 1.2377 - val_accuracy: 0.6693\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 58s 1s/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 1.1133 - val_accuracy: 0.6846\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 56s 1s/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 1.2002 - val_accuracy: 0.6569\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 53s 974ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 1.4189 - val_accuracy: 0.6315\n",
      "Epoch 13/15\n",
      "54/54 [==============================] - 52s 957ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 1.3070 - val_accuracy: 0.6501\n",
      "Epoch 1/15\n",
      "53/53 [==============================] - 67s 1s/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.1832 - val_accuracy: 0.9552\n",
      "Epoch 2/15\n",
      "53/53 [==============================] - 62s 1s/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 0.1826 - val_accuracy: 0.9536\n",
      "Epoch 3/15\n",
      "53/53 [==============================] - 57s 1s/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 0.2164 - val_accuracy: 0.9465\n",
      "Epoch 4/15\n",
      "53/53 [==============================] - 58s 1s/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.1447 - val_accuracy: 0.9657\n",
      "Epoch 5/15\n",
      "53/53 [==============================] - 61s 1s/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.2046 - val_accuracy: 0.9479\n",
      "Epoch 6/15\n",
      "53/53 [==============================] - 57s 1s/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.1996 - val_accuracy: 0.9491\n",
      "Epoch 7/15\n",
      "53/53 [==============================] - 54s 1s/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.1878 - val_accuracy: 0.9520\n",
      "Epoch 8/15\n",
      "53/53 [==============================] - 52s 988ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.1902 - val_accuracy: 0.9533\n",
      "Epoch 9/15\n",
      "53/53 [==============================] - 53s 996ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.1832 - val_accuracy: 0.9536\n",
      "Epoch 10/15\n",
      "53/53 [==============================] - 52s 973ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.1578 - val_accuracy: 0.9627\n",
      "Epoch 11/15\n",
      "53/53 [==============================] - 54s 1s/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.2145 - val_accuracy: 0.9462\n",
      "Epoch 12/15\n",
      "53/53 [==============================] - 54s 1s/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.1681 - val_accuracy: 0.9593\n",
      "Epoch 13/15\n",
      "53/53 [==============================] - 54s 1s/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.2071 - val_accuracy: 0.9482\n",
      "Epoch 14/15\n",
      "53/53 [==============================] - 54s 1s/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.2246 - val_accuracy: 0.9442\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 61s 1s/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.5299 - val_accuracy: 0.8567\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 56s 1s/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 0.5236 - val_accuracy: 0.8620\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 50s 935ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.7795 - val_accuracy: 0.7979\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 49s 901ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.3973 - val_accuracy: 0.8876\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 50s 933ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.5734 - val_accuracy: 0.8477\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 50s 922ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.5493 - val_accuracy: 0.8565\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 52s 957ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.3936 - val_accuracy: 0.8933\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 51s 938ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.4406 - val_accuracy: 0.8817\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 54s 994ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.4847 - val_accuracy: 0.8690\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 52s 971ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.6065 - val_accuracy: 0.8453\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 57s 1s/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.5117 - val_accuracy: 0.8621\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 55s 1s/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.5313 - val_accuracy: 0.8576\n",
      "Epoch 13/15\n",
      "54/54 [==============================] - 55s 1s/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.5416 - val_accuracy: 0.8563\n",
      "Epoch 14/15\n",
      "54/54 [==============================] - 51s 951ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.3955 - val_accuracy: 0.8941\n",
      "Epoch 15/15\n",
      "54/54 [==============================] - 52s 955ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.6610 - val_accuracy: 0.8361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279/4279 [==============================] - 77s 18ms/step - loss: 5.6637 - accuracy: 0.57240s - loss: 5.6656 - \n",
      "1721/1721 [==============================] - 29s 17ms/step - loss: 3.5059 - accuracy: 0.8754\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 57s 1s/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 1.3809 - val_accuracy: 0.6423\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 52s 956ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 1.6639 - val_accuracy: 0.6271\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 52s 968ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 1.1198 - val_accuracy: 0.6978\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 52s 955ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 1.6275 - val_accuracy: 0.6244\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 49s 905ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.9406 - val_accuracy: 0.7061\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 54s 1s/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 1.0172 - val_accuracy: 0.6922\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 56s 1s/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 1.1095 - val_accuracy: 0.6611\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 55s 1s/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 1.2057 - val_accuracy: 0.6724\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 55s 1s/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 1.1292 - val_accuracy: 0.6716\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 55s 1s/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 1.0222 - val_accuracy: 0.6829\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 49s 899ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 1.1294 - val_accuracy: 0.6831\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 49s 913ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 1.4472 - val_accuracy: 0.6539\n",
      "Epoch 13/15\n",
      "54/54 [==============================] - 51s 947ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 1.4586 - val_accuracy: 0.6506\n",
      "Epoch 14/15\n",
      "54/54 [==============================] - 54s 1s/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 1.4857 - val_accuracy: 0.6482\n",
      "Epoch 15/15\n",
      "54/54 [==============================] - 51s 947ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.9769 - val_accuracy: 0.6888\n",
      "Epoch 1/15\n",
      "53/53 [==============================] - 53s 999ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.1991 - val_accuracy: 0.9498\n",
      "Epoch 2/15\n",
      "53/53 [==============================] - 44s 835ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.2371 - val_accuracy: 0.9439\n",
      "Epoch 3/15\n",
      "53/53 [==============================] - 47s 884ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.1773 - val_accuracy: 0.9549\n",
      "Epoch 4/15\n",
      "53/53 [==============================] - 43s 809ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.1943 - val_accuracy: 0.9499\n",
      "Epoch 5/15\n",
      "53/53 [==============================] - 45s 855ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.1962 - val_accuracy: 0.9519\n",
      "Epoch 6/15\n",
      "53/53 [==============================] - 42s 789ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.1717 - val_accuracy: 0.9573\n",
      "Epoch 7/15\n",
      "53/53 [==============================] - 48s 901ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.1925 - val_accuracy: 0.9516\n",
      "Epoch 8/15\n",
      "53/53 [==============================] - 53s 997ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.2185 - val_accuracy: 0.9460\n",
      "Epoch 9/15\n",
      "53/53 [==============================] - 54s 1s/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.2156 - val_accuracy: 0.9470\n",
      "Epoch 10/15\n",
      "53/53 [==============================] - 56s 1s/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.2584 - val_accuracy: 0.9387\n",
      "Epoch 11/15\n",
      "53/53 [==============================] - 54s 1s/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.1879 - val_accuracy: 0.9537\n",
      "Epoch 12/15\n",
      "53/53 [==============================] - 52s 973ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.1466 - val_accuracy: 0.9660\n",
      "Epoch 13/15\n",
      "53/53 [==============================] - 53s 1s/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.1787 - val_accuracy: 0.9577\n",
      "Epoch 14/15\n",
      "53/53 [==============================] - 50s 951ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.1691 - val_accuracy: 0.9596\n",
      "Epoch 15/15\n",
      "53/53 [==============================] - 51s 958ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.2180 - val_accuracy: 0.9469\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 59s 1s/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 0.2902 - val_accuracy: 0.9148\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 51s 941ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.3622 - val_accuracy: 0.8930\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 54s 1s/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.5805 - val_accuracy: 0.8508\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 55s 1s/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.4550 - val_accuracy: 0.8729\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 56s 1s/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.4812 - val_accuracy: 0.8692\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 56s 1s/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.4555 - val_accuracy: 0.8780\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 51s 952ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.4118 - val_accuracy: 0.8858\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 51s 941ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.4099 - val_accuracy: 0.8873\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 54s 1s/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.5485 - val_accuracy: 0.8567\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 55s 1s/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.4576 - val_accuracy: 0.8760\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 56s 1s/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.5281 - val_accuracy: 0.8606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279/4279 [==============================] - 76s 18ms/step - loss: 4.2634 - accuracy: 0.5651\n",
      "1721/1721 [==============================] - 28s 16ms/step - loss: 2.7175 - accuracy: 0.9122\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 45s 838ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 1.2688 - val_accuracy: 0.6874\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 42s 778ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 1.0658 - val_accuracy: 0.6817\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 36s 661ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 1.4413 - val_accuracy: 0.6327\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 37s 686ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 1.2432 - val_accuracy: 0.6666\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 38s 707ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 1.3713 - val_accuracy: 0.6657\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 40s 745ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 1.0603 - val_accuracy: 0.6985\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 40s 732ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 1.3024 - val_accuracy: 0.6685\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 39s 717ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 1.2229 - val_accuracy: 0.6703\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 32s 589ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 1.2270 - val_accuracy: 0.6631\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 31s 571ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 1.0663 - val_accuracy: 0.6925\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 37s 694ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 1.6173 - val_accuracy: 0.6340\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 37s 688ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 1.4335 - val_accuracy: 0.6444\n",
      "Epoch 13/15\n",
      "54/54 [==============================] - 37s 694ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 1.5399 - val_accuracy: 0.6364\n",
      "Epoch 14/15\n",
      "54/54 [==============================] - 34s 627ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 1.0525 - val_accuracy: 0.6870\n",
      "Epoch 15/15\n",
      "54/54 [==============================] - 33s 616ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 1.5231 - val_accuracy: 0.6395\n",
      "Epoch 1/15\n",
      "53/53 [==============================] - 28s 521ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.1748 - val_accuracy: 0.9559\n",
      "Epoch 2/15\n",
      "53/53 [==============================] - 23s 431ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.1984 - val_accuracy: 0.9505\n",
      "Epoch 3/15\n",
      "53/53 [==============================] - 22s 406ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.1888 - val_accuracy: 0.9541\n",
      "Epoch 4/15\n",
      "53/53 [==============================] - 21s 403ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.1678 - val_accuracy: 0.9594\n",
      "Epoch 5/15\n",
      "53/53 [==============================] - 14s 263ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.1556 - val_accuracy: 0.9634\n",
      "Epoch 6/15\n",
      "53/53 [==============================] - 16s 297ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.1524 - val_accuracy: 0.9619\n",
      "Epoch 7/15\n",
      "53/53 [==============================] - 19s 365ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.2335 - val_accuracy: 0.9444\n",
      "Epoch 8/15\n",
      "53/53 [==============================] - 19s 354ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.1340 - val_accuracy: 0.9702\n",
      "Epoch 9/15\n",
      "53/53 [==============================] - 19s 349ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.1841 - val_accuracy: 0.9550\n",
      "Epoch 10/15\n",
      "53/53 [==============================] - 19s 352ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.2222 - val_accuracy: 0.9466\n",
      "Epoch 11/15\n",
      "53/53 [==============================] - 11s 210ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.2106 - val_accuracy: 0.9507\n",
      "Epoch 12/15\n",
      "53/53 [==============================] - 17s 329ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.2117 - val_accuracy: 0.9488\n",
      "Epoch 13/15\n",
      "53/53 [==============================] - 15s 291ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.2392 - val_accuracy: 0.9461\n",
      "Epoch 14/15\n",
      "53/53 [==============================] - 11s 201ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.2021 - val_accuracy: 0.9530\n",
      "Epoch 15/15\n",
      "53/53 [==============================] - 12s 233ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.1965 - val_accuracy: 0.9521\n",
      "Epoch 1/15\n",
      "54/54 [==============================] - 8s 151ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.4915 - val_accuracy: 0.8701\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 8s 154ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.4083 - val_accuracy: 0.8865\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 9s 160ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.5269 - val_accuracy: 0.8631\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 8s 149ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.5461 - val_accuracy: 0.8599\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 8s 147ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.5820 - val_accuracy: 0.8524\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 8s 152ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.5122 - val_accuracy: 0.8678\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 8s 148ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.4589 - val_accuracy: 0.8771\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 9s 158ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.4760 - val_accuracy: 0.8779\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 9s 164ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.4136 - val_accuracy: 0.8882\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 10s 178ms/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 0.4337 - val_accuracy: 0.8871\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 9s 173ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.4254 - val_accuracy: 0.8847\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 9s 173ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.4643 - val_accuracy: 0.8792\n",
      "  15/4279 [..............................] - ETA: 14s - loss: 2.7923 - accuracy: 0.6062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279/4279 [==============================] - 21s 5ms/step - loss: 3.0032 - accuracy: 0.5839\n",
      "1721/1721 [==============================] - 9s 5ms/step - loss: 2.2940 - accuracy: 0.9080\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        else:\n",
    "            x, y = x3, y3\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(y, predictions)\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/id600.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.27303168177604675, 0.767395555973053], [1.4864134788513184, 1.988478422164917], [3.059551477432251, 2.3411474227905273], [4.030683517456055, 2.9348199367523193], [4.79466438293457, 3.5389466285705566], [6.169393539428711, 3.8523378372192383], [5.884477138519287, 3.590357542037964], [5.663670063018799, 3.5059311389923096], [4.263436317443848, 2.717472791671753], [3.003235340118408, 2.2939751148223877]]\n",
      "Accuracy for iterations:  [[0.8311154246330261, 0.7599542140960693], [0.5936705470085144, 0.6567790508270264], [0.5879298448562622, 0.7279481291770935], [0.5834599137306213, 0.7581195831298828], [0.5807064175605774, 0.7777555584907532], [0.5651348233222961, 0.8460001349449158], [0.5638712644577026, 0.8708857297897339], [0.5724385976791382, 0.8754450082778931], [0.5650982856750488, 0.9122102856636047], [0.5839273929595947, 0.9079960584640503]]\n",
      "F1 for iterations:  [[0.8252422004921448, 0.7378583448746595], [0.5031123471935158, 0.5895755884799824], [0.5012240946963751, 0.698164629192136], [0.49925964057566136, 0.7364930249972996], [0.4983728441652729, 0.7602590476655027], [0.4888604859089061, 0.8402470961398921], [0.49039131720222645, 0.8673263099756864], [0.4953510900463211, 0.8722989105748825], [0.4942028730773457, 0.9114129046207606], [0.5086493601331831, 0.907168229744644]]\n",
      "Precision for iterations:  [[0.8647604964849352, 0.822559438537054], [0.7318598535075244, 0.7744251397481247], [0.6932547558084523, 0.7957958862173237], [0.6696678313225282, 0.816996293135304], [0.655829282593234, 0.8316049242785729], [0.6011760661469265, 0.8701118287295074], [0.5948080157239936, 0.8879346811216401], [0.6213338828260557, 0.8906537975823219], [0.5948927711659255, 0.9155886494241181], [0.6493101782456828, 0.9112170807490602]]\n",
      "Recall for iterations:  [[0.8311154284378743, 0.7599542250962726], [0.5936705717374157, 0.6567790452662937], [0.587929825586491, 0.7279481217757756], [0.5834599316369161, 0.7581195960183099], [0.5807064185339916, 0.7777555765458112], [0.5651348271933156, 0.8460001453171547], [0.5638712787402494, 0.8708857080578363], [0.5724385754769348, 0.8754450337862385], [0.5650983084518976, 0.9122102739228366], [0.5839273715270676, 0.9079960764368233]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 3B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_11172/1167559547.py:2: DtypeWarning: Columns (2,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3B-Part1.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_11172/1167559547.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3B-Part2.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3B-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3B-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3B-Part3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "node_datasets = [training1, training2, training3]\n",
    "num_nodes = 3\n",
    "global_updates = 10\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'id601.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    avg_grad = np.mean(grad_list, axis=0)\n",
    "    return avg_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11172/513676356.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mxbasic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mybasic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_basic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mxplus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myplus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_plus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11172/2575831635.py\u001b[0m in \u001b[0;36mpreprocessing\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m# Convert all ports with 0 decimal, and HEX to DEC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mdata_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sport'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sport'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'.0'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0mdata_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sport'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sport'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;32mTrue\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\UX430\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4431\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4432\u001b[0m         \"\"\"\n\u001b[1;32m-> 4433\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4435\u001b[0m     def _reduce(\n",
      "\u001b[1;32mc:\\Users\\UX430\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1086\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1088\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1089\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\UX430\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1141\u001b[0m                 \u001b[1;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m                 \u001b[1;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1143\u001b[1;33m                 mapped = lib.map_infer(\n\u001b[0m\u001b[0;32m   1144\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\UX430\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11172/2575831635.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m# Convert all ports with 0 decimal, and HEX to DEC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mdata_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sport'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sport'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'.0'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0mdata_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sport'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sport'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;32mTrue\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        else:\n",
    "            x, y = x3, y3\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(y, predictions)\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/id601.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 3C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3C-Part3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "node_datasets = [training1, training2, training3]\n",
    "num_nodes = 3\n",
    "global_updates = 10\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'id602.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    avg_grad = np.mean(grad_list, axis=0)\n",
    "    return avg_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        else:\n",
    "            x, y = x3, y3\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(y, predictions)\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/id602.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3D-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3D-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3D-Part3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "node_datasets = [training1, training2, training3]\n",
    "num_nodes = 3\n",
    "global_updates = 10\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'id603.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    avg_grad = np.mean(grad_list, axis=0)\n",
    "    return avg_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        else:\n",
    "            x, y = x3, y3\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(y, predictions)\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/id603.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATASET 3E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3E-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3E-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3E-Part3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "node_datasets = [training1, training2, training3]\n",
    "num_nodes = 3\n",
    "global_updates = 10\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'id604.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    avg_grad = np.mean(grad_list, axis=0)\n",
    "    return avg_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        else:\n",
    "            x, y = x3, y3\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(y, predictions)\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/id604.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATASET 3F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3F-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3F-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3F-Part3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "node_datasets = [training1, training2, training3]\n",
    "num_nodes = 3\n",
    "global_updates = 10\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'id605.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    avg_grad = np.mean(grad_list, axis=0)\n",
    "    return avg_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        else:\n",
    "            x, y = x3, y3\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(y, predictions)\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/id605.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATASET 3G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3G-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3G-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3G-Part3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "node_datasets = [training1, training2, training3]\n",
    "num_nodes = 3\n",
    "global_updates = 10\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'id606.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    avg_grad = np.mean(grad_list, axis=0)\n",
    "    return avg_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        else:\n",
    "            x, y = x3, y3\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(y, predictions)\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/id606.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with epochs and iterations \n",
    "\n",
    "Use of dataset 3C, considering it contains an equal partition of the data between the 3 nodes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #Epochs = 10, #Iterations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3C-Part3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "node_datasets = [training1, training2, training3]\n",
    "num_nodes = 3\n",
    "global_updates = 10\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'id610.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    avg_grad = np.mean(grad_list, axis=0)\n",
    "    return avg_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        else:\n",
    "            x, y = x3, y3\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(y, predictions)\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/id610.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #Epochs = 5, #Iterations = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-3C-Part3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "node_datasets = [training1, training2, training3]\n",
    "num_nodes = 3\n",
    "global_updates = 5\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'id611.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    avg_grad = np.mean(grad_list, axis=0)\n",
    "    return avg_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        else:\n",
    "            x, y = x3, y3\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.keras.losses.categorical_crossentropy(y, predictions)\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/id611.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
