{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Federated Learning for attack detection: 5 nodes sharing gradients: MEDIAN**\n",
    "\n",
    "IDs from this file = **idMEDxy** (x = 0 if experiment with dataset, x = 1 if epochs & iterations, y being integer equal or greater than 0)\n",
    "\n",
    "In this file, experiments with different datasets, and number of epochs & iterations are done. The experiments are divided into sections, based on the elements being changed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static elements for all experiments (execute first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Disable warns\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data): \n",
    "\n",
    "    # Select the 'proto' and 'state' values that I want\n",
    "    data = data.loc[(data['proto'] == 'tcp') | (data['proto'] =='udp') | (data['proto'] =='icmp') | (data['proto'] =='arp') | (data['proto'] =='ipv6-icmp') | (data['proto'] =='igmp') | (data['proto'] =='rarp'), :]\n",
    "    data = data.loc[(data['state'] == 'RST') | (data['state'] =='REQ') | (data['state'] =='INT') | (data['state'] =='FIN') | (data['state'] =='CON') | (data['state'] =='ECO') | (data['state'] =='ACC') | (data['state'] == 'PAR'), :]\n",
    "\n",
    "    # Extracting labels \n",
    "    data_labels = data[['label']]\n",
    "\n",
    "    # Drop the invalid features and select interested data features\n",
    "    data_features=data[['proto','srcip','sport','dstip','dsport','spkts','dpkts','sbytes','dbytes','state','stime','ltime','dur']]\n",
    "\n",
    "    \"\"\"PREPROCESSING\"\"\"\n",
    "\n",
    "\n",
    "    # Preprocess IP and ports features\n",
    "    # IP Source Address\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "\n",
    "    # IP Destination Address\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "    # Ports\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "\n",
    "    # Convert all ports with 0 decimal, and HEX to DEC\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    # Convert field to int format\n",
    "    data_features['srcip'] = data_features['srcip'].astype(int)\n",
    "    data_features['sport'] = data_features['sport'].astype(int)\n",
    "    data_features['dstip'] = data_features['dstip'].astype(int)\n",
    "    data_features['dsport'] = data_features['dsport'].astype(int)\n",
    "\n",
    "    # Convert some fields to logarithmic\n",
    "    log1p_col = ['dur', 'sbytes', 'dbytes', 'spkts']\n",
    "\n",
    "    for col in log1p_col:\n",
    "        data_features[col] = data_features[col].apply(np.log1p)\n",
    "\n",
    "    # Create a complementary field of attack & Transform to One hot encoding - LABELS\n",
    "    normal=data_labels['label']\n",
    "    normal=normal.replace(1,2)\n",
    "    normal=normal.replace(0,1)\n",
    "    normal=normal.replace(2,0)\n",
    "\n",
    "    # Insert the new column in data labels\n",
    "    data_labels.insert(1, 'normal', normal)\n",
    "    data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "    data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "    # Transform to One hot encoding - FEATURES\n",
    "    data_features=pd.get_dummies(data_features)\n",
    "\n",
    "    # Value given for the missing columns\n",
    "    auxCol=0\n",
    "\n",
    "    # As we are using different datasets that might not have all representations, we are going to detect and add the missing columns \n",
    "    # The columns that can have types are: proto and state: need to check if all representations are done \n",
    "    state_cols = [col for col in data_features if col.startswith('state_')]\n",
    "    proto_cols = [col for col in data_features if col.startswith('proto_')]\n",
    "    \n",
    "    # Check if all columns are present\n",
    "    if 'state_PAR' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_PAR', auxCol, True)\n",
    "    if 'state_ACC' not in state_cols: \n",
    "        data_features.insert(data_features.shape[1], 'state_ACC', auxCol, True)\n",
    "    if 'state_ECO' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_ECO', auxCol, True)\n",
    "    if 'state_CON' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_CON', auxCol, True)\n",
    "    if 'state_FIN' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_FIN', auxCol, True)\n",
    "    if 'state_INT' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_INT', auxCol, True)\n",
    "    if 'state_REQ' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_REQ', auxCol, True)\n",
    "    if 'state_RST' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_RST', auxCol, True)\n",
    "    if 'proto_igmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_igmp', auxCol, True)\n",
    "    if 'proto_arp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_arp', auxCol, True)\n",
    "    if 'proto_icmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_icmp', auxCol, True)\n",
    "    if 'proto_udp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_udp', auxCol, True)\n",
    "    if 'proto_tcp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_tcp', auxCol, True)\n",
    "\n",
    "    # Normalize all data features\n",
    "    data_features = StandardScaler().fit_transform(data_features)\n",
    "\n",
    "    #Add dimension to data features\n",
    "    data_features = np.expand_dims(data_features, axis=2)\n",
    "    data_features = np.expand_dims(data_features, axis=3)\n",
    "\n",
    "    x = data_features\n",
    "    y = data_labels.to_numpy()\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building and definition\n",
    "def build_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(filters=32,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(1, 2), padding='same'))\n",
    "    model.add(layers.Conv2D(filters=64,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(1, 2), padding='same'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(Dense(444, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns values of loss, accuracy, f1, precision and recall of model evaluating with test dataset \n",
    "def evaluation(model, x, y): \n",
    "    loss, accuracy = model.evaluate(x, y)\n",
    "    y_pred = model.predict(x)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y = np.argmax(y, axis=1)\n",
    "    report = classification_report(y, y_pred, target_names=['normal', 'attack'], output_dict=True)\n",
    "    # Obtain f1, precision and recall from the report\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    return loss, accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_2808/3457440085.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_2808/3457440085.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_complete = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Complete.csv')\n"
     ]
    }
   ],
   "source": [
    "test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n",
    "test_plus = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test+.csv')\n",
    "test_complete = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)\n",
    "xcomplete, ycomplete = preprocessing(test_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments with datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Filt5A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part1.csv', low_memory=False)\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part2.csv', low_memory=False)\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part3.csv', low_memory=False)\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part4.csv', low_memory=False)\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part5.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idMED00.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list):\n",
    "    \n",
    "    # Compute the median gradient for each layer\n",
    "    med_grad = [\n",
    "        tf.numpy_function(lambda grads: np.median(grads, axis=0), [tf.stack(layer_grads)], tf.float32)\n",
    "        for layer_grads in zip(*grad_list)\n",
    "    ]\n",
    "    return med_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 13s 409ms/step - loss: 0.3975 - accuracy: 0.9656 - val_loss: 1.6841 - val_accuracy: 0.6197\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 342ms/step - loss: 0.0641 - accuracy: 0.9914 - val_loss: 0.9172 - val_accuracy: 0.6200\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 251ms/step - loss: 0.0307 - accuracy: 0.9918 - val_loss: 0.8356 - val_accuracy: 0.6233\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 392ms/step - loss: 0.0270 - accuracy: 0.9922 - val_loss: 0.6461 - val_accuracy: 0.6453\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 359ms/step - loss: 0.0257 - accuracy: 0.9921 - val_loss: 0.5399 - val_accuracy: 0.6733\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 13s 404ms/step - loss: 0.0435 - accuracy: 0.9900 - val_loss: 0.6338 - val_accuracy: 0.6925\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 354ms/step - loss: 0.0270 - accuracy: 0.9910 - val_loss: 0.3758 - val_accuracy: 0.7880\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 238ms/step - loss: 0.0249 - accuracy: 0.9915 - val_loss: 0.5152 - val_accuracy: 0.6597 loss: 0.0250 - accuracy: \n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 322ms/step - loss: 0.0230 - accuracy: 0.9921 - val_loss: 0.3357 - val_accuracy: 0.7940\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 356ms/step - loss: 0.0212 - accuracy: 0.9928 - val_loss: 0.4258 - val_accuracy: 0.7052\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 358ms/step - loss: 0.0200 - accuracy: 0.9930 - val_loss: 0.3557 - val_accuracy: 0.7647\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 301ms/step - loss: 0.0178 - accuracy: 0.9939 - val_loss: 0.3381 - val_accuracy: 0.7876\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 265ms/step - loss: 0.0167 - accuracy: 0.9943 - val_loss: 0.3895 - val_accuracy: 0.7723\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 13s 435ms/step - loss: 0.0161 - accuracy: 0.9944 - val_loss: 0.2765 - val_accuracy: 0.8357\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 12s 390ms/step - loss: 0.0154 - accuracy: 0.9950 - val_loss: 0.2678 - val_accuracy: 0.8437\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 20s 647ms/step - loss: 0.0159 - accuracy: 0.9950 - val_loss: 0.4606 - val_accuracy: 0.7757\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 14s 445ms/step - loss: 0.0151 - accuracy: 0.9953 - val_loss: 0.3670 - val_accuracy: 0.8189\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 334ms/step - loss: 0.0151 - accuracy: 0.9954 - val_loss: 0.5719 - val_accuracy: 0.7603\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 15s 469ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.2844 - val_accuracy: 0.8502\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 13s 414ms/step - loss: 0.0144 - accuracy: 0.9955 - val_loss: 0.4009 - val_accuracy: 0.8215\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 16s 519ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.4232 - val_accuracy: 0.8127\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 13s 413ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.4556 - val_accuracy: 0.8076\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 12s 382ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.2638 - val_accuracy: 0.8601\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 13s 416ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.3500 - val_accuracy: 0.8412\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 318ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.2498 - val_accuracy: 0.8651\n",
      "4279/4279 [==============================] - 40s 9ms/step - loss: 0.0402 - accuracy: 0.9814\n",
      "1721/1721 [==============================] - 21s 12ms/step - loss: 0.2004 - accuracy: 0.9206\n",
      "4481/4481 [==============================] - 54s 12ms/step - loss: 0.0625 - accuracy: 0.9727\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 20s 639ms/step - loss: 0.0159 - accuracy: 0.9953 - val_loss: 0.4109 - val_accuracy: 0.8161\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 12s 385ms/step - loss: 0.0139 - accuracy: 0.9960 - val_loss: 0.4608 - val_accuracy: 0.8056\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 258ms/step - loss: 0.0136 - accuracy: 0.9960 - val_loss: 0.4697 - val_accuracy: 0.8048\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 213ms/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 0.4689 - val_accuracy: 0.8023\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 13s 406ms/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 0.3991 - val_accuracy: 0.8277\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 15s 476ms/step - loss: 0.0151 - accuracy: 0.9957 - val_loss: 0.3226 - val_accuracy: 0.8509\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 13s 408ms/step - loss: 0.0142 - accuracy: 0.9960 - val_loss: 0.4446 - val_accuracy: 0.8248\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 305ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.4369 - val_accuracy: 0.8262\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 216ms/step - loss: 0.0139 - accuracy: 0.9959 - val_loss: 0.6393 - val_accuracy: 0.7678\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 13s 405ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.5269 - val_accuracy: 0.8043\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 17s 535ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.3974 - val_accuracy: 0.8374\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 335ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 0.4888 - val_accuracy: 0.8099\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 364ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.5166 - val_accuracy: 0.8072\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 387ms/step - loss: 0.0117 - accuracy: 0.9967 - val_loss: 0.4502 - val_accuracy: 0.8276\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 13s 426ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.5563 - val_accuracy: 0.8028\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 18s 575ms/step - loss: 0.0132 - accuracy: 0.9959 - val_loss: 0.4334 - val_accuracy: 0.8373\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 13s 418ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 0.4616 - val_accuracy: 0.8316\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 14s 467ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.4456 - val_accuracy: 0.8371\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 14s 445ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.4546 - val_accuracy: 0.8363\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 361ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 0.6245 - val_accuracy: 0.7855\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 14s 452ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.4864 - val_accuracy: 0.8257\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 278ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.3318 - val_accuracy: 0.8631\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 13s 430ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.5329 - val_accuracy: 0.8145\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 14s 461ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.3739 - val_accuracy: 0.8545\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 15s 476ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.6574 - val_accuracy: 0.7781\n",
      "4279/4279 [==============================] - 38s 9ms/step - loss: 0.0826 - accuracy: 0.9689\n",
      "1721/1721 [==============================] - 19s 11ms/step - loss: 0.4385 - accuracy: 0.7853\n",
      "4481/4481 [==============================] - 56s 13ms/step - loss: 0.1390 - accuracy: 0.9419\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 17s 550ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 0.5388 - val_accuracy: 0.8030\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 14s 464ms/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.7587 - val_accuracy: 0.7441\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 295ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.2701 - val_accuracy: 0.8740\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 371ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.7138 - val_accuracy: 0.7632\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 361ms/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 0.5538 - val_accuracy: 0.8012\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 401ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.6519 - val_accuracy: 0.7765\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 340ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 0.5064 - val_accuracy: 0.8272\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 236ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.5849 - val_accuracy: 0.8021\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 321ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.6669 - val_accuracy: 0.7792\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 353ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.3631 - val_accuracy: 0.8537\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 392ms/step - loss: 0.0101 - accuracy: 0.9971 - val_loss: 0.6649 - val_accuracy: 0.7902\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 13s 404ms/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.8167 - val_accuracy: 0.7480\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 323ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.6778 - val_accuracy: 0.7891\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 14s 454ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.6130 - val_accuracy: 0.8029\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 14s 453ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 0.5303 - val_accuracy: 0.8265\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 15s 484ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 0.6292 - val_accuracy: 0.8075\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 12s 402ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.4401 - val_accuracy: 0.8447\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 342ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.9714 - val_accuracy: 0.7284\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 13s 406ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.6908 - val_accuracy: 0.7924\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 12s 376ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.6085 - val_accuracy: 0.8047\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 14s 439ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 0.7007 - val_accuracy: 0.7817\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 334ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.5305 - val_accuracy: 0.8231\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 13s 434ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.3347 - val_accuracy: 0.8605\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 334ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.6013 - val_accuracy: 0.8017\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 14s 446ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.7091 - val_accuracy: 0.7706\n",
      "4279/4279 [==============================] - 37s 9ms/step - loss: 0.0834 - accuracy: 0.9686\n",
      "1721/1721 [==============================] - 16s 9ms/step - loss: 0.4407 - accuracy: 0.7906\n",
      "4481/4481 [==============================] - 44s 10ms/step - loss: 0.1519 - accuracy: 0.9381\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "    loss_complete, accuracy_complete, f1_complete, precision_complete, recall_complete = evaluation(global_model, xcomplete, ycomplete)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus, loss_complete])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus, accuracy_complete])\n",
    "    f1_it.append([f1_basic, f1_plus, f1_complete])\n",
    "    precision_it.append([precision_basic, precision_plus, precision_complete])\n",
    "    recall_it.append([recall_basic, recall_plus, recall_complete])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idMED00.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.04021567478775978, 0.2003970593214035, 0.06247953698039055], [0.08260253071784973, 0.43851250410079956, 0.1389634609222412], [0.08335065841674805, 0.4406733512878418, 0.15186883509159088]]\n",
      "Accuracy for iterations:  [[0.9814484715461731, 0.9205660223960876, 0.9726998209953308], [0.9688568115234375, 0.7853302359580994, 0.9418911933898926], [0.9685865640640259, 0.7905797958374023, 0.9380689263343811]]\n",
      "F1 for iterations:  [[0.9814405848988382, 0.9197056210882352, 0.9726930520938676], [0.9687899127092552, 0.7695675686308082, 0.9417341465116771], [0.9685108164478585, 0.7759273251167887, 0.9378625699018214]]\n",
      "Precision for iterations:  [[0.9815186781177139, 0.9254324948106357, 0.9731684551937836], [0.970011102049446, 0.8355941927317043, 0.9467069664943243], [0.9699706538488233, 0.8385065526992616, 0.9439649392456899]]\n",
      "Recall for iterations:  [[0.9814484793596073, 0.920566010317518, 0.9726998165572753], [0.9688568173186479, 0.7853302332340333, 0.9418912038167246], [0.968586578632154, 0.7905798154472136, 0.9380688991344014]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Filt5B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part1.csv', low_memory=False)\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part2.csv', low_memory=False)\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part3.csv', low_memory=False)\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part4.csv', low_memory=False)\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part5.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idMED01.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 17s 562ms/step - loss: 0.3846 - accuracy: 0.9539 - val_loss: 2.0922 - val_accuracy: 0.5504\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 13s 420ms/step - loss: 0.0644 - accuracy: 0.9912 - val_loss: 1.4158 - val_accuracy: 0.5526\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 359ms/step - loss: 0.0297 - accuracy: 0.9917 - val_loss: 0.7306 - val_accuracy: 0.5773\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 258ms/step - loss: 0.0261 - accuracy: 0.9921 - val_loss: 0.6551 - val_accuracy: 0.6053\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 366ms/step - loss: 0.0247 - accuracy: 0.9920 - val_loss: 0.5809 - val_accuracy: 0.6394\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 15s 494ms/step - loss: 0.0342 - accuracy: 0.9902 - val_loss: 0.4173 - val_accuracy: 0.7676\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 313ms/step - loss: 0.0249 - accuracy: 0.9913 - val_loss: 0.3211 - val_accuracy: 0.8073\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 241ms/step - loss: 0.0229 - accuracy: 0.9921 - val_loss: 0.2965 - val_accuracy: 0.8160\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 279ms/step - loss: 0.0215 - accuracy: 0.9926 - val_loss: 0.3221 - val_accuracy: 0.7880\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 274ms/step - loss: 0.0196 - accuracy: 0.9933 - val_loss: 0.3605 - val_accuracy: 0.7566\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 377ms/step - loss: 0.0096 - accuracy: 0.9973 - val_loss: 4.7365 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 13s 426ms/step - loss: 2.7255e-07 - accuracy: 1.0000 - val_loss: 5.1342 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 371ms/step - loss: 1.8455e-07 - accuracy: 1.0000 - val_loss: 5.1556 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 13s 405ms/step - loss: 1.8088e-07 - accuracy: 1.0000 - val_loss: 5.1578 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 13s 419ms/step - loss: 1.8012e-07 - accuracy: 1.0000 - val_loss: 5.1593 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 15s 479ms/step - loss: 4.7326 - accuracy: 0.4186 - val_loss: 0.0519 - val_accuracy: 0.9881\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 350ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 369ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 306ms/step - loss: 8.5560e-04 - accuracy: 1.0000 - val_loss: 7.0839e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 305ms/step - loss: 4.4286e-04 - accuracy: 1.0000 - val_loss: 3.8711e-04 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 340ms/step - loss: 1.5998 - accuracy: 0.6786 - val_loss: 0.9308 - val_accuracy: 0.6310\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 202ms/step - loss: 0.0444 - accuracy: 0.9943 - val_loss: 0.7343 - val_accuracy: 0.6372\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 284ms/step - loss: 0.0243 - accuracy: 0.9942 - val_loss: 0.7389 - val_accuracy: 0.6373\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 299ms/step - loss: 0.0221 - accuracy: 0.9942 - val_loss: 0.7562 - val_accuracy: 0.6367\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 296ms/step - loss: 0.0208 - accuracy: 0.9943 - val_loss: 0.7426 - val_accuracy: 0.6367\n",
      "4279/4279 [==============================] - 28s 7ms/step - loss: 0.1417 - accuracy: 0.9240 0s - loss: 0.1418 \n",
      "1721/1721 [==============================] - 10s 6ms/step - loss: 0.2996 - accuracy: 0.8117\n",
      "4481/4481 [==============================] - 40s 9ms/step - loss: 0.2048 - accuracy: 0.8911\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 10s 334ms/step - loss: 0.0214 - accuracy: 0.9929 - val_loss: 0.3482 - val_accuracy: 0.7907\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 294ms/step - loss: 0.0181 - accuracy: 0.9941 - val_loss: 0.3867 - val_accuracy: 0.7585\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 227ms/step - loss: 0.0169 - accuracy: 0.9946 - val_loss: 0.2868 - val_accuracy: 0.8358\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 270ms/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 0.3723 - val_accuracy: 0.7838\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 283ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.4171 - val_accuracy: 0.7701\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 347ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 0.4008 - val_accuracy: 0.7940\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 314ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.3990 - val_accuracy: 0.8048\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 242ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.2897 - val_accuracy: 0.8401\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 273ms/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.3384 - val_accuracy: 0.8330\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 281ms/step - loss: 0.0151 - accuracy: 0.9953 - val_loss: 0.4678 - val_accuracy: 0.8096\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 10s 319ms/step - loss: 0.0146 - accuracy: 0.9947 - val_loss: 5.8315 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 361ms/step - loss: 3.8080e-08 - accuracy: 1.0000 - val_loss: 6.2171 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 287ms/step - loss: 2.5492e-08 - accuracy: 1.0000 - val_loss: 6.2368 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 330ms/step - loss: 2.5040e-08 - accuracy: 1.0000 - val_loss: 6.2378 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 12s 377ms/step - loss: 2.5023e-08 - accuracy: 1.0000 - val_loss: 6.2380 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 392ms/step - loss: 8.5747 - accuracy: 0.3474 - val_loss: 0.6386 - val_accuracy: 0.8463\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 327ms/step - loss: 0.1527 - accuracy: 0.9466 - val_loss: 0.0178 - val_accuracy: 0.9938\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 330ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9950\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 323ms/step - loss: 9.6317e-04 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9955\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 313ms/step - loss: 8.3305e-04 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9957\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 272ms/step - loss: 1.9543 - accuracy: 0.7230 - val_loss: 0.8485 - val_accuracy: 0.6825\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 219ms/step - loss: 0.0199 - accuracy: 0.9947 - val_loss: 0.6231 - val_accuracy: 0.6964\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 287ms/step - loss: 0.0158 - accuracy: 0.9946 - val_loss: 0.5935 - val_accuracy: 0.6998\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 309ms/step - loss: 0.0154 - accuracy: 0.9946 - val_loss: 0.5896 - val_accuracy: 0.7020\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 303ms/step - loss: 0.0151 - accuracy: 0.9946 - val_loss: 0.5609 - val_accuracy: 0.7083\n",
      "4279/4279 [==============================] - 28s 7ms/step - loss: 0.0891 - accuracy: 0.9534\n",
      "1721/1721 [==============================] - 11s 6ms/step - loss: 0.2522 - accuracy: 0.8691\n",
      "4481/4481 [==============================] - 41s 9ms/step - loss: 0.1466 - accuracy: 0.9211\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 344ms/step - loss: 0.0182 - accuracy: 0.9940 - val_loss: 0.3162 - val_accuracy: 0.8199\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 307ms/step - loss: 0.0152 - accuracy: 0.9956 - val_loss: 0.4018 - val_accuracy: 0.7825\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 230ms/step - loss: 0.0147 - accuracy: 0.9959 - val_loss: 0.3884 - val_accuracy: 0.7990\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 263ms/step - loss: 0.0145 - accuracy: 0.9961 - val_loss: 0.2679 - val_accuracy: 0.8698\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 224ms/step - loss: 0.0140 - accuracy: 0.9960 - val_loss: 0.3642 - val_accuracy: 0.8273\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 13s 433ms/step - loss: 0.0233 - accuracy: 0.9944 - val_loss: 0.3736 - val_accuracy: 0.8282\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 321ms/step - loss: 0.0161 - accuracy: 0.9953 - val_loss: 0.4071 - val_accuracy: 0.8235\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 266ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.4531 - val_accuracy: 0.8133\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 206ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 0.3439 - val_accuracy: 0.8384\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 310ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.4569 - val_accuracy: 0.8204\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 13s 421ms/step - loss: 0.0804 - accuracy: 0.9686 - val_loss: 4.1639 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 13s 409ms/step - loss: 5.1601e-06 - accuracy: 1.0000 - val_loss: 4.6070 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 12s 393ms/step - loss: 3.2462e-06 - accuracy: 1.0000 - val_loss: 4.6372 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 343ms/step - loss: 3.1256e-06 - accuracy: 1.0000 - val_loss: 4.6467 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 354ms/step - loss: 3.0570e-06 - accuracy: 1.0000 - val_loss: 4.6566 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 13s 429ms/step - loss: 7.1098 - accuracy: 0.4157 - val_loss: 1.2193 - val_accuracy: 0.8157\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 13s 423ms/step - loss: 0.4148 - accuracy: 0.8954 - val_loss: 0.0290 - val_accuracy: 0.9898\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 12s 398ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9953\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 347ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 0.9962\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 320ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9970\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 9s 281ms/step - loss: 0.9273 - accuracy: 0.8093 - val_loss: 0.6008 - val_accuracy: 0.7199\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 322ms/step - loss: 0.0203 - accuracy: 0.9945 - val_loss: 0.5959 - val_accuracy: 0.7195\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 304ms/step - loss: 0.0172 - accuracy: 0.9943 - val_loss: 0.5796 - val_accuracy: 0.7213\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 312ms/step - loss: 0.0164 - accuracy: 0.9946 - val_loss: 0.5327 - val_accuracy: 0.7277\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 308ms/step - loss: 0.0162 - accuracy: 0.9948 - val_loss: 0.5497 - val_accuracy: 0.7257\n",
      "4279/4279 [==============================] - 38s 9ms/step - loss: 0.0912 - accuracy: 0.9525\n",
      "1721/1721 [==============================] - 15s 9ms/step - loss: 0.2547 - accuracy: 0.8683\n",
      "4481/4481 [==============================] - 19s 4ms/step - loss: 0.1512 - accuracy: 0.9217 0s -\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "    loss_complete, accuracy_complete, f1_complete, precision_complete, recall_complete = evaluation(global_model, xcomplete, ycomplete)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus, loss_complete])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus, accuracy_complete])\n",
    "    f1_it.append([f1_basic, f1_plus, f1_complete])\n",
    "    precision_it.append([precision_basic, precision_plus, precision_complete])\n",
    "    recall_it.append([recall_basic, recall_plus, recall_complete])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idMED01.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.14167417585849762, 0.2995983958244324, 0.20479938387870789], [0.08905424177646637, 0.25220876932144165, 0.1466495245695114], [0.09121678024530411, 0.254693865776062, 0.15116024017333984]]\n",
      "Accuracy for iterations:  [[0.9240118265151978, 0.8116871118545532, 0.8911201357841492], [0.9534313082695007, 0.8691055774688721, 0.9211475253105164], [0.9524891376495361, 0.8683063387870789, 0.9217055439949036]]\n",
      "F1 for iterations:  [[0.9232854151269415, 0.8010585992597671, 0.8899009860283438], [0.9532346007403208, 0.8653498725888372, 0.920712350375337], [0.9522853829097507, 0.8645479830216747, 0.9212841612252541]]\n",
      "Precision for iterations:  [[0.9326049342184513, 0.849999150947512, 0.9092451437869306], [0.9564657771770103, 0.8870928244969982, 0.9306001356404968], [0.9555799542266943, 0.8860697097195477, 0.9309317373909491]]\n",
      "Recall for iterations:  [[0.9240118028572263, 0.8116871321659522, 0.8911201166221429], [0.9534313009436443, 0.8691055729128824, 0.9211475284057223], [0.9524891174150574, 0.8683063285620868, 0.9217055290892732]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Filt5C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part1.csv', low_memory=False)\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part2.csv', low_memory=False)\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part3.csv', low_memory=False)\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part4.csv', low_memory=False)\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part5.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idMED02.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 6s 371ms/step - loss: 0.5397 - accuracy: 0.7491 - val_loss: 1.7106 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 5s 300ms/step - loss: 0.2074 - accuracy: 0.9489 - val_loss: 3.6385 - val_accuracy: 0.1299\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 4s 253ms/step - loss: 0.0849 - accuracy: 0.9893 - val_loss: 3.9016 - val_accuracy: 0.1339\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 207ms/step - loss: 0.0507 - accuracy: 0.9894 - val_loss: 1.7949 - val_accuracy: 0.1355\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 4s 250ms/step - loss: 0.0352 - accuracy: 0.9899 - val_loss: 1.3799 - val_accuracy: 0.1771\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 5s 387ms/step - loss: 0.0225 - accuracy: 0.9949 - val_loss: 0.8095 - val_accuracy: 0.7271\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 4s 283ms/step - loss: 0.0200 - accuracy: 0.9950 - val_loss: 0.5206 - val_accuracy: 0.7311\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 4s 292ms/step - loss: 0.0197 - accuracy: 0.9949 - val_loss: 0.5402 - val_accuracy: 0.7310\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 4s 302ms/step - loss: 0.0191 - accuracy: 0.9950 - val_loss: 0.6301 - val_accuracy: 0.7287\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 4s 285ms/step - loss: 0.0181 - accuracy: 0.9950 - val_loss: 0.7187 - val_accuracy: 0.7277\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 7s 252ms/step - loss: 0.0137 - accuracy: 0.9962 - val_loss: 2.5081 - val_accuracy: 0.4405\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 6s 227ms/step - loss: 0.0128 - accuracy: 0.9965 - val_loss: 1.9807 - val_accuracy: 0.4420\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 7s 283ms/step - loss: 0.0125 - accuracy: 0.9968 - val_loss: 2.0743 - val_accuracy: 0.4384\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 7s 271ms/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 2.1613 - val_accuracy: 0.4381\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 7s 269ms/step - loss: 0.0117 - accuracy: 0.9971 - val_loss: 1.5830 - val_accuracy: 0.4727\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 12s 457ms/step - loss: 2.3534 - accuracy: 0.5875 - val_loss: 0.0482 - val_accuracy: 0.9841\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 11s 424ms/step - loss: 0.0058 - accuracy: 0.9997 - val_loss: 0.0093 - val_accuracy: 0.9961\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 11s 415ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9985\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 10s 366ms/step - loss: 5.3605e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9998\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 9s 345ms/step - loss: 2.4694e-04 - accuracy: 1.0000 - val_loss: 9.8029e-04 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 28s 394ms/step - loss: 0.6610 - accuracy: 0.8819 - val_loss: 0.4695 - val_accuracy: 0.8268\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 24s 346ms/step - loss: 0.0237 - accuracy: 0.9930 - val_loss: 0.2502 - val_accuracy: 0.8559\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 21s 293ms/step - loss: 0.0212 - accuracy: 0.9937 - val_loss: 0.2458 - val_accuracy: 0.8571loss: 0.0212 - accuracy: 0.\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 22s 308ms/step - loss: 0.0199 - accuracy: 0.9938 - val_loss: 0.2079 - val_accuracy: 0.8783\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 23s 325ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.2245 - val_accuracy: 0.8676\n",
      "4279/4279 [==============================] - 37s 9ms/step - loss: 0.0783 - accuracy: 0.9879\n",
      "1721/1721 [==============================] - 11s 6ms/step - loss: 0.1625 - accuracy: 0.9515\n",
      "4481/4481 [==============================] - 33s 7ms/step - loss: 0.0880 - accuracy: 0.9813\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 6s 393ms/step - loss: 0.0234 - accuracy: 0.9917 - val_loss: 1.0046 - val_accuracy: 0.4259\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 5s 322ms/step - loss: 0.0208 - accuracy: 0.9930 - val_loss: 0.7905 - val_accuracy: 0.5834\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 5s 315ms/step - loss: 0.0200 - accuracy: 0.9934 - val_loss: 0.8261 - val_accuracy: 0.5836\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 5s 298ms/step - loss: 0.0193 - accuracy: 0.9934 - val_loss: 1.1231 - val_accuracy: 0.4621\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.0188 - accuracy: 0.9937 - val_loss: 0.9019 - val_accuracy: 0.5719\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 7s 525ms/step - loss: 0.0154 - accuracy: 0.9960 - val_loss: 0.8050 - val_accuracy: 0.7364\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 4s 317ms/step - loss: 0.0138 - accuracy: 0.9965 - val_loss: 0.6808 - val_accuracy: 0.7459\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 4s 315ms/step - loss: 0.0135 - accuracy: 0.9966 - val_loss: 0.8132 - val_accuracy: 0.7399\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 4s 320ms/step - loss: 0.0135 - accuracy: 0.9964 - val_loss: 0.6700 - val_accuracy: 0.7488\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 4s 308ms/step - loss: 0.0131 - accuracy: 0.9965 - val_loss: 0.8217 - val_accuracy: 0.7400\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 329ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 1.8627 - val_accuracy: 0.5020\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 6s 248ms/step - loss: 0.0106 - accuracy: 0.9975 - val_loss: 1.6638 - val_accuracy: 0.5414\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 6s 231ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 1.6106 - val_accuracy: 0.5499\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 8s 307ms/step - loss: 0.0102 - accuracy: 0.9975 - val_loss: 2.1276 - val_accuracy: 0.5057\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 8s 306ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 1.6407 - val_accuracy: 0.5584\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 13s 484ms/step - loss: 4.3520 - accuracy: 0.4399 - val_loss: 0.4285 - val_accuracy: 0.8962\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 11s 416ms/step - loss: 0.1455 - accuracy: 0.9464 - val_loss: 0.0405 - val_accuracy: 0.9878\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 9s 318ms/step - loss: 0.0034 - accuracy: 0.9998 - val_loss: 0.0244 - val_accuracy: 0.9913\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 10s 364ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0210 - val_accuracy: 0.9923\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 11s 410ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0187 - val_accuracy: 0.9930\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 31s 446ms/step - loss: 0.7331 - accuracy: 0.8929 - val_loss: 0.3232 - val_accuracy: 0.8620\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 27s 388ms/step - loss: 0.0186 - accuracy: 0.9948 - val_loss: 0.2006 - val_accuracy: 0.9063\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 18s 255ms/step - loss: 0.0172 - accuracy: 0.9948 - val_loss: 0.1947 - val_accuracy: 0.9027\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 22s 319ms/step - loss: 0.0164 - accuracy: 0.9950 - val_loss: 0.1743 - val_accuracy: 0.9091\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 24s 338ms/step - loss: 0.0158 - accuracy: 0.9950 - val_loss: 0.1612 - val_accuracy: 0.9136\n",
      "4279/4279 [==============================] - 40s 9ms/step - loss: 0.0589 - accuracy: 0.9893\n",
      "1721/1721 [==============================] - 11s 6ms/step - loss: 0.0994 - accuracy: 0.9794\n",
      "4481/4481 [==============================] - 31s 7ms/step - loss: 0.0551 - accuracy: 0.9901\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 6s 393ms/step - loss: 0.0205 - accuracy: 0.9932 - val_loss: 0.7829 - val_accuracy: 0.5945\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 5s 308ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 0.9597 - val_accuracy: 0.5424\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 5s 293ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.9787 - val_accuracy: 0.5464\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 5s 300ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.7973 - val_accuracy: 0.6290\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 5s 301ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 0.8726 - val_accuracy: 0.6037\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 6s 400ms/step - loss: 0.0141 - accuracy: 0.9963 - val_loss: 0.9334 - val_accuracy: 0.7359\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 242ms/step - loss: 0.0128 - accuracy: 0.9972 - val_loss: 0.7490 - val_accuracy: 0.7515\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 4s 305ms/step - loss: 0.0124 - accuracy: 0.9971 - val_loss: 0.8510 - val_accuracy: 0.7495\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 4s 318ms/step - loss: 0.0122 - accuracy: 0.9973 - val_loss: 0.8553 - val_accuracy: 0.7522\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 4s 317ms/step - loss: 0.0122 - accuracy: 0.9970 - val_loss: 0.7089 - val_accuracy: 0.7640\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 345ms/step - loss: 0.0109 - accuracy: 0.9975 - val_loss: 1.6300 - val_accuracy: 0.5379\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 7s 280ms/step - loss: 0.0099 - accuracy: 0.9975 - val_loss: 1.6610 - val_accuracy: 0.5435\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 6s 227ms/step - loss: 0.0099 - accuracy: 0.9975 - val_loss: 1.7482 - val_accuracy: 0.5490\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 6s 224ms/step - loss: 0.0098 - accuracy: 0.9975 - val_loss: 1.2949 - val_accuracy: 0.6265\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 8s 301ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 2.0144 - val_accuracy: 0.5276\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 9s 326ms/step - loss: 4.1542 - accuracy: 0.5197 - val_loss: 0.3407 - val_accuracy: 0.9176\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 10s 383ms/step - loss: 0.0717 - accuracy: 0.9698 - val_loss: 0.0084 - val_accuracy: 0.9964\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 11s 406ms/step - loss: 2.9777e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9978\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 11s 420ms/step - loss: 1.9756e-04 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9978\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 10s 382ms/step - loss: 1.7782e-04 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9979\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 28s 407ms/step - loss: 0.7549 - accuracy: 0.8986 - val_loss: 0.2367 - val_accuracy: 0.8976\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 28s 397ms/step - loss: 0.0171 - accuracy: 0.9948 - val_loss: 0.1701 - val_accuracy: 0.9219\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 25s 357ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.1579 - val_accuracy: 0.9235\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 20s 279ms/step - loss: 0.0147 - accuracy: 0.9955 - val_loss: 0.1578 - val_accuracy: 0.9211\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 23s 324ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.1470 - val_accuracy: 0.9288\n",
      "4279/4279 [==============================] - 37s 9ms/step - loss: 0.0607 - accuracy: 0.9888\n",
      "1721/1721 [==============================] - 14s 8ms/step - loss: 0.0857 - accuracy: 0.9838\n",
      "4481/4481 [==============================] - 19s 4ms/step - loss: 0.0549 - accuracy: 0.9900 0s - l\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "    loss_complete, accuracy_complete, f1_complete, precision_complete, recall_complete = evaluation(global_model, xcomplete, ycomplete)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus, loss_complete])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus, accuracy_complete])\n",
    "    f1_it.append([f1_basic, f1_plus, f1_complete])\n",
    "    precision_it.append([precision_basic, precision_plus, precision_complete])\n",
    "    recall_it.append([recall_basic, recall_plus, recall_complete])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idMED02.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.07833056151866913, 0.16251912713050842, 0.08799697458744049], [0.058851320296525955, 0.09940706938505173, 0.05509649217128754], [0.060660067945718765, 0.0856747254729271, 0.05493783578276634]]\n",
      "Accuracy for iterations:  [[0.9878976941108704, 0.9515185356140137, 0.9812790751457214], [0.9893438220024109, 0.979419469833374, 0.9900745749473572], [0.9887887239456177, 0.9837789535522461, 0.9900466799736023]]\n",
      "F1 for iterations:  [[0.9879017615640726, 0.951333855590243, 0.9812790133480048], [0.989349069254417, 0.9794558062330426, 0.990073768534064], [0.9887945470246919, 0.9838066189632456, 0.9900456965845631]]\n",
      "Precision for iterations:  [[0.9879915605163647, 0.9524089898434744, 0.9812856042865771], [0.9895683243562778, 0.9800396702321673, 0.9902316018026237], [0.9890446953678572, 0.9843397518722772, 0.9902371400138832]]\n",
      "Recall for iterations:  [[0.9878976890940431, 0.9515185642665117, 0.9812790770668695], [0.9893438312541997, 0.979419457967013, 0.9900745628413394], [0.9887887463846446, 0.9837789726077163, 0.9900466628071619]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
