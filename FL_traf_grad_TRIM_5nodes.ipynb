{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Federated Learning for attack detection: 5 nodes sharing gradients: TRIMMED MEAN**\n",
    "\n",
    "IDs from this file = **idTRIMxy** (x = 0 if experiment with dataset, x = 1 if epochs & iterations, y being integer equal or greater than 0)\n",
    "\n",
    "In this file, experiments with different datasets, and number of epochs & iterations are done. The experiments are divided into sections, based on the elements being changed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static elements for all experiments (execute first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Disable warns\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data): \n",
    "\n",
    "    # Select the 'proto' and 'state' values that I want\n",
    "    data = data.loc[(data['proto'] == 'tcp') | (data['proto'] =='udp') | (data['proto'] =='icmp') | (data['proto'] =='arp') | (data['proto'] =='ipv6-icmp') | (data['proto'] =='igmp') | (data['proto'] =='rarp'), :]\n",
    "    data = data.loc[(data['state'] == 'RST') | (data['state'] =='REQ') | (data['state'] =='INT') | (data['state'] =='FIN') | (data['state'] =='CON') | (data['state'] =='ECO') | (data['state'] =='ACC') | (data['state'] == 'PAR'), :]\n",
    "\n",
    "    # Extracting labels \n",
    "    data_labels = data[['label']]\n",
    "\n",
    "    # Drop the invalid features and select interested data features\n",
    "    data_features=data[['proto','srcip','sport','dstip','dsport','spkts','dpkts','sbytes','dbytes','state','stime','ltime','dur']]\n",
    "\n",
    "    \"\"\"PREPROCESSING\"\"\"\n",
    "\n",
    "\n",
    "    # Preprocess IP and ports features\n",
    "    # IP Source Address\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "\n",
    "    # IP Destination Address\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "    # Ports\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "\n",
    "    # Convert all ports with 0 decimal, and HEX to DEC\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    # Convert field to int format\n",
    "    data_features['srcip'] = data_features['srcip'].astype(int)\n",
    "    data_features['sport'] = data_features['sport'].astype(int)\n",
    "    data_features['dstip'] = data_features['dstip'].astype(int)\n",
    "    data_features['dsport'] = data_features['dsport'].astype(int)\n",
    "\n",
    "    # Convert some fields to logarithmic\n",
    "    log1p_col = ['dur', 'sbytes', 'dbytes', 'spkts']\n",
    "\n",
    "    for col in log1p_col:\n",
    "        data_features[col] = data_features[col].apply(np.log1p)\n",
    "\n",
    "    # Create a complementary field of attack & Transform to One hot encoding - LABELS\n",
    "    normal=data_labels['label']\n",
    "    normal=normal.replace(1,2)\n",
    "    normal=normal.replace(0,1)\n",
    "    normal=normal.replace(2,0)\n",
    "\n",
    "    # Insert the new column in data labels\n",
    "    data_labels.insert(1, 'normal', normal)\n",
    "    data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "    data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "    # Transform to One hot encoding - FEATURES\n",
    "    data_features=pd.get_dummies(data_features)\n",
    "\n",
    "    # Value given for the missing columns\n",
    "    auxCol=0\n",
    "\n",
    "    # As we are using different datasets that might not have all representations, we are going to detect and add the missing columns \n",
    "    # The columns that can have types are: proto and state: need to check if all representations are done \n",
    "    state_cols = [col for col in data_features if col.startswith('state_')]\n",
    "    proto_cols = [col for col in data_features if col.startswith('proto_')]\n",
    "    \n",
    "    # Check if all columns are present\n",
    "    if 'state_PAR' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_PAR', auxCol, True)\n",
    "    if 'state_ACC' not in state_cols: \n",
    "        data_features.insert(data_features.shape[1], 'state_ACC', auxCol, True)\n",
    "    if 'state_ECO' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_ECO', auxCol, True)\n",
    "    if 'state_CON' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_CON', auxCol, True)\n",
    "    if 'state_FIN' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_FIN', auxCol, True)\n",
    "    if 'state_INT' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_INT', auxCol, True)\n",
    "    if 'state_REQ' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_REQ', auxCol, True)\n",
    "    if 'state_RST' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_RST', auxCol, True)\n",
    "    if 'proto_igmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_igmp', auxCol, True)\n",
    "    if 'proto_arp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_arp', auxCol, True)\n",
    "    if 'proto_icmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_icmp', auxCol, True)\n",
    "    if 'proto_udp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_udp', auxCol, True)\n",
    "    if 'proto_tcp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_tcp', auxCol, True)\n",
    "\n",
    "    # Normalize all data features\n",
    "    data_features = StandardScaler().fit_transform(data_features)\n",
    "\n",
    "    #Add dimension to data features\n",
    "    data_features = np.expand_dims(data_features, axis=2)\n",
    "    data_features = np.expand_dims(data_features, axis=3)\n",
    "\n",
    "    x = data_features\n",
    "    y = data_labels.to_numpy()\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building and definition\n",
    "def build_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(filters=32,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(1, 2), padding='same'))\n",
    "    model.add(layers.Conv2D(filters=64,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(1, 2), padding='same'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(Dense(444, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns values of loss, accuracy, f1, precision and recall of model evaluating with test dataset \n",
    "def evaluation(model, x, y): \n",
    "    loss, accuracy = model.evaluate(x, y)\n",
    "    y_pred = model.predict(x)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y = np.argmax(y, axis=1)\n",
    "    report = classification_report(y, y_pred, target_names=['normal', 'attack'], output_dict=True)\n",
    "    # Obtain f1, precision and recall from the report\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    return loss, accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_13668/3457440085.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_13668/3457440085.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_complete = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Complete.csv')\n"
     ]
    }
   ],
   "source": [
    "test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n",
    "test_plus = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test+.csv')\n",
    "test_complete = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)\n",
    "xcomplete, ycomplete = preprocessing(test_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments with datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Filt5A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part1.csv', low_memory=False)\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part2.csv', low_memory=False)\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part3.csv', low_memory=False)\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part4.csv', low_memory=False)\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part5.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idTRIM00.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(grad_list, trim_num = 1):\n",
    "    # Calculate 20% trimmed mean -> stay with 3 closer nodes \n",
    "    # Initialize the list to store trimmed mean gradients\n",
    "    trim_mean_grad = []\n",
    "    \n",
    "    # Iterate over the gradients coordinate-wise\n",
    "    for layer_grads in zip(*grad_list):\n",
    "        # Stack gradients for the current layer to shape (num_nodes, ...)\n",
    "        stacked_grads = tf.stack(layer_grads, axis=0)\n",
    "\n",
    "        # Sort the gradients along the node axis\n",
    "        sorted_grads = tf.sort(stacked_grads, axis=0)\n",
    "\n",
    "        # Trim the top and bottom trim_count gradients\n",
    "        trimmed_grads = sorted_grads[trim_num:num_nodes - trim_num - 1]\n",
    "\n",
    "        # Calculate the mean of the remaining gradients\n",
    "        trimmed_mean = tf.reduce_mean(trimmed_grads, axis=0)\n",
    "\n",
    "        # Append the trimmed mean gradient for the current layer\n",
    "        trim_mean_grad.append(trimmed_mean)\n",
    "    \n",
    "    \n",
    "    return trim_mean_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.3738 - accuracy: 0.9486 - val_loss: 1.8827 - val_accuracy: 0.6190\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 143ms/step - loss: 0.0614 - accuracy: 0.9916 - val_loss: 0.9174 - val_accuracy: 0.6200\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 0.0285 - accuracy: 0.9922 - val_loss: 0.6653 - val_accuracy: 0.6306\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 145ms/step - loss: 0.0258 - accuracy: 0.9923 - val_loss: 0.5180 - val_accuracy: 0.6771\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 0.0246 - accuracy: 0.9919 - val_loss: 0.5999 - val_accuracy: 0.6361\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 0.0359 - accuracy: 0.9903 - val_loss: 0.5119 - val_accuracy: 0.7176\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 145ms/step - loss: 0.0243 - accuracy: 0.9916 - val_loss: 0.3888 - val_accuracy: 0.7582\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 136ms/step - loss: 0.0220 - accuracy: 0.9924 - val_loss: 0.4518 - val_accuracy: 0.6929\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 0.0205 - accuracy: 0.9931 - val_loss: 0.3852 - val_accuracy: 0.7332\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.0197 - accuracy: 0.9935 - val_loss: 0.4642 - val_accuracy: 0.6991\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.0185 - accuracy: 0.9940 - val_loss: 0.4649 - val_accuracy: 0.7296\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 0.5868 - val_accuracy: 0.7033\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 0.3384 - val_accuracy: 0.8076\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.3509 - val_accuracy: 0.8103\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0149 - accuracy: 0.9952 - val_loss: 0.4017 - val_accuracy: 0.8035\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.0155 - accuracy: 0.9954 - val_loss: 0.6086 - val_accuracy: 0.7497\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 144ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 0.6298 - val_accuracy: 0.7443\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.0149 - accuracy: 0.9955 - val_loss: 0.3639 - val_accuracy: 0.8297\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.5911 - val_accuracy: 0.7623\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 0.4667 - val_accuracy: 0.8029\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 145ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.3125 - val_accuracy: 0.8431\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 138ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 0.2980 - val_accuracy: 0.8478\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 0.4488 - val_accuracy: 0.8068\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.4268 - val_accuracy: 0.8165\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.4760 - val_accuracy: 0.8014\n",
      "4279/4279 [==============================] - 30s 7ms/step - loss: 0.0597 - accuracy: 0.9705\n",
      "1721/1721 [==============================] - 11s 7ms/step - loss: 0.2916 - accuracy: 0.8746\n",
      "4481/4481 [==============================] - 23s 5ms/step - loss: 0.1020 - accuracy: 0.9497\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.0149 - accuracy: 0.9955 - val_loss: 0.3640 - val_accuracy: 0.8331\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 146ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.4934 - val_accuracy: 0.7913\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 0.4966 - val_accuracy: 0.7924\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 145ms/step - loss: 0.0135 - accuracy: 0.9962 - val_loss: 0.3742 - val_accuracy: 0.8328\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.3482 - val_accuracy: 0.8354\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0148 - accuracy: 0.9955 - val_loss: 0.4077 - val_accuracy: 0.8257\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 143ms/step - loss: 0.0139 - accuracy: 0.9959 - val_loss: 0.3888 - val_accuracy: 0.8413\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 144ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.5222 - val_accuracy: 0.8010\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 151ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.6722 - val_accuracy: 0.7648\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 145ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.4173 - val_accuracy: 0.8432\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 146ms/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.6158 - val_accuracy: 0.7875\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.4628 - val_accuracy: 0.8224\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 0.4696 - val_accuracy: 0.8204\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 160ms/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 0.4220 - val_accuracy: 0.8399\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0119 - accuracy: 0.9966 - val_loss: 0.4819 - val_accuracy: 0.8201\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.5179 - val_accuracy: 0.8096\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.4622 - val_accuracy: 0.8255\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.5054 - val_accuracy: 0.8170\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.3302 - val_accuracy: 0.8584\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.4763 - val_accuracy: 0.8270\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.5187 - val_accuracy: 0.8228\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.4730 - val_accuracy: 0.8254\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.5176 - val_accuracy: 0.8115\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 0.6037 - val_accuracy: 0.7840\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.4654 - val_accuracy: 0.8299\n",
      "4279/4279 [==============================] - 19s 4ms/step - loss: 0.0642 - accuracy: 0.9716\n",
      "1721/1721 [==============================] - 8s 5ms/step - loss: 0.4418 - accuracy: 0.7973: 0s -\n",
      "4481/4481 [==============================] - 21s 5ms/step - loss: 0.1105 - accuracy: 0.9526\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 146ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.5136 - val_accuracy: 0.7977\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.4431 - val_accuracy: 0.8269\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.6217 - val_accuracy: 0.7738\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 145ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.5828 - val_accuracy: 0.7852\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.0103 - accuracy: 0.9971 - val_loss: 0.5152 - val_accuracy: 0.7996\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.6405 - val_accuracy: 0.7799\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.4457 - val_accuracy: 0.8330\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 144ms/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.5445 - val_accuracy: 0.8109\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.7140 - val_accuracy: 0.7612\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.4194 - val_accuracy: 0.8449\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0101 - accuracy: 0.9964 - val_loss: 0.4708 - val_accuracy: 0.8275\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.4509 - val_accuracy: 0.8366\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.5514 - val_accuracy: 0.8083\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.6004 - val_accuracy: 0.8026\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.6963 - val_accuracy: 0.7704\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.4141 - val_accuracy: 0.8430\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 0.4397 - val_accuracy: 0.8417\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.4267 - val_accuracy: 0.8416\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 0.7727 - val_accuracy: 0.7579\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.7371 - val_accuracy: 0.7686\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 0.5275 - val_accuracy: 0.8244\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.0080 - accuracy: 0.9969 - val_loss: 0.4085 - val_accuracy: 0.8502\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 0.7977 - val_accuracy: 0.7559\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 170ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 0.8036 - val_accuracy: 0.7550\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 164ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.6763 - val_accuracy: 0.7856\n",
      "4279/4279 [==============================] - 17s 4ms/step - loss: 0.0873 - accuracy: 0.9693\n",
      "1721/1721 [==============================] - 8s 5ms/step - loss: 0.8354 - accuracy: 0.7067\n",
      "4481/4481 [==============================] - 18s 4ms/step - loss: 0.1651 - accuracy: 0.9406\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "    loss_complete, accuracy_complete, f1_complete, precision_complete, recall_complete = evaluation(global_model, xcomplete, ycomplete)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus, loss_complete])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus, accuracy_complete])\n",
    "    f1_it.append([f1_basic, f1_plus, f1_complete])\n",
    "    precision_it.append([precision_basic, precision_plus, precision_complete])\n",
    "    recall_it.append([recall_basic, recall_plus, recall_complete])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idTRIM00.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.05969271808862686, 0.2915704548358917, 0.10198070853948593], [0.0642365962266922, 0.44180890917778015, 0.11046914011240005], [0.08726736158132553, 0.8354020714759827, 0.16511306166648865]]\n",
      "Accuracy for iterations:  [[0.9705220460891724, 0.8745912909507751, 0.949661374092102], [0.9715957045555115, 0.7973188757896423, 0.9526257514953613], [0.9692877531051636, 0.7067499756813049, 0.9406426548957825]]\n",
      "F1 for iterations:  [[0.9704706645269148, 0.87120098130225, 0.9495707437412798], [0.9715515317688745, 0.7844534669481538, 0.9525535472630936], [0.9692174919876617, 0.665614374572885, 0.9404631622826496]]\n",
      "Precision for iterations:  [[0.9713528792582724, 0.891441222803041, 0.9529162992637652], [0.9722875720346605, 0.8399235549397693, 0.9553969578710816], [0.9705653078566339, 0.7984771010769703, 0.9460213145679357]]\n",
      "Recall for iterations:  [[0.9705220719273131, 0.8745912955024341, 0.94966136333517], [0.9715957229250051, 0.7973188984959675, 0.9526257419665339], [0.9692877384673815, 0.7067499818353556, 0.9406426772872797]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Filt5B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part1.csv', low_memory=False)\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part2.csv', low_memory=False)\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part3.csv', low_memory=False)\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part4.csv', low_memory=False)\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part5.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idTRIM01.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.3730 - accuracy: 0.9730 - val_loss: 2.0605 - val_accuracy: 0.5516\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0603 - accuracy: 0.9916 - val_loss: 1.2512 - val_accuracy: 0.5526\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 173ms/step - loss: 0.0308 - accuracy: 0.9920 - val_loss: 0.8967 - val_accuracy: 0.5590\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 173ms/step - loss: 0.0273 - accuracy: 0.9922 - val_loss: 0.9090 - val_accuracy: 0.5605\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.0260 - accuracy: 0.9921 - val_loss: 0.7492 - val_accuracy: 0.5793\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.0436 - accuracy: 0.9898 - val_loss: 0.4700 - val_accuracy: 0.7766\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 135ms/step - loss: 0.0270 - accuracy: 0.9908 - val_loss: 0.4411 - val_accuracy: 0.7336\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 138ms/step - loss: 0.0248 - accuracy: 0.9916 - val_loss: 0.4964 - val_accuracy: 0.6676\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 145ms/step - loss: 0.0230 - accuracy: 0.9921 - val_loss: 0.5413 - val_accuracy: 0.6507\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.0215 - accuracy: 0.9929 - val_loss: 0.3726 - val_accuracy: 0.7429\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 4.9838 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 2.4490e-07 - accuracy: 1.0000 - val_loss: 5.4001 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 1.6390e-07 - accuracy: 1.0000 - val_loss: 5.4223 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 1.6043e-07 - accuracy: 1.0000 - val_loss: 5.4245 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 1.5982e-07 - accuracy: 1.0000 - val_loss: 5.4259 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 150ms/step - loss: 4.1747 - accuracy: 0.4675 - val_loss: 0.0243 - val_accuracy: 0.9976\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 143ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 145ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 151ms/step - loss: 7.5503e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 1.3044 - accuracy: 0.7221 - val_loss: 1.0712 - val_accuracy: 0.6351\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.0401 - accuracy: 0.9938 - val_loss: 0.8607 - val_accuracy: 0.6367\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 0.0254 - accuracy: 0.9937 - val_loss: 0.8197 - val_accuracy: 0.6367\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 0.0235 - accuracy: 0.9942 - val_loss: 0.7971 - val_accuracy: 0.6367\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 177ms/step - loss: 0.0223 - accuracy: 0.9942 - val_loss: 0.7770 - val_accuracy: 0.6368\n",
      "4279/4279 [==============================] - 17s 4ms/step - loss: 0.1505 - accuracy: 0.9238\n",
      "1721/1721 [==============================] - 10s 6ms/step - loss: 0.2707 - accuracy: 0.8405\n",
      "4481/4481 [==============================] - 32s 7ms/step - loss: 0.2123 - accuracy: 0.8909\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 150ms/step - loss: 0.0238 - accuracy: 0.9921 - val_loss: 0.3930 - val_accuracy: 0.7739\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 144ms/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 0.5089 - val_accuracy: 0.6539\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 151ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.3977 - val_accuracy: 0.7486\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 145ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.4709 - val_accuracy: 0.7145\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 0.3911 - val_accuracy: 0.7798\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 0.3300 - val_accuracy: 0.8171\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.3871 - val_accuracy: 0.8088\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 0.0162 - accuracy: 0.9951 - val_loss: 0.4288 - val_accuracy: 0.8037\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 146ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 0.3792 - val_accuracy: 0.8239\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 0.5173 - val_accuracy: 0.7882\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 157ms/step - loss: 0.0118 - accuracy: 0.9955 - val_loss: 5.4380 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 8.8910e-08 - accuracy: 1.0000 - val_loss: 5.7960 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 185ms/step - loss: 6.2700e-08 - accuracy: 1.0000 - val_loss: 5.8144 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 191ms/step - loss: 6.1819e-08 - accuracy: 1.0000 - val_loss: 5.8156 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 179ms/step - loss: 6.1728e-08 - accuracy: 1.0000 - val_loss: 5.8160 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 7.2155 - accuracy: 0.3633 - val_loss: 0.2223 - val_accuracy: 0.8979\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 184ms/step - loss: 0.0267 - accuracy: 0.9890 - val_loss: 0.0106 - val_accuracy: 0.9956\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 179ms/step - loss: 8.8514e-04 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9964\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 185ms/step - loss: 6.4786e-04 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9973\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 181ms/step - loss: 4.9874e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 0.9978\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 216ms/step - loss: 1.6056 - accuracy: 0.7596 - val_loss: 0.7177 - val_accuracy: 0.6931\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 193ms/step - loss: 0.0191 - accuracy: 0.9950 - val_loss: 0.9001 - val_accuracy: 0.6758\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 211ms/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 0.6871 - val_accuracy: 0.6959\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 205ms/step - loss: 0.0156 - accuracy: 0.9945 - val_loss: 0.6456 - val_accuracy: 0.7007\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 212ms/step - loss: 0.0153 - accuracy: 0.9946 - val_loss: 0.6063 - val_accuracy: 0.7052\n",
      "4279/4279 [==============================] - 23s 5ms/step - loss: 0.0986 - accuracy: 0.9458\n",
      "1721/1721 [==============================] - 9s 5ms/step - loss: 0.2691 - accuracy: 0.8736\n",
      "4481/4481 [==============================] - 20s 5ms/step - loss: 0.1611 - accuracy: 0.9125\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.5380 - val_accuracy: 0.7195\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.2923 - val_accuracy: 0.8558\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.3500 - val_accuracy: 0.8309\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0138 - accuracy: 0.9961 - val_loss: 0.4579 - val_accuracy: 0.7819\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 151ms/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 0.3518 - val_accuracy: 0.8339\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 156ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 0.4517 - val_accuracy: 0.8306\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 145ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.4491 - val_accuracy: 0.8292\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.4040 - val_accuracy: 0.8377\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.6145 - val_accuracy: 0.7961\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 146ms/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.5710 - val_accuracy: 0.8067\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 207ms/step - loss: 0.0224 - accuracy: 0.9913 - val_loss: 4.8172 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 5.2304e-07 - accuracy: 1.0000 - val_loss: 5.1547 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 188ms/step - loss: 3.9883e-07 - accuracy: 1.0000 - val_loss: 5.1732 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 202ms/step - loss: 3.9212e-07 - accuracy: 1.0000 - val_loss: 5.1753 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 201ms/step - loss: 3.9044e-07 - accuracy: 1.0000 - val_loss: 5.1770 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 193ms/step - loss: 7.8923 - accuracy: 0.3590 - val_loss: 0.5009 - val_accuracy: 0.8457\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 184ms/step - loss: 0.0569 - accuracy: 0.9746 - val_loss: 0.0017 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 188ms/step - loss: 2.3538e-04 - accuracy: 1.0000 - val_loss: 9.4631e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 181ms/step - loss: 1.9416e-04 - accuracy: 1.0000 - val_loss: 8.7023e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 186ms/step - loss: 1.8267e-04 - accuracy: 1.0000 - val_loss: 8.1612e-04 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 177ms/step - loss: 1.0120 - accuracy: 0.8175 - val_loss: 0.4648 - val_accuracy: 0.7242\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 166ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.6895 - val_accuracy: 0.6931\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 158ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 0.6060 - val_accuracy: 0.7005\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0162 - accuracy: 0.9944 - val_loss: 0.5880 - val_accuracy: 0.7032\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.0158 - accuracy: 0.9945 - val_loss: 0.5769 - val_accuracy: 0.7052\n",
      "4279/4279 [==============================] - 23s 5ms/step - loss: 0.0937 - accuracy: 0.9483\n",
      "1721/1721 [==============================] - 8s 5ms/step - loss: 0.2608 - accuracy: 0.8756\n",
      "4481/4481 [==============================] - 21s 5ms/step - loss: 0.1555 - accuracy: 0.9159\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "    loss_complete, accuracy_complete, f1_complete, precision_complete, recall_complete = evaluation(global_model, xcomplete, ycomplete)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus, loss_complete])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus, accuracy_complete])\n",
    "    f1_it.append([f1_basic, f1_plus, f1_complete])\n",
    "    precision_it.append([precision_basic, precision_plus, precision_complete])\n",
    "    recall_it.append([recall_basic, recall_plus, recall_complete])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idTRIM01.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.15048830211162567, 0.2706582546234131, 0.21234183013439178], [0.09855924546718597, 0.26912254095077515, 0.16108646988868713], [0.0936637818813324, 0.26076558232307434, 0.15550008416175842]]\n",
      "Accuracy for iterations:  [[0.9237561821937561, 0.8405326008796692, 0.8908969163894653], [0.9457988739013672, 0.873628556728363, 0.9125264286994934], [0.9482675790786743, 0.8755903244018555, 0.9159371852874756]]\n",
      "F1 for iterations:  [[0.9230244383092906, 0.8338628034326047, 0.8896706967528193], [0.9455059969541966, 0.8701993090109613, 0.9119231312271288], [0.9480098734652984, 0.8722869313316397, 0.9154071673070557]]\n",
      "Precision for iterations:  [[0.9323879080506825, 0.8684777420618092, 0.9090820362827001], [0.9500075225645492, 0.8904957134324715, 0.9241461941426544], [0.9520472639387606, 0.892055665080549, 0.9266286148727427]]\n",
      "Recall for iterations:  [[0.9237561716672996, 0.8405325873719393, 0.8908969163487225], [0.9457988839872623, 0.8736285693526121, 0.9125264178448619], [0.9482675509071256, 0.8755903509409286, 0.9159371970230663]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Filt5C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part1.csv', low_memory=False)\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part2.csv', low_memory=False)\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part3.csv', low_memory=False)\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part4.csv', low_memory=False)\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part5.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idTRIM02.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 5s 299ms/step - loss: 0.5356 - accuracy: 0.7194 - val_loss: 1.6739 - val_accuracy: 0.0046\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.1969 - accuracy: 0.9703 - val_loss: 3.8471 - val_accuracy: 0.1261\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 4s 243ms/step - loss: 0.0848 - accuracy: 0.9892 - val_loss: 4.0223 - val_accuracy: 0.1337\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 4s 232ms/step - loss: 0.0497 - accuracy: 0.9897 - val_loss: 1.9199 - val_accuracy: 0.1342\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 206ms/step - loss: 0.0353 - accuracy: 0.9899 - val_loss: 1.3465 - val_accuracy: 0.1821\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 5s 323ms/step - loss: 0.0212 - accuracy: 0.9950 - val_loss: 0.8122 - val_accuracy: 0.7270\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 209ms/step - loss: 0.0194 - accuracy: 0.9950 - val_loss: 0.5937 - val_accuracy: 0.7288\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 234ms/step - loss: 0.0187 - accuracy: 0.9950 - val_loss: 0.6852 - val_accuracy: 0.7277\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 4s 299ms/step - loss: 0.0184 - accuracy: 0.9950 - val_loss: 0.4560 - val_accuracy: 0.7469\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 182ms/step - loss: 0.0177 - accuracy: 0.9951 - val_loss: 0.5589 - val_accuracy: 0.7310\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 8s 315ms/step - loss: 0.0137 - accuracy: 0.9965 - val_loss: 2.2670 - val_accuracy: 0.4419\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 6s 228ms/step - loss: 0.0129 - accuracy: 0.9968 - val_loss: 2.0524 - val_accuracy: 0.4398\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 8s 315ms/step - loss: 0.0129 - accuracy: 0.9967 - val_loss: 2.5821 - val_accuracy: 0.4353\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 209ms/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 1.7411 - val_accuracy: 0.4413\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 10s 400ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 2.1253 - val_accuracy: 0.4374\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 12s 461ms/step - loss: 2.1506 - accuracy: 0.5854 - val_loss: 0.0551 - val_accuracy: 0.9822\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 9s 341ms/step - loss: 0.0066 - accuracy: 0.9997 - val_loss: 0.0105 - val_accuracy: 0.9956\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 9s 329ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0064 - val_accuracy: 0.9976\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 9s 325ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9983\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 8s 312ms/step - loss: 5.6783e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9997\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 29s 413ms/step - loss: 0.5260 - accuracy: 0.8892 - val_loss: 0.3575 - val_accuracy: 0.8275\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 30s 424ms/step - loss: 0.0237 - accuracy: 0.9926 - val_loss: 0.2832 - val_accuracy: 0.8302\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 28s 401ms/step - loss: 0.0217 - accuracy: 0.9930 - val_loss: 0.2370 - val_accuracy: 0.8491\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 28s 403ms/step - loss: 0.0203 - accuracy: 0.9934 - val_loss: 0.2115 - val_accuracy: 0.8688\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 28s 400ms/step - loss: 0.0193 - accuracy: 0.9938 - val_loss: 0.2280 - val_accuracy: 0.8608\n",
      "4279/4279 [==============================] - 43s 10ms/step - loss: 0.0766 - accuracy: 0.98710s - loss: 0.0767 - \n",
      "1721/1721 [==============================] - 17s 10ms/step - loss: 0.1648 - accuracy: 0.9489\n",
      "4481/4481 [==============================] - 42s 9ms/step - loss: 0.0869 - accuracy: 0.9806\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 10s 608ms/step - loss: 0.0245 - accuracy: 0.9915 - val_loss: 0.9366 - val_accuracy: 0.4355\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 6s 401ms/step - loss: 0.0219 - accuracy: 0.9924 - val_loss: 0.9036 - val_accuracy: 0.4902\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 6s 406ms/step - loss: 0.0207 - accuracy: 0.9929 - val_loss: 1.1591 - val_accuracy: 0.3785\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 7s 414ms/step - loss: 0.0199 - accuracy: 0.9932 - val_loss: 1.0243 - val_accuracy: 0.4589\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 6s 389ms/step - loss: 0.0193 - accuracy: 0.9935 - val_loss: 1.1647 - val_accuracy: 0.4367\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 6s 403ms/step - loss: 0.0146 - accuracy: 0.9959 - val_loss: 0.6591 - val_accuracy: 0.7423\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 5s 359ms/step - loss: 0.0139 - accuracy: 0.9966 - val_loss: 0.7480 - val_accuracy: 0.7402\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 6s 447ms/step - loss: 0.0133 - accuracy: 0.9967 - val_loss: 0.6757 - val_accuracy: 0.7458\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 5s 373ms/step - loss: 0.0131 - accuracy: 0.9967 - val_loss: 0.8181 - val_accuracy: 0.7407\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 5s 333ms/step - loss: 0.0129 - accuracy: 0.9966 - val_loss: 0.7332 - val_accuracy: 0.7466\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 362ms/step - loss: 0.0109 - accuracy: 0.9974 - val_loss: 1.5384 - val_accuracy: 0.5453\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 10s 371ms/step - loss: 0.0107 - accuracy: 0.9974 - val_loss: 1.6162 - val_accuracy: 0.5459\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 11s 411ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 1.8242 - val_accuracy: 0.5279\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 10s 380ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 1.5433 - val_accuracy: 0.5689\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 9s 364ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 1.3708 - val_accuracy: 0.5981\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 10s 365ms/step - loss: 4.3508 - accuracy: 0.4415 - val_loss: 0.3982 - val_accuracy: 0.9134\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 11s 418ms/step - loss: 0.1328 - accuracy: 0.9501 - val_loss: 0.0351 - val_accuracy: 0.9888\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 8s 307ms/step - loss: 0.0034 - accuracy: 0.9999 - val_loss: 0.0213 - val_accuracy: 0.9923\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 13s 470ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0176 - val_accuracy: 0.9933\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 9s 335ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0145 - val_accuracy: 0.9939\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 26s 374ms/step - loss: 0.7124 - accuracy: 0.8906 - val_loss: 0.3152 - val_accuracy: 0.8621\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 29s 411ms/step - loss: 0.0186 - accuracy: 0.9947 - val_loss: 0.2028 - val_accuracy: 0.9043\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 28s 400ms/step - loss: 0.0172 - accuracy: 0.9947 - val_loss: 0.1887 - val_accuracy: 0.9050\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 26s 366ms/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.1788 - val_accuracy: 0.9052\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 28s 393ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.1598 - val_accuracy: 0.9141\n",
      "4279/4279 [==============================] - 41s 10ms/step - loss: 0.0537 - accuracy: 0.9898\n",
      "1721/1721 [==============================] - 18s 10ms/step - loss: 0.1096 - accuracy: 0.9653\n",
      "4481/4481 [==============================] - 50s 11ms/step - loss: 0.0540 - accuracy: 0.9888\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 9s 554ms/step - loss: 0.0203 - accuracy: 0.9933 - val_loss: 0.6972 - val_accuracy: 0.6360\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 5s 326ms/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 0.8743 - val_accuracy: 0.5732\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 5s 339ms/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 0.9807 - val_accuracy: 0.5508\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 5s 340ms/step - loss: 0.0176 - accuracy: 0.9946 - val_loss: 0.8802 - val_accuracy: 0.5996\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 6s 348ms/step - loss: 0.0175 - accuracy: 0.9944 - val_loss: 0.8388 - val_accuracy: 0.6172\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 6s 456ms/step - loss: 0.0146 - accuracy: 0.9962 - val_loss: 0.8279 - val_accuracy: 0.7405\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 5s 385ms/step - loss: 0.0133 - accuracy: 0.9968 - val_loss: 0.6842 - val_accuracy: 0.7567\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 5s 374ms/step - loss: 0.0129 - accuracy: 0.9968 - val_loss: 0.7528 - val_accuracy: 0.7564\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 6s 411ms/step - loss: 0.0124 - accuracy: 0.9971 - val_loss: 0.7559 - val_accuracy: 0.7568\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 6s 447ms/step - loss: 0.0120 - accuracy: 0.9972 - val_loss: 0.8478 - val_accuracy: 0.7534\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 12s 458ms/step - loss: 0.0112 - accuracy: 0.9974 - val_loss: 1.7139 - val_accuracy: 0.5260\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 9s 347ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 1.5573 - val_accuracy: 0.5436\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 11s 433ms/step - loss: 0.0099 - accuracy: 0.9975 - val_loss: 1.5579 - val_accuracy: 0.5618\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 10s 384ms/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 1.3025 - val_accuracy: 0.6259\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 10s 368ms/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 1.6388 - val_accuracy: 0.5787\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 13s 493ms/step - loss: 3.7349 - accuracy: 0.5455 - val_loss: 0.1870 - val_accuracy: 0.9250\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 9s 350ms/step - loss: 0.0239 - accuracy: 0.9897 - val_loss: 0.0097 - val_accuracy: 0.9957\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 12s 449ms/step - loss: 3.9611e-04 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 0.9967\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 12s 437ms/step - loss: 3.0127e-04 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9969\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 8s 303ms/step - loss: 2.7111e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9971\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 27s 386ms/step - loss: 0.6969 - accuracy: 0.9016 - val_loss: 0.2358 - val_accuracy: 0.8987\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 26s 375ms/step - loss: 0.0158 - accuracy: 0.9952 - val_loss: 0.1662 - val_accuracy: 0.9246\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 22s 313ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.1424 - val_accuracy: 0.9320\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 25s 364ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.1436 - val_accuracy: 0.9323\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 26s 364ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.1345 - val_accuracy: 0.9361\n",
      "4279/4279 [==============================] - 38s 9ms/step - loss: 0.0543 - accuracy: 0.9893\n",
      "1721/1721 [==============================] - 15s 9ms/step - loss: 0.1002 - accuracy: 0.9703\n",
      "4481/4481 [==============================] - ETA: 0s - loss: 0.0532 - accuracy: 0.98 - 34s 8ms/step - loss: 0.0532 - accuracy: 0.9893\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "    loss_complete, accuracy_complete, f1_complete, precision_complete, recall_complete = evaluation(global_model, xcomplete, ycomplete)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus, loss_complete])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus, accuracy_complete])\n",
    "    f1_it.append([f1_basic, f1_plus, f1_complete])\n",
    "    precision_it.append([precision_basic, precision_plus, precision_complete])\n",
    "    recall_it.append([recall_basic, recall_plus, recall_complete])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idTRIM02.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.0766071006655693, 0.16483476758003235, 0.08687343448400497], [0.053682878613471985, 0.10956870019435883, 0.05403756722807884], [0.054337188601493835, 0.10015823692083359, 0.053241025656461716]]\n",
      "Accuracy for iterations:  [[0.9870796799659729, 0.9489210247993469, 0.980602502822876], [0.9897966384887695, 0.965305507183075, 0.9888120889663696], [0.989270806312561, 0.9703007936477661, 0.9893072843551636]]\n",
      "F1 for iterations:  [[0.9870834330414608, 0.948781287812263, 0.9806023765439287], [0.9898013014297357, 0.9652704131472895, 0.9888115468563127], [0.9892761308924688, 0.9702999397527143, 0.9893065571211679]]\n",
      "Precision for iterations:  [[0.9871489563081493, 0.949348360841073, 0.980614824786568], [0.9899816536128866, 0.9653518580824769, 0.9889064703963136], [0.9895021323314124, 0.9702991827410952, 0.9894456149808546]]\n",
      "Recall for iterations:  [[0.9870796692862778, 0.9489210201264259, 0.980602501238064], [0.9897966636477841, 0.9653055293177359, 0.9888120862948057], [0.9892707937713635, 0.9703008065102086, 0.989307311901457]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
