{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Federated Learning for attack detection: 5 nodes sharing weights**\n",
    "\n",
    "IDs from this file = **id10xy** (x = 0 if experiment with dataset, x = 1 if epochs & iterations, y being integer equal or greater than 0)\n",
    "\n",
    "In this file, experiments with different datasets, and number of epochs & iterations are done. The experiments are divided into sections, based on the elements being changed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static elements for all experiments (execute first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Disable warns\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data): \n",
    "\n",
    "    # Select the 'proto' and 'state' values that I want\n",
    "    data = data.loc[(data['proto'] == 'tcp') | (data['proto'] =='udp') | (data['proto'] =='icmp') | (data['proto'] =='arp') | (data['proto'] =='ipv6-icmp') | (data['proto'] =='igmp') | (data['proto'] =='rarp'), :]\n",
    "    data = data.loc[(data['state'] == 'RST') | (data['state'] =='REQ') | (data['state'] =='INT') | (data['state'] =='FIN') | (data['state'] =='CON') | (data['state'] =='ECO') | (data['state'] =='ACC') | (data['state'] == 'PAR'), :]\n",
    "\n",
    "    # Extracting labels \n",
    "    data_labels = pd.DataFrame()\n",
    "\n",
    "    # Drop the invalid features and select interested data features\n",
    "    data_features=data[['proto','srcip','sport','dstip','dsport','spkts','dpkts','sbytes','dbytes','state','stime','ltime','dur']]\n",
    "\n",
    "    \"\"\"PREPROCESSING\"\"\"\n",
    "\n",
    "\n",
    "    # Preprocess IP and ports features\n",
    "    # IP Source Address\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "\n",
    "    # IP Destination Address\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "    # Ports\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "\n",
    "    # Convert all ports with 0 decimal, and HEX to DEC\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    # Convert field to int format\n",
    "    data_features['srcip'] = data_features['srcip'].astype(int)\n",
    "    data_features['sport'] = data_features['sport'].astype(int)\n",
    "    data_features['dstip'] = data_features['dstip'].astype(int)\n",
    "    data_features['dsport'] = data_features['dsport'].astype(int)\n",
    "\n",
    "    # Convert some fields to logarithmic\n",
    "    log1p_col = ['dur', 'sbytes', 'dbytes', 'spkts']\n",
    "\n",
    "    for col in log1p_col:\n",
    "        data_features[col] = data_features[col].apply(np.log1p)\n",
    "\n",
    "    # Transform to One Hot Encoding the Categories - normal, attack\n",
    "    data_labels.insert(0, 'normal', data['attack_cat'].replace('normal', 1).replace(['dos', 'reconnaissance', 'generic', 'exploits', 'worms', 'fuzzers', 'analysis', 'backdoor', 'shellcode'], 0))\n",
    "    data_labels.insert(1, 'attack', data['attack_cat'].replace(['dos', 'reconnaissance', 'generic', 'exploits', 'worms', 'fuzzers', 'analysis', 'backdoor', 'shellcode'], 1).replace('normal', 0))\n",
    "\n",
    "    data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "    # Transform to One hot encoding - FEATURES\n",
    "    data_features=pd.get_dummies(data_features)\n",
    "\n",
    "    # Value given for the missing columns\n",
    "    auxCol=0\n",
    "\n",
    "    # As we are using different datasets that might not have all representations, we are going to detect and add the missing columns \n",
    "    # The columns that can have types are: proto and state: need to check if all representations are done \n",
    "    state_cols = [col for col in data_features if col.startswith('state_')]\n",
    "    proto_cols = [col for col in data_features if col.startswith('proto_')]\n",
    "    \n",
    "    # Check if all columns are present\n",
    "    if 'state_PAR' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_PAR', auxCol, True)\n",
    "    if 'state_ACC' not in state_cols: \n",
    "        data_features.insert(data_features.shape[1], 'state_ACC', auxCol, True)\n",
    "    if 'state_ECO' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_ECO', auxCol, True)\n",
    "    if 'state_CON' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_CON', auxCol, True)\n",
    "    if 'state_FIN' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_FIN', auxCol, True)\n",
    "    if 'state_INT' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_INT', auxCol, True)\n",
    "    if 'state_REQ' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_REQ', auxCol, True)\n",
    "    if 'state_RST' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_RST', auxCol, True)\n",
    "    if 'proto_igmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_igmp', auxCol, True)\n",
    "    if 'proto_arp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_arp', auxCol, True)\n",
    "    if 'proto_icmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_icmp', auxCol, True)\n",
    "    if 'proto_udp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_udp', auxCol, True)\n",
    "    if 'proto_tcp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_tcp', auxCol, True)\n",
    "\n",
    "    # Normalize all data features\n",
    "    data_features = StandardScaler().fit_transform(data_features)\n",
    "\n",
    "    #Add dimension to data features\n",
    "    data_features = np.expand_dims(data_features, axis=2)\n",
    "    data_features = np.expand_dims(data_features, axis=3)\n",
    "\n",
    "    x = data_features\n",
    "    y = data_labels.to_numpy()\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building and definition\n",
    "def build_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(filters=32,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(1, 1), padding='same'))\n",
    "    model.add(layers.Conv2D(filters=64,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(1, 1), padding='same'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(Dense(444, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns values of loss, accuracy, f1, precision and recall of model evaluating with test dataset \n",
    "def evaluation(model, x, y): \n",
    "    loss, accuracy = model.evaluate(x, y)\n",
    "    y_pred = model.predict(x)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y = np.argmax(y, axis=1)\n",
    "    report = classification_report(y, y_pred, target_names=['normal', 'attack'], output_dict=True)\n",
    "    # Obtain f1, precision and recall from the report\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    return loss, accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments with datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 5A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_6960/3207952841.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part1.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_6960/3207952841.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_6960/3207952841.py:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_6960/3207952841.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part4.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_6960/3207952841.py:6: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part5.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_6960/3207952841.py:7: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5A-Part5.csv')\n",
    "test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n",
    "test_plus = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test+.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "node_datasets = [training1, training2, training3, training4, training5]\n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'id1000.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(w_list): \n",
    "    avg_w = np.mean(w_list, axis=0)\n",
    "    return avg_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)\n",
    "\n",
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 214ms/step - loss: 0.3943 - accuracy: 0.9653 - val_loss: 1.7129 - val_accuracy: 0.6194\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 202ms/step - loss: 0.0643 - accuracy: 0.9916 - val_loss: 1.1418 - val_accuracy: 0.6200\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 191ms/step - loss: 0.0306 - accuracy: 0.9922 - val_loss: 0.6976 - val_accuracy: 0.6345\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 191ms/step - loss: 0.0272 - accuracy: 0.9922 - val_loss: 0.7039 - val_accuracy: 0.6326\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 193ms/step - loss: 0.0258 - accuracy: 0.9923 - val_loss: 0.7505 - val_accuracy: 0.6254\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 237ms/step - loss: 0.0444 - accuracy: 0.9902 - val_loss: 0.3993 - val_accuracy: 0.8214\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 191ms/step - loss: 0.0284 - accuracy: 0.9911 - val_loss: 0.6198 - val_accuracy: 0.6391\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 190ms/step - loss: 0.0256 - accuracy: 0.9917 - val_loss: 0.5059 - val_accuracy: 0.6619\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 192ms/step - loss: 0.0236 - accuracy: 0.9922 - val_loss: 0.4197 - val_accuracy: 0.7079\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 223ms/step - loss: 0.0220 - accuracy: 0.9928 - val_loss: 0.4088 - val_accuracy: 0.7140\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 204ms/step - loss: 0.0202 - accuracy: 0.9931 - val_loss: 0.3294 - val_accuracy: 0.7861\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 230ms/step - loss: 0.0182 - accuracy: 0.9938 - val_loss: 0.3749 - val_accuracy: 0.7585\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 213ms/step - loss: 0.0168 - accuracy: 0.9943 - val_loss: 0.3282 - val_accuracy: 0.8011\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 211ms/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 0.3830 - val_accuracy: 0.7919\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 198ms/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 0.3661 - val_accuracy: 0.8079\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 206ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 0.4151 - val_accuracy: 0.8041\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 178ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.2400 - val_accuracy: 0.8645\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 181ms/step - loss: 0.0156 - accuracy: 0.9948 - val_loss: 0.3051 - val_accuracy: 0.8393\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 206ms/step - loss: 0.0150 - accuracy: 0.9955 - val_loss: 0.3519 - val_accuracy: 0.8315\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 191ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.3853 - val_accuracy: 0.8248\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 166ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.4815 - val_accuracy: 0.7907\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.3605 - val_accuracy: 0.8292\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 177ms/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 0.7441 - val_accuracy: 0.7267\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 170ms/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 0.4187 - val_accuracy: 0.8173\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.3742 - val_accuracy: 0.8343\n",
      "  25/4279 [..............................] - ETA: 17s - loss: 0.0713 - accuracy: 0.9638"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.0649 - accuracy: 0.9685\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1920 - accuracy: 0.9093\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.4438 - val_accuracy: 0.7691\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 166ms/step - loss: 0.0157 - accuracy: 0.9952 - val_loss: 0.3325 - val_accuracy: 0.8242\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 166ms/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 0.3442 - val_accuracy: 0.8231\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 0.0145 - accuracy: 0.9955 - val_loss: 0.4058 - val_accuracy: 0.8101\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 0.0144 - accuracy: 0.9956 - val_loss: 0.3537 - val_accuracy: 0.8305\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 164ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.5204 - val_accuracy: 0.7834\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 175ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 0.4144 - val_accuracy: 0.8246\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 0.5264 - val_accuracy: 0.7880\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0144 - accuracy: 0.9956 - val_loss: 0.4533 - val_accuracy: 0.8184\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 0.0144 - accuracy: 0.9956 - val_loss: 0.4348 - val_accuracy: 0.8220\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 0.5455 - val_accuracy: 0.7907\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 164ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.3624 - val_accuracy: 0.8460\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.4009 - val_accuracy: 0.8286\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 175ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.4959 - val_accuracy: 0.8079\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 0.0128 - accuracy: 0.9962 - val_loss: 0.3876 - val_accuracy: 0.8433\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.3174 - val_accuracy: 0.8521\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 164ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.4394 - val_accuracy: 0.8306\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 164ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 0.5244 - val_accuracy: 0.8068\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 166ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.4847 - val_accuracy: 0.8206\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 163ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.5925 - val_accuracy: 0.7886\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 176ms/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 0.3868 - val_accuracy: 0.8440\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.4433 - val_accuracy: 0.8267\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 164ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.5096 - val_accuracy: 0.8063\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 164ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.6341 - val_accuracy: 0.7746\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.5592 - val_accuracy: 0.7968\n",
      "  14/4279 [..............................] - ETA: 16s - loss: 0.1160 - accuracy: 0.9509"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.0982 - accuracy: 0.9629\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.5650 - accuracy: 0.7394\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 177ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.4749 - val_accuracy: 0.8116\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.5764 - val_accuracy: 0.7809\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.4218 - val_accuracy: 0.8215\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 166ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 0.4770 - val_accuracy: 0.8054\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.4961 - val_accuracy: 0.8016\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 175ms/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.4294 - val_accuracy: 0.8367\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 182ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.3870 - val_accuracy: 0.8468\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.5418 - val_accuracy: 0.8114\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.3749 - val_accuracy: 0.8508\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 171ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.4109 - val_accuracy: 0.8435\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 0.3887 - val_accuracy: 0.8469\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 164ms/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 0.4839 - val_accuracy: 0.8198\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.3895 - val_accuracy: 0.8439\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 173ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.6589 - val_accuracy: 0.7855\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 171ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.6042 - val_accuracy: 0.7873\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 176ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.4514 - val_accuracy: 0.8369\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.3403 - val_accuracy: 0.8569\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 177ms/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 0.4439 - val_accuracy: 0.8377\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 169ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 0.5766 - val_accuracy: 0.8079\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 169ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.5354 - val_accuracy: 0.8233\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 181ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.8488 - val_accuracy: 0.7471\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 164ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 0.4834 - val_accuracy: 0.8345\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.3775 - val_accuracy: 0.8517\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 0.0091 - accuracy: 0.9967 - val_loss: 0.5798 - val_accuracy: 0.8010\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.4454 - val_accuracy: 0.8376\n",
      "  33/4279 [..............................] - ETA: 13s - loss: 0.1245 - accuracy: 0.9602"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.1234 - accuracy: 0.9589\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.8705 - accuracy: 0.6733\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    w_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2: \n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else:\n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        w_list.append(local_model.get_weights())\n",
    "\n",
    "    avg_w = aggregate(w_list)\n",
    "    global_model.set_weights(avg_w) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) # Evaluate with test basic to know progress\n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus) # Evaluate with test plus to know progress\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/id1000.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.06492394208908081, 0.19202971458435059], [0.09822872281074524, 0.5650112628936768], [0.12339755147695541, 0.870532751083374]]\n",
      "Accuracy for iterations:  [[0.9684770107269287, 0.9093220829963684], [0.9629261493682861, 0.7393736839294434], [0.9589383006095886, 0.6733088493347168]]\n",
      "F1 for iterations:  [[0.9684224244475296, 0.9079446594003465], [0.962810208743622, 0.7114403379229214], [0.9587823563071344, 0.6161749438257738]]\n",
      "Precision for iterations:  [[0.9692894589894216, 0.9173583051340704], [0.9649416043187354, 0.8103986817351979], [0.9615910415422185, 0.7809228810934163]]\n",
      "Recall for iterations:  [[0.9684770224078997, 0.9093220954733706], [0.9629261737123492, 0.7393736830632857], [0.9589383271494931, 0.6733088716122938]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 5B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_6960/4261673179.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part1.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_6960/4261673179.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_6960/4261673179.py:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_6960/4261673179.py:6: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5B-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "node_datasets = [training1, training2, training3, training4, training5]\n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'id1001.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(w_list): \n",
    "    avg_w = np.mean(w_list, axis=0)\n",
    "    return avg_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)\n",
    "\n",
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.3388 - accuracy: 0.9771 - val_loss: 2.1843 - val_accuracy: 0.5518\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 0.0505 - accuracy: 0.9916 - val_loss: 0.9944 - val_accuracy: 0.5540\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 0.0291 - accuracy: 0.9923 - val_loss: 0.8833 - val_accuracy: 0.5641\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 166ms/step - loss: 0.0272 - accuracy: 0.9922 - val_loss: 0.9497 - val_accuracy: 0.5583\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 0.0260 - accuracy: 0.9924 - val_loss: 0.7349 - val_accuracy: 0.5745\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 0.0424 - accuracy: 0.9903 - val_loss: 0.5374 - val_accuracy: 0.7160\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 190ms/step - loss: 0.0271 - accuracy: 0.9911 - val_loss: 0.6042 - val_accuracy: 0.6419\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 178ms/step - loss: 0.0246 - accuracy: 0.9918 - val_loss: 0.3635 - val_accuracy: 0.7563\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 176ms/step - loss: 0.0224 - accuracy: 0.9925 - val_loss: 0.3663 - val_accuracy: 0.7449\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 176ms/step - loss: 0.0209 - accuracy: 0.9931 - val_loss: 0.4010 - val_accuracy: 0.7167\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 183ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 5.1260 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 184ms/step - loss: 1.7390e-07 - accuracy: 1.0000 - val_loss: 5.5375 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 1.2035e-07 - accuracy: 1.0000 - val_loss: 5.5594 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 1.1783e-07 - accuracy: 1.0000 - val_loss: 5.5616 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 1.1735e-07 - accuracy: 1.0000 - val_loss: 5.5630 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 170ms/step - loss: 4.2374 - accuracy: 0.4861 - val_loss: 0.0222 - val_accuracy: 0.9973\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 170ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 171ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 173ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 187ms/step - loss: 8.9967e-04 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 173ms/step - loss: 1.1896 - accuracy: 0.7356 - val_loss: 1.0429 - val_accuracy: 0.6350\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 0.0345 - accuracy: 0.9939 - val_loss: 0.7831 - val_accuracy: 0.6368\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 173ms/step - loss: 0.0233 - accuracy: 0.9939 - val_loss: 0.7167 - val_accuracy: 0.6368\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 170ms/step - loss: 0.0215 - accuracy: 0.9942 - val_loss: 0.6671 - val_accuracy: 0.6368\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 186ms/step - loss: 0.0204 - accuracy: 0.9942 - val_loss: 0.6182 - val_accuracy: 0.6368\n",
      "  15/4279 [..............................] - ETA: 14s - loss: 0.0860 - accuracy: 0.9458"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.0868 - accuracy: 0.9491\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1647 - accuracy: 0.9489\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 0.0210 - accuracy: 0.9930 - val_loss: 0.4809 - val_accuracy: 0.6696\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 0.0187 - accuracy: 0.9941 - val_loss: 0.6008 - val_accuracy: 0.6298\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 0.0173 - accuracy: 0.9947 - val_loss: 0.3377 - val_accuracy: 0.7944\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 180ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 0.4260 - val_accuracy: 0.7585\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.2794 - val_accuracy: 0.8558\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 172ms/step - loss: 0.0169 - accuracy: 0.9948 - val_loss: 0.4057 - val_accuracy: 0.7968\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 0.0161 - accuracy: 0.9949 - val_loss: 0.3334 - val_accuracy: 0.8284\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 169ms/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 0.2866 - val_accuracy: 0.8462\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 0.5133 - val_accuracy: 0.7927\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 169ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.3274 - val_accuracy: 0.8398\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 182ms/step - loss: 0.0142 - accuracy: 0.9945 - val_loss: 5.9046 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 5.3379e-08 - accuracy: 1.0000 - val_loss: 6.2856 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 3.7851e-08 - accuracy: 1.0000 - val_loss: 6.3051 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 164ms/step - loss: 3.7197e-08 - accuracy: 1.0000 - val_loss: 6.3062 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 173ms/step - loss: 3.7145e-08 - accuracy: 1.0000 - val_loss: 6.3064 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 7.3593 - accuracy: 0.4058 - val_loss: 0.2107 - val_accuracy: 0.9035\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 170ms/step - loss: 0.0249 - accuracy: 0.9870 - val_loss: 0.0083 - val_accuracy: 0.9965\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 181ms/step - loss: 4.2102e-04 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 0.9969\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 170ms/step - loss: 3.3695e-04 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9970\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 172ms/step - loss: 3.0159e-04 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9970\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 181ms/step - loss: 2.2245 - accuracy: 0.7085 - val_loss: 0.9024 - val_accuracy: 0.6599\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 166ms/step - loss: 0.0243 - accuracy: 0.9947 - val_loss: 0.9866 - val_accuracy: 0.6497\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.7444 - val_accuracy: 0.6726\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 182ms/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 0.6605 - val_accuracy: 0.6840\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 170ms/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 0.6363 - val_accuracy: 0.6878\n",
      "  14/4279 [..............................] - ETA: 16s - loss: 0.0386 - accuracy: 0.9933"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.0352 - accuracy: 0.9909\n",
      "1721/1721 [==============================] - 6s 4ms/step - loss: 0.0971 - accuracy: 0.9765\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 196ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.5332 - val_accuracy: 0.7211\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 187ms/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 0.4215 - val_accuracy: 0.7797\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 187ms/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.3998 - val_accuracy: 0.7997\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 170ms/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.3743 - val_accuracy: 0.8153\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 172ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 0.3279 - val_accuracy: 0.8434\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 172ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 0.6375 - val_accuracy: 0.7549\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 0.0146 - accuracy: 0.9959 - val_loss: 0.3375 - val_accuracy: 0.8488\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 0.4354 - val_accuracy: 0.8248\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 175ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.4103 - val_accuracy: 0.8343\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 0.0144 - accuracy: 0.9958 - val_loss: 0.5153 - val_accuracy: 0.8144\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 170ms/step - loss: 0.0153 - accuracy: 0.9937 - val_loss: 6.0681 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 175ms/step - loss: 3.5587e-08 - accuracy: 1.0000 - val_loss: 6.4569 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 164ms/step - loss: 2.5258e-08 - accuracy: 1.0000 - val_loss: 6.4767 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 2.4842e-08 - accuracy: 1.0000 - val_loss: 6.4778 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 2.4817e-08 - accuracy: 1.0000 - val_loss: 6.4780 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 167ms/step - loss: 9.0196 - accuracy: 0.3675 - val_loss: 0.9818 - val_accuracy: 0.8482\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 179ms/step - loss: 0.2722 - accuracy: 0.9331 - val_loss: 0.0040 - val_accuracy: 0.9983\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 169ms/step - loss: 1.7321e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9992\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 172ms/step - loss: 1.0015e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9992\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 170ms/step - loss: 9.3035e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9992\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 172ms/step - loss: 3.1652 - accuracy: 0.6581 - val_loss: 0.8176 - val_accuracy: 0.6881\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 177ms/step - loss: 0.0241 - accuracy: 0.9950 - val_loss: 1.2046 - val_accuracy: 0.6571\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 0.0176 - accuracy: 0.9949 - val_loss: 0.8866 - val_accuracy: 0.6801\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 0.7228 - val_accuracy: 0.6934\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 173ms/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 0.6526 - val_accuracy: 0.6998\n",
      "  23/4279 [..............................] - ETA: 19s - loss: 0.0383 - accuracy: 0.9851"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.0380 - accuracy: 0.9855\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1286 - accuracy: 0.9639\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    w_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2: \n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else:\n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        w_list.append(local_model.get_weights())\n",
    "\n",
    "    avg_w = aggregate(w_list)\n",
    "    global_model.set_weights(avg_w) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) # Evaluate with test basic to know progress\n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus) # Evaluate with test plus to know progress\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/id1001.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.0867944061756134, 0.16470888257026672], [0.03516291826963425, 0.0971357449889183], [0.037969958037137985, 0.12858761847019196]]\n",
      "Accuracy for iterations:  [[0.9491001963615417, 0.9488846659660339], [0.9909433722496033, 0.9765130877494812], [0.9855166673660278, 0.9639250040054321]]\n",
      "F1 for iterations:  [[0.9488842740056337, 0.9486127452561498], [0.9909463198861936, 0.9765008641808393], [0.9855160795159222, 0.9638348278908137]]\n",
      "Precision for iterations:  [[0.9521007166111072, 0.950541977371563], [0.9910302059642497, 0.9765217688534996], [0.9855164440206748, 0.9643572623430751]]\n",
      "Recall for iterations:  [[0.9491001782114581, 0.9488846908377534], [0.9909433521283123, 0.9765131148732108], [0.9855166671535832, 0.96392501634818]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 5C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_6960/4154259209.py:6: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt5C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "node_datasets = [training1, training2, training3, training4, training5]\n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'id1002.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(w_list): \n",
    "    avg_w = np.mean(w_list, axis=0)\n",
    "    return avg_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)\n",
    "\n",
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 179ms/step - loss: 0.5617 - accuracy: 0.7300 - val_loss: 1.6020 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 161ms/step - loss: 0.2339 - accuracy: 0.9235 - val_loss: 3.3507 - val_accuracy: 0.1288\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 2s 155ms/step - loss: 0.0957 - accuracy: 0.9893 - val_loss: 4.2276 - val_accuracy: 0.1337\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.0593 - accuracy: 0.9893 - val_loss: 2.2942 - val_accuracy: 0.1343\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 157ms/step - loss: 0.0388 - accuracy: 0.9898 - val_loss: 1.3347 - val_accuracy: 0.1800\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 172ms/step - loss: 0.0226 - accuracy: 0.9950 - val_loss: 0.7685 - val_accuracy: 0.7270\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 157ms/step - loss: 0.0205 - accuracy: 0.9950 - val_loss: 0.5687 - val_accuracy: 0.7290\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 155ms/step - loss: 0.0197 - accuracy: 0.9950 - val_loss: 0.7021 - val_accuracy: 0.7277\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 154ms/step - loss: 0.0191 - accuracy: 0.9950 - val_loss: 0.9256 - val_accuracy: 0.7262\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 153ms/step - loss: 0.0191 - accuracy: 0.9950 - val_loss: 0.7911 - val_accuracy: 0.7274\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 158ms/step - loss: 0.0139 - accuracy: 0.9962 - val_loss: 2.3065 - val_accuracy: 0.4424\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 165ms/step - loss: 0.0129 - accuracy: 0.9965 - val_loss: 2.2954 - val_accuracy: 0.4374\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 173ms/step - loss: 0.0132 - accuracy: 0.9968 - val_loss: 2.7710 - val_accuracy: 0.4392\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 158ms/step - loss: 0.0126 - accuracy: 0.9970 - val_loss: 1.9157 - val_accuracy: 0.4377\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 160ms/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 2.7528 - val_accuracy: 0.4367\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 4s 162ms/step - loss: 2.2779 - accuracy: 0.5587 - val_loss: 0.0811 - val_accuracy: 0.9743\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 4s 163ms/step - loss: 0.0113 - accuracy: 0.9997 - val_loss: 0.0131 - val_accuracy: 0.9952\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 4s 162ms/step - loss: 0.0034 - accuracy: 0.9999 - val_loss: 0.0066 - val_accuracy: 0.9977\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 4s 161ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9996\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 4s 164ms/step - loss: 8.7117e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 13s 180ms/step - loss: 0.4444 - accuracy: 0.8978 - val_loss: 0.4178 - val_accuracy: 0.8274\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 12s 172ms/step - loss: 0.0247 - accuracy: 0.9925 - val_loss: 0.2750 - val_accuracy: 0.8346\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 13s 186ms/step - loss: 0.0219 - accuracy: 0.9931 - val_loss: 0.2378 - val_accuracy: 0.8546\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 13s 184ms/step - loss: 0.0206 - accuracy: 0.9935 - val_loss: 0.2309 - val_accuracy: 0.8607\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 12s 177ms/step - loss: 0.0195 - accuracy: 0.9936 - val_loss: 0.2135 - val_accuracy: 0.8710\n",
      "  35/4279 [..............................] - ETA: 12s - loss: 0.0909 - accuracy: 0.9821"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.0987 - accuracy: 0.9783\n",
      "1721/1721 [==============================] - 6s 4ms/step - loss: 0.1513 - accuracy: 0.9573\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 157ms/step - loss: 0.0307 - accuracy: 0.9901 - val_loss: 0.8628 - val_accuracy: 0.4910\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 0.0266 - accuracy: 0.9900 - val_loss: 1.4338 - val_accuracy: 0.1564\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 0.0246 - accuracy: 0.9906 - val_loss: 1.1253 - val_accuracy: 0.2912\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 156ms/step - loss: 0.0232 - accuracy: 0.9915 - val_loss: 0.8781 - val_accuracy: 0.4636\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 2s 155ms/step - loss: 0.0219 - accuracy: 0.9921 - val_loss: 1.0077 - val_accuracy: 0.3904\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 170ms/step - loss: 0.0167 - accuracy: 0.9953 - val_loss: 0.7141 - val_accuracy: 0.7278\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 165ms/step - loss: 0.0155 - accuracy: 0.9955 - val_loss: 0.6582 - val_accuracy: 0.7327\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 158ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.6125 - val_accuracy: 0.7354\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 158ms/step - loss: 0.0142 - accuracy: 0.9961 - val_loss: 0.8150 - val_accuracy: 0.7293\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 165ms/step - loss: 0.0140 - accuracy: 0.9963 - val_loss: 0.6430 - val_accuracy: 0.7372\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 163ms/step - loss: 0.0112 - accuracy: 0.9973 - val_loss: 1.5913 - val_accuracy: 0.4977\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 165ms/step - loss: 0.0111 - accuracy: 0.9973 - val_loss: 1.9484 - val_accuracy: 0.4751\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 167ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 2.0507 - val_accuracy: 0.4852\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 179ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 1.3756 - val_accuracy: 0.5588\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 167ms/step - loss: 0.0110 - accuracy: 0.9973 - val_loss: 1.8434 - val_accuracy: 0.5085\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 177ms/step - loss: 4.2029 - accuracy: 0.4713 - val_loss: 0.1743 - val_accuracy: 0.9271\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 175ms/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 0.0173 - val_accuracy: 0.9935\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 180ms/step - loss: 8.6743e-04 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9952\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 181ms/step - loss: 4.9984e-04 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 0.9963\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 177ms/step - loss: 2.9560e-04 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 0.9973\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 13s 185ms/step - loss: 0.8285 - accuracy: 0.8706 - val_loss: 0.3533 - val_accuracy: 0.8389\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 13s 179ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.2278 - val_accuracy: 0.8772\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 12s 178ms/step - loss: 0.0189 - accuracy: 0.9944 - val_loss: 0.2026 - val_accuracy: 0.8870\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 13s 186ms/step - loss: 0.0179 - accuracy: 0.9946 - val_loss: 0.1982 - val_accuracy: 0.8860\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 13s 181ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.1834 - val_accuracy: 0.8931\n",
      "  33/4279 [..............................] - ETA: 13s - loss: 0.0995 - accuracy: 0.9716"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279/4279 [==============================] - 14s 3ms/step - loss: 0.1202 - accuracy: 0.9689\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1169 - accuracy: 0.9717\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 0.0268 - accuracy: 0.9915 - val_loss: 1.2463 - val_accuracy: 0.3406\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.0204 - accuracy: 0.9931 - val_loss: 0.9053 - val_accuracy: 0.4993\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 159ms/step - loss: 0.0191 - accuracy: 0.9936 - val_loss: 1.0327 - val_accuracy: 0.4528\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 0.0187 - accuracy: 0.9937 - val_loss: 0.8801 - val_accuracy: 0.5398\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 159ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 0.9063 - val_accuracy: 0.5400\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 177ms/step - loss: 0.0144 - accuracy: 0.9962 - val_loss: 0.6795 - val_accuracy: 0.7426\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 160ms/step - loss: 0.0132 - accuracy: 0.9967 - val_loss: 0.5546 - val_accuracy: 0.7558\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 159ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.6629 - val_accuracy: 0.7482\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 171ms/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.7689 - val_accuracy: 0.7410\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 159ms/step - loss: 0.0124 - accuracy: 0.9968 - val_loss: 0.7989 - val_accuracy: 0.7456\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 168ms/step - loss: 0.0107 - accuracy: 0.9975 - val_loss: 1.4033 - val_accuracy: 0.5550\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 172ms/step - loss: 0.0101 - accuracy: 0.9975 - val_loss: 1.8162 - val_accuracy: 0.5226\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 163ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 1.9343 - val_accuracy: 0.5232\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 174ms/step - loss: 0.0101 - accuracy: 0.9975 - val_loss: 1.7659 - val_accuracy: 0.5441\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 165ms/step - loss: 0.0098 - accuracy: 0.9975 - val_loss: 1.6785 - val_accuracy: 0.5564\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 5.3974 - accuracy: 0.4096 - val_loss: 0.4668 - val_accuracy: 0.9150\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 175ms/step - loss: 0.1307 - accuracy: 0.9550 - val_loss: 0.0287 - val_accuracy: 0.9919\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 172ms/step - loss: 9.2726e-04 - accuracy: 0.9999 - val_loss: 0.0189 - val_accuracy: 0.9933\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 172ms/step - loss: 5.5850e-04 - accuracy: 0.9999 - val_loss: 0.0168 - val_accuracy: 0.9938\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 172ms/step - loss: 4.3622e-04 - accuracy: 0.9999 - val_loss: 0.0149 - val_accuracy: 0.9946\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 13s 186ms/step - loss: 0.8680 - accuracy: 0.8736 - val_loss: 0.3325 - val_accuracy: 0.8554\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 12s 178ms/step - loss: 0.0191 - accuracy: 0.9945 - val_loss: 0.2200 - val_accuracy: 0.8904\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 13s 181ms/step - loss: 0.0177 - accuracy: 0.9947 - val_loss: 0.1944 - val_accuracy: 0.8994\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 13s 182ms/step - loss: 0.0168 - accuracy: 0.9949 - val_loss: 0.1775 - val_accuracy: 0.9054\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 12s 176ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.1679 - val_accuracy: 0.9079\n",
      "  31/4279 [..............................] - ETA: 13s - loss: 0.1061 - accuracy: 0.9677"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UX430\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4279/4279 [==============================] - 14s 3ms/step - loss: 0.1290 - accuracy: 0.9641\n",
      "1721/1721 [==============================] - 6s 3ms/step - loss: 0.1252 - accuracy: 0.9666: 0s - loss: 0.1247 - accuracy: 0.\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    w_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2: \n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else:\n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        w_list.append(local_model.get_weights())\n",
    "\n",
    "    avg_w = aggregate(w_list)\n",
    "    global_model.set_weights(avg_w) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) # Evaluate with test basic to know progress\n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus) # Evaluate with test plus to know progress\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/id1002.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.09872888773679733, 0.15131351351737976], [0.12024590373039246, 0.11685054004192352], [0.12895263731479645, 0.12522338330745697]]\n",
      "Accuracy for iterations:  [[0.978322446346283, 0.957313060760498], [0.9688568115234375, 0.9716994762420654], [0.9641166925430298, 0.9666497111320496]]\n",
      "F1 for iterations:  [[0.978335505113202, 0.9573955484948163], [0.9688825098598914, 0.9717691391251647], [0.9641447047900135, 0.9667394851144581]]\n",
      "Precision for iterations:  [[0.9787138383022526, 0.958142008093737], [0.9707612324360201, 0.9730941427738602], [0.9666378442992711, 0.968435550001543]]\n",
      "Recall for iterations:  [[0.9783224750942183, 0.9573130858097798], [0.9688568173186479, 0.9716994841241009], [0.964116684682579, 0.9666497129986195]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with epochs and iterations \n",
    "\n",
    "Use of dataset 5A, considering it contains an equal partition of the data between the 5 nodes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #Epochs = 10, #Iterations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-5A-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-5A-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-5A-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-5A-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-5A-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "node_datasets = [training1, training2, training3, training4, training5]\n",
    "num_nodes = 5\n",
    "global_updates = 10\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'id1010.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(w_list): \n",
    "    avg_w = np.mean(w_list, axis=0)\n",
    "    return avg_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)\n",
    "\n",
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    w_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2: \n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else:\n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        w_list.append(local_model.get_weights())\n",
    "\n",
    "    avg_w = aggregate(w_list)\n",
    "    global_model.set_weights(avg_w) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) # Evaluate with test basic to know progress\n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus) # Evaluate with test plus to know progress\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/id1010.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #Epochs = 5, #Iterations = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training datasets and testing datasets \n",
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-5A-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-5A-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-5A-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-5A-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-5A-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "node_datasets = [training1, training2, training3, training4, training5]\n",
    "num_nodes = 5\n",
    "global_updates = 5\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'id1011.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(w_list): \n",
    "    avg_w = np.mean(w_list, axis=0)\n",
    "    return avg_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)\n",
    "\n",
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    w_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2: \n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else:\n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        w_list.append(local_model.get_weights())\n",
    "\n",
    "    avg_w = aggregate(w_list)\n",
    "    global_model.set_weights(avg_w) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) # Evaluate with test basic to know progress\n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus) # Evaluate with test plus to know progress\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/id1011.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
