{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partitioning UNSW-NB15-Train-Basic into 3 nodes \n",
    "\n",
    "The partitions made can be balanced/ unbalanced, with 3 nodes. Attacks might appear in all nodes or only a subset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # for array\n",
    "import pandas as pd  # for csv files and dataframe\n",
    "import matplotlib.pyplot as plt  # for plotting\n",
    "import seaborn as sns  # plotting\n",
    "from scipy import stats\n",
    "\n",
    "import pickle  # To load data int disk\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, make_scorer\n",
    "from sklearn.metrics import auc, f1_score, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get UNSW-NB15-Train-Basic dataset \n",
    "complete = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proto</th>\n",
       "      <th>srcip</th>\n",
       "      <th>sport</th>\n",
       "      <th>dstip</th>\n",
       "      <th>dsport</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>state</th>\n",
       "      <th>stime</th>\n",
       "      <th>ltime</th>\n",
       "      <th>dur</th>\n",
       "      <th>label</th>\n",
       "      <th>attack_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>udp</td>\n",
       "      <td>59.166.0.7</td>\n",
       "      <td>45584</td>\n",
       "      <td>149.171.126.0</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>162</td>\n",
       "      <td>CON</td>\n",
       "      <td>1424257612</td>\n",
       "      <td>1424257612</td>\n",
       "      <td>0.003362</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tcp</td>\n",
       "      <td>59.166.0.2</td>\n",
       "      <td>18633</td>\n",
       "      <td>149.171.126.3</td>\n",
       "      <td>8908</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "      <td>2438</td>\n",
       "      <td>19440</td>\n",
       "      <td>FIN</td>\n",
       "      <td>1424258064</td>\n",
       "      <td>1424258064</td>\n",
       "      <td>0.013975</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tcp</td>\n",
       "      <td>59.166.0.7</td>\n",
       "      <td>48428</td>\n",
       "      <td>149.171.126.4</td>\n",
       "      <td>143</td>\n",
       "      <td>122</td>\n",
       "      <td>126</td>\n",
       "      <td>7824</td>\n",
       "      <td>14814</td>\n",
       "      <td>FIN</td>\n",
       "      <td>1421951117</td>\n",
       "      <td>1421951118</td>\n",
       "      <td>0.757193</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unas</td>\n",
       "      <td>175.45.176.1</td>\n",
       "      <td>0</td>\n",
       "      <td>149.171.126.17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>INT</td>\n",
       "      <td>1424244417</td>\n",
       "      <td>1424244417</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tcp</td>\n",
       "      <td>175.45.176.1</td>\n",
       "      <td>65485</td>\n",
       "      <td>149.171.126.17</td>\n",
       "      <td>179</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>876</td>\n",
       "      <td>268</td>\n",
       "      <td>FIN</td>\n",
       "      <td>1421928270</td>\n",
       "      <td>1421928271</td>\n",
       "      <td>0.436004</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435514</th>\n",
       "      <td>udp</td>\n",
       "      <td>175.45.176.2</td>\n",
       "      <td>31072</td>\n",
       "      <td>149.171.126.19</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>INT</td>\n",
       "      <td>1424223755</td>\n",
       "      <td>1424223755</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435515</th>\n",
       "      <td>tcp</td>\n",
       "      <td>59.166.0.5</td>\n",
       "      <td>2758</td>\n",
       "      <td>149.171.126.8</td>\n",
       "      <td>51824</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>2766</td>\n",
       "      <td>28558</td>\n",
       "      <td>FIN</td>\n",
       "      <td>1424261274</td>\n",
       "      <td>1424261274</td>\n",
       "      <td>0.014994</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435516</th>\n",
       "      <td>udp</td>\n",
       "      <td>175.45.176.0</td>\n",
       "      <td>47439</td>\n",
       "      <td>149.171.126.10</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>INT</td>\n",
       "      <td>1424259155</td>\n",
       "      <td>1424259155</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1</td>\n",
       "      <td>generic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435517</th>\n",
       "      <td>udp</td>\n",
       "      <td>175.45.176.1</td>\n",
       "      <td>47439</td>\n",
       "      <td>149.171.126.18</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>INT</td>\n",
       "      <td>1424238658</td>\n",
       "      <td>1424238658</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1</td>\n",
       "      <td>generic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435518</th>\n",
       "      <td>tcp</td>\n",
       "      <td>59.166.0.9</td>\n",
       "      <td>21223</td>\n",
       "      <td>149.171.126.7</td>\n",
       "      <td>5190</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1064</td>\n",
       "      <td>2260</td>\n",
       "      <td>FIN</td>\n",
       "      <td>1424231610</td>\n",
       "      <td>1424231610</td>\n",
       "      <td>0.004064</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>435519 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       proto         srcip  sport           dstip dsport  spkts  dpkts  \\\n",
       "0        udp    59.166.0.7  45584   149.171.126.0     53      2      2   \n",
       "1        tcp    59.166.0.2  18633   149.171.126.3   8908     38     40   \n",
       "2        tcp    59.166.0.7  48428   149.171.126.4    143    122    126   \n",
       "3       unas  175.45.176.1      0  149.171.126.17      0      2      0   \n",
       "4        tcp  175.45.176.1  65485  149.171.126.17    179     10      6   \n",
       "...      ...           ...    ...             ...    ...    ...    ...   \n",
       "435514   udp  175.45.176.2  31072  149.171.126.19    500      2      0   \n",
       "435515   tcp    59.166.0.5   2758   149.171.126.8  51824     44     46   \n",
       "435516   udp  175.45.176.0  47439  149.171.126.10     53      2      0   \n",
       "435517   udp  175.45.176.1  47439  149.171.126.18     53      2      0   \n",
       "435518   tcp    59.166.0.9  21223   149.171.126.7   5190     12     12   \n",
       "\n",
       "        sbytes  dbytes state       stime       ltime       dur  label  \\\n",
       "0          130     162   CON  1424257612  1424257612  0.003362      0   \n",
       "1         2438   19440   FIN  1424258064  1424258064  0.013975      0   \n",
       "2         7824   14814   FIN  1421951117  1421951118  0.757193      0   \n",
       "3          200       0   INT  1424244417  1424244417  0.000004      1   \n",
       "4          876     268   FIN  1421928270  1421928271  0.436004      0   \n",
       "...        ...     ...   ...         ...         ...       ...    ...   \n",
       "435514     136       0   INT  1424223755  1424223755  0.000001      1   \n",
       "435515    2766   28558   FIN  1424261274  1424261274  0.014994      0   \n",
       "435516     114       0   INT  1424259155  1424259155  0.000002      1   \n",
       "435517     114       0   INT  1424238658  1424238658  0.000002      1   \n",
       "435518    1064    2260   FIN  1424231610  1424231610  0.004064      0   \n",
       "\n",
       "       attack_cat  \n",
       "0          normal  \n",
       "1          normal  \n",
       "2          normal  \n",
       "3             dos  \n",
       "4          normal  \n",
       "...           ...  \n",
       "435514        dos  \n",
       "435515     normal  \n",
       "435516    generic  \n",
       "435517    generic  \n",
       "435518     normal  \n",
       "\n",
       "[435519 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(dataset): \n",
    "    # Get only the rows that contain state (PAR, ACC, ECO, CON, FIN, INT, REQ, RST) and proto (igmp, arp, icmp, udp, tcp, ipv6-icmp, rarp)\n",
    "    dataset = dataset[dataset['state'].isin(['PAR', 'ACC', 'ECO', 'CON', 'FIN', 'INT', 'REQ', 'RST'])]\n",
    "    dataset = dataset[dataset['proto'].isin(['igmp', 'arp', 'icmp', 'udp', 'tcp', 'ipv6-icmp', 'rarp'])]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete = filter(complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### id = Filt3A : Partition with 3 balanced nodes \n",
    "\n",
    "Normal (3 nodes), Generic (3 nodes), Exploits (2 nodes), DoS and Reconnaissance (1 node).\n",
    "\n",
    "WARNING: There are 24084 preprocessed normal traffic samples that are not being used to maintain a 50-50% rate in each node. \n",
    "- UNSW-NB15-Train-Basic-Part1 (128824): \n",
    "    - Normal: 64412 (50.0%)\n",
    "    - Generic: 42360 (%)\n",
    "    - Exploits: 13140 (%)\n",
    "    - DoS: 0 (0.0%)\n",
    "    - Reconnaissance: 8912 (%)\n",
    "\n",
    "- UNSW-NB15-Train-Basic-Part2 (128824): \n",
    "    - Normal: 64412 (50.0%)\n",
    "    - Generic: 61498 (%)\n",
    "    - Exploits: 0 (0.0%)\n",
    "    - DoS: 2914 (%)\n",
    "    - Reconnaissance: 0 (0.0%)\n",
    "\n",
    "- UNSW-NB15-Train-Basic-Part3 (128824): \n",
    "    - Normal: 64412 (50.0%)\n",
    "    - Generic: 56183 (%)\n",
    "    - Exploits: 8229 (%)\n",
    "    - DoS: 0 (0.0%)\n",
    "    - Reconnaissance: 0 (0.0%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get amount of samples for every type of traffic (attack subtypes as well): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(217320, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal = complete[complete['label'] == 0]\n",
    "normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160041, 15)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generic = complete[complete['attack_cat'] == \"generic\"]\n",
    "generic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21369, 15)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploits = complete[complete['attack_cat'] == \"exploits\"]\n",
    "exploits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2914, 15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dos = complete[complete['attack_cat'] == \"dos\"]\n",
    "dos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8912, 15)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconnaissance = complete[complete['attack_cat'] == \"reconnaissance\"]\n",
    "reconnaissance.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the partitions for each subtype: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into three partitions normal samples (64412)\n",
    "normal1 = complete[complete['label'] == 0].iloc[:64412]\n",
    "normal2 = complete[complete['label'] == 0].iloc[64412:64412*2]\n",
    "normal3 = complete[complete['label'] == 0].iloc[64412*2:64412*3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into three partitions generic samples (47369, 60213, 53792)\n",
    "generic1 = complete[complete['attack_cat'] == \"generic\"].iloc[:42360]\n",
    "generic2 = complete[complete['attack_cat'] == \"generic\"].iloc[42360:(42360+61498)]\n",
    "generic3 = complete[complete['attack_cat'] == \"generic\"].iloc[(42360+61498):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into two partitions exploits samples (14728, 18808)\n",
    "exploits1 = complete[complete['attack_cat'] == \"exploits\"].iloc[:13140]\n",
    "exploits2 = complete[complete['attack_cat'] == \"exploits\"].iloc[13140:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all dos samples and reconnaissance samples\n",
    "dos = complete[complete['attack_cat'] == \"dos\"]\n",
    "recon = complete[complete['attack_cat'] == \"reconnaissance\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the different df to obtain the three final partitions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UNSW-NB15-Train-Basic-PartN, N = 1,2,3, dataset and export to csv\n",
    "part1 = pd.concat([normal1, generic1, exploits1, recon])\n",
    "part2 = pd.concat([normal2, generic2, dos])\n",
    "part3 = pd.concat([normal3, generic3, exploits2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "part1.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt3A-Part1.csv', index=False)\n",
    "part2.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt3A-Part2.csv', index=False)\n",
    "part3.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt3A-Part3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### id = Filt3B : Partition with 3 balanced nodes \n",
    "\n",
    "Normal (2 nodes), Generic (2 nodes), Exploits (1 nodes), DoS and Reconnaissance (1 node).\n",
    "\n",
    "\n",
    "- UNSW-NB15-Train-Basic-Part1 (128824): \n",
    "    - Normal: 128824 (100.0%)\n",
    "    - Generic: 0 (0.0%)\n",
    "    - Exploits: 0 (0.0%)\n",
    "    - DoS: 0 (0.0%)\n",
    "    - Reconnaissance: 0 (0.0%)\n",
    "\n",
    "- UNSW-NB15-Train-Basic-Part2 (128824): \n",
    "    - Normal: 64412 (50.0%)\n",
    "    - Generic: 61498 (%)\n",
    "    - Exploits: 0 (0.0%)\n",
    "    - DoS: 2914 (%)\n",
    "    - Reconnaissance: 0 (0.0%)\n",
    "\n",
    "- UNSW-NB15-Train-Basic-Part3 (128824): \n",
    "    - Normal: 0 (0.0%)\n",
    "    - Generic: 98543 (69.7%)\n",
    "    - Exploits: 21369 (23.1%)\n",
    "    - DoS: 0 (0.0%)\n",
    "    - Reconnaissance: 8912 (7.2%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the partitions \n",
    "\n",
    "# Separate into two partitions normal samples (145200, 64412)\n",
    "normal1 = complete[complete['label'] == 0].iloc[:128824]\n",
    "normal2 = complete[complete['label'] == 0].iloc[128824:(128824+64412)]\n",
    "\n",
    "# Separate into two partitions generic samples (60213, 101161)\n",
    "generic1 = complete[complete['attack_cat'] == \"generic\"].iloc[:61498]\n",
    "generic2 = complete[complete['attack_cat'] == \"generic\"].iloc[61498:]\n",
    "\n",
    "# Grab the samples with exploit attacks \n",
    "exploits1 = complete[complete['attack_cat'] == \"exploits\"]\n",
    "\n",
    "# Get all dos samples and reconnaissance samples\n",
    "dos = complete[complete['attack_cat'] == \"dos\"]\n",
    "recon = complete[complete['attack_cat'] == \"reconnaissance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UNSW-NB15-Train-Basic-PartN, N = 1,2,3, dataset and export to csv\n",
    "part1 = pd.concat([normal1])\n",
    "part2 = pd.concat([normal2, generic1, dos])\n",
    "part3 = pd.concat([generic1, exploits1, recon])\n",
    "part1.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt3B-Part1.csv', index=False)\n",
    "part2.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt3B-Part2.csv', index=False)\n",
    "part3.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt3B-Part3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### id = Filt3C : Partition with 3 balanced nodes \n",
    "\n",
    "All types of traffic represented in all nodes: \n",
    " \n",
    "- UNSW-NB15-Train-Basic-Part1 (128824): \n",
    "    - Normal: 64412 (50.0%)\n",
    "    - Generic: 53347 (%)\n",
    "    - Exploits: 7123 (%)\n",
    "    - DoS: 971 (%)\n",
    "    - Reconnaissance: 2971 (%)\n",
    "\n",
    "- UNSW-NB15-Train-Basic-Part2 (128824): \n",
    "    - Normal: 64412 (50.0%)\n",
    "    - Generic: 53347 (%)\n",
    "    - Exploits: 7123 (%)\n",
    "    - DoS: 971 (%)\n",
    "    - Reconnaissance: 2971 (%)\n",
    "\n",
    "- UNSW-NB15-Train-Basic-Part3 (128824): \n",
    "    - Normal: 64412 (50.0%)\n",
    "    - Generic: 53347 (%)\n",
    "    - Exploits: 7123 (%)\n",
    "    - DoS: 972 (%)\n",
    "    - Reconnaissance: 2970 (%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the partitions \n",
    "\n",
    "# Separate into three partitions normal samples (64412)\n",
    "normal1 = complete[complete['label'] == 0].iloc[:64412]\n",
    "normal2 = complete[complete['label'] == 0].iloc[64412:64412*2]\n",
    "normal3 = complete[complete['label'] == 0].iloc[64412*2:64412*3]\n",
    "\n",
    "# Separate into three partitions generic samples (53347, 53347, 53792)\n",
    "generic1 = complete[complete['attack_cat'] == \"generic\"].iloc[:53347]\n",
    "generic2 = complete[complete['attack_cat'] == \"generic\"].iloc[53347:53347*2]\n",
    "generic3 = complete[complete['attack_cat'] == \"generic\"].iloc[53347*2:]\n",
    "\n",
    "# Separate into three partitions exploits samples (7123, 7123, 11178) \n",
    "exploits1 = complete[complete['attack_cat'] == \"exploits\"].iloc[:7123]\n",
    "exploits2 = complete[complete['attack_cat'] == \"exploits\"].iloc[7123:7123*2]\n",
    "exploits3 = complete[complete['attack_cat'] == \"exploits\"].iloc[7123*2:]\n",
    "\n",
    "# Separate into three partitions dos samples (971)\n",
    "dos1 = complete[complete['attack_cat'] == \"dos\"].iloc[:971]\n",
    "dos2 = complete[complete['attack_cat'] == \"dos\"].iloc[971:971*2]\n",
    "dos3 = complete[complete['attack_cat'] == \"dos\"].iloc[971*2:]\n",
    "\n",
    "# Separate into three partitions reconnaissance samples (2971)\n",
    "recon1 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[:2971]\n",
    "recon2 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[2971:2971*2]\n",
    "recon3 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[2971*2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UNSW-NB15-Train-Basic-PartN, N = 1,2,3, dataset and export to csv\n",
    "part1 = pd.concat([normal1, generic1, exploits1, dos1, recon1])\n",
    "part2 = pd.concat([normal2, generic2, exploits2, dos2, recon2])\n",
    "part3 = pd.concat([normal3, generic3, exploits3, dos3, recon3])\n",
    "part1.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt3C-Part1.csv', index=False)\n",
    "part2.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt3C-Part2.csv', index=False)\n",
    "part3.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt3C-Part3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### id = Filt3D : Partition with 3 balanced nodes \n",
    "\n",
    "To try with balanced nodes (same number of samples) that only contain Normal or Generic in one node, we need to restrict the number of samples at each node. \n",
    "- UNSW-NB15-Train-Basic-Part1 (33195): \n",
    "    - Normal: 33195 (100.0%)\n",
    "    - Generic: 0 (0.0%)\n",
    "    - Exploits: 0 (0.0%)\n",
    "    - DoS: 0 (0.0%)\n",
    "    - Reconnaissance: 0 (0.0%)\n",
    "\n",
    "- UNSW-NB15-Train-Basic-Part2 (33195): \n",
    "    - Normal: 0 (0.0%)\n",
    "    - Generic: 33195 (100.0%)\n",
    "    - Exploits: 0 (0.0%)\n",
    "    - DoS: 0 (0.0%)\n",
    "    - Reconnaissance: 0 (0.0%)\n",
    "\n",
    "- UNSW-NB15-Train-Basic-Part3 (33195): \n",
    "    - Normal: 0 (0.0%)\n",
    "    - Generic: 0 (0.0%)\n",
    "    - Exploits: 21369 (%)\n",
    "    - DoS: 2914 (%)\n",
    "    - Reconnaissance: 8912 (%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the partitions \n",
    "\n",
    "# Grab 56345 random samples from normal traffic \n",
    "normal = complete[complete['attack_cat'] == \"normal\"].sample(33195)\n",
    "\n",
    "# Grab 56345 random samples from generic attacks\n",
    "generic = complete[complete['attack_cat'] == \"generic\"].sample(33195)\n",
    "\n",
    "# Grab the samples with exploit attacks \n",
    "exploits1 = complete[complete['attack_cat'] == \"exploits\"]\n",
    "\n",
    "# Get all dos samples and reconnaissance samples\n",
    "dos = complete[complete['attack_cat'] == \"dos\"]\n",
    "recon = complete[complete['attack_cat'] == \"reconnaissance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UNSW-NB15-Train-Basic-PartN, N = 1,2,3, dataset and export to csv\n",
    "part1 = pd.concat([normal])\n",
    "part2 = pd.concat([generic])\n",
    "part3 = pd.concat([exploits1, dos, recon])\n",
    "part1.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt3D-Part1.csv', index=False)\n",
    "part2.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt3D-Part2.csv', index=False)\n",
    "part3.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt3D-Part3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### id = Filt3E : Partition with 3 unbalanced nodes \n",
    "\n",
    "\n",
    "- UNSW-NB15-Train-Basic-Part1 (128824): \n",
    "    - Normal: 66897 (%)\n",
    "    - Generic: 53347 (%)\n",
    "    - Exploits: 7123 (%)\n",
    "    - DoS: 1457 (%)\n",
    "    - Reconnaissance: 0 (0.0%)\n",
    "\n",
    "- UNSW-NB15-Train-Basic-Part2 (128824): \n",
    "    - Normal: 62441 (%)\n",
    "    - Generic: 53347 (%)\n",
    "    - Exploits: 7123 (%)\n",
    "    - DoS: 1457 (%)\n",
    "    - Reconnaissance: 4456 (%)\n",
    "\n",
    "- UNSW-NB15-Train-Basic-Part3 (128824): \n",
    "    - Normal: 63898 (%)\n",
    "    - Generic: 53347 (%)\n",
    "    - Exploits: 7123 (%)\n",
    "    - DoS: 0 (0.0%)\n",
    "    - Reconnaissance: 4456 (%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the partitions \n",
    "\n",
    "# Separate into three partitions normal samples (74050, 68799, 74951)\n",
    "normal1 = complete[complete['label'] == 0].iloc[:66897]\n",
    "normal2 = complete[complete['label'] == 0].iloc[66897:(66897+62441)]\n",
    "normal3 = complete[complete['label'] == 0].iloc[(66897+62441):(66897+62441+63898)]\n",
    "\n",
    "# Separate into three partitions generic samples (53347, 53347, 53792)\n",
    "generic1 = complete[complete['attack_cat'] == \"generic\"].iloc[:53347]\n",
    "generic2 = complete[complete['attack_cat'] == \"generic\"].iloc[53347:53347*2]\n",
    "generic3 = complete[complete['attack_cat'] == \"generic\"].iloc[53347*2:]\n",
    "\n",
    "# Separate into three partitions exploits samples (7123, 7123, 11178) \n",
    "exploits1 = complete[complete['attack_cat'] == \"exploits\"].iloc[:7123]\n",
    "exploits2 = complete[complete['attack_cat'] == \"exploits\"].iloc[7123:7123*2]\n",
    "exploits3 = complete[complete['attack_cat'] == \"exploits\"].iloc[7123*2:]\n",
    "\n",
    "# Separate into two partitions dos samples (6153)\n",
    "dos1 = complete[complete['attack_cat'] == \"dos\"].iloc[:1457]\n",
    "dos2 = complete[complete['attack_cat'] == \"dos\"].iloc[1457:]\n",
    "\n",
    "\n",
    "# Separate into two partitions reconnaissance samples (5251, 5252)\n",
    "recon1 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[:4456]\n",
    "recon2 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[4456:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UNSW-NB15-Train-Basic-PartN, N = 1,2,3, dataset and export to csv\n",
    "part1 = pd.concat([normal1, generic1, exploits1, dos1])\n",
    "part2 = pd.concat([normal2, generic2, exploits2, dos2, recon1])\n",
    "part3 = pd.concat([normal3, generic3, exploits3, recon2])\n",
    "part1.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt3E-Part1.csv', index=False)\n",
    "part2.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt3E-Part2.csv', index=False)\n",
    "part3.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt3E-Part3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### id = Filt3F : Partition with 3 unbalanced nodes\n",
    "\n",
    "Normal (3 nodes), Generic (3 nodes), Exploits (2 nodes), DoS (1 node), Reconnaissance (1 node)\n",
    "\n",
    "- UNSW-NB15-Train-Basic-Part1 (100000): \n",
    "    - Normal: 50000 \n",
    "    - Generic: 23174 \n",
    "    - Exploits: 15000\n",
    "    - DoS: 2914 \n",
    "    - Reconnaissance: 8912 \n",
    "\n",
    "- UNSW-NB15-Train-Basic-Part2 (250000): \n",
    "    - Normal: 137042 \n",
    "    - Generic: 112958 \n",
    "    - Exploits: 0 (0.0%)\n",
    "    - DoS: 0 (0%)\n",
    "    - Reconnaissance: 0 (0.0%)\n",
    "\n",
    "- UNSW-NB15-Train-Basic-Part3 (60556): \n",
    "    - Normal: 30278\n",
    "    - Generic: 23909\n",
    "    - Exploits: 6369 \n",
    "    - DoS: 0 (0.0%)\n",
    "    - Reconnaissance: 0 (0.0%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the partitions \n",
    "\n",
    "# Separate into three partitions normal samples \n",
    "normal1 = complete[complete['label'] == 0].iloc[:50000]\n",
    "normal2 = complete[complete['label'] == 0].iloc[50000:(50000+137042)]\n",
    "normal3 = complete[complete['label'] == 0].iloc[(50000+137042):]\n",
    "\n",
    "# Separate into three partitions generic samples\n",
    "generic1 = complete[complete['attack_cat'] == \"generic\"].iloc[:2317]\n",
    "generic2 = complete[complete['attack_cat'] == \"generic\"].iloc[2317:(2317+112958)]\n",
    "generic3 = complete[complete['attack_cat'] == \"generic\"].iloc[(2317+112958):]\n",
    "\n",
    "# Separate into two partitions exploits samples \n",
    "exploits1 = complete[complete['attack_cat'] == \"exploits\"].iloc[:15000]\n",
    "exploits2 = complete[complete['attack_cat'] == \"exploits\"].iloc[15000:]\n",
    "\n",
    "# Gather all DoS components\n",
    "dos1 = complete[complete['attack_cat'] == \"dos\"]\n",
    "\n",
    "# Gather all Reconnaissance components \n",
    "recon1 = complete[complete['attack_cat'] == \"reconnaissance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UNSW-NB15-Train-Basic-PartN, N = 1,2,3, dataset and export to csv\n",
    "part1 = pd.concat([normal1, generic1, exploits1, dos1, recon1])\n",
    "part2 = pd.concat([normal2, generic2])\n",
    "part3 = pd.concat([normal3, generic3, exploits2])\n",
    "part1.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt3F-Part1.csv', index=False)\n",
    "part2.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt3F-Part2.csv', index=False)\n",
    "part3.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt3F-Part3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### id = Filt3G : Partition with 3 unbalanced nodes \n",
    "\n",
    "- UNSW-NB15-Train-Basic-Part1 (50000): \n",
    "    - Normal: 25000 \n",
    "    - Generic: 13935\n",
    "    - Exploits: 7123\n",
    "    - DoS: 971\n",
    "    - Reconnaissance: 2971\n",
    "\n",
    "- UNSW-NB15-Train-Basic-Part2 (136472): \n",
    "    - Normal: 68236 \n",
    "    - Generic: 57171\n",
    "    - Exploits: 7123\n",
    "    - DoS: 971\n",
    "    - Reconnaissance: 2971\n",
    "\n",
    "- UNSW-NB15-Train-Basic-Part3 (200000)\n",
    "    - Normal: 100000\n",
    "    - Generic: 88935\n",
    "    - Exploits: 7123\n",
    "    - DoS: 972\n",
    "    - Reconnaissance: 2970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the partitions \n",
    "\n",
    "# Separate into three partitions normal samples \n",
    "normal1 = complete[complete['label'] == 0].iloc[:25000]\n",
    "normal2 = complete[complete['label'] == 0].iloc[25000:(25000+68236)]\n",
    "normal3 = complete[complete['label'] == 0].iloc[(25000+68236):(25000+68236+100000)]\n",
    "\n",
    "# Separate into three partitions generic samples \n",
    "generic1 = complete[complete['attack_cat'] == \"generic\"].iloc[:13935]\n",
    "generic2 = complete[complete['attack_cat'] == \"generic\"].iloc[13935:(13935+57171)]\n",
    "generic3 = complete[complete['attack_cat'] == \"generic\"].iloc[(13935+57171):]\n",
    "\n",
    "# Separate into three partitions exploits samples\n",
    "exploits1 = complete[complete['attack_cat'] == \"exploits\"].iloc[:7123]\n",
    "exploits2 = complete[complete['attack_cat'] == \"exploits\"].iloc[7123:(7123*2)]\n",
    "exploits3 = complete[complete['attack_cat'] == \"exploits\"].iloc[(7123*2):]\n",
    "\n",
    "# Separate into three partitions dos samples\n",
    "dos1 = complete[complete['attack_cat'] == \"dos\"].iloc[:971]\n",
    "dos2 = complete[complete['attack_cat'] == \"dos\"].iloc[971:(971*2)]\n",
    "dos3 = complete[complete['attack_cat'] == \"dos\"].iloc[(971*2):]\n",
    "\n",
    "\n",
    "# Separate into three partitions reconnaissance samples\n",
    "recon1 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[:2971]\n",
    "recon2 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[2971:(2971*2)]\n",
    "recon3 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[2971*2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UNSW-NB15-Train-Basic-PartN, N = 1,2,3, dataset and export to csv\n",
    "part1 = pd.concat([normal1, generic1, exploits1, dos1, recon1])\n",
    "part2 = pd.concat([normal2, generic2, exploits2, dos2, recon2])\n",
    "part3 = pd.concat([normal3, generic3, exploits3, recon3, dos3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part1.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt3G-Part1.csv', index=False)\n",
    "part2.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt3G-Part2.csv', index=False)\n",
    "part3.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Filt3G-Part3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification datasets \n",
    "\n",
    "Normal traffic is not considered, as it's going to feed models that categorize attacks (when detection model detects attack). Information about percentages and distribution of attacks is included in the \"datasets.xslx\" file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_cat = complete[complete['attack_cat'] != \"normal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generic           160041\n",
       "exploits           21369\n",
       "reconnaissance      8912\n",
       "dos                 2914\n",
       "Name: attack_cat, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_cat['attack_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cat3A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the partitions \n",
    "\n",
    "# Separate into three partitions generic samples (53347, 53347, 53792)\n",
    "generic1 = complete[complete['attack_cat'] == \"generic\"].iloc[:53347]\n",
    "generic2 = complete[complete['attack_cat'] == \"generic\"].iloc[53347:53347*2]\n",
    "generic3 = complete[complete['attack_cat'] == \"generic\"].iloc[53347*2:]\n",
    "\n",
    "# Separate into three partitions exploits samples (7123, 7123, 11178) \n",
    "exploits1 = complete[complete['attack_cat'] == \"exploits\"].iloc[:7123]\n",
    "exploits2 = complete[complete['attack_cat'] == \"exploits\"].iloc[7123:7123*2]\n",
    "exploits3 = complete[complete['attack_cat'] == \"exploits\"].iloc[7123*2:]\n",
    "\n",
    "# Separate into three partitions dos samples (971)\n",
    "dos1 = complete[complete['attack_cat'] == \"dos\"].iloc[:971]\n",
    "dos2 = complete[complete['attack_cat'] == \"dos\"].iloc[971:971*2]\n",
    "dos3 = complete[complete['attack_cat'] == \"dos\"].iloc[971*2:]\n",
    "\n",
    "# Separate into three partitions reconnaissance samples (2971)\n",
    "recon1 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[:2971]\n",
    "recon2 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[2971:2971*2]\n",
    "recon3 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[2971*2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UNSW-NB15-Train-Basic-PartN, N = 1,2,3, dataset and export to csv\n",
    "part1 = pd.concat([generic1, exploits1, dos1, recon1])\n",
    "part2 = pd.concat([generic2, exploits2, dos2, recon2])\n",
    "part3 = pd.concat([generic3, exploits3, dos3, recon3])\n",
    "part1.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat3A-Part1.csv', index=False)\n",
    "part2.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat3A-Part2.csv', index=False)\n",
    "part3.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat3A-Part3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cat3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the partitions \n",
    "\n",
    "# Separate into three partitions generic samples (53347, 53347, 53792)\n",
    "generic1 = complete[complete['attack_cat'] == \"generic\"].iloc[:7123]\n",
    "generic2 = complete[complete['attack_cat'] == \"generic\"].iloc[7123:7123*2]\n",
    "generic3 = complete[complete['attack_cat'] == \"generic\"].iloc[7123*2:7123*3]\n",
    "\n",
    "# Separate into three partitions exploits samples (7123, 7123, 11178) \n",
    "exploits1 = complete[complete['attack_cat'] == \"exploits\"].iloc[:7123]\n",
    "exploits2 = complete[complete['attack_cat'] == \"exploits\"].iloc[7123:7123*2]\n",
    "exploits3 = complete[complete['attack_cat'] == \"exploits\"].iloc[7123*2:]\n",
    "\n",
    "# Separate into three partitions dos samples (971)\n",
    "dos1 = complete[complete['attack_cat'] == \"dos\"].iloc[:971]\n",
    "dos2 = complete[complete['attack_cat'] == \"dos\"].iloc[971:971*2]\n",
    "dos3 = complete[complete['attack_cat'] == \"dos\"].iloc[971*2:]\n",
    "\n",
    "# Separate into three partitions reconnaissance samples (2971)\n",
    "recon1 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[:2971]\n",
    "recon2 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[2971:2971*2]\n",
    "recon3 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[2971*2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UNSW-NB15-Train-Basic-PartN, N = 1,2,3, dataset and export to csv\n",
    "part1 = pd.concat([generic1, exploits1, dos1, recon1])\n",
    "part2 = pd.concat([generic2, exploits2, dos2, recon2])\n",
    "part3 = pd.concat([generic3, exploits3, dos3, recon3])\n",
    "part1.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat3B-Part1.csv', index=False)\n",
    "part2.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat3B-Part2.csv', index=False)\n",
    "part3.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat3B-Part3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cat3C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the partitions \n",
    "\n",
    "# Separate into three partitions generic samples (53347, 53347, 53792)\n",
    "generic1 = complete[complete['attack_cat'] == \"generic\"].iloc[:1000]\n",
    "generic2 = complete[complete['attack_cat'] == \"generic\"].iloc[1000:1000*2]\n",
    "generic3 = complete[complete['attack_cat'] == \"generic\"].iloc[1000*2:1000*3]\n",
    "\n",
    "# Separate into three partitions exploits samples (7123, 7123, 11178) \n",
    "exploits1 = complete[complete['attack_cat'] == \"exploits\"].iloc[:1000]\n",
    "exploits2 = complete[complete['attack_cat'] == \"exploits\"].iloc[1000:1000*2]\n",
    "exploits3 = complete[complete['attack_cat'] == \"exploits\"].iloc[1000*2:1000*3]\n",
    "\n",
    "# Separate into three partitions dos samples (971)\n",
    "dos1 = complete[complete['attack_cat'] == \"dos\"].iloc[:971]\n",
    "dos2 = complete[complete['attack_cat'] == \"dos\"].iloc[971:971*2]\n",
    "dos3 = complete[complete['attack_cat'] == \"dos\"].iloc[971*2:]\n",
    "\n",
    "# Separate into three partitions reconnaissance samples (2971)\n",
    "recon1 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[:1000]\n",
    "recon2 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[1000:1000*2]\n",
    "recon3 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[1000*2:1000*3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UNSW-NB15-Train-Basic-PartN, N = 1,2,3, dataset and export to csv\n",
    "part1 = pd.concat([generic1, exploits1, dos1, recon1])\n",
    "part2 = pd.concat([generic2, exploits2, dos2, recon2])\n",
    "part3 = pd.concat([generic3, exploits3, dos3, recon3])\n",
    "part1.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat3C-Part1.csv', index=False)\n",
    "part2.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat3C-Part2.csv', index=False)\n",
    "part3.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat3C-Part3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cat3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the partitions \n",
    "\n",
    "# Separate into three partitions generic samples (53347, 53347, 53792)\n",
    "generic1 = complete[complete['attack_cat'] == \"generic\"].iloc[:21369]\n",
    "generic2 = complete[complete['attack_cat'] == \"generic\"].iloc[21369:(21369+2914)]\n",
    "generic3 = complete[complete['attack_cat'] == \"generic\"].iloc[(21369+2914):(21369+2914+8912)]\n",
    "\n",
    "# Separate into three partitions exploits samples (7123, 7123, 11178) \n",
    "exploits1 = complete[complete['attack_cat'] == \"exploits\"]\n",
    "\n",
    "# Separate into three partitions dos samples (971)\n",
    "dos1 = complete[complete['attack_cat'] == \"dos\"]\n",
    "\n",
    "\n",
    "# Separate into three partitions reconnaissance samples (2971)\n",
    "recon1 = complete[complete['attack_cat'] == \"reconnaissance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UNSW-NB15-Train-Basic-PartN, N = 1,2,3, dataset and export to csv\n",
    "part1 = pd.concat([generic1, exploits1])\n",
    "part2 = pd.concat([generic2, dos1])\n",
    "part3 = pd.concat([generic3,recon1])\n",
    "part1.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat3D-Part1.csv', index=False)\n",
    "part2.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat3D-Part2.csv', index=False)\n",
    "part3.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat3D-Part3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cat3E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the partitions \n",
    "\n",
    "# Separate into three partitions generic samples (53347, 53347, 53792)\n",
    "generic1 = complete[complete['attack_cat'] == \"generic\"]\n",
    "\n",
    "# Separate into three partitions exploits samples (7123, 7123, 11178) \n",
    "exploits1 = complete[complete['attack_cat'] == \"exploits\"]\n",
    "\n",
    "# Separate into three partitions dos samples (971)\n",
    "dos1 = complete[complete['attack_cat'] == \"dos\"]\n",
    "# Separate into three partitions reconnaissance samples (2971)\n",
    "recon1 = complete[complete['attack_cat'] == \"reconnaissance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UNSW-NB15-Train-Basic-PartN, N = 1,2,3, dataset and export to csv\n",
    "part1 = pd.concat([generic1])\n",
    "part2 = pd.concat([exploits1])\n",
    "part3 = pd.concat([dos1, recon1])\n",
    "part1.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat3E-Part1.csv', index=False)\n",
    "part2.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat3E-Part2.csv', index=False)\n",
    "part3.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Cat3E-Part3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrupted datasets\n",
    "\n",
    "Based on the idea of corrupting a local node's model by performing Label Switching in the creation of the local partition's dataset. The name of the variation includes the percentage of random data switched and the node in which this has been performed. The project doesn't consider more than one node being corrupted, which would cause in the 3 nodes case the majority being corrupted, and in the 5 and 7 nodes case it would complicate more the findings of a robust aggregation function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corr5%13C\n",
    "5% of the samples of node 1 in the variation 3C are affected by label switching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the partitions \n",
    "\n",
    "# Separate into three partitions normal samples (64412)\n",
    "normal1 = complete[complete['label'] == 0].iloc[:64412]\n",
    "normal2 = complete[complete['label'] == 0].iloc[64412:64412*2]\n",
    "normal3 = complete[complete['label'] == 0].iloc[64412*2:64412*3]\n",
    "\n",
    "# Separate into three partitions generic samples (53347, 53347, 53792)\n",
    "generic1 = complete[complete['attack_cat'] == \"generic\"].iloc[:53347]\n",
    "generic2 = complete[complete['attack_cat'] == \"generic\"].iloc[53347:53347*2]\n",
    "generic3 = complete[complete['attack_cat'] == \"generic\"].iloc[53347*2:]\n",
    "\n",
    "# Separate into three partitions exploits samples (7123, 7123, 11178) \n",
    "exploits1 = complete[complete['attack_cat'] == \"exploits\"].iloc[:7123]\n",
    "exploits2 = complete[complete['attack_cat'] == \"exploits\"].iloc[7123:7123*2]\n",
    "exploits3 = complete[complete['attack_cat'] == \"exploits\"].iloc[7123*2:]\n",
    "\n",
    "# Separate into three partitions dos samples (971)\n",
    "dos1 = complete[complete['attack_cat'] == \"dos\"].iloc[:971]\n",
    "dos2 = complete[complete['attack_cat'] == \"dos\"].iloc[971:971*2]\n",
    "dos3 = complete[complete['attack_cat'] == \"dos\"].iloc[971*2:]\n",
    "\n",
    "# Separate into three partitions reconnaissance samples (2971)\n",
    "recon1 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[:2971]\n",
    "recon2 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[2971:2971*2]\n",
    "recon3 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[2971*2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UNSW-NB15-Train-Basic-PartN, N = 1,2,3, dataset and export to csv\n",
    "part1 = pd.concat([normal1, generic1, exploits1, dos1, recon1])\n",
    "part2 = pd.concat([normal2, generic2, exploits2, dos2, recon2])\n",
    "part3 = pd.concat([normal3, generic3, exploits3, dos3, recon3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select 2.5% of samples with label 0 and change their label to 1 and attack_cat to \"generic\"\n",
    "part1_sample_label0 = part1[part1['label'] == 0].sample(frac=0.025, random_state=42)\n",
    "part1_sample_label0['label'] = 1\n",
    "part1_sample_label0['attack_cat'] = \"generic\"\n",
    "\n",
    "# Randomly select 2.5% of samples with label 1 and change their label to 0 and attack_cat to \"normal\"\n",
    "part1_sample_label1 = part1[part1['label'] == 1].sample(frac=0.025, random_state=42)\n",
    "part1_sample_label1['label'] = 0\n",
    "part1_sample_label1['attack_cat'] = \"normal\"\n",
    "\n",
    "# Concatenate the modified parts and the original part1, dropping the modified samples\n",
    "part1_concatenated = pd.concat([part1.drop(part1_sample_label0.index).drop(part1_sample_label1.index), part1_sample_label0, part1_sample_label1])\n",
    "\n",
    "# Shuffle the rows of the concatenated dataframe\n",
    "part1 = part1_concatenated.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "part1.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%13C-Part1.csv', index=False)\n",
    "part2.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%13C-Part2.csv', index=False)\n",
    "part3.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%13C-Part3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corr25%13C\n",
    "25% of the samples of node 1 in the variation 3C are affected by label switching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the partitions \n",
    "\n",
    "# Separate into three partitions normal samples (64412)\n",
    "normal1 = complete[complete['label'] == 0].iloc[:64412]\n",
    "normal2 = complete[complete['label'] == 0].iloc[64412:64412*2]\n",
    "normal3 = complete[complete['label'] == 0].iloc[64412*2:64412*3]\n",
    "\n",
    "# Separate into three partitions generic samples (53347, 53347, 53792)\n",
    "generic1 = complete[complete['attack_cat'] == \"generic\"].iloc[:53347]\n",
    "generic2 = complete[complete['attack_cat'] == \"generic\"].iloc[53347:53347*2]\n",
    "generic3 = complete[complete['attack_cat'] == \"generic\"].iloc[53347*2:]\n",
    "\n",
    "# Separate into three partitions exploits samples (7123, 7123, 11178) \n",
    "exploits1 = complete[complete['attack_cat'] == \"exploits\"].iloc[:7123]\n",
    "exploits2 = complete[complete['attack_cat'] == \"exploits\"].iloc[7123:7123*2]\n",
    "exploits3 = complete[complete['attack_cat'] == \"exploits\"].iloc[7123*2:]\n",
    "\n",
    "# Separate into three partitions dos samples (971)\n",
    "dos1 = complete[complete['attack_cat'] == \"dos\"].iloc[:971]\n",
    "dos2 = complete[complete['attack_cat'] == \"dos\"].iloc[971:971*2]\n",
    "dos3 = complete[complete['attack_cat'] == \"dos\"].iloc[971*2:]\n",
    "\n",
    "# Separate into three partitions reconnaissance samples (2971)\n",
    "recon1 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[:2971]\n",
    "recon2 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[2971:2971*2]\n",
    "recon3 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[2971*2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UNSW-NB15-Train-Basic-PartN, N = 1,2,3, dataset and export to csv\n",
    "part1 = pd.concat([normal1, generic1, exploits1, dos1, recon1])\n",
    "part2 = pd.concat([normal2, generic2, exploits2, dos2, recon2])\n",
    "part3 = pd.concat([normal3, generic3, exploits3, dos3, recon3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select 2.5% of samples with label 0 and change their label to 1 and attack_cat to \"generic\"\n",
    "part1_sample_label0 = part1[part1['label'] == 0].sample(frac=0.125, random_state=42)\n",
    "part1_sample_label0['label'] = 1\n",
    "part1_sample_label0['attack_cat'] = \"generic\"\n",
    "\n",
    "# Randomly select 2.5% of samples with label 1 and change their label to 0 and attack_cat to \"normal\"\n",
    "part1_sample_label1 = part1[part1['label'] == 1].sample(frac=0.125, random_state=42)\n",
    "part1_sample_label1['label'] = 0\n",
    "part1_sample_label1['attack_cat'] = \"normal\"\n",
    "\n",
    "# Concatenate the modified parts and the original part1, dropping the modified samples\n",
    "part1_concatenated = pd.concat([part1.drop(part1_sample_label0.index).drop(part1_sample_label1.index), part1_sample_label0, part1_sample_label1])\n",
    "\n",
    "# Shuffle the rows of the concatenated dataframe\n",
    "part1 = part1_concatenated.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "part1.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%13C-Part1.csv', index=False)\n",
    "part2.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%13C-Part2.csv', index=False)\n",
    "part3.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%13C-Part3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corr50%13C\n",
    "50% of the samples of node 1 in the variation 3C are affected by label switching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the partitions \n",
    "\n",
    "# Separate into three partitions normal samples (64412)\n",
    "normal1 = complete[complete['label'] == 0].iloc[:64412]\n",
    "normal2 = complete[complete['label'] == 0].iloc[64412:64412*2]\n",
    "normal3 = complete[complete['label'] == 0].iloc[64412*2:64412*3]\n",
    "\n",
    "# Separate into three partitions generic samples (53347, 53347, 53792)\n",
    "generic1 = complete[complete['attack_cat'] == \"generic\"].iloc[:53347]\n",
    "generic2 = complete[complete['attack_cat'] == \"generic\"].iloc[53347:53347*2]\n",
    "generic3 = complete[complete['attack_cat'] == \"generic\"].iloc[53347*2:]\n",
    "\n",
    "# Separate into three partitions exploits samples (7123, 7123, 11178) \n",
    "exploits1 = complete[complete['attack_cat'] == \"exploits\"].iloc[:7123]\n",
    "exploits2 = complete[complete['attack_cat'] == \"exploits\"].iloc[7123:7123*2]\n",
    "exploits3 = complete[complete['attack_cat'] == \"exploits\"].iloc[7123*2:]\n",
    "\n",
    "# Separate into three partitions dos samples (971)\n",
    "dos1 = complete[complete['attack_cat'] == \"dos\"].iloc[:971]\n",
    "dos2 = complete[complete['attack_cat'] == \"dos\"].iloc[971:971*2]\n",
    "dos3 = complete[complete['attack_cat'] == \"dos\"].iloc[971*2:]\n",
    "\n",
    "# Separate into three partitions reconnaissance samples (2971)\n",
    "recon1 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[:2971]\n",
    "recon2 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[2971:2971*2]\n",
    "recon3 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[2971*2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UNSW-NB15-Train-Basic-PartN, N = 1,2,3, dataset and export to csv\n",
    "part1 = pd.concat([normal1, generic1, exploits1, dos1, recon1])\n",
    "part2 = pd.concat([normal2, generic2, exploits2, dos2, recon2])\n",
    "part3 = pd.concat([normal3, generic3, exploits3, dos3, recon3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select 2.5% of samples with label 0 and change their label to 1 and attack_cat to \"generic\"\n",
    "part1_sample_label0 = part1[part1['label'] == 0].sample(frac=0.25, random_state=42)\n",
    "part1_sample_label0['label'] = 1\n",
    "part1_sample_label0['attack_cat'] = \"generic\"\n",
    "\n",
    "# Randomly select 2.5% of samples with label 1 and change their label to 0 and attack_cat to \"normal\"\n",
    "part1_sample_label1 = part1[part1['label'] == 1].sample(frac=0.25, random_state=42)\n",
    "part1_sample_label1['label'] = 0\n",
    "part1_sample_label1['attack_cat'] = \"normal\"\n",
    "\n",
    "# Concatenate the modified parts and the original part1, dropping the modified samples\n",
    "part1_concatenated = pd.concat([part1.drop(part1_sample_label0.index).drop(part1_sample_label1.index), part1_sample_label0, part1_sample_label1])\n",
    "\n",
    "# Shuffle the rows of the concatenated dataframe\n",
    "part1 = part1_concatenated.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "part1.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr50%13C-Part1.csv', index=False)\n",
    "part2.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr50%13C-Part2.csv', index=False)\n",
    "part3.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr50%13C-Part3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corr5%23G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the partitions \n",
    "\n",
    "# Separate into three partitions normal samples \n",
    "normal1 = complete[complete['label'] == 0].iloc[:25000]\n",
    "normal2 = complete[complete['label'] == 0].iloc[25000:(25000+68236)]\n",
    "normal3 = complete[complete['label'] == 0].iloc[(25000+68236):(25000+68236+100000)]\n",
    "\n",
    "# Separate into three partitions generic samples \n",
    "generic1 = complete[complete['attack_cat'] == \"generic\"].iloc[:13935]\n",
    "generic2 = complete[complete['attack_cat'] == \"generic\"].iloc[13935:(13935+57171)]\n",
    "generic3 = complete[complete['attack_cat'] == \"generic\"].iloc[(13935+57171):]\n",
    "\n",
    "# Separate into three partitions exploits samples\n",
    "exploits1 = complete[complete['attack_cat'] == \"exploits\"].iloc[:7123]\n",
    "exploits2 = complete[complete['attack_cat'] == \"exploits\"].iloc[7123:(7123*2)]\n",
    "exploits3 = complete[complete['attack_cat'] == \"exploits\"].iloc[(7123*2):]\n",
    "\n",
    "# Separate into three partitions dos samples\n",
    "dos1 = complete[complete['attack_cat'] == \"dos\"].iloc[:971]\n",
    "dos2 = complete[complete['attack_cat'] == \"dos\"].iloc[971:(971*2)]\n",
    "dos3 = complete[complete['attack_cat'] == \"dos\"].iloc[(971*2):]\n",
    "\n",
    "\n",
    "# Separate into three partitions reconnaissance samples\n",
    "recon1 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[:2971]\n",
    "recon2 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[2971:(2971*2)]\n",
    "recon3 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[2971*2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UNSW-NB15-Train-Basic-PartN, N = 1,2,3, dataset and export to csv\n",
    "part1 = pd.concat([normal1, generic1, exploits1, dos1, recon1])\n",
    "part2 = pd.concat([normal2, generic2, exploits2, dos2, recon2])\n",
    "part3 = pd.concat([normal3, generic3, exploits3, recon3, dos3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Randomly select 2.5% of samples with label 0 and change their label to 1 and attack_cat to \"generic\"\n",
    "part2_sample_label0 = part2[part2['label'] == 0].sample(frac=0.025, random_state=42)\n",
    "part2_sample_label0['label'] = 1\n",
    "part2_sample_label0['attack_cat'] = \"generic\"\n",
    "\n",
    "# Randomly select 2.5% of samples with label 1 and change their label to 0 and attack_cat to \"normal\"\n",
    "part2_sample_label1 = part2[part2['label'] == 1].sample(frac=0.025, random_state=42)\n",
    "part2_sample_label1['label'] = 0\n",
    "part2_sample_label1['attack_cat'] = \"normal\"\n",
    "\n",
    "# Concatenate the modified parts and the original part2, dropping the modified samples\n",
    "part2_concatenated = pd.concat([part2.drop(part2_sample_label0.index).drop(part2_sample_label1.index), part2_sample_label0, part2_sample_label1])\n",
    "\n",
    "# Shuffle the rows of the concatenated dataframe\n",
    "part2 = part2_concatenated.sample(frac=1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "part1.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%23G-Part1.csv', index=False)\n",
    "part2.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%23G-Part2.csv', index=False)\n",
    "part3.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%23G-Part3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corr25%23G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the partitions \n",
    "\n",
    "# Separate into three partitions normal samples \n",
    "normal1 = complete[complete['label'] == 0].iloc[:25000]\n",
    "normal2 = complete[complete['label'] == 0].iloc[25000:(25000+68236)]\n",
    "normal3 = complete[complete['label'] == 0].iloc[(25000+68236):(25000+68236+100000)]\n",
    "\n",
    "# Separate into three partitions generic samples \n",
    "generic1 = complete[complete['attack_cat'] == \"generic\"].iloc[:13935]\n",
    "generic2 = complete[complete['attack_cat'] == \"generic\"].iloc[13935:(13935+57171)]\n",
    "generic3 = complete[complete['attack_cat'] == \"generic\"].iloc[(13935+57171):]\n",
    "\n",
    "# Separate into three partitions exploits samples\n",
    "exploits1 = complete[complete['attack_cat'] == \"exploits\"].iloc[:7123]\n",
    "exploits2 = complete[complete['attack_cat'] == \"exploits\"].iloc[7123:(7123*2)]\n",
    "exploits3 = complete[complete['attack_cat'] == \"exploits\"].iloc[(7123*2):]\n",
    "\n",
    "# Separate into three partitions dos samples\n",
    "dos1 = complete[complete['attack_cat'] == \"dos\"].iloc[:971]\n",
    "dos2 = complete[complete['attack_cat'] == \"dos\"].iloc[971:(971*2)]\n",
    "dos3 = complete[complete['attack_cat'] == \"dos\"].iloc[(971*2):]\n",
    "\n",
    "\n",
    "# Separate into three partitions reconnaissance samples\n",
    "recon1 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[:2971]\n",
    "recon2 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[2971:(2971*2)]\n",
    "recon3 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[2971*2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UNSW-NB15-Train-Basic-PartN, N = 1,2,3, dataset and export to csv\n",
    "part1 = pd.concat([normal1, generic1, exploits1, dos1, recon1])\n",
    "part2 = pd.concat([normal2, generic2, exploits2, dos2, recon2])\n",
    "part3 = pd.concat([normal3, generic3, exploits3, recon3, dos3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Randomly select 2.5% of samples with label 0 and change their label to 1 and attack_cat to \"generic\"\n",
    "part2_sample_label0 = part2[part2['label'] == 0].sample(frac=0.125, random_state=42)\n",
    "part2_sample_label0['label'] = 1\n",
    "part2_sample_label0['attack_cat'] = \"generic\"\n",
    "\n",
    "# Randomly select 2.5% of samples with label 1 and change their label to 0 and attack_cat to \"normal\"\n",
    "part2_sample_label1 = part2[part2['label'] == 1].sample(frac=0.125, random_state=42)\n",
    "part2_sample_label1['label'] = 0\n",
    "part2_sample_label1['attack_cat'] = \"normal\"\n",
    "\n",
    "# Concatenate the modified parts and the original part2, dropping the modified samples\n",
    "part2_concatenated = pd.concat([part2.drop(part2_sample_label0.index).drop(part2_sample_label1.index), part2_sample_label0, part2_sample_label1])\n",
    "\n",
    "# Shuffle the rows of the concatenated dataframe\n",
    "part2 = part2_concatenated.sample(frac=1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "part1.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%23G-Part1.csv', index=False)\n",
    "part2.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%23G-Part2.csv', index=False)\n",
    "part3.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%23G-Part3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corr50%23G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the partitions \n",
    "\n",
    "# Separate into three partitions normal samples \n",
    "normal1 = complete[complete['label'] == 0].iloc[:25000]\n",
    "normal2 = complete[complete['label'] == 0].iloc[25000:(25000+68236)]\n",
    "normal3 = complete[complete['label'] == 0].iloc[(25000+68236):(25000+68236+100000)]\n",
    "\n",
    "# Separate into three partitions generic samples \n",
    "generic1 = complete[complete['attack_cat'] == \"generic\"].iloc[:13935]\n",
    "generic2 = complete[complete['attack_cat'] == \"generic\"].iloc[13935:(13935+57171)]\n",
    "generic3 = complete[complete['attack_cat'] == \"generic\"].iloc[(13935+57171):]\n",
    "\n",
    "# Separate into three partitions exploits samples\n",
    "exploits1 = complete[complete['attack_cat'] == \"exploits\"].iloc[:7123]\n",
    "exploits2 = complete[complete['attack_cat'] == \"exploits\"].iloc[7123:(7123*2)]\n",
    "exploits3 = complete[complete['attack_cat'] == \"exploits\"].iloc[(7123*2):]\n",
    "\n",
    "# Separate into three partitions dos samples\n",
    "dos1 = complete[complete['attack_cat'] == \"dos\"].iloc[:971]\n",
    "dos2 = complete[complete['attack_cat'] == \"dos\"].iloc[971:(971*2)]\n",
    "dos3 = complete[complete['attack_cat'] == \"dos\"].iloc[(971*2):]\n",
    "\n",
    "\n",
    "# Separate into three partitions reconnaissance samples\n",
    "recon1 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[:2971]\n",
    "recon2 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[2971:(2971*2)]\n",
    "recon3 = complete[complete['attack_cat'] == \"reconnaissance\"].iloc[2971*2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UNSW-NB15-Train-Basic-PartN, N = 1,2,3, dataset and export to csv\n",
    "part1 = pd.concat([normal1, generic1, exploits1, dos1, recon1])\n",
    "part2 = pd.concat([normal2, generic2, exploits2, dos2, recon2])\n",
    "part3 = pd.concat([normal3, generic3, exploits3, recon3, dos3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Randomly select 2.5% of samples with label 0 and change their label to 1 and attack_cat to \"generic\"\n",
    "part2_sample_label0 = part2[part2['label'] == 0].sample(frac=0.25, random_state=42)\n",
    "part2_sample_label0['label'] = 1\n",
    "part2_sample_label0['attack_cat'] = \"generic\"\n",
    "\n",
    "# Randomly select 2.5% of samples with label 1 and change their label to 0 and attack_cat to \"normal\"\n",
    "part2_sample_label1 = part2[part2['label'] == 1].sample(frac=0.25, random_state=42)\n",
    "part2_sample_label1['label'] = 0\n",
    "part2_sample_label1['attack_cat'] = \"normal\"\n",
    "\n",
    "# Concatenate the modified parts and the original part2, dropping the modified samples\n",
    "part2_concatenated = pd.concat([part2.drop(part2_sample_label0.index).drop(part2_sample_label1.index), part2_sample_label0, part2_sample_label1])\n",
    "\n",
    "# Shuffle the rows of the concatenated dataframe\n",
    "part2 = part2_concatenated.sample(frac=1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "part1.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr50%23G-Part1.csv', index=False)\n",
    "part2.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr50%23G-Part2.csv', index=False)\n",
    "part3.to_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr50%23G-Part3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
