{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated Learning with one corrupted node: geometric median\n",
    "Using one balanced and one unbalanced dataset with one corrupted node (5%, 25% and 50% corrupted samples) to test different aggregation functions and determine the more robust one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Disable warns\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data): \n",
    "\n",
    "    # Select the 'proto' and 'state' values that I want\n",
    "    data = data.loc[(data['proto'] == 'tcp') | (data['proto'] =='udp') | (data['proto'] =='icmp') | (data['proto'] =='arp') | (data['proto'] =='ipv6-icmp') | (data['proto'] =='igmp') | (data['proto'] =='rarp'), :]\n",
    "    data = data.loc[(data['state'] == 'RST') | (data['state'] =='REQ') | (data['state'] =='INT') | (data['state'] =='FIN') | (data['state'] =='CON') | (data['state'] =='ECO') | (data['state'] =='ACC') | (data['state'] == 'PAR'), :]\n",
    "\n",
    "    # Extracting labels \n",
    "    data_labels = data[['label']]\n",
    "\n",
    "    # Drop the invalid features and select interested data features\n",
    "    data_features=data[['proto','srcip','sport','dstip','dsport','spkts','dpkts','sbytes','dbytes','state','stime','ltime','dur']]\n",
    "\n",
    "    \"\"\"PREPROCESSING\"\"\"\n",
    "\n",
    "\n",
    "    # Preprocess IP and ports features\n",
    "    # IP Source Address\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['srcip'] = data_features['srcip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "\n",
    "    # IP Destination Address\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\".\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: x.split(\":\")[-1])\n",
    "    data_features['dstip'] = data_features['dstip'].apply(lambda x: int(x, 16))\n",
    "\n",
    "    # Ports\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: x.replace('0x','') if \"0x\" in str(x) else x)\n",
    "\n",
    "    # Convert all ports with 0 decimal, and HEX to DEC\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['sport'] = data_features['sport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: str(x)[:-2] if str(x)[-2:] == '.0' else str(x))\n",
    "    data_features['dsport'] = data_features['dsport'].apply(lambda x: -1 if str(x).isalpha()==True else int(x,16))\n",
    "\n",
    "    # Convert field to int format\n",
    "    data_features['srcip'] = data_features['srcip'].astype(int)\n",
    "    data_features['sport'] = data_features['sport'].astype(int)\n",
    "    data_features['dstip'] = data_features['dstip'].astype(int)\n",
    "    data_features['dsport'] = data_features['dsport'].astype(int)\n",
    "\n",
    "    # Convert some fields to logarithmic\n",
    "    log1p_col = ['dur', 'sbytes', 'dbytes', 'spkts']\n",
    "\n",
    "    for col in log1p_col:\n",
    "        data_features[col] = data_features[col].apply(np.log1p)\n",
    "\n",
    "    # Create a complementary field of attack & Transform to One hot encoding - LABELS\n",
    "    normal=data_labels['label']\n",
    "    normal=normal.replace(1,2)\n",
    "    normal=normal.replace(0,1)\n",
    "    normal=normal.replace(2,0)\n",
    "\n",
    "    # Insert the new column in data labels\n",
    "    data_labels.insert(1, 'normal', normal)\n",
    "    data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "    data_labels = pd.get_dummies(data_labels)\n",
    "\n",
    "    # Transform to One hot encoding - FEATURES\n",
    "    data_features=pd.get_dummies(data_features)\n",
    "\n",
    "    # Value given for the missing columns\n",
    "    auxCol=0\n",
    "\n",
    "    # As we are using different datasets that might not have all representations, we are going to detect and add the missing columns \n",
    "    # The columns that can have types are: proto and state: need to check if all representations are done \n",
    "    state_cols = [col for col in data_features if col.startswith('state_')]\n",
    "    proto_cols = [col for col in data_features if col.startswith('proto_')]\n",
    "    \n",
    "    # Check if all columns are present\n",
    "    if 'state_PAR' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_PAR', auxCol, True)\n",
    "    if 'state_ACC' not in state_cols: \n",
    "        data_features.insert(data_features.shape[1], 'state_ACC', auxCol, True)\n",
    "    if 'state_ECO' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_ECO', auxCol, True)\n",
    "    if 'state_CON' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_CON', auxCol, True)\n",
    "    if 'state_FIN' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_FIN', auxCol, True)\n",
    "    if 'state_INT' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_INT', auxCol, True)\n",
    "    if 'state_REQ' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_REQ', auxCol, True)\n",
    "    if 'state_RST' not in state_cols:\n",
    "        data_features.insert(data_features.shape[1], 'state_RST', auxCol, True)\n",
    "    if 'proto_igmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_igmp', auxCol, True)\n",
    "    if 'proto_arp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_arp', auxCol, True)\n",
    "    if 'proto_icmp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_icmp', auxCol, True)\n",
    "    if 'proto_udp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_udp', auxCol, True)\n",
    "    if 'proto_tcp' not in proto_cols:\n",
    "        data_features.insert(data_features.shape[1], 'proto_tcp', auxCol, True)\n",
    "\n",
    "    # Normalize all data features\n",
    "    data_features = StandardScaler().fit_transform(data_features)\n",
    "\n",
    "    #Add dimension to data features\n",
    "    data_features = np.expand_dims(data_features, axis=2)\n",
    "    data_features = np.expand_dims(data_features, axis=3)\n",
    "\n",
    "    x = data_features\n",
    "    y = data_labels.to_numpy()\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building and definition\n",
    "def build_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(filters=32,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(1, 2), padding='same'))\n",
    "    model.add(layers.Conv2D(filters=64,  input_shape=input_shape, kernel_size=(1,10), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(1, 2), padding='same'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(Dense(444, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns values of loss, accuracy, f1, precision and recall of model evaluating with test dataset \n",
    "def evaluation(model, x, y): \n",
    "    loss, accuracy = model.evaluate(x, y)\n",
    "    y_pred = model.predict(x)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y = np.argmax(y, axis=1)\n",
    "    report = classification_report(y, y_pred, target_names=['normal', 'attack'], output_dict=True)\n",
    "    # Obtain f1, precision and recall from the report\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    return loss, accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weiszfeld_update(points, tol=1e-5, max_iter=100):\n",
    "    \"\"\"\n",
    "    Compute the geometric median using Weiszfeld's algorithm.\n",
    "\n",
    "    Args:\n",
    "    points: A list of points (numpy arrays) to find the geometric median of.\n",
    "    tol: Tolerance for stopping criterion.\n",
    "    max_iter: Maximum number of iterations.\n",
    "\n",
    "    Returns:\n",
    "    The geometric median of the points.\n",
    "    \"\"\"\n",
    "    points = np.array(points)\n",
    "    median = np.mean(points, axis=0)\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        distances = np.linalg.norm(points - median, axis=1)\n",
    "        nonzero_distances = np.where(distances != 0, distances, np.finfo(float).eps)\n",
    "        weights = 1 / nonzero_distances\n",
    "        new_median = np.sum(points * weights[:, None], axis=0) / np.sum(weights)\n",
    "\n",
    "        if np.linalg.norm(new_median - median) < tol:\n",
    "            return new_median\n",
    "\n",
    "        median = new_median\n",
    "\n",
    "    return median\n",
    "\n",
    "def aggregate(grad_list):\n",
    "    \"\"\"\n",
    "    Apply Geometric Median aggregation method to a list of gradients.\n",
    "\n",
    "    Args:\n",
    "    grad_list: List of gradients from different models. Each element in the list\n",
    "               is a list of gradients for each layer of a model.\n",
    "\n",
    "    Returns:\n",
    "    The geometric median of the gradients.\n",
    "    \"\"\"\n",
    "    # Flatten gradients to compute geometric median\n",
    "    flat_grads = [tf.concat([tf.reshape(g, [-1]) for g in grad], axis=0).numpy() for grad in grad_list]\n",
    "\n",
    "    # Compute geometric median using Weiszfeld's algorithm\n",
    "    flat_median = weiszfeld_update(flat_grads)\n",
    "\n",
    "    # Reshape the flat median back to the original shape\n",
    "    median_grad = []\n",
    "    index = 0\n",
    "    for grad in grad_list[0]:\n",
    "        shape = tf.shape(grad)\n",
    "        size = tf.reduce_prod(shape)\n",
    "        median_grad.append(tf.reshape(flat_median[index:index + size], shape))\n",
    "        index += size\n",
    "\n",
    "    return median_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_2424/3836997398.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n"
     ]
    }
   ],
   "source": [
    "test_basic = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Basic.csv')\n",
    "test_plus = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test+.csv')\n",
    "test_complete = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Test-Complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbasic, ybasic = preprocessing(test_basic)\n",
    "xplus, yplus = preprocessing(test_plus)\n",
    "xcomplete, ycomplete = preprocessing(test_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5A 5% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_2424/3687049449.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_2424/3687049449.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_2424/3687049449.py:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part4.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_2424/3687049449.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15A-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr55Ageo.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 13s 418ms/step - loss: 0.4778 - accuracy: 0.8250 - val_loss: 0.2640 - val_accuracy: 0.8810\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 346ms/step - loss: 0.1970 - accuracy: 0.9489 - val_loss: 0.1787 - val_accuracy: 0.9613\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 323ms/step - loss: 0.1663 - accuracy: 0.9648 - val_loss: 0.1628 - val_accuracy: 0.9633\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 297ms/step - loss: 0.1539 - accuracy: 0.9662 - val_loss: 0.1542 - val_accuracy: 0.9649\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 12s 384ms/step - loss: 0.1465 - accuracy: 0.9675 - val_loss: 0.1489 - val_accuracy: 0.9655\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 14s 442ms/step - loss: 0.0338 - accuracy: 0.9898 - val_loss: 0.3732 - val_accuracy: 0.7678\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 324ms/step - loss: 0.0235 - accuracy: 0.9909 - val_loss: 0.4554 - val_accuracy: 0.6506\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 290ms/step - loss: 0.0220 - accuracy: 0.9917 - val_loss: 0.5191 - val_accuracy: 0.6306\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 308ms/step - loss: 0.0209 - accuracy: 0.9924 - val_loss: 0.4185 - val_accuracy: 0.6698\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 12s 382ms/step - loss: 0.0197 - accuracy: 0.9930 - val_loss: 0.3863 - val_accuracy: 0.7013\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 14s 436ms/step - loss: 0.0194 - accuracy: 0.9926 - val_loss: 0.4341 - val_accuracy: 0.6798\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 312ms/step - loss: 0.0176 - accuracy: 0.9936 - val_loss: 0.3528 - val_accuracy: 0.7528\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 315ms/step - loss: 0.0161 - accuracy: 0.9943 - val_loss: 0.4864 - val_accuracy: 0.7167\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 326ms/step - loss: 0.0157 - accuracy: 0.9946 - val_loss: 0.2765 - val_accuracy: 0.8266\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 318ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.2384 - val_accuracy: 0.8560\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 10s 322ms/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 0.3240 - val_accuracy: 0.8187\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 223ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.2745 - val_accuracy: 0.8439\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 280ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.3373 - val_accuracy: 0.8242\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 307ms/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 0.3678 - val_accuracy: 0.8238\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 295ms/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 0.2640 - val_accuracy: 0.8550\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 9s 290ms/step - loss: 0.0175 - accuracy: 0.9952 - val_loss: 0.4035 - val_accuracy: 0.8081\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 346ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.2851 - val_accuracy: 0.8496\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 301ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 0.4193 - val_accuracy: 0.8083\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 369ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.4875 - val_accuracy: 0.7889\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 360ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.3536 - val_accuracy: 0.8354\n",
      "4279/4279 [==============================] - 32s 8ms/step - loss: 0.0489 - accuracy: 0.9736\n",
      "1721/1721 [==============================] - 17s 10ms/step - loss: 0.4478 - accuracy: 0.7613\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 15s 491ms/step - loss: 0.1967 - accuracy: 0.9665 - val_loss: 0.1624 - val_accuracy: 0.9655\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 347ms/step - loss: 0.1468 - accuracy: 0.9683 - val_loss: 0.1473 - val_accuracy: 0.9660\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 313ms/step - loss: 0.1391 - accuracy: 0.9686 - val_loss: 0.1441 - val_accuracy: 0.9664\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 322ms/step - loss: 0.1375 - accuracy: 0.9686 - val_loss: 0.1431 - val_accuracy: 0.9664\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 12s 394ms/step - loss: 0.1368 - accuracy: 0.9686 - val_loss: 0.1424 - val_accuracy: 0.9664\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 14s 452ms/step - loss: 0.0207 - accuracy: 0.9939 - val_loss: 0.3181 - val_accuracy: 0.8061\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 336ms/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 0.4040 - val_accuracy: 0.7846\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 325ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.4089 - val_accuracy: 0.7964\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 301ms/step - loss: 0.0143 - accuracy: 0.9960 - val_loss: 0.3276 - val_accuracy: 0.8398\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 13s 412ms/step - loss: 0.0139 - accuracy: 0.9960 - val_loss: 0.3723 - val_accuracy: 0.8314\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 15s 468ms/step - loss: 0.0143 - accuracy: 0.9955 - val_loss: 0.3744 - val_accuracy: 0.8228\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 330ms/step - loss: 0.0128 - accuracy: 0.9962 - val_loss: 0.3338 - val_accuracy: 0.8468\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 345ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 0.4466 - val_accuracy: 0.8176\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 333ms/step - loss: 0.0121 - accuracy: 0.9965 - val_loss: 0.3415 - val_accuracy: 0.8506\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 359ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.4483 - val_accuracy: 0.8266\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 357ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.4809 - val_accuracy: 0.8165\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 215ms/step - loss: 0.0127 - accuracy: 0.9964 - val_loss: 0.3689 - val_accuracy: 0.8448\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 326ms/step - loss: 0.0124 - accuracy: 0.9962 - val_loss: 0.4209 - val_accuracy: 0.8348\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 339ms/step - loss: 0.0121 - accuracy: 0.9965 - val_loss: 0.4724 - val_accuracy: 0.8233\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 351ms/step - loss: 0.0119 - accuracy: 0.9966 - val_loss: 0.4996 - val_accuracy: 0.8149\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 376ms/step - loss: 0.0131 - accuracy: 0.9965 - val_loss: 0.4380 - val_accuracy: 0.8334\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 313ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.5107 - val_accuracy: 0.8050\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 351ms/step - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.4312 - val_accuracy: 0.8340\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 340ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.3951 - val_accuracy: 0.8451\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 356ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.3747 - val_accuracy: 0.8491\n",
      "4279/4279 [==============================] - 35s 8ms/step - loss: 0.0599 - accuracy: 0.9738\n",
      "1721/1721 [==============================] - 20s 12ms/step - loss: 0.5274 - accuracy: 0.74800s - loss: 0.5344 - accura\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 377ms/step - loss: 0.2145 - accuracy: 0.9633 - val_loss: 0.1627 - val_accuracy: 0.9637\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 343ms/step - loss: 0.1445 - accuracy: 0.9680 - val_loss: 0.1455 - val_accuracy: 0.9661\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 366ms/step - loss: 0.1372 - accuracy: 0.9685 - val_loss: 0.1430 - val_accuracy: 0.9664\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 13s 424ms/step - loss: 0.1361 - accuracy: 0.9687 - val_loss: 0.1420 - val_accuracy: 0.9664\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 13s 416ms/step - loss: 0.1351 - accuracy: 0.9687 - val_loss: 0.1424 - val_accuracy: 0.9662\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 372ms/step - loss: 0.0182 - accuracy: 0.9945 - val_loss: 0.2556 - val_accuracy: 0.8535\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 349ms/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 0.4031 - val_accuracy: 0.8190\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 310ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.4715 - val_accuracy: 0.8135\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 13s 417ms/step - loss: 0.0125 - accuracy: 0.9964 - val_loss: 0.5043 - val_accuracy: 0.8112\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 13s 410ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.4348 - val_accuracy: 0.8307\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 386ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.4230 - val_accuracy: 0.8294\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 367ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.4914 - val_accuracy: 0.8176\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 291ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.4396 - val_accuracy: 0.8353\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 351ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.4510 - val_accuracy: 0.8338\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 365ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.5369 - val_accuracy: 0.8151\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 10s 309ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.4325 - val_accuracy: 0.8338\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 213ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.4608 - val_accuracy: 0.8318\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 297ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 0.5059 - val_accuracy: 0.8200\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 326ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.3804 - val_accuracy: 0.8484\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 310ms/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.5674 - val_accuracy: 0.8076\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 10s 316ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 0.4872 - val_accuracy: 0.8419\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 206ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.5207 - val_accuracy: 0.8262\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 198ms/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 0.5076 - val_accuracy: 0.8308\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 199ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.5176 - val_accuracy: 0.8233\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 195ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.4262 - val_accuracy: 0.8450\n",
      "4279/4279 [==============================] - 36s 8ms/step - loss: 0.0700 - accuracy: 0.9728\n",
      "1721/1721 [==============================] - 14s 8ms/step - loss: 0.5447 - accuracy: 0.7575\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr55Ageo.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.04889281094074249, 0.4478214681148529], [0.05990856885910034, 0.5273932814598083], [0.07000613957643509, 0.5446551442146301]]\n",
      "Accuracy for iterations:  [[0.9735750555992126, 0.7613165974617004], [0.9738233685493469, 0.7479655742645264], [0.9727862477302551, 0.7575383186340332]]\n",
      "F1 for iterations:  [[0.9735385254940947, 0.7398564684871461], [0.9737850415692508, 0.7234486441670435], [0.9727401086043492, 0.7360250499662067]]\n",
      "Precision for iterations:  [[0.9741483887157147, 0.8220007622883527], [0.9744563735051996, 0.8115405582179294], [0.9735887599953557, 0.8154317890204095]]\n",
      "Recall for iterations:  [[0.973575038709866, 0.7613165734214924], [0.973823366151509, 0.7479655598343384], [0.972786233895235, 0.7575383273995495]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5B 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_2424/2463029928.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part1.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_2424/2463029928.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_2424/2463029928.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_2424/2463029928.py:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part4.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_2424/2463029928.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15A-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr105Ageo.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 13s 420ms/step - loss: 0.4867 - accuracy: 0.8029 - val_loss: 0.2931 - val_accuracy: 0.9085\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 308ms/step - loss: 0.2632 - accuracy: 0.9302 - val_loss: 0.2451 - val_accuracy: 0.9389\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 279ms/step - loss: 0.2410 - accuracy: 0.9404 - val_loss: 0.2314 - val_accuracy: 0.9418\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 393ms/step - loss: 0.2301 - accuracy: 0.9420 - val_loss: 0.2244 - val_accuracy: 0.9426\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 13s 425ms/step - loss: 0.2242 - accuracy: 0.9426 - val_loss: 0.2206 - val_accuracy: 0.9426\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 13s 422ms/step - loss: 0.0360 - accuracy: 0.9896 - val_loss: 0.4871 - val_accuracy: 0.6711\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 315ms/step - loss: 0.0232 - accuracy: 0.9910 - val_loss: 0.4265 - val_accuracy: 0.6665\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 272ms/step - loss: 0.0218 - accuracy: 0.9918 - val_loss: 0.2746 - val_accuracy: 0.8210\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 400ms/step - loss: 0.0210 - accuracy: 0.9923 - val_loss: 0.3119 - val_accuracy: 0.7587\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 13s 415ms/step - loss: 0.0201 - accuracy: 0.9926 - val_loss: 0.3773 - val_accuracy: 0.7030\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 14s 440ms/step - loss: 0.0198 - accuracy: 0.9927 - val_loss: 0.4048 - val_accuracy: 0.6947\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 307ms/step - loss: 0.0176 - accuracy: 0.9938 - val_loss: 0.3800 - val_accuracy: 0.7351\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 298ms/step - loss: 0.0166 - accuracy: 0.9941 - val_loss: 0.4411 - val_accuracy: 0.7284\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 341ms/step - loss: 0.0161 - accuracy: 0.9944 - val_loss: 0.1591 - val_accuracy: 0.9235\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 349ms/step - loss: 0.0155 - accuracy: 0.9948 - val_loss: 0.3522 - val_accuracy: 0.7963\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 10s 329ms/step - loss: 0.0163 - accuracy: 0.9948 - val_loss: 0.2911 - val_accuracy: 0.8294\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 255ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.3809 - val_accuracy: 0.8005\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 262ms/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 0.5195 - val_accuracy: 0.7635\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 295ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.3042 - val_accuracy: 0.8380\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 359ms/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 0.3760 - val_accuracy: 0.8246\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 380ms/step - loss: 0.0171 - accuracy: 0.9954 - val_loss: 0.3133 - val_accuracy: 0.8345\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 335ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 0.3557 - val_accuracy: 0.8259\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 356ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 0.2952 - val_accuracy: 0.8463\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 359ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.5295 - val_accuracy: 0.7792\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 355ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.4453 - val_accuracy: 0.8057\n",
      "4279/4279 [==============================] - 33s 8ms/step - loss: 0.0574 - accuracy: 0.9701\n",
      "1721/1721 [==============================] - 19s 11ms/step - loss: 0.4591 - accuracy: 0.7760\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 402ms/step - loss: 0.3711 - accuracy: 0.9327 - val_loss: 0.2645 - val_accuracy: 0.9365\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 245ms/step - loss: 0.2440 - accuracy: 0.9424 - val_loss: 0.2249 - val_accuracy: 0.9432\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 332ms/step - loss: 0.2245 - accuracy: 0.9433 - val_loss: 0.2187 - val_accuracy: 0.9433\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 13s 431ms/step - loss: 0.2204 - accuracy: 0.9434 - val_loss: 0.2161 - val_accuracy: 0.9434\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 13s 428ms/step - loss: 0.2189 - accuracy: 0.9434 - val_loss: 0.2155 - val_accuracy: 0.9433\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 14s 446ms/step - loss: 0.0259 - accuracy: 0.9936 - val_loss: 0.4519 - val_accuracy: 0.7103\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 243ms/step - loss: 0.0164 - accuracy: 0.9950 - val_loss: 0.3098 - val_accuracy: 0.8149\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 344ms/step - loss: 0.0157 - accuracy: 0.9953 - val_loss: 0.2643 - val_accuracy: 0.8488\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 400ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.3203 - val_accuracy: 0.8361\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 14s 450ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.4962 - val_accuracy: 0.7762\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 14s 451ms/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 0.4225 - val_accuracy: 0.8087\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 256ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 0.4046 - val_accuracy: 0.8189\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 341ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.5777 - val_accuracy: 0.7817\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 357ms/step - loss: 0.0126 - accuracy: 0.9964 - val_loss: 0.3910 - val_accuracy: 0.8325\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 359ms/step - loss: 0.0128 - accuracy: 0.9964 - val_loss: 0.4638 - val_accuracy: 0.8149\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 10s 334ms/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 0.2981 - val_accuracy: 0.8550\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 221ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.2737 - val_accuracy: 0.8644\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 309ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.3414 - val_accuracy: 0.8480\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 366ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.7762 - val_accuracy: 0.7350\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 353ms/step - loss: 0.0135 - accuracy: 0.9962 - val_loss: 0.4272 - val_accuracy: 0.8293\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 403ms/step - loss: 0.0123 - accuracy: 0.9965 - val_loss: 0.3915 - val_accuracy: 0.8335\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 353ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.4662 - val_accuracy: 0.8163\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 348ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.4340 - val_accuracy: 0.8223\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 367ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.3893 - val_accuracy: 0.8390\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 357ms/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.5298 - val_accuracy: 0.7914\n",
      "4279/4279 [==============================] - 36s 8ms/step - loss: 0.0766 - accuracy: 0.9688 0s - loss: 0.076\n",
      "1721/1721 [==============================] - 21s 12ms/step - loss: 0.4517 - accuracy: 0.77090s - loss: 0.4605 - \n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 370ms/step - loss: 0.3660 - accuracy: 0.9332 - val_loss: 0.2506 - val_accuracy: 0.9374\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 342ms/step - loss: 0.2339 - accuracy: 0.9419 - val_loss: 0.2218 - val_accuracy: 0.9433\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 343ms/step - loss: 0.2223 - accuracy: 0.9427 - val_loss: 0.2179 - val_accuracy: 0.9432\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 399ms/step - loss: 0.2192 - accuracy: 0.9431 - val_loss: 0.2159 - val_accuracy: 0.9435\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 14s 440ms/step - loss: 0.2174 - accuracy: 0.9434 - val_loss: 0.2148 - val_accuracy: 0.9433\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 13s 404ms/step - loss: 0.0209 - accuracy: 0.9945 - val_loss: 0.2678 - val_accuracy: 0.8444\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 295ms/step - loss: 0.0142 - accuracy: 0.9960 - val_loss: 0.2911 - val_accuracy: 0.8530\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 312ms/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 0.3220 - val_accuracy: 0.8504\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 398ms/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 0.3620 - val_accuracy: 0.8426\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 13s 435ms/step - loss: 0.0129 - accuracy: 0.9963 - val_loss: 0.4012 - val_accuracy: 0.8350\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 386ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.4402 - val_accuracy: 0.8215\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 352ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 0.5227 - val_accuracy: 0.8034\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 339ms/step - loss: 0.0115 - accuracy: 0.9967 - val_loss: 0.6691 - val_accuracy: 0.7638\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 360ms/step - loss: 0.0114 - accuracy: 0.9967 - val_loss: 0.4675 - val_accuracy: 0.8244\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 362ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 0.3992 - val_accuracy: 0.8441\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 260ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.4363 - val_accuracy: 0.8308\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 244ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.3369 - val_accuracy: 0.8548\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 300ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 0.4300 - val_accuracy: 0.8347\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 338ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.4900 - val_accuracy: 0.8152\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 339ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.4152 - val_accuracy: 0.8393\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 10s 337ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 0.5136 - val_accuracy: 0.8226\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 219ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.6131 - val_accuracy: 0.7887\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 216ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.4731 - val_accuracy: 0.8268\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 219ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.5004 - val_accuracy: 0.8191\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 215ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.4803 - val_accuracy: 0.8272\n",
      "4279/4279 [==============================] - 41s 9ms/step - loss: 0.0698 - accuracy: 0.9717\n",
      "1721/1721 [==============================] - 14s 8ms/step - loss: 0.3088 - accuracy: 0.8326\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr105Ageo.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.05741056054830551, 0.4590655267238617], [0.07663948088884354, 0.45165905356407166], [0.06982630491256714, 0.3087761104106903]]\n",
      "Accuracy for iterations:  [[0.970149576663971, 0.7760117650032043], [0.9688495397567749, 0.770943820476532], [0.971741795539856, 0.8325583338737488]]\n",
      "F1 for iterations:  [[0.9700949410282225, 0.7582688345798568], [0.9687809597016985, 0.751831152230553], [0.971691480828758, 0.8248670942131826]]\n",
      "Precision for iterations:  [[0.9710471170781172, 0.8298399379845439], [0.9700489101010882, 0.8278210977491526], [0.9726070256090559, 0.8635768653781645]]\n",
      "Recall for iterations:  [[0.9701495807648485, 0.7760117706895299], [0.9688495135703643, 0.7709438349197123], [0.9717417978906775, 0.8325583085083194]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5B 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_2424/3855986297.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_2424/3855986297.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_2424/3855986297.py:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part4.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_2424/3855986297.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15A-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr255Ageo.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 264ms/step - loss: 0.4617 - accuracy: 0.8634 - val_loss: 0.2182 - val_accuracy: 0.9276\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 301ms/step - loss: 0.1508 - accuracy: 0.9629 - val_loss: 0.1238 - val_accuracy: 0.9755\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 12s 382ms/step - loss: 0.1166 - accuracy: 0.9771 - val_loss: 0.1093 - val_accuracy: 0.9776\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 13s 418ms/step - loss: 0.1038 - accuracy: 0.9791 - val_loss: 0.1026 - val_accuracy: 0.9787\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 13s 417ms/step - loss: 0.0988 - accuracy: 0.9798 - val_loss: 0.1013 - val_accuracy: 0.9787\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 10s 337ms/step - loss: 0.0336 - accuracy: 0.9899 - val_loss: 0.4402 - val_accuracy: 0.7092\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 9s 305ms/step - loss: 0.0230 - accuracy: 0.9907 - val_loss: 0.3895 - val_accuracy: 0.6843\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 12s 399ms/step - loss: 0.0213 - accuracy: 0.9919 - val_loss: 0.3833 - val_accuracy: 0.6799\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 13s 414ms/step - loss: 0.0206 - accuracy: 0.9927 - val_loss: 0.3726 - val_accuracy: 0.6942\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 12s 393ms/step - loss: 0.0195 - accuracy: 0.9935 - val_loss: 0.2991 - val_accuracy: 0.7765\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 356ms/step - loss: 0.0196 - accuracy: 0.9928 - val_loss: 0.3844 - val_accuracy: 0.7184\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 261ms/step - loss: 0.0170 - accuracy: 0.9940 - val_loss: 0.3924 - val_accuracy: 0.7383\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 263ms/step - loss: 0.0160 - accuracy: 0.9946 - val_loss: 0.2192 - val_accuracy: 0.8647\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 302ms/step - loss: 0.0153 - accuracy: 0.9949 - val_loss: 0.3091 - val_accuracy: 0.8157\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 320ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.2901 - val_accuracy: 0.8321\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 346ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.2564 - val_accuracy: 0.8490\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 255ms/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 0.4427 - val_accuracy: 0.7909\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 223ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.4030 - val_accuracy: 0.8116\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 288ms/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 0.3632 - val_accuracy: 0.8240\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 336ms/step - loss: 0.0139 - accuracy: 0.9959 - val_loss: 0.2803 - val_accuracy: 0.8533\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 13s 422ms/step - loss: 0.0178 - accuracy: 0.9949 - val_loss: 0.2723 - val_accuracy: 0.8482\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 366ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.4403 - val_accuracy: 0.7949\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 323ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 0.3620 - val_accuracy: 0.8295\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 326ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.6327 - val_accuracy: 0.7426\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 10s 325ms/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 0.3939 - val_accuracy: 0.8226\n",
      "4279/4279 [==============================] - 37s 9ms/step - loss: 0.0460 - accuracy: 0.9753\n",
      "1721/1721 [==============================] - 19s 11ms/step - loss: 0.3030 - accuracy: 0.8548\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 382ms/step - loss: 0.1265 - accuracy: 0.9791 - val_loss: 0.1045 - val_accuracy: 0.9796\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 365ms/step - loss: 0.0966 - accuracy: 0.9804 - val_loss: 0.0966 - val_accuracy: 0.9798\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 343ms/step - loss: 0.0924 - accuracy: 0.9806 - val_loss: 0.0943 - val_accuracy: 0.9798\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 391ms/step - loss: 0.0910 - accuracy: 0.9806 - val_loss: 0.0943 - val_accuracy: 0.9797\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 13s 415ms/step - loss: 0.0902 - accuracy: 0.9806 - val_loss: 0.0926 - val_accuracy: 0.9798\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 381ms/step - loss: 0.0202 - accuracy: 0.9943 - val_loss: 0.3431 - val_accuracy: 0.7845\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 12s 390ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 0.3275 - val_accuracy: 0.8135\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 337ms/step - loss: 0.0147 - accuracy: 0.9957 - val_loss: 0.3987 - val_accuracy: 0.7909\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 341ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.4252 - val_accuracy: 0.7905\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 11s 357ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.3438 - val_accuracy: 0.8336\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 357ms/step - loss: 0.0140 - accuracy: 0.9960 - val_loss: 0.4142 - val_accuracy: 0.8121\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 319ms/step - loss: 0.0127 - accuracy: 0.9964 - val_loss: 0.4481 - val_accuracy: 0.8107\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 324ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.3396 - val_accuracy: 0.8517\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 263ms/step - loss: 0.0126 - accuracy: 0.9964 - val_loss: 0.5229 - val_accuracy: 0.8011\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 227ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.4590 - val_accuracy: 0.8218\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 349ms/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.4416 - val_accuracy: 0.8248\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 308ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.4212 - val_accuracy: 0.8303\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 330ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.4238 - val_accuracy: 0.8327\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 255ms/step - loss: 0.0122 - accuracy: 0.9962 - val_loss: 0.3122 - val_accuracy: 0.8620\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 262ms/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 0.4753 - val_accuracy: 0.8264\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 15s 478ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 0.4620 - val_accuracy: 0.8286\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 13s 434ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.4386 - val_accuracy: 0.8343\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 13s 406ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 0.4393 - val_accuracy: 0.8327\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 11s 355ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.5150 - val_accuracy: 0.8094\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 302ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.4398 - val_accuracy: 0.8293\n",
      "4279/4279 [==============================] - 38s 9ms/step - loss: 0.0596 - accuracy: 0.9726 0s - loss: 0.0597 - accura\n",
      "1721/1721 [==============================] - 13s 7ms/step - loss: 0.4718 - accuracy: 0.7663\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 15s 487ms/step - loss: 0.1271 - accuracy: 0.9791 - val_loss: 0.1011 - val_accuracy: 0.9790\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 13s 430ms/step - loss: 0.0939 - accuracy: 0.9806 - val_loss: 0.0950 - val_accuracy: 0.9797\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 13s 431ms/step - loss: 0.0906 - accuracy: 0.9806 - val_loss: 0.0931 - val_accuracy: 0.9798\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 10s 336ms/step - loss: 0.0892 - accuracy: 0.9806 - val_loss: 0.0919 - val_accuracy: 0.9798\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 265ms/step - loss: 0.0882 - accuracy: 0.9807 - val_loss: 0.0910 - val_accuracy: 0.9798\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 15s 485ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.2863 - val_accuracy: 0.8499\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 13s 433ms/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 0.3566 - val_accuracy: 0.8341\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 13s 420ms/step - loss: 0.0128 - accuracy: 0.9962 - val_loss: 0.4320 - val_accuracy: 0.8245\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 9s 291ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.4774 - val_accuracy: 0.8095\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 256ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 0.5073 - val_accuracy: 0.8149\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 362ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.5094 - val_accuracy: 0.8090\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 328ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.3823 - val_accuracy: 0.8497\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 333ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.5845 - val_accuracy: 0.7938\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 241ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.5406 - val_accuracy: 0.8189\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 213ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.5068 - val_accuracy: 0.8281\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 12s 391ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.5058 - val_accuracy: 0.8247\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 10s 316ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.7076 - val_accuracy: 0.7663\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 319ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.6970 - val_accuracy: 0.7812\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 218ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.5332 - val_accuracy: 0.8188\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 237ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.6295 - val_accuracy: 0.7987\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 9s 292ms/step - loss: 0.0120 - accuracy: 0.9966 - val_loss: 0.5441 - val_accuracy: 0.8284\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 272ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.5614 - val_accuracy: 0.8211\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 289ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.4690 - val_accuracy: 0.8420\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 207ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.5852 - val_accuracy: 0.8165\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 188ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.3744 - val_accuracy: 0.8548\n",
      "4279/4279 [==============================] - 16s 4ms/step - loss: 0.0527 - accuracy: 0.9758\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.3359 - accuracy: 0.8447\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr255Ageo.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.045988935977220535, 0.30304765701293945], [0.05962508171796799, 0.47183671593666077], [0.052721574902534485, 0.33591940999031067]]\n",
      "Accuracy for iterations:  [[0.9753279089927673, 0.8548281788825989], [0.9726255536079407, 0.7662755250930786], [0.975846529006958, 0.8447467684745789]]\n",
      "F1 for iterations:  [[0.9752996501961515, 0.8497638865929611], [0.9725824306937283, 0.7458750322544874], [0.9758194239809572, 0.8385634886002252]]\n",
      "Precision for iterations:  [[0.9757488527705024, 0.8775109729448786], [0.9733359605589635, 0.825845210382415], [0.9762527430319973, 0.8712136934730742]]\n",
      "Recall for iterations:  [[0.9753279382979345, 0.8548281624645789], [0.9726255514329954, 0.7662755213252924], [0.9758465044260715, 0.8447467848579525]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5B 5% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_18408/3503541895.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_18408/3503541895.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_18408/3503541895.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15B-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr55Bgeo.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 258ms/step - loss: 0.4721 - accuracy: 0.8053 - val_loss: 0.2419 - val_accuracy: 0.9303\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 261ms/step - loss: 0.1975 - accuracy: 0.9519 - val_loss: 0.1725 - val_accuracy: 0.9627\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 250ms/step - loss: 0.1680 - accuracy: 0.9649 - val_loss: 0.1596 - val_accuracy: 0.9647\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 14s 452ms/step - loss: 0.1544 - accuracy: 0.9665 - val_loss: 0.1509 - val_accuracy: 0.9660\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 23s 734ms/step - loss: 0.1469 - accuracy: 0.9675 - val_loss: 0.1460 - val_accuracy: 0.9660\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 236ms/step - loss: 0.0317 - accuracy: 0.9905 - val_loss: 0.2953 - val_accuracy: 0.8311\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 18s 583ms/step - loss: 0.0230 - accuracy: 0.9912 - val_loss: 0.3854 - val_accuracy: 0.6841\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 246ms/step - loss: 0.0215 - accuracy: 0.9921 - val_loss: 0.4476 - val_accuracy: 0.6564\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 245ms/step - loss: 0.0204 - accuracy: 0.9927 - val_loss: 0.2824 - val_accuracy: 0.7850\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 14s 462ms/step - loss: 0.0195 - accuracy: 0.9929 - val_loss: 0.4092 - val_accuracy: 0.7030\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 238ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 4.8560 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 245ms/step - loss: 2.5228e-07 - accuracy: 1.0000 - val_loss: 5.1928 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 234ms/step - loss: 1.9184e-07 - accuracy: 1.0000 - val_loss: 5.2112 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 374ms/step - loss: 1.8900e-07 - accuracy: 1.0000 - val_loss: 5.2135 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 21s 680ms/step - loss: 1.8806e-07 - accuracy: 1.0000 - val_loss: 5.2152 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 245ms/step - loss: 4.5838 - accuracy: 0.4295 - val_loss: 0.0456 - val_accuracy: 0.9909\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 247ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 20s 650ms/step - loss: 9.1257e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 20s 653ms/step - loss: 6.8715e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 22s 714ms/step - loss: 5.4921e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 43s 1s/step - loss: 1.6517 - accuracy: 0.6779 - val_loss: 0.7134 - val_accuracy: 0.6312\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 16s 505ms/step - loss: 0.0375 - accuracy: 0.9944 - val_loss: 0.5945 - val_accuracy: 0.6382\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 16s 503ms/step - loss: 0.0219 - accuracy: 0.9942 - val_loss: 0.5855 - val_accuracy: 0.6383\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 245ms/step - loss: 0.0202 - accuracy: 0.9943 - val_loss: 0.5959 - val_accuracy: 0.6380\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 19s 608ms/step - loss: 0.0191 - accuracy: 0.9943 - val_loss: 0.5860 - val_accuracy: 0.6379\n",
      "4279/4279 [==============================] - 25s 6ms/step - loss: 0.1149 - accuracy: 0.9255\n",
      "1721/1721 [==============================] - 23s 13ms/step - loss: 0.2471 - accuracy: 0.85450s - loss:\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 15s 483ms/step - loss: 0.1502 - accuracy: 0.9666 - val_loss: 0.1439 - val_accuracy: 0.9657\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 17s 546ms/step - loss: 0.1405 - accuracy: 0.9675 - val_loss: 0.1422 - val_accuracy: 0.9660\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 24s 783ms/step - loss: 0.1385 - accuracy: 0.9675 - val_loss: 0.1420 - val_accuracy: 0.9660\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 400ms/step - loss: 0.1377 - accuracy: 0.9676 - val_loss: 0.1416 - val_accuracy: 0.9659\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 259ms/step - loss: 0.1371 - accuracy: 0.9678 - val_loss: 0.1414 - val_accuracy: 0.9664\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 11s 358ms/step - loss: 0.0225 - accuracy: 0.9933 - val_loss: 0.2602 - val_accuracy: 0.8141\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 236ms/step - loss: 0.0190 - accuracy: 0.9940 - val_loss: 0.4004 - val_accuracy: 0.7315\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 242ms/step - loss: 0.0179 - accuracy: 0.9940 - val_loss: 0.3363 - val_accuracy: 0.7773\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 260ms/step - loss: 0.0169 - accuracy: 0.9943 - val_loss: 0.2750 - val_accuracy: 0.8126\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 255ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.2706 - val_accuracy: 0.8189\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 249ms/step - loss: 0.0133 - accuracy: 0.9943 - val_loss: 4.4008 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 23s 734ms/step - loss: 5.2401e-07 - accuracy: 1.0000 - val_loss: 4.7341 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 10s 313ms/step - loss: 3.9638e-07 - accuracy: 1.0000 - val_loss: 4.7525 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 249ms/step - loss: 3.8948e-07 - accuracy: 1.0000 - val_loss: 4.7551 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 240ms/step - loss: 3.8754e-07 - accuracy: 1.0000 - val_loss: 4.7572 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 242ms/step - loss: 4.6507 - accuracy: 0.4506 - val_loss: 0.1439 - val_accuracy: 0.9021\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 356ms/step - loss: 0.0241 - accuracy: 0.9909 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 20s 649ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 23s 753ms/step - loss: 7.7434e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 18s 580ms/step - loss: 5.3926e-04 - accuracy: 1.0000 - val_loss: 7.8201e-04 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 17s 546ms/step - loss: 1.4308 - accuracy: 0.7165 - val_loss: 0.7989 - val_accuracy: 0.6649\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 21s 688ms/step - loss: 0.0232 - accuracy: 0.9947 - val_loss: 0.4794 - val_accuracy: 0.7100\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 11s 349ms/step - loss: 0.0167 - accuracy: 0.9943 - val_loss: 0.5298 - val_accuracy: 0.6988\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 12s 395ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 0.5434 - val_accuracy: 0.6963\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 25s 806ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 0.5437 - val_accuracy: 0.6962\n",
      "4279/4279 [==============================] - 24s 6ms/step - loss: 0.1036 - accuracy: 0.9423\n",
      "1721/1721 [==============================] - 10s 6ms/step - loss: 0.3014 - accuracy: 0.8315\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 9s 298ms/step - loss: 0.1435 - accuracy: 0.9675 - val_loss: 0.1414 - val_accuracy: 0.9660\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 274ms/step - loss: 0.1369 - accuracy: 0.9680 - val_loss: 0.1414 - val_accuracy: 0.9662\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 16s 501ms/step - loss: 0.1359 - accuracy: 0.9681 - val_loss: 0.1407 - val_accuracy: 0.9666\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 28s 908ms/step - loss: 0.1354 - accuracy: 0.9684 - val_loss: 0.1400 - val_accuracy: 0.9667\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 13s 424ms/step - loss: 0.1349 - accuracy: 0.9685 - val_loss: 0.1400 - val_accuracy: 0.9666\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 14s 443ms/step - loss: 0.0207 - accuracy: 0.9941 - val_loss: 0.2699 - val_accuracy: 0.8149\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 13s 419ms/step - loss: 0.0174 - accuracy: 0.9946 - val_loss: 0.2832 - val_accuracy: 0.8110\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 29s 950ms/step - loss: 0.0161 - accuracy: 0.9948 - val_loss: 0.2961 - val_accuracy: 0.8105\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 26s 837ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.3471 - val_accuracy: 0.8030\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 28s 901ms/step - loss: 0.0151 - accuracy: 0.9954 - val_loss: 0.3716 - val_accuracy: 0.8054\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 23s 758ms/step - loss: 0.0238 - accuracy: 0.9899 - val_loss: 3.9339 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 364ms/step - loss: 1.6883e-06 - accuracy: 1.0000 - val_loss: 4.2941 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 16s 528ms/step - loss: 1.2205e-06 - accuracy: 1.0000 - val_loss: 4.3161 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 263ms/step - loss: 1.1913e-06 - accuracy: 1.0000 - val_loss: 4.3212 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 248ms/step - loss: 1.1778e-06 - accuracy: 1.0000 - val_loss: 4.3261 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 252ms/step - loss: 3.8114 - accuracy: 0.5409 - val_loss: 0.0668 - val_accuracy: 0.9799\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 23s 753ms/step - loss: 0.0059 - accuracy: 0.9998 - val_loss: 0.0086 - val_accuracy: 0.9990\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 12s 401ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9994\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 249ms/step - loss: 8.1729e-04 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9995\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 21s 675ms/step - loss: 5.3506e-04 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9996\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 236ms/step - loss: 0.4738 - accuracy: 0.8721 - val_loss: 1.1687 - val_accuracy: 0.6647\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 250ms/step - loss: 0.0178 - accuracy: 0.9953 - val_loss: 0.7158 - val_accuracy: 0.7139\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 9s 303ms/step - loss: 0.0149 - accuracy: 0.9955 - val_loss: 0.6116 - val_accuracy: 0.7343\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 25s 791ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.5273 - val_accuracy: 0.7553\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 22s 717ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.5174 - val_accuracy: 0.7579\n",
      "4279/4279 [==============================] - 20s 5ms/step - loss: 0.0867 - accuracy: 0.9570\n",
      "1721/1721 [==============================] - 9s 5ms/step - loss: 0.3657 - accuracy: 0.8112\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr55Bgeo.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.11491592228412628, 0.24709856510162354], [0.10359504073858261, 0.30141469836235046], [0.08666576445102692, 0.365721732378006]]\n",
      "Accuracy for iterations:  [[0.9255090951919556, 0.8544648885726929], [0.9423003792762756, 0.8314865827560425], [0.9570101499557495, 0.8111603856086731]]\n",
      "F1 for iterations:  [[0.9248198198004561, 0.8493405193344246], [0.9419529878843841, 0.8237084306097469], [0.9568479638750795, 0.8002756404314799]]\n",
      "Precision for iterations:  [[0.9337741252821732, 0.8774352711870831], [0.9471440452961941, 0.862565997012988], [0.9596152895107926, 0.8506515144349549]]\n",
      "Recall for iterations:  [[0.9255090712553683, 0.8544648695778536], [0.9423003885594087, 0.8314865944924799], [0.9570101376026177, 0.8111603574802005]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5B 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16896/2097221778.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part1.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16896/2097221778.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16896/2097221778.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16896/2097221778.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15B-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr105Bgeo.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 4s 138ms/step - loss: 0.4904 - accuracy: 0.8183 - val_loss: 0.2862 - val_accuracy: 0.9218\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.2706 - accuracy: 0.9273 - val_loss: 0.2487 - val_accuracy: 0.9396\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 138ms/step - loss: 0.2459 - accuracy: 0.9391 - val_loss: 0.2341 - val_accuracy: 0.9417\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 135ms/step - loss: 0.2323 - accuracy: 0.9412 - val_loss: 0.2234 - val_accuracy: 0.9429\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 137ms/step - loss: 0.2236 - accuracy: 0.9424 - val_loss: 0.2185 - val_accuracy: 0.9433\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.0379 - accuracy: 0.9899 - val_loss: 0.3268 - val_accuracy: 0.8140\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 143ms/step - loss: 0.0239 - accuracy: 0.9909 - val_loss: 0.3649 - val_accuracy: 0.7392\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 138ms/step - loss: 0.0224 - accuracy: 0.9918 - val_loss: 0.2432 - val_accuracy: 0.8682\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 136ms/step - loss: 0.0214 - accuracy: 0.9924 - val_loss: 0.2858 - val_accuracy: 0.8011\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 0.0207 - accuracy: 0.9928 - val_loss: 0.4167 - val_accuracy: 0.6899\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 4.1308 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 1.4399e-06 - accuracy: 1.0000 - val_loss: 4.4510 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 1.0753e-06 - accuracy: 1.0000 - val_loss: 4.4717 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 143ms/step - loss: 1.0500e-06 - accuracy: 1.0000 - val_loss: 4.4776 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 1.0358e-06 - accuracy: 1.0000 - val_loss: 4.4837 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 3.7130 - accuracy: 0.4824 - val_loss: 0.0165 - val_accuracy: 0.9975\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 151ms/step - loss: 7.1951e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 4.9142e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 3.1672e-04 - accuracy: 1.0000 - val_loss: 8.5004e-04 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 216ms/step - loss: 1.6130 - accuracy: 0.6911 - val_loss: 0.7662 - val_accuracy: 0.6345\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 199ms/step - loss: 0.0398 - accuracy: 0.9942 - val_loss: 0.5920 - val_accuracy: 0.6381\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 205ms/step - loss: 0.0231 - accuracy: 0.9942 - val_loss: 0.5676 - val_accuracy: 0.6384\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 197ms/step - loss: 0.0214 - accuracy: 0.9942 - val_loss: 0.5859 - val_accuracy: 0.6381\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 202ms/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 0.5825 - val_accuracy: 0.6378\n",
      "4279/4279 [==============================] - 32s 8ms/step - loss: 0.1147 - accuracy: 0.9250\n",
      "1721/1721 [==============================] - 14s 8ms/step - loss: 0.2322 - accuracy: 0.8733\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 215ms/step - loss: 0.2312 - accuracy: 0.9417 - val_loss: 0.2164 - val_accuracy: 0.9433\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 210ms/step - loss: 0.2190 - accuracy: 0.9425 - val_loss: 0.2146 - val_accuracy: 0.9433\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 203ms/step - loss: 0.2174 - accuracy: 0.9425 - val_loss: 0.2147 - val_accuracy: 0.9431\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 208ms/step - loss: 0.2166 - accuracy: 0.9426 - val_loss: 0.2154 - val_accuracy: 0.9431\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 206ms/step - loss: 0.2166 - accuracy: 0.9427 - val_loss: 0.2134 - val_accuracy: 0.9435\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 218ms/step - loss: 0.0248 - accuracy: 0.9929 - val_loss: 0.2844 - val_accuracy: 0.7975\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 208ms/step - loss: 0.0200 - accuracy: 0.9938 - val_loss: 0.3842 - val_accuracy: 0.7259\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 209ms/step - loss: 0.0189 - accuracy: 0.9940 - val_loss: 0.4059 - val_accuracy: 0.7301\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 195ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.3674 - val_accuracy: 0.7666\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 203ms/step - loss: 0.0171 - accuracy: 0.9944 - val_loss: 0.3887 - val_accuracy: 0.7736\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 0.0100 - accuracy: 0.9960 - val_loss: 4.0571 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 1.5012e-06 - accuracy: 1.0000 - val_loss: 4.3522 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 135ms/step - loss: 1.1577e-06 - accuracy: 1.0000 - val_loss: 4.3710 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 138ms/step - loss: 1.1327e-06 - accuracy: 1.0000 - val_loss: 4.3763 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 134ms/step - loss: 1.1194e-06 - accuracy: 1.0000 - val_loss: 4.3816 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 3.9911 - accuracy: 0.4603 - val_loss: 0.0820 - val_accuracy: 0.9800\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 4s 143ms/step - loss: 9.3771e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 6.8118e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 5.3618e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 4s 145ms/step - loss: 1.3872 - accuracy: 0.7285 - val_loss: 0.6116 - val_accuracy: 0.6691\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.0255 - accuracy: 0.9946 - val_loss: 0.5478 - val_accuracy: 0.6747\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.4877 - val_accuracy: 0.6854\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.0172 - accuracy: 0.9943 - val_loss: 0.5066 - val_accuracy: 0.6816\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 4s 144ms/step - loss: 0.0169 - accuracy: 0.9943 - val_loss: 0.5201 - val_accuracy: 0.6803\n",
      "4279/4279 [==============================] - 29s 7ms/step - loss: 0.0996 - accuracy: 0.9408\n",
      "1721/1721 [==============================] - 8s 5ms/step - loss: 0.2595 - accuracy: 0.8528\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.2317 - accuracy: 0.9421 - val_loss: 0.2152 - val_accuracy: 0.9431\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.2174 - accuracy: 0.9425 - val_loss: 0.2133 - val_accuracy: 0.9435\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 0.2162 - accuracy: 0.9429 - val_loss: 0.2129 - val_accuracy: 0.9435\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 164ms/step - loss: 0.2160 - accuracy: 0.9432 - val_loss: 0.2128 - val_accuracy: 0.9435\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 159ms/step - loss: 0.2156 - accuracy: 0.9432 - val_loss: 0.2136 - val_accuracy: 0.9435\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 172ms/step - loss: 0.0244 - accuracy: 0.9935 - val_loss: 0.3701 - val_accuracy: 0.7436\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 153ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.2791 - val_accuracy: 0.8070\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0175 - accuracy: 0.9946 - val_loss: 0.3513 - val_accuracy: 0.7834\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 170ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.3594 - val_accuracy: 0.7920\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 0.3541 - val_accuracy: 0.8048\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 6s 180ms/step - loss: 0.0160 - accuracy: 0.9938 - val_loss: 3.5346 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 185ms/step - loss: 5.5548e-06 - accuracy: 1.0000 - val_loss: 3.8401 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 168ms/step - loss: 4.2033e-06 - accuracy: 1.0000 - val_loss: 3.8668 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 183ms/step - loss: 4.0325e-06 - accuracy: 1.0000 - val_loss: 3.8808 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 186ms/step - loss: 3.8983e-06 - accuracy: 1.0000 - val_loss: 3.8957 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 171ms/step - loss: 3.4538 - accuracy: 0.4767 - val_loss: 0.1314 - val_accuracy: 0.9696\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 6s 189ms/step - loss: 0.0188 - accuracy: 0.9999 - val_loss: 0.0098 - val_accuracy: 0.9981\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 181ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 169ms/step - loss: 9.7945e-04 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 177ms/step - loss: 5.7254e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 165ms/step - loss: 0.7455 - accuracy: 0.8098 - val_loss: 0.7603 - val_accuracy: 0.6715\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 5s 162ms/step - loss: 0.0199 - accuracy: 0.9948 - val_loss: 0.6112 - val_accuracy: 0.6902\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 171ms/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 0.5381 - val_accuracy: 0.7050\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.5503 - val_accuracy: 0.7027\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 184ms/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 0.5323 - val_accuracy: 0.7085\n",
      "4279/4279 [==============================] - 15s 4ms/step - loss: 0.0941 - accuracy: 0.9484\n",
      "1721/1721 [==============================] - 6s 3ms/step - loss: 0.2622 - accuracy: 0.8647\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr105Bgeo.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.11470375955104828, 0.23222364485263824], [0.09963300824165344, 0.259491503238678], [0.09414619952440262, 0.26222124695777893]]\n",
      "Accuracy for iterations:  [[0.9249832034111023, 0.8733197450637817], [0.9408031105995178, 0.8527936935424805], [0.9483625292778015, 0.8646552562713623]]\n",
      "F1 for iterations:  [[0.9242816503937178, 0.8698344379594948], [0.940434626040827, 0.8475370303696735], [0.948103720135536, 0.8604375955006761]]\n",
      "Precision for iterations:  [[0.9333531466382072, 0.8905279448236121], [0.9458517835799812, 0.8760728745656486], [0.9521770208609084, 0.8846596668569583]]\n",
      "Recall for iterations:  [[0.9249832013789476, 0.8733197703988956], [0.9408031201612668, 0.8527937222989174], [0.9483624996348126, 0.8646552350504977]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5B 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16896/3291834707.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part1.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16896/3291834707.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part2.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16896/3291834707.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part3.csv')\n",
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16896/3291834707.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15B-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr255Bgeo.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 5s 145ms/step - loss: 0.5577 - accuracy: 0.7447 - val_loss: 0.4328 - val_accuracy: 0.8525\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.4210 - accuracy: 0.8598 - val_loss: 0.4024 - val_accuracy: 0.8689\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.4061 - accuracy: 0.8665 - val_loss: 0.3930 - val_accuracy: 0.8697\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 6s 192ms/step - loss: 0.3973 - accuracy: 0.8676 - val_loss: 0.3893 - val_accuracy: 0.8705\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 6s 194ms/step - loss: 0.3939 - accuracy: 0.8684 - val_loss: 0.3869 - val_accuracy: 0.8705\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 0.0492 - accuracy: 0.9897 - val_loss: 0.5851 - val_accuracy: 0.6476\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 11s 345ms/step - loss: 0.0242 - accuracy: 0.9911 - val_loss: 0.4860 - val_accuracy: 0.6481\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 6s 194ms/step - loss: 0.0224 - accuracy: 0.9916 - val_loss: 0.2838 - val_accuracy: 0.8049\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.0214 - accuracy: 0.9919 - val_loss: 0.3354 - val_accuracy: 0.7367\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 5s 161ms/step - loss: 0.0204 - accuracy: 0.9929 - val_loss: 0.3569 - val_accuracy: 0.7147\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 33s 1s/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 4.3393 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 34s 1s/step - loss: 8.1073e-07 - accuracy: 1.0000 - val_loss: 4.6543 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 15s 495ms/step - loss: 6.1338e-07 - accuracy: 1.0000 - val_loss: 4.6729 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 269ms/step - loss: 6.0182e-07 - accuracy: 1.0000 - val_loss: 4.6768 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 252ms/step - loss: 5.9664e-07 - accuracy: 1.0000 - val_loss: 4.6804 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 233ms/step - loss: 3.9921 - accuracy: 0.4439 - val_loss: 0.0416 - val_accuracy: 0.9910\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 239ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 242ms/step - loss: 8.2845e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 242ms/step - loss: 4.7482e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 244ms/step - loss: 2.7109e-04 - accuracy: 1.0000 - val_loss: 7.3614e-04 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 238ms/step - loss: 1.6873 - accuracy: 0.6656 - val_loss: 0.5950 - val_accuracy: 0.6357\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 237ms/step - loss: 0.0463 - accuracy: 0.9942 - val_loss: 0.5529 - val_accuracy: 0.6383\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 231ms/step - loss: 0.0273 - accuracy: 0.9943 - val_loss: 0.7173 - val_accuracy: 0.6372\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 254ms/step - loss: 0.0236 - accuracy: 0.9943 - val_loss: 0.7108 - val_accuracy: 0.6370\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 242ms/step - loss: 0.0218 - accuracy: 0.9942 - val_loss: 0.6650 - val_accuracy: 0.6367\n",
      "   1/4279 [..............................] - ETA: 0s - loss: 0.1177 - accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0027s vs `on_test_batch_begin` time: 0.0150s). Check your callbacks.\n",
      "4279/4279 [==============================] - 21s 5ms/step - loss: 0.1333 - accuracy: 0.9240\n",
      "1721/1721 [==============================] - 8s 5ms/step - loss: 0.2549 - accuracy: 0.8540\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 9s 287ms/step - loss: 0.4263 - accuracy: 0.8653 - val_loss: 0.3926 - val_accuracy: 0.8703\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 248ms/step - loss: 0.3958 - accuracy: 0.8680 - val_loss: 0.3866 - val_accuracy: 0.8705\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 247ms/step - loss: 0.3920 - accuracy: 0.8683 - val_loss: 0.3850 - val_accuracy: 0.8705\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 239ms/step - loss: 0.3905 - accuracy: 0.8683 - val_loss: 0.3847 - val_accuracy: 0.8703\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 247ms/step - loss: 0.3898 - accuracy: 0.8683 - val_loss: 0.3840 - val_accuracy: 0.8705\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 0.0326 - accuracy: 0.9914 - val_loss: 0.2948 - val_accuracy: 0.8056\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 259ms/step - loss: 0.0213 - accuracy: 0.9927 - val_loss: 0.3075 - val_accuracy: 0.7594\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 239ms/step - loss: 0.0200 - accuracy: 0.9932 - val_loss: 0.2846 - val_accuracy: 0.7847\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 266ms/step - loss: 0.0191 - accuracy: 0.9936 - val_loss: 0.3235 - val_accuracy: 0.7595\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 273ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 0.3353 - val_accuracy: 0.7656\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 266ms/step - loss: 0.0115 - accuracy: 0.9956 - val_loss: 3.9290 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 248ms/step - loss: 2.0227e-06 - accuracy: 1.0000 - val_loss: 4.2359 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 257ms/step - loss: 1.5505e-06 - accuracy: 1.0000 - val_loss: 4.2560 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 254ms/step - loss: 1.5142e-06 - accuracy: 1.0000 - val_loss: 4.2619 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 246ms/step - loss: 1.4942e-06 - accuracy: 1.0000 - val_loss: 4.2679 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 9s 282ms/step - loss: 3.8304 - accuracy: 0.4373 - val_loss: 0.1467 - val_accuracy: 0.9003\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 238ms/step - loss: 0.0291 - accuracy: 0.9933 - val_loss: 0.0070 - val_accuracy: 0.9997\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 238ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 9s 275ms/step - loss: 8.2876e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 250ms/step - loss: 1.1503 - accuracy: 0.7089 - val_loss: 0.5866 - val_accuracy: 0.6641\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 256ms/step - loss: 0.0332 - accuracy: 0.9938 - val_loss: 0.3427 - val_accuracy: 0.7590\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 258ms/step - loss: 0.0208 - accuracy: 0.9932 - val_loss: 0.4573 - val_accuracy: 0.6781\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 261ms/step - loss: 0.0191 - accuracy: 0.9941 - val_loss: 0.5085 - val_accuracy: 0.6705\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 260ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.5311 - val_accuracy: 0.6667\n",
      "4279/4279 [==============================] - 21s 5ms/step - loss: 0.1027 - accuracy: 0.9343\n",
      "1721/1721 [==============================] - 8s 5ms/step - loss: 0.2271 - accuracy: 0.8732\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 256ms/step - loss: 0.4304 - accuracy: 0.8664 - val_loss: 0.3926 - val_accuracy: 0.8701\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 8s 250ms/step - loss: 0.3925 - accuracy: 0.8683 - val_loss: 0.3841 - val_accuracy: 0.8704\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 8s 253ms/step - loss: 0.3902 - accuracy: 0.8682 - val_loss: 0.3836 - val_accuracy: 0.8705\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 255ms/step - loss: 0.3890 - accuracy: 0.8683 - val_loss: 0.3833 - val_accuracy: 0.8704\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 8s 247ms/step - loss: 0.3889 - accuracy: 0.8683 - val_loss: 0.3831 - val_accuracy: 0.8705\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 8s 265ms/step - loss: 0.0330 - accuracy: 0.9922 - val_loss: 0.3348 - val_accuracy: 0.7408\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 236ms/step - loss: 0.0195 - accuracy: 0.9935 - val_loss: 0.2385 - val_accuracy: 0.8384\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 0.0190 - accuracy: 0.9935 - val_loss: 0.2733 - val_accuracy: 0.8026\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 8s 247ms/step - loss: 0.0178 - accuracy: 0.9939 - val_loss: 0.3207 - val_accuracy: 0.7897\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 235ms/step - loss: 0.0173 - accuracy: 0.9940 - val_loss: 0.3594 - val_accuracy: 0.7825\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 240ms/step - loss: 0.0238 - accuracy: 0.9900 - val_loss: 3.5579 - val_accuracy: 0.5794\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 228ms/step - loss: 6.8498e-06 - accuracy: 1.0000 - val_loss: 3.8838 - val_accuracy: 0.5794\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 237ms/step - loss: 5.0661e-06 - accuracy: 1.0000 - val_loss: 3.9106 - val_accuracy: 0.5794\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 4.8770e-06 - accuracy: 1.0000 - val_loss: 3.9231 - val_accuracy: 0.5794\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 237ms/step - loss: 4.7327e-06 - accuracy: 1.0000 - val_loss: 3.9361 - val_accuracy: 0.5794\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 237ms/step - loss: 3.3090 - accuracy: 0.4906 - val_loss: 0.1274 - val_accuracy: 0.9649\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 225ms/step - loss: 0.0206 - accuracy: 0.9997 - val_loss: 0.0147 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 235ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 235ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 228ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 7s 240ms/step - loss: 0.3792 - accuracy: 0.8562 - val_loss: 0.7572 - val_accuracy: 0.6782\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 7s 233ms/step - loss: 0.0192 - accuracy: 0.9942 - val_loss: 0.4603 - val_accuracy: 0.7244\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 7s 235ms/step - loss: 0.0162 - accuracy: 0.9945 - val_loss: 0.5862 - val_accuracy: 0.6991\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 7s 233ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.5073 - val_accuracy: 0.7242\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 7s 232ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.4662 - val_accuracy: 0.7436\n",
      "4279/4279 [==============================] - 19s 5ms/step - loss: 0.0763 - accuracy: 0.9566\n",
      "1721/1721 [==============================] - 7s 4ms/step - loss: 0.2490 - accuracy: 0.8711\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr255Bgeo.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.13327844440937042, 0.2549484968185425], [0.1026846170425415, 0.2271340936422348], [0.07630041986703873, 0.249038428068161]]\n",
      "Accuracy for iterations:  [[0.923982560634613, 0.8539562821388245], [0.9342954754829407, 0.8732107877731323], [0.9566011428833008, 0.8710673451423645]]\n",
      "F1 for iterations:  [[0.9232559208613232, 0.8489066584180305], [0.9338084600112092, 0.8697433202461109], [0.9564431931758209, 0.8673570867825495]]\n",
      "Precision for iterations:  [[0.932574827909274, 0.876227258613864], [0.9405867705057854, 0.8902485428821898], [0.9590661290639726, 0.8893179846143305]]\n",
      "Recall for iterations:  [[0.9239825878640918, 0.8539562595364383], [0.9342954804405621, 0.873210782532878], [0.956601127698735, 0.8710673545011989]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 1 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_17588/591709827.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%15C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr55C1geo.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 6s 351ms/step - loss: 0.6101 - accuracy: 0.7566 - val_loss: 0.4808 - val_accuracy: 0.8062\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 4s 264ms/step - loss: 0.3725 - accuracy: 0.8689 - val_loss: 0.2576 - val_accuracy: 0.9247\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.2289 - accuracy: 0.9376 - val_loss: 0.2027 - val_accuracy: 0.9511\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.1983 - accuracy: 0.9560 - val_loss: 0.1832 - val_accuracy: 0.9609\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 4s 233ms/step - loss: 0.1840 - accuracy: 0.9616 - val_loss: 0.1710 - val_accuracy: 0.9645\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 4s 262ms/step - loss: 0.0414 - accuracy: 0.9910 - val_loss: 0.6484 - val_accuracy: 0.7275\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 233ms/step - loss: 0.0234 - accuracy: 0.9940 - val_loss: 0.8319 - val_accuracy: 0.7270\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 227ms/step - loss: 0.0216 - accuracy: 0.9950 - val_loss: 0.7372 - val_accuracy: 0.7271\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 232ms/step - loss: 0.0204 - accuracy: 0.9950 - val_loss: 0.5665 - val_accuracy: 0.7290\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 227ms/step - loss: 0.0197 - accuracy: 0.9950 - val_loss: 0.5083 - val_accuracy: 0.7321\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 6s 238ms/step - loss: 0.0151 - accuracy: 0.9959 - val_loss: 2.1520 - val_accuracy: 0.4440\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 6s 236ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 2.2568 - val_accuracy: 0.4421\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 6s 220ms/step - loss: 0.0130 - accuracy: 0.9965 - val_loss: 2.2838 - val_accuracy: 0.4398\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 202ms/step - loss: 0.0125 - accuracy: 0.9970 - val_loss: 1.8726 - val_accuracy: 0.4405\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 6s 233ms/step - loss: 0.0123 - accuracy: 0.9972 - val_loss: 1.7873 - val_accuracy: 0.4394\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 6s 236ms/step - loss: 1.7880 - accuracy: 0.6288 - val_loss: 0.0396 - val_accuracy: 0.9865\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 6s 222ms/step - loss: 0.0057 - accuracy: 0.9998 - val_loss: 0.0092 - val_accuracy: 0.9959\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 6s 210ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 0.9972\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 6s 236ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9983\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 6s 235ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9991\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 14s 203ms/step - loss: 0.4481 - accuracy: 0.8977 - val_loss: 0.3627 - val_accuracy: 0.8274\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 13s 184ms/step - loss: 0.0234 - accuracy: 0.9925 - val_loss: 0.2601 - val_accuracy: 0.8334\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 12s 177ms/step - loss: 0.0215 - accuracy: 0.9926 - val_loss: 0.2368 - val_accuracy: 0.8449\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 12s 177ms/step - loss: 0.0205 - accuracy: 0.9928 - val_loss: 0.2200 - val_accuracy: 0.8554\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 13s 179ms/step - loss: 0.0196 - accuracy: 0.9929 - val_loss: 0.2213 - val_accuracy: 0.8538\n",
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.0692 - accuracy: 0.9852\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1446 - accuracy: 0.9568\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 0.1914 - accuracy: 0.9592 - val_loss: 0.1631 - val_accuracy: 0.9663\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 178ms/step - loss: 0.1622 - accuracy: 0.9648 - val_loss: 0.1524 - val_accuracy: 0.9671\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 165ms/step - loss: 0.1549 - accuracy: 0.9654 - val_loss: 0.1474 - val_accuracy: 0.9671\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 170ms/step - loss: 0.1520 - accuracy: 0.9655 - val_loss: 0.1453 - val_accuracy: 0.9676\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 0.1496 - accuracy: 0.9657 - val_loss: 0.1432 - val_accuracy: 0.9678\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 169ms/step - loss: 0.0300 - accuracy: 0.9921 - val_loss: 0.7358 - val_accuracy: 0.7245\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 176ms/step - loss: 0.0178 - accuracy: 0.9952 - val_loss: 0.7741 - val_accuracy: 0.7258\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 164ms/step - loss: 0.0165 - accuracy: 0.9953 - val_loss: 0.5053 - val_accuracy: 0.7251\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 162ms/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 0.4814 - val_accuracy: 0.7239\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 171ms/step - loss: 0.0151 - accuracy: 0.9957 - val_loss: 0.5347 - val_accuracy: 0.7242\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 168ms/step - loss: 0.0121 - accuracy: 0.9971 - val_loss: 1.1528 - val_accuracy: 0.4543\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 166ms/step - loss: 0.0116 - accuracy: 0.9971 - val_loss: 1.7277 - val_accuracy: 0.4412\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 168ms/step - loss: 0.0110 - accuracy: 0.9973 - val_loss: 1.4089 - val_accuracy: 0.4569\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 167ms/step - loss: 0.0109 - accuracy: 0.9973 - val_loss: 1.6738 - val_accuracy: 0.4492\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 167ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 1.3731 - val_accuracy: 0.4998\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 172ms/step - loss: 2.9309 - accuracy: 0.5659 - val_loss: 0.1560 - val_accuracy: 0.9288\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 171ms/step - loss: 0.0313 - accuracy: 0.9842 - val_loss: 0.0017 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 181ms/step - loss: 3.4354e-04 - accuracy: 1.0000 - val_loss: 8.4871e-04 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 174ms/step - loss: 2.4439e-04 - accuracy: 1.0000 - val_loss: 7.4107e-04 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 178ms/step - loss: 2.2010e-04 - accuracy: 1.0000 - val_loss: 6.7195e-04 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 176ms/step - loss: 0.7412 - accuracy: 0.8787 - val_loss: 0.2080 - val_accuracy: 0.8884\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 12s 177ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.1990 - val_accuracy: 0.8852\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 13s 179ms/step - loss: 0.0178 - accuracy: 0.9943 - val_loss: 0.1996 - val_accuracy: 0.8756\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 13s 186ms/step - loss: 0.0172 - accuracy: 0.9943 - val_loss: 0.1896 - val_accuracy: 0.8772\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 13s 183ms/step - loss: 0.0166 - accuracy: 0.9944 - val_loss: 0.1728 - val_accuracy: 0.8853\n",
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.0619 - accuracy: 0.9882\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1246 - accuracy: 0.9682\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 168ms/step - loss: 0.1867 - accuracy: 0.9610 - val_loss: 0.1545 - val_accuracy: 0.9678\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 0.1561 - accuracy: 0.9658 - val_loss: 0.1481 - val_accuracy: 0.9678\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 170ms/step - loss: 0.1509 - accuracy: 0.9658 - val_loss: 0.1439 - val_accuracy: 0.9678\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 169ms/step - loss: 0.1489 - accuracy: 0.9657 - val_loss: 0.1425 - val_accuracy: 0.9679\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 169ms/step - loss: 0.1470 - accuracy: 0.9658 - val_loss: 0.1410 - val_accuracy: 0.9680\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 175ms/step - loss: 0.0282 - accuracy: 0.9934 - val_loss: 0.7531 - val_accuracy: 0.7238\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 175ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 0.7441 - val_accuracy: 0.7267\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 161ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.5088 - val_accuracy: 0.7255\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 161ms/step - loss: 0.0143 - accuracy: 0.9957 - val_loss: 0.5822 - val_accuracy: 0.7249\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 178ms/step - loss: 0.0138 - accuracy: 0.9962 - val_loss: 0.6216 - val_accuracy: 0.7265\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 175ms/step - loss: 0.0109 - accuracy: 0.9973 - val_loss: 1.4414 - val_accuracy: 0.4611\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 167ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 1.5812 - val_accuracy: 0.4783\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 165ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 1.1463 - val_accuracy: 0.5990\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 175ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 1.6586 - val_accuracy: 0.5004\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 173ms/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 1.6970 - val_accuracy: 0.5114\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 177ms/step - loss: 2.8237 - accuracy: 0.6049 - val_loss: 0.1654 - val_accuracy: 0.9275\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 171ms/step - loss: 0.0369 - accuracy: 0.9805 - val_loss: 0.0041 - val_accuracy: 0.9985\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 176ms/step - loss: 8.5643e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 172ms/step - loss: 5.2607e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9997\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 172ms/step - loss: 3.9018e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 173ms/step - loss: 0.5131 - accuracy: 0.9043 - val_loss: 0.2776 - val_accuracy: 0.8771\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 13s 179ms/step - loss: 0.0177 - accuracy: 0.9938 - val_loss: 0.1948 - val_accuracy: 0.9066\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 13s 179ms/step - loss: 0.0168 - accuracy: 0.9940 - val_loss: 0.1871 - val_accuracy: 0.9041\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 13s 179ms/step - loss: 0.0160 - accuracy: 0.9943 - val_loss: 0.1693 - val_accuracy: 0.9098\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 12s 178ms/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 0.1584 - val_accuracy: 0.9127\n",
      "4279/4279 [==============================] - 13s 3ms/step - loss: 0.0869 - accuracy: 0.9796\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.2201 - accuracy: 0.9219\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr55C1geo.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.06918075680732727, 0.1445847898721695], [0.06189906597137451, 0.1246391162276268], [0.0868644118309021, 0.22009800374507904]]\n",
      "Accuracy for iterations:  [[0.9851734042167664, 0.9568226337432861], [0.988153338432312, 0.9681937098503113], [0.9796006083488464, 0.9219101667404175]]\n",
      "F1 for iterations:  [[0.9851756418054838, 0.9567013051454595], [0.9881597348862576, 0.9682852036840406], [0.9796161107324796, 0.9221756408354781]]\n",
      "Precision for iterations:  [[0.9851929503093813, 0.9573274946641492], [0.988441769814709, 0.9703413561437108], [0.9804435791205228, 0.9336873622329488]]\n",
      "Recall for iterations:  [[0.9851733909842532, 0.9568226404127007], [0.9881533202839697, 0.9681937077672019], [0.9796006310438518, 0.9219101939984015]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 1 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_16896/372464333.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%15C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr105C1geo.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.6154 - accuracy: 0.7681 - val_loss: 0.4970 - val_accuracy: 0.7811\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 216ms/step - loss: 0.4002 - accuracy: 0.8472 - val_loss: 0.3168 - val_accuracy: 0.9028\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 218ms/step - loss: 0.2936 - accuracy: 0.9172 - val_loss: 0.2823 - val_accuracy: 0.9271\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 203ms/step - loss: 0.2698 - accuracy: 0.9332 - val_loss: 0.2664 - val_accuracy: 0.9379\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 4s 220ms/step - loss: 0.2558 - accuracy: 0.9373 - val_loss: 0.2525 - val_accuracy: 0.9390\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 239ms/step - loss: 0.0486 - accuracy: 0.9908 - val_loss: 0.7414 - val_accuracy: 0.7270\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 206ms/step - loss: 0.0244 - accuracy: 0.9941 - val_loss: 0.8693 - val_accuracy: 0.7270\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 188ms/step - loss: 0.0217 - accuracy: 0.9951 - val_loss: 0.7607 - val_accuracy: 0.7270\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 201ms/step - loss: 0.0207 - accuracy: 0.9950 - val_loss: 0.5744 - val_accuracy: 0.7272\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 200ms/step - loss: 0.0200 - accuracy: 0.9950 - val_loss: 0.5555 - val_accuracy: 0.7280\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 199ms/step - loss: 0.0154 - accuracy: 0.9960 - val_loss: 2.6631 - val_accuracy: 0.4436\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 206ms/step - loss: 0.0140 - accuracy: 0.9962 - val_loss: 2.5621 - val_accuracy: 0.4409\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 201ms/step - loss: 0.0134 - accuracy: 0.9964 - val_loss: 2.0534 - val_accuracy: 0.4435\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 205ms/step - loss: 0.0127 - accuracy: 0.9967 - val_loss: 1.6363 - val_accuracy: 0.4434\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 194ms/step - loss: 0.0125 - accuracy: 0.9968 - val_loss: 2.1739 - val_accuracy: 0.4370\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 202ms/step - loss: 1.9033 - accuracy: 0.6043 - val_loss: 0.0327 - val_accuracy: 0.9872\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 6s 208ms/step - loss: 0.0045 - accuracy: 0.9998 - val_loss: 0.0071 - val_accuracy: 0.9971\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 198ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9984\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 199ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9996\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 196ms/step - loss: 7.1294e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 16s 231ms/step - loss: 0.4503 - accuracy: 0.8972 - val_loss: 0.3245 - val_accuracy: 0.8276\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 16s 232ms/step - loss: 0.0239 - accuracy: 0.9925 - val_loss: 0.2541 - val_accuracy: 0.8291\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 16s 228ms/step - loss: 0.0218 - accuracy: 0.9926 - val_loss: 0.2288 - val_accuracy: 0.8410\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 16s 226ms/step - loss: 0.0207 - accuracy: 0.9929 - val_loss: 0.2248 - val_accuracy: 0.8455\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 16s 228ms/step - loss: 0.0198 - accuracy: 0.9930 - val_loss: 0.1957 - val_accuracy: 0.8670\n",
      "4279/4279 [==============================] - 18s 4ms/step - loss: 0.0664 - accuracy: 0.9884\n",
      "1721/1721 [==============================] - 9s 5ms/step - loss: 0.1257 - accuracy: 0.9755\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 4s 270ms/step - loss: 0.2850 - accuracy: 0.9343 - val_loss: 0.2457 - val_accuracy: 0.9410\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 4s 224ms/step - loss: 0.2417 - accuracy: 0.9401 - val_loss: 0.2320 - val_accuracy: 0.9421\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 218ms/step - loss: 0.2315 - accuracy: 0.9407 - val_loss: 0.2263 - val_accuracy: 0.9424\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 4s 223ms/step - loss: 0.2278 - accuracy: 0.9410 - val_loss: 0.2233 - val_accuracy: 0.9428\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 4s 220ms/step - loss: 0.2254 - accuracy: 0.9411 - val_loss: 0.2219 - val_accuracy: 0.9426\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 232ms/step - loss: 0.0385 - accuracy: 0.9912 - val_loss: 0.7458 - val_accuracy: 0.7254\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 212ms/step - loss: 0.0183 - accuracy: 0.9951 - val_loss: 0.8565 - val_accuracy: 0.7265\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 219ms/step - loss: 0.0178 - accuracy: 0.9951 - val_loss: 0.6636 - val_accuracy: 0.7255\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 218ms/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 0.4669 - val_accuracy: 0.7258\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 226ms/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 0.4791 - val_accuracy: 0.7260\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 6s 225ms/step - loss: 0.0122 - accuracy: 0.9970 - val_loss: 1.6984 - val_accuracy: 0.4395\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 6s 229ms/step - loss: 0.0114 - accuracy: 0.9972 - val_loss: 1.7911 - val_accuracy: 0.4404\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 8s 306ms/step - loss: 0.0112 - accuracy: 0.9973 - val_loss: 2.0387 - val_accuracy: 0.4377\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 8s 320ms/step - loss: 0.0110 - accuracy: 0.9973 - val_loss: 1.7842 - val_accuracy: 0.4503\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 7s 271ms/step - loss: 0.0108 - accuracy: 0.9973 - val_loss: 1.7372 - val_accuracy: 0.4670\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 7s 260ms/step - loss: 3.1287 - accuracy: 0.5180 - val_loss: 0.2469 - val_accuracy: 0.9134\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 8s 282ms/step - loss: 0.0538 - accuracy: 0.9754 - val_loss: 0.0066 - val_accuracy: 0.9961\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 6s 235ms/step - loss: 5.0582e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9985\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 6s 236ms/step - loss: 3.0446e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 0.9988\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 7s 258ms/step - loss: 2.4677e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9993\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 18s 254ms/step - loss: 0.5797 - accuracy: 0.8959 - val_loss: 0.2546 - val_accuracy: 0.8540\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 20s 287ms/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 0.1954 - val_accuracy: 0.8857\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 18s 252ms/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 0.1849 - val_accuracy: 0.8852\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 20s 284ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.1631 - val_accuracy: 0.8951\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 17s 245ms/step - loss: 0.0167 - accuracy: 0.9944 - val_loss: 0.1659 - val_accuracy: 0.8906\n",
      "4279/4279 [==============================] - 24s 6ms/step - loss: 0.0544 - accuracy: 0.9898\n",
      "1721/1721 [==============================] - 9s 5ms/step - loss: 0.1096 - accuracy: 0.9761\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 4s 254ms/step - loss: 0.2896 - accuracy: 0.9374 - val_loss: 0.2381 - val_accuracy: 0.9426\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 4s 228ms/step - loss: 0.2367 - accuracy: 0.9414 - val_loss: 0.2268 - val_accuracy: 0.9428\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 217ms/step - loss: 0.2284 - accuracy: 0.9414 - val_loss: 0.2238 - val_accuracy: 0.9424\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 4s 223ms/step - loss: 0.2259 - accuracy: 0.9414 - val_loss: 0.2230 - val_accuracy: 0.9425\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 4s 232ms/step - loss: 0.2245 - accuracy: 0.9415 - val_loss: 0.2204 - val_accuracy: 0.9429\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 4s 291ms/step - loss: 0.0409 - accuracy: 0.9923 - val_loss: 0.5121 - val_accuracy: 0.7258\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 4s 255ms/step - loss: 0.0161 - accuracy: 0.9950 - val_loss: 0.7564 - val_accuracy: 0.7255\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 246ms/step - loss: 0.0160 - accuracy: 0.9957 - val_loss: 0.6915 - val_accuracy: 0.7239\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 4s 266ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.5433 - val_accuracy: 0.7281\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 4s 255ms/step - loss: 0.0141 - accuracy: 0.9962 - val_loss: 0.4914 - val_accuracy: 0.7340\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 7s 253ms/step - loss: 0.0117 - accuracy: 0.9973 - val_loss: 1.8215 - val_accuracy: 0.4412\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 7s 250ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 1.2963 - val_accuracy: 0.4996\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 7s 261ms/step - loss: 0.0106 - accuracy: 0.9973 - val_loss: 1.7453 - val_accuracy: 0.4759\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 7s 259ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 1.5411 - val_accuracy: 0.5171\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 7s 266ms/step - loss: 0.0098 - accuracy: 0.9975 - val_loss: 1.5853 - val_accuracy: 0.5381\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 7s 273ms/step - loss: 2.9354 - accuracy: 0.5882 - val_loss: 0.1717 - val_accuracy: 0.9263\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 7s 245ms/step - loss: 0.0257 - accuracy: 0.9866 - val_loss: 0.0013 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 7s 262ms/step - loss: 5.3169e-05 - accuracy: 1.0000 - val_loss: 6.2483e-04 - val_accuracy: 0.9999\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 7s 256ms/step - loss: 3.7384e-05 - accuracy: 1.0000 - val_loss: 5.7669e-04 - val_accuracy: 0.9999\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 8s 280ms/step - loss: 3.5498e-05 - accuracy: 1.0000 - val_loss: 5.5714e-04 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 19s 264ms/step - loss: 0.5756 - accuracy: 0.9066 - val_loss: 0.2589 - val_accuracy: 0.8680\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 19s 270ms/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 0.1799 - val_accuracy: 0.9042\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 20s 281ms/step - loss: 0.0165 - accuracy: 0.9943 - val_loss: 0.1703 - val_accuracy: 0.9034\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 19s 271ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 0.1745 - val_accuracy: 0.8970\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 18s 262ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.1442 - val_accuracy: 0.9151\n",
      "4279/4279 [==============================] - 21s 5ms/step - loss: 0.0517 - accuracy: 0.9900\n",
      "1721/1721 [==============================] - 8s 5ms/step - loss: 0.0858 - accuracy: 0.9846\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr105C1geo.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.06640256196260452, 0.1257031261920929], [0.0543942004442215, 0.10962170362472534], [0.051678989082574844, 0.08576647192239761]]\n",
      "Accuracy for iterations:  [[0.988379716873169, 0.9754777550697327], [0.9897966384887695, 0.976113498210907], [0.9899938702583313, 0.9845600724220276]]\n",
      "F1 for iterations:  [[0.9883839596066323, 0.975493552587857], [0.9898015906657185, 0.9761696717141854], [0.9899986226483048, 0.9845855778790374]]\n",
      "Precision for iterations:  [[0.9884906782301287, 0.9755687720040811], [0.9900111184654423, 0.9773419606883076], [0.9902001605974614, 0.9850820400334382]]\n",
      "Recall for iterations:  [[0.9883797364807619, 0.9754777301460438], [0.9897966636477841, 0.976113492697813], [0.9899938648514418, 0.9845600523141756]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 1 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_21336/2868219575.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%15C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr255C1geo.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 184ms/step - loss: 0.6350 - accuracy: 0.7102 - val_loss: 0.5472 - val_accuracy: 0.7394\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 207ms/step - loss: 0.4898 - accuracy: 0.8046 - val_loss: 0.4409 - val_accuracy: 0.8484\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 0.4400 - accuracy: 0.8509 - val_loss: 0.4209 - val_accuracy: 0.8651\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 197ms/step - loss: 0.4258 - accuracy: 0.8624 - val_loss: 0.4109 - val_accuracy: 0.8677\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 199ms/step - loss: 0.4166 - accuracy: 0.8637 - val_loss: 0.4042 - val_accuracy: 0.8683\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 180ms/step - loss: 0.0816 - accuracy: 0.9906 - val_loss: 0.5417 - val_accuracy: 0.7270\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 177ms/step - loss: 0.0281 - accuracy: 0.9937 - val_loss: 0.7455 - val_accuracy: 0.7270\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 175ms/step - loss: 0.0235 - accuracy: 0.9946 - val_loss: 0.9317 - val_accuracy: 0.7270\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 160ms/step - loss: 0.0220 - accuracy: 0.9951 - val_loss: 0.7417 - val_accuracy: 0.7270\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 162ms/step - loss: 0.0208 - accuracy: 0.9950 - val_loss: 0.5774 - val_accuracy: 0.7271\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 174ms/step - loss: 0.0155 - accuracy: 0.9960 - val_loss: 2.2878 - val_accuracy: 0.4442\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 171ms/step - loss: 0.0143 - accuracy: 0.9961 - val_loss: 2.0605 - val_accuracy: 0.4443\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 184ms/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 2.5908 - val_accuracy: 0.4398\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 6s 214ms/step - loss: 0.0130 - accuracy: 0.9967 - val_loss: 1.9786 - val_accuracy: 0.4452\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 186ms/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 1.6930 - val_accuracy: 0.4430\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 183ms/step - loss: 1.6557 - accuracy: 0.6418 - val_loss: 0.0351 - val_accuracy: 0.9872\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 173ms/step - loss: 0.0062 - accuracy: 0.9997 - val_loss: 0.0071 - val_accuracy: 0.9974\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 181ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9985\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 183ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9996\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 180ms/step - loss: 8.8626e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 13s 188ms/step - loss: 0.4790 - accuracy: 0.8958 - val_loss: 0.3721 - val_accuracy: 0.8275\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 13s 179ms/step - loss: 0.0243 - accuracy: 0.9926 - val_loss: 0.2526 - val_accuracy: 0.8401\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 13s 182ms/step - loss: 0.0217 - accuracy: 0.9928 - val_loss: 0.2241 - val_accuracy: 0.8544\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 13s 181ms/step - loss: 0.0205 - accuracy: 0.9928 - val_loss: 0.2071 - val_accuracy: 0.8640\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 13s 180ms/step - loss: 0.0195 - accuracy: 0.9931 - val_loss: 0.2150 - val_accuracy: 0.8580\n",
      "4279/4279 [==============================] - 13s 3ms/step - loss: 0.0730 - accuracy: 0.9883\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1369 - accuracy: 0.9682\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 177ms/step - loss: 0.5552 - accuracy: 0.8496 - val_loss: 0.4290 - val_accuracy: 0.8590\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 178ms/step - loss: 0.4244 - accuracy: 0.8629 - val_loss: 0.4096 - val_accuracy: 0.8691\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.4102 - accuracy: 0.8658 - val_loss: 0.3983 - val_accuracy: 0.8696\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 177ms/step - loss: 0.4036 - accuracy: 0.8664 - val_loss: 0.3952 - val_accuracy: 0.8698\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.4004 - accuracy: 0.8664 - val_loss: 0.3928 - val_accuracy: 0.8701\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 183ms/step - loss: 0.0652 - accuracy: 0.9910 - val_loss: 0.5423 - val_accuracy: 0.7242\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 168ms/step - loss: 0.0186 - accuracy: 0.9952 - val_loss: 0.6875 - val_accuracy: 0.7257\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 166ms/step - loss: 0.0177 - accuracy: 0.9952 - val_loss: 0.7359 - val_accuracy: 0.7252\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 161ms/step - loss: 0.0170 - accuracy: 0.9952 - val_loss: 0.5439 - val_accuracy: 0.7255\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 162ms/step - loss: 0.0161 - accuracy: 0.9953 - val_loss: 0.5265 - val_accuracy: 0.7249\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 177ms/step - loss: 0.0122 - accuracy: 0.9969 - val_loss: 1.6570 - val_accuracy: 0.4377\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 177ms/step - loss: 0.0115 - accuracy: 0.9972 - val_loss: 1.7427 - val_accuracy: 0.4384\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 171ms/step - loss: 0.0114 - accuracy: 0.9972 - val_loss: 1.5738 - val_accuracy: 0.4482\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 179ms/step - loss: 0.0109 - accuracy: 0.9972 - val_loss: 1.4229 - val_accuracy: 0.4774\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 172ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 1.8652 - val_accuracy: 0.4550\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 167ms/step - loss: 3.1330 - accuracy: 0.5338 - val_loss: 0.2735 - val_accuracy: 0.9160\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 174ms/step - loss: 0.0724 - accuracy: 0.9685 - val_loss: 0.0053 - val_accuracy: 0.9975\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 181ms/step - loss: 6.0083e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9990\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 192ms/step - loss: 3.5683e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9995\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 181ms/step - loss: 3.0177e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9999\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 13s 186ms/step - loss: 0.7061 - accuracy: 0.8860 - val_loss: 0.2218 - val_accuracy: 0.8750\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 14s 197ms/step - loss: 0.0191 - accuracy: 0.9941 - val_loss: 0.1959 - val_accuracy: 0.8849\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 13s 187ms/step - loss: 0.0178 - accuracy: 0.9943 - val_loss: 0.2023 - val_accuracy: 0.8726\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 12s 177ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.1665 - val_accuracy: 0.8922\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 13s 184ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.1577 - val_accuracy: 0.8960\n",
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.0797 - accuracy: 0.9850\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1811 - accuracy: 0.9388\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 0.5818 - accuracy: 0.8553 - val_loss: 0.4276 - val_accuracy: 0.8685\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 0.4236 - accuracy: 0.8632 - val_loss: 0.4122 - val_accuracy: 0.8687\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.4096 - accuracy: 0.8669 - val_loss: 0.4001 - val_accuracy: 0.8703\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 0.4034 - accuracy: 0.8671 - val_loss: 0.3973 - val_accuracy: 0.8704\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 0.4003 - accuracy: 0.8671 - val_loss: 0.3943 - val_accuracy: 0.8706\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 225ms/step - loss: 0.0806 - accuracy: 0.9937 - val_loss: 0.6263 - val_accuracy: 0.7214\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 173ms/step - loss: 0.0204 - accuracy: 0.9952 - val_loss: 0.6534 - val_accuracy: 0.7258\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 158ms/step - loss: 0.0175 - accuracy: 0.9950 - val_loss: 0.7566 - val_accuracy: 0.7252\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 191ms/step - loss: 0.0163 - accuracy: 0.9955 - val_loss: 0.6899 - val_accuracy: 0.7237\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 234ms/step - loss: 0.0154 - accuracy: 0.9955 - val_loss: 0.5541 - val_accuracy: 0.7248\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 181ms/step - loss: 0.0122 - accuracy: 0.9972 - val_loss: 1.8800 - val_accuracy: 0.4377\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 178ms/step - loss: 0.0110 - accuracy: 0.9973 - val_loss: 1.6584 - val_accuracy: 0.4474\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 207ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 1.3464 - val_accuracy: 0.5028\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 155ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 1.2736 - val_accuracy: 0.5578\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 148ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 2.0652 - val_accuracy: 0.4612\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 4s 157ms/step - loss: 3.4354 - accuracy: 0.5215 - val_loss: 0.3485 - val_accuracy: 0.9021\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 4s 155ms/step - loss: 0.1046 - accuracy: 0.9599 - val_loss: 0.0015 - val_accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 174ms/step - loss: 2.3530e-04 - accuracy: 1.0000 - val_loss: 4.3018e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 4s 158ms/step - loss: 1.3802e-04 - accuracy: 1.0000 - val_loss: 3.5872e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 6s 204ms/step - loss: 1.2294e-04 - accuracy: 1.0000 - val_loss: 3.2431e-04 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 14s 201ms/step - loss: 0.6291 - accuracy: 0.8979 - val_loss: 0.1892 - val_accuracy: 0.9057\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 14s 195ms/step - loss: 0.0180 - accuracy: 0.9946 - val_loss: 0.1763 - val_accuracy: 0.9011\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 14s 201ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.1694 - val_accuracy: 0.8978\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 14s 196ms/step - loss: 0.0162 - accuracy: 0.9948 - val_loss: 0.1530 - val_accuracy: 0.9038\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 12s 176ms/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 0.1374 - val_accuracy: 0.9151\n",
      "4279/4279 [==============================] - 10s 2ms/step - loss: 0.1110 - accuracy: 0.9744\n",
      "1721/1721 [==============================] - 4s 3ms/step - loss: 0.2670 - accuracy: 0.9006\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr255C1geo.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.07301006466150284, 0.13686226308345795], [0.07973063737154007, 0.1810533106327057], [0.11098721623420715, 0.2670384347438812]]\n",
      "Accuracy for iterations:  [[0.9883286356925964, 0.9682118892669678], [0.9850346446037292, 0.9388033151626587], [0.9744295477867126, 0.9005667567253113]]\n",
      "F1 for iterations:  [[0.9883327370084766, 0.9681764578223622], [0.9850441636705817, 0.9390300567638474], [0.9744505128900312, 0.9007852290323695]]\n",
      "Precision for iterations:  [[0.9884330080269008, 0.9682811247686117], [0.9854926668972157, 0.946286857250159], [0.9757355470526499, 0.9189210677814361]]\n",
      "Recall for iterations:  [[0.9883286102427766, 0.9682118724115382], [0.9850346197668643, 0.938803313231127], [0.9744295772590493, 0.9005667369032915]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 3 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_21336/927562370.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr5%35C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr55C3geo.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 168ms/step - loss: 0.5297 - accuracy: 0.7412 - val_loss: 1.7559 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 170ms/step - loss: 0.1924 - accuracy: 0.9607 - val_loss: 3.6784 - val_accuracy: 0.1332\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 0.0802 - accuracy: 0.9893 - val_loss: 3.6751 - val_accuracy: 0.1342\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0515 - accuracy: 0.9893 - val_loss: 1.8339 - val_accuracy: 0.1357\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 202ms/step - loss: 0.0374 - accuracy: 0.9899 - val_loss: 1.5210 - val_accuracy: 0.1622\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 230ms/step - loss: 0.0231 - accuracy: 0.9949 - val_loss: 0.8074 - val_accuracy: 0.7271\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 197ms/step - loss: 0.0208 - accuracy: 0.9949 - val_loss: 0.5096 - val_accuracy: 0.7351\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 192ms/step - loss: 0.0207 - accuracy: 0.9949 - val_loss: 0.7279 - val_accuracy: 0.7278\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 5s 345ms/step - loss: 0.0194 - accuracy: 0.9951 - val_loss: 0.4990 - val_accuracy: 0.7382\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 244ms/step - loss: 0.0197 - accuracy: 0.9950 - val_loss: 0.5134 - val_accuracy: 0.7360\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 6s 212ms/step - loss: 0.2402 - accuracy: 0.9391 - val_loss: 0.1866 - val_accuracy: 0.9606\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 210ms/step - loss: 0.1814 - accuracy: 0.9607 - val_loss: 0.1722 - val_accuracy: 0.9639\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 6s 221ms/step - loss: 0.1693 - accuracy: 0.9626 - val_loss: 0.1650 - val_accuracy: 0.9642\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 6s 220ms/step - loss: 0.1629 - accuracy: 0.9632 - val_loss: 0.1611 - val_accuracy: 0.9642\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 6s 221ms/step - loss: 0.1585 - accuracy: 0.9634 - val_loss: 0.1569 - val_accuracy: 0.9646\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 198ms/step - loss: 0.3551 - accuracy: 0.8636 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 190ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.3198e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 6s 214ms/step - loss: 4.4800e-04 - accuracy: 1.0000 - val_loss: 1.5714e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 6s 207ms/step - loss: 2.3705e-04 - accuracy: 1.0000 - val_loss: 9.1338e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 189ms/step - loss: 1.4259e-04 - accuracy: 1.0000 - val_loss: 5.7025e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 13s 188ms/step - loss: 0.8832 - accuracy: 0.8480 - val_loss: 0.3723 - val_accuracy: 0.8289\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 13s 192ms/step - loss: 0.0312 - accuracy: 0.9913 - val_loss: 0.2581 - val_accuracy: 0.8498\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 14s 201ms/step - loss: 0.0249 - accuracy: 0.9907 - val_loss: 0.2305 - val_accuracy: 0.8568\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 14s 196ms/step - loss: 0.0227 - accuracy: 0.9915 - val_loss: 0.2124 - val_accuracy: 0.8621\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 14s 195ms/step - loss: 0.0212 - accuracy: 0.9924 - val_loss: 0.2036 - val_accuracy: 0.8665\n",
      "4279/4279 [==============================] - 13s 3ms/step - loss: 0.1084 - accuracy: 0.9880\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1124 - accuracy: 0.9728\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 0.0245 - accuracy: 0.9912 - val_loss: 0.6338 - val_accuracy: 0.5818\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 0.0219 - accuracy: 0.9926 - val_loss: 0.5576 - val_accuracy: 0.6555\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 170ms/step - loss: 0.0208 - accuracy: 0.9930 - val_loss: 0.6398 - val_accuracy: 0.5888\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 181ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 0.7204 - val_accuracy: 0.5739\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 0.0184 - accuracy: 0.9938 - val_loss: 0.7047 - val_accuracy: 0.6035\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 181ms/step - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.6531 - val_accuracy: 0.7402\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 173ms/step - loss: 0.0135 - accuracy: 0.9964 - val_loss: 0.6942 - val_accuracy: 0.7410\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 168ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.5898 - val_accuracy: 0.7575\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 170ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.7759 - val_accuracy: 0.7413\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 178ms/step - loss: 0.0127 - accuracy: 0.9967 - val_loss: 0.6388 - val_accuracy: 0.7610\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 182ms/step - loss: 0.2522 - accuracy: 0.9524 - val_loss: 0.1784 - val_accuracy: 0.9639\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 170ms/step - loss: 0.1664 - accuracy: 0.9634 - val_loss: 0.1571 - val_accuracy: 0.9642\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 179ms/step - loss: 0.1544 - accuracy: 0.9636 - val_loss: 0.1527 - val_accuracy: 0.9642\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 179ms/step - loss: 0.1516 - accuracy: 0.9638 - val_loss: 0.1508 - val_accuracy: 0.9642\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 174ms/step - loss: 0.1504 - accuracy: 0.9638 - val_loss: 0.1495 - val_accuracy: 0.9646\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 183ms/step - loss: 0.5451 - accuracy: 0.8148 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 6s 206ms/step - loss: 6.3985e-04 - accuracy: 1.0000 - val_loss: 1.0485e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 189ms/step - loss: 1.4204e-04 - accuracy: 1.0000 - val_loss: 6.5234e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 187ms/step - loss: 9.8956e-05 - accuracy: 1.0000 - val_loss: 4.8167e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 185ms/step - loss: 7.2734e-05 - accuracy: 1.0000 - val_loss: 3.5307e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 13s 188ms/step - loss: 0.9436 - accuracy: 0.8374 - val_loss: 0.2665 - val_accuracy: 0.8700\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 13s 186ms/step - loss: 0.0236 - accuracy: 0.9934 - val_loss: 0.2062 - val_accuracy: 0.8921\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 13s 188ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 0.1835 - val_accuracy: 0.8956\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 13s 187ms/step - loss: 0.0182 - accuracy: 0.9944 - val_loss: 0.1795 - val_accuracy: 0.8953\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 13s 187ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.1735 - val_accuracy: 0.8991\n",
      "4279/4279 [==============================] - 14s 3ms/step - loss: 0.1162 - accuracy: 0.9890\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1426 - accuracy: 0.9530\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 218ms/step - loss: 0.0194 - accuracy: 0.9940 - val_loss: 0.8413 - val_accuracy: 0.5303\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0178 - accuracy: 0.9943 - val_loss: 0.8763 - val_accuracy: 0.5632\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 218ms/step - loss: 0.0170 - accuracy: 0.9946 - val_loss: 0.8555 - val_accuracy: 0.5894\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 4s 228ms/step - loss: 0.0165 - accuracy: 0.9946 - val_loss: 0.8369 - val_accuracy: 0.6017\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 0.0165 - accuracy: 0.9948 - val_loss: 0.8232 - val_accuracy: 0.6119\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 4s 275ms/step - loss: 0.0129 - accuracy: 0.9965 - val_loss: 0.7772 - val_accuracy: 0.7550\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 203ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 0.6729 - val_accuracy: 0.7666\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 191ms/step - loss: 0.0123 - accuracy: 0.9968 - val_loss: 1.0088 - val_accuracy: 0.7461\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 197ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.8823 - val_accuracy: 0.7548\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 3s 218ms/step - loss: 0.0116 - accuracy: 0.9971 - val_loss: 0.9232 - val_accuracy: 0.7557\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 6s 228ms/step - loss: 0.2505 - accuracy: 0.9476 - val_loss: 0.1725 - val_accuracy: 0.9643\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 6s 221ms/step - loss: 0.1605 - accuracy: 0.9633 - val_loss: 0.1542 - val_accuracy: 0.9644\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 7s 251ms/step - loss: 0.1525 - accuracy: 0.9637 - val_loss: 0.1509 - val_accuracy: 0.9642\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 6s 246ms/step - loss: 0.1503 - accuracy: 0.9637 - val_loss: 0.1490 - val_accuracy: 0.9642\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 7s 285ms/step - loss: 0.1487 - accuracy: 0.9639 - val_loss: 0.1482 - val_accuracy: 0.9646\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 198ms/step - loss: 0.4401 - accuracy: 0.8433 - val_loss: 6.0441e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 186ms/step - loss: 3.1184e-04 - accuracy: 1.0000 - val_loss: 6.7926e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 199ms/step - loss: 9.7697e-05 - accuracy: 1.0000 - val_loss: 4.9452e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 194ms/step - loss: 7.8897e-05 - accuracy: 1.0000 - val_loss: 4.1915e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 201ms/step - loss: 6.6823e-05 - accuracy: 1.0000 - val_loss: 3.5225e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 16s 231ms/step - loss: 0.8261 - accuracy: 0.8535 - val_loss: 0.2426 - val_accuracy: 0.8906\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 13s 187ms/step - loss: 0.0198 - accuracy: 0.9940 - val_loss: 0.1899 - val_accuracy: 0.9095\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 11s 161ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.1819 - val_accuracy: 0.9072\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 12s 169ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.1592 - val_accuracy: 0.9166\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 15s 208ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.1546 - val_accuracy: 0.9192\n",
      "4279/4279 [==============================] - 13s 3ms/step - loss: 0.1181 - accuracy: 0.9901\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1680 - accuracy: 0.9472\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr55C3geo.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.1084146797657013, 0.1123688668012619], [0.1162383109331131, 0.1426282525062561], [0.11805704981088638, 0.16804981231689453]]\n",
      "Accuracy for iterations:  [[0.9879999160766602, 0.9727712273597717], [0.9890370965003967, 0.952953577041626], [0.9900742173194885, 0.9472498893737793]]\n",
      "F1 for iterations:  [[0.988003964019539, 0.9727450833085427], [0.9890408833630392, 0.9527551368789061], [0.9900774749113563, 0.9469688561753138]]\n",
      "Precision for iterations:  [[0.9880929627462135, 0.9728250915394179], [0.9891371143801229, 0.9540567725774562], [0.9901625178749895, 0.9488898335585798]]\n",
      "Recall for iterations:  [[0.9879999415700137, 0.9727711981399404], [0.9890370738262877, 0.9529535711690765], [0.9900742060825616, 0.9472498728474896]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 3 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_21336/4114672810.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr10%35C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr105C3geo.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 212ms/step - loss: 0.5324 - accuracy: 0.7423 - val_loss: 1.7323 - val_accuracy: 0.0233\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 182ms/step - loss: 0.1918 - accuracy: 0.9744 - val_loss: 3.9565 - val_accuracy: 0.1281\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 0.0867 - accuracy: 0.9892 - val_loss: 3.8688 - val_accuracy: 0.1339\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 0.0524 - accuracy: 0.9892 - val_loss: 1.6523 - val_accuracy: 0.1386\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 163ms/step - loss: 0.0364 - accuracy: 0.9891 - val_loss: 1.2198 - val_accuracy: 0.2383\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 184ms/step - loss: 0.0220 - accuracy: 0.9948 - val_loss: 0.8367 - val_accuracy: 0.7270\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 171ms/step - loss: 0.0195 - accuracy: 0.9950 - val_loss: 0.6023 - val_accuracy: 0.7283\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 159ms/step - loss: 0.0188 - accuracy: 0.9950 - val_loss: 0.6598 - val_accuracy: 0.7281\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 164ms/step - loss: 0.0180 - accuracy: 0.9950 - val_loss: 0.6554 - val_accuracy: 0.7284\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 161ms/step - loss: 0.0174 - accuracy: 0.9950 - val_loss: 0.5685 - val_accuracy: 0.7323\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 172ms/step - loss: 0.3627 - accuracy: 0.9147 - val_loss: 0.2729 - val_accuracy: 0.9328\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.2626 - accuracy: 0.9372 - val_loss: 0.2563 - val_accuracy: 0.9367\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 5s 188ms/step - loss: 0.2497 - accuracy: 0.9384 - val_loss: 0.2489 - val_accuracy: 0.9374\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 196ms/step - loss: 0.2429 - accuracy: 0.9392 - val_loss: 0.2428 - val_accuracy: 0.9376\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 162ms/step - loss: 0.2378 - accuracy: 0.9394 - val_loss: 0.2387 - val_accuracy: 0.9380\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 5s 168ms/step - loss: 0.2749 - accuracy: 0.8872 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 4s 162ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 5.6492e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 4s 162ms/step - loss: 7.2765e-04 - accuracy: 1.0000 - val_loss: 2.5842e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 4s 158ms/step - loss: 3.7052e-04 - accuracy: 1.0000 - val_loss: 1.4458e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 4s 156ms/step - loss: 2.1632e-04 - accuracy: 1.0000 - val_loss: 8.8571e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 177ms/step - loss: 0.7890 - accuracy: 0.8405 - val_loss: 0.3870 - val_accuracy: 0.8277\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 15s 220ms/step - loss: 0.0328 - accuracy: 0.9920 - val_loss: 0.2892 - val_accuracy: 0.8285\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 14s 206ms/step - loss: 0.0246 - accuracy: 0.9912 - val_loss: 0.2501 - val_accuracy: 0.8329\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 14s 200ms/step - loss: 0.0225 - accuracy: 0.9914 - val_loss: 0.2273 - val_accuracy: 0.8409\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 14s 193ms/step - loss: 0.0211 - accuracy: 0.9919 - val_loss: 0.2090 - val_accuracy: 0.8538\n",
      "4279/4279 [==============================] - 14s 3ms/step - loss: 0.0791 - accuracy: 0.9885\n",
      "1721/1721 [==============================] - 5s 3ms/step - loss: 0.1097 - accuracy: 0.9746\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 166ms/step - loss: 0.0286 - accuracy: 0.9892 - val_loss: 0.8898 - val_accuracy: 0.3131\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.0232 - accuracy: 0.9907 - val_loss: 0.7205 - val_accuracy: 0.5136\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 2s 156ms/step - loss: 0.0216 - accuracy: 0.9919 - val_loss: 0.7826 - val_accuracy: 0.4706\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 162ms/step - loss: 0.0206 - accuracy: 0.9927 - val_loss: 0.7543 - val_accuracy: 0.5206\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 161ms/step - loss: 0.0199 - accuracy: 0.9932 - val_loss: 0.8750 - val_accuracy: 0.4640\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 197ms/step - loss: 0.0145 - accuracy: 0.9959 - val_loss: 0.6386 - val_accuracy: 0.7351\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 161ms/step - loss: 0.0137 - accuracy: 0.9962 - val_loss: 0.4926 - val_accuracy: 0.7504\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 145ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.6833 - val_accuracy: 0.7384\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.0130 - accuracy: 0.9966 - val_loss: 0.6979 - val_accuracy: 0.7406\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 157ms/step - loss: 0.0130 - accuracy: 0.9966 - val_loss: 0.7084 - val_accuracy: 0.7430\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 156ms/step - loss: 0.4276 - accuracy: 0.9143 - val_loss: 0.2970 - val_accuracy: 0.9367\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 154ms/step - loss: 0.2628 - accuracy: 0.9383 - val_loss: 0.2490 - val_accuracy: 0.9377\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 149ms/step - loss: 0.2388 - accuracy: 0.9394 - val_loss: 0.2384 - val_accuracy: 0.9381\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 159ms/step - loss: 0.2330 - accuracy: 0.9397 - val_loss: 0.2352 - val_accuracy: 0.9381\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 159ms/step - loss: 0.2304 - accuracy: 0.9397 - val_loss: 0.2335 - val_accuracy: 0.9371\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 4s 159ms/step - loss: 0.2933 - accuracy: 0.8743 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 4s 152ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3713e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 4s 156ms/step - loss: 4.5854e-04 - accuracy: 1.0000 - val_loss: 1.7824e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 4s 156ms/step - loss: 2.7256e-04 - accuracy: 1.0000 - val_loss: 1.1501e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 171ms/step - loss: 1.8240e-04 - accuracy: 1.0000 - val_loss: 7.8962e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 165ms/step - loss: 0.8375 - accuracy: 0.8326 - val_loss: 0.3236 - val_accuracy: 0.8297\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 11s 161ms/step - loss: 0.0255 - accuracy: 0.9928 - val_loss: 0.2154 - val_accuracy: 0.8626\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 11s 162ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.1784 - val_accuracy: 0.8906\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 11s 162ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.1733 - val_accuracy: 0.8952\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 11s 162ms/step - loss: 0.0172 - accuracy: 0.9946 - val_loss: 0.1686 - val_accuracy: 0.9003\n",
      "4279/4279 [==============================] - 10s 2ms/step - loss: 0.1111 - accuracy: 0.9895\n",
      "1721/1721 [==============================] - 6s 3ms/step - loss: 0.1262 - accuracy: 0.9660: 0s - loss: 0.1262 - accuracy: 0.96\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.0206 - accuracy: 0.9934 - val_loss: 0.7357 - val_accuracy: 0.5371\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.8186 - val_accuracy: 0.5474\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 2s 150ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.8657 - val_accuracy: 0.5547\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.8777 - val_accuracy: 0.5634\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 2s 152ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.9334 - val_accuracy: 0.5638\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 2s 161ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.7267 - val_accuracy: 0.7514\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.0125 - accuracy: 0.9968 - val_loss: 0.8461 - val_accuracy: 0.7452\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 158ms/step - loss: 0.0123 - accuracy: 0.9971 - val_loss: 0.8586 - val_accuracy: 0.7478\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 155ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.8841 - val_accuracy: 0.7494\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.0120 - accuracy: 0.9971 - val_loss: 0.9329 - val_accuracy: 0.7486\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 4s 156ms/step - loss: 0.4388 - accuracy: 0.9110 - val_loss: 0.3022 - val_accuracy: 0.9360\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 4s 154ms/step - loss: 0.2633 - accuracy: 0.9379 - val_loss: 0.2487 - val_accuracy: 0.9370\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 155ms/step - loss: 0.2370 - accuracy: 0.9389 - val_loss: 0.2370 - val_accuracy: 0.9371\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4s 156ms/step - loss: 0.2309 - accuracy: 0.9392 - val_loss: 0.2336 - val_accuracy: 0.9371\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 4s 152ms/step - loss: 0.2285 - accuracy: 0.9390 - val_loss: 0.2318 - val_accuracy: 0.9372\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 4s 154ms/step - loss: 0.2791 - accuracy: 0.8780 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 4s 150ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.1110e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 4s 156ms/step - loss: 4.6370e-04 - accuracy: 1.0000 - val_loss: 1.8524e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 4s 157ms/step - loss: 2.9870e-04 - accuracy: 1.0000 - val_loss: 1.2237e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 167ms/step - loss: 2.0142e-04 - accuracy: 1.0000 - val_loss: 8.3771e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 12s 167ms/step - loss: 0.7087 - accuracy: 0.8556 - val_loss: 0.2820 - val_accuracy: 0.8466\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 12s 168ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.1791 - val_accuracy: 0.8913\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 14s 196ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.1778 - val_accuracy: 0.8920\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 13s 186ms/step - loss: 0.0166 - accuracy: 0.9947 - val_loss: 0.1683 - val_accuracy: 0.9003\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 12s 171ms/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 0.1478 - val_accuracy: 0.9159\n",
      "4279/4279 [==============================] - 12s 3ms/step - loss: 0.1059 - accuracy: 0.9902 0s - loss: 0.1060 - accuracy: 0.99\n",
      "1721/1721 [==============================] - 6s 4ms/step - loss: 0.1465 - accuracy: 0.9479\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr105C3geo.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.07911981642246246, 0.10972201079130173], [0.11108022183179855, 0.12621992826461792], [0.10594591498374939, 0.14654435217380524]]\n",
      "Accuracy for iterations:  [[0.9884600639343262, 0.9746421575546265], [0.989482581615448, 0.9660139679908752], [0.9902129769325256, 0.9479401111602783]]\n",
      "F1 for iterations:  [[0.9884641874354215, 0.9746253145543056], [0.9894866514296236, 0.9659476699492876], [0.9902162674857102, 0.9476694014296102]]\n",
      "Precision for iterations:  [[0.9885660727407686, 0.9746612204195951], [0.9896081802206068, 0.9662745375191877], [0.9903052955349512, 0.9495162369660378]]\n",
      "Recall for iterations:  [[0.9884600777118817, 0.9746421565065756], [0.9894826024715884, 0.9660139504468502], [0.9902129772999503, 0.9479401293322677]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5C NODE 3 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UX430\\AppData\\Local\\Temp/ipykernel_21336/512859027.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part5.csv')\n"
     ]
    }
   ],
   "source": [
    "training1 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part1.csv')\n",
    "training2 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part2.csv')\n",
    "training3 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part3.csv')\n",
    "training4 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part4.csv')\n",
    "training5 = pd.read_csv('C:/Users/UX430/Documents/thesis/datasets/UNSW-NB15/UNSW-NB15-Train-Basic-Corr25%35C-Part5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define \n",
    "num_nodes = 5\n",
    "global_updates = 3\n",
    "\n",
    "# Define model training parameters\n",
    "loss_fct = \"categorical_crossentropy\"\n",
    "metrics = ['accuracy']\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(model, node, x_train, y_train): \n",
    "    filepath = 'C:/Users/UX430/Documents/thesis/code/models/node'+str(node)+'idcorr255C3geo.hdf5'\n",
    "    callbacks = [\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor = 'val_loss', # Use accuracy to monitor the model\n",
    "                patience = 10 # Stop after 10 steps with lower accuracy\n",
    "            ),\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath = filepath, # file where the checkpoint is saved\n",
    "                monitor = 'val_loss', # Don't overwrite the saved model unless val_loss is worse\n",
    "                save_best_only = True)]# Only save model if it is the best\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fct, metrics=metrics)\n",
    "    history = model.fit(x_train, y_train, epochs=local_epochs, validation_split=0.2, callbacks=callbacks, batch_size=2048)\n",
    "    return model, history.history['loss'], history.history['accuracy'], history.history['val_loss'], history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = build_model((24,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = preprocessing(training1)\n",
    "x2, y2 = preprocessing(training2)\n",
    "x3, y3 = preprocessing(training3)\n",
    "x4, y4 = preprocessing(training4)\n",
    "x5, y5 = preprocessing(training5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 181ms/step - loss: 0.5393 - accuracy: 0.7489 - val_loss: 1.6758 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 0.2027 - accuracy: 0.9544 - val_loss: 3.6085 - val_accuracy: 0.1320\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0847 - accuracy: 0.9892 - val_loss: 4.0488 - val_accuracy: 0.1337\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 0.0519 - accuracy: 0.9894 - val_loss: 2.0923 - val_accuracy: 0.1343\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 206ms/step - loss: 0.0370 - accuracy: 0.9903 - val_loss: 1.6371 - val_accuracy: 0.1401\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 212ms/step - loss: 0.0219 - accuracy: 0.9950 - val_loss: 0.8711 - val_accuracy: 0.7271\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 219ms/step - loss: 0.0203 - accuracy: 0.9950 - val_loss: 0.6223 - val_accuracy: 0.7294\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 185ms/step - loss: 0.0195 - accuracy: 0.9950 - val_loss: 0.7629 - val_accuracy: 0.7275\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 170ms/step - loss: 0.0189 - accuracy: 0.9950 - val_loss: 0.6572 - val_accuracy: 0.7283\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 172ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.5615 - val_accuracy: 0.7307\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 178ms/step - loss: 0.6814 - accuracy: 0.8284 - val_loss: 0.4621 - val_accuracy: 0.8586\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 187ms/step - loss: 0.4393 - accuracy: 0.8621 - val_loss: 0.4274 - val_accuracy: 0.8631\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 168ms/step - loss: 0.4229 - accuracy: 0.8641 - val_loss: 0.4172 - val_accuracy: 0.8635\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 183ms/step - loss: 0.4153 - accuracy: 0.8647 - val_loss: 0.4132 - val_accuracy: 0.8648\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 185ms/step - loss: 0.4107 - accuracy: 0.8654 - val_loss: 0.4088 - val_accuracy: 0.8651\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 6s 209ms/step - loss: 0.1994 - accuracy: 0.9256 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 175ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2715e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 4.2659e-04 - accuracy: 1.0000 - val_loss: 1.7053e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 173ms/step - loss: 2.5153e-04 - accuracy: 1.0000 - val_loss: 1.0910e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 184ms/step - loss: 1.6586e-04 - accuracy: 1.0000 - val_loss: 7.3649e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 15s 214ms/step - loss: 0.7972 - accuracy: 0.8453 - val_loss: 0.4424 - val_accuracy: 0.8277\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 15s 216ms/step - loss: 0.0342 - accuracy: 0.9919 - val_loss: 0.3176 - val_accuracy: 0.8279\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 15s 212ms/step - loss: 0.0253 - accuracy: 0.9919 - val_loss: 0.2509 - val_accuracy: 0.8323\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 15s 208ms/step - loss: 0.0228 - accuracy: 0.9915 - val_loss: 0.2372 - val_accuracy: 0.8364\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 14s 203ms/step - loss: 0.0213 - accuracy: 0.9920 - val_loss: 0.2045 - val_accuracy: 0.8576\n",
      "4279/4279 [==============================] - 15s 3ms/step - loss: 0.0854 - accuracy: 0.9879\n",
      "1721/1721 [==============================] - 14s 8ms/step - loss: 0.1233 - accuracy: 0.9722\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 6s 362ms/step - loss: 0.0304 - accuracy: 0.9890 - val_loss: 0.6837 - val_accuracy: 0.5475\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 5s 326ms/step - loss: 0.0243 - accuracy: 0.9903 - val_loss: 0.8217 - val_accuracy: 0.4209\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 5s 288ms/step - loss: 0.0221 - accuracy: 0.9919 - val_loss: 0.6621 - val_accuracy: 0.5958\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 5s 282ms/step - loss: 0.0211 - accuracy: 0.9921 - val_loss: 0.7667 - val_accuracy: 0.5050\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 0.0200 - accuracy: 0.9927 - val_loss: 0.7843 - val_accuracy: 0.5108\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 6s 400ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.7377 - val_accuracy: 0.7283\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.0144 - accuracy: 0.9961 - val_loss: 0.6855 - val_accuracy: 0.7328\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 5s 339ms/step - loss: 0.0141 - accuracy: 0.9962 - val_loss: 0.8307 - val_accuracy: 0.7300\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 5s 339ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.7994 - val_accuracy: 0.7314\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 5s 325ms/step - loss: 0.0137 - accuracy: 0.9965 - val_loss: 0.7753 - val_accuracy: 0.7333\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 336ms/step - loss: 0.8308 - accuracy: 0.8163 - val_loss: 0.5129 - val_accuracy: 0.8592\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 6s 233ms/step - loss: 0.4479 - accuracy: 0.8615 - val_loss: 0.4277 - val_accuracy: 0.8643\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 9s 330ms/step - loss: 0.4159 - accuracy: 0.8659 - val_loss: 0.4135 - val_accuracy: 0.8649\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 9s 346ms/step - loss: 0.4073 - accuracy: 0.8658 - val_loss: 0.4084 - val_accuracy: 0.8647\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 8s 326ms/step - loss: 0.4029 - accuracy: 0.8657 - val_loss: 0.4053 - val_accuracy: 0.8643\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 10s 358ms/step - loss: 0.3422 - accuracy: 0.8581 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 7s 274ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.3284e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 7s 248ms/step - loss: 3.8807e-04 - accuracy: 1.0000 - val_loss: 1.1994e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 9s 330ms/step - loss: 1.7278e-04 - accuracy: 1.0000 - val_loss: 6.4806e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 10s 377ms/step - loss: 1.0078e-04 - accuracy: 1.0000 - val_loss: 4.0374e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 24s 342ms/step - loss: 1.0503 - accuracy: 0.8036 - val_loss: 0.3417 - val_accuracy: 0.8286\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 23s 328ms/step - loss: 0.0309 - accuracy: 0.9929 - val_loss: 0.2337 - val_accuracy: 0.8482\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 24s 340ms/step - loss: 0.0217 - accuracy: 0.9936 - val_loss: 0.2001 - val_accuracy: 0.8708\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 22s 320ms/step - loss: 0.0192 - accuracy: 0.9941 - val_loss: 0.1757 - val_accuracy: 0.8915\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 17s 248ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.1893 - val_accuracy: 0.8863\n",
      "4279/4279 [==============================] - 21s 5ms/step - loss: 0.0968 - accuracy: 0.9889\n",
      "1721/1721 [==============================] - 16s 9ms/step - loss: 0.1369 - accuracy: 0.9630\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 5s 340ms/step - loss: 0.0206 - accuracy: 0.9932 - val_loss: 0.7193 - val_accuracy: 0.5644\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 5s 335ms/step - loss: 0.0189 - accuracy: 0.9937 - val_loss: 0.8442 - val_accuracy: 0.5371\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 5s 316ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 1.0348 - val_accuracy: 0.4892\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 5s 324ms/step - loss: 0.0175 - accuracy: 0.9941 - val_loss: 0.8742 - val_accuracy: 0.5659\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 5s 311ms/step - loss: 0.0171 - accuracy: 0.9944 - val_loss: 0.8505 - val_accuracy: 0.5937\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 5s 354ms/step - loss: 0.0138 - accuracy: 0.9962 - val_loss: 0.7529 - val_accuracy: 0.7462\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 4s 258ms/step - loss: 0.0130 - accuracy: 0.9970 - val_loss: 0.8292 - val_accuracy: 0.7446\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 243ms/step - loss: 0.0124 - accuracy: 0.9967 - val_loss: 0.7802 - val_accuracy: 0.7532\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 215ms/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.8835 - val_accuracy: 0.7463\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 4s 258ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 0.8176 - val_accuracy: 0.7529\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 353ms/step - loss: 0.8833 - accuracy: 0.8125 - val_loss: 0.5505 - val_accuracy: 0.8479\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 8s 316ms/step - loss: 0.4630 - accuracy: 0.8575 - val_loss: 0.4302 - val_accuracy: 0.8629\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 9s 328ms/step - loss: 0.4121 - accuracy: 0.8654 - val_loss: 0.4107 - val_accuracy: 0.8639\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 8s 319ms/step - loss: 0.4019 - accuracy: 0.8657 - val_loss: 0.4051 - val_accuracy: 0.8640\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 8s 312ms/step - loss: 0.3982 - accuracy: 0.8657 - val_loss: 0.4031 - val_accuracy: 0.8640\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 9s 349ms/step - loss: 0.3258 - accuracy: 0.8552 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 9s 336ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.8281e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 9s 324ms/step - loss: 3.1193e-04 - accuracy: 1.0000 - val_loss: 8.7859e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 9s 340ms/step - loss: 1.0835e-04 - accuracy: 1.0000 - val_loss: 3.1469e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 9s 328ms/step - loss: 4.1622e-05 - accuracy: 1.0000 - val_loss: 1.3216e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 25s 359ms/step - loss: 1.0030 - accuracy: 0.8176 - val_loss: 0.1944 - val_accuracy: 0.8873\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 25s 362ms/step - loss: 0.0226 - accuracy: 0.9937 - val_loss: 0.1861 - val_accuracy: 0.8726\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 22s 316ms/step - loss: 0.0187 - accuracy: 0.9943 - val_loss: 0.1984 - val_accuracy: 0.8737\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 17s 244ms/step - loss: 0.0175 - accuracy: 0.9946 - val_loss: 0.1735 - val_accuracy: 0.8942\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 18s 258ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.1823 - val_accuracy: 0.8911\n",
      "4279/4279 [==============================] - 30s 7ms/step - loss: 0.1229 - accuracy: 0.9891\n",
      "1721/1721 [==============================] - 12s 7ms/step - loss: 0.1541 - accuracy: 0.9476\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr255C3geo.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 3s 181ms/step - loss: 0.5393 - accuracy: 0.7489 - val_loss: 1.6758 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 0.2027 - accuracy: 0.9544 - val_loss: 3.6085 - val_accuracy: 0.1320\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0847 - accuracy: 0.9892 - val_loss: 4.0488 - val_accuracy: 0.1337\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 0.0519 - accuracy: 0.9894 - val_loss: 2.0923 - val_accuracy: 0.1343\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 206ms/step - loss: 0.0370 - accuracy: 0.9903 - val_loss: 1.6371 - val_accuracy: 0.1401\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 3s 212ms/step - loss: 0.0219 - accuracy: 0.9950 - val_loss: 0.8711 - val_accuracy: 0.7271\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 3s 219ms/step - loss: 0.0203 - accuracy: 0.9950 - val_loss: 0.6223 - val_accuracy: 0.7294\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 185ms/step - loss: 0.0195 - accuracy: 0.9950 - val_loss: 0.7629 - val_accuracy: 0.7275\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 170ms/step - loss: 0.0189 - accuracy: 0.9950 - val_loss: 0.6572 - val_accuracy: 0.7283\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 172ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.5615 - val_accuracy: 0.7307\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 5s 178ms/step - loss: 0.6814 - accuracy: 0.8284 - val_loss: 0.4621 - val_accuracy: 0.8586\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 5s 187ms/step - loss: 0.4393 - accuracy: 0.8621 - val_loss: 0.4274 - val_accuracy: 0.8631\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 4s 168ms/step - loss: 0.4229 - accuracy: 0.8641 - val_loss: 0.4172 - val_accuracy: 0.8635\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 5s 183ms/step - loss: 0.4153 - accuracy: 0.8647 - val_loss: 0.4132 - val_accuracy: 0.8648\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 5s 185ms/step - loss: 0.4107 - accuracy: 0.8654 - val_loss: 0.4088 - val_accuracy: 0.8651\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 6s 209ms/step - loss: 0.1994 - accuracy: 0.9256 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 5s 175ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.2715e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 5s 170ms/step - loss: 4.2659e-04 - accuracy: 1.0000 - val_loss: 1.7053e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 5s 173ms/step - loss: 2.5153e-04 - accuracy: 1.0000 - val_loss: 1.0910e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 5s 184ms/step - loss: 1.6586e-04 - accuracy: 1.0000 - val_loss: 7.3649e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 15s 214ms/step - loss: 0.7972 - accuracy: 0.8453 - val_loss: 0.4424 - val_accuracy: 0.8277\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 15s 216ms/step - loss: 0.0342 - accuracy: 0.9919 - val_loss: 0.3176 - val_accuracy: 0.8279\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 15s 212ms/step - loss: 0.0253 - accuracy: 0.9919 - val_loss: 0.2509 - val_accuracy: 0.8323\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 15s 208ms/step - loss: 0.0228 - accuracy: 0.9915 - val_loss: 0.2372 - val_accuracy: 0.8364\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 14s 203ms/step - loss: 0.0213 - accuracy: 0.9920 - val_loss: 0.2045 - val_accuracy: 0.8576\n",
      "4279/4279 [==============================] - 15s 3ms/step - loss: 0.0854 - accuracy: 0.9879\n",
      "1721/1721 [==============================] - 14s 8ms/step - loss: 0.1233 - accuracy: 0.9722\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 6s 362ms/step - loss: 0.0304 - accuracy: 0.9890 - val_loss: 0.6837 - val_accuracy: 0.5475\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 5s 326ms/step - loss: 0.0243 - accuracy: 0.9903 - val_loss: 0.8217 - val_accuracy: 0.4209\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 5s 288ms/step - loss: 0.0221 - accuracy: 0.9919 - val_loss: 0.6621 - val_accuracy: 0.5958\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 5s 282ms/step - loss: 0.0211 - accuracy: 0.9921 - val_loss: 0.7667 - val_accuracy: 0.5050\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 0.0200 - accuracy: 0.9927 - val_loss: 0.7843 - val_accuracy: 0.5108\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 6s 400ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.7377 - val_accuracy: 0.7283\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.0144 - accuracy: 0.9961 - val_loss: 0.6855 - val_accuracy: 0.7328\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 5s 339ms/step - loss: 0.0141 - accuracy: 0.9962 - val_loss: 0.8307 - val_accuracy: 0.7300\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 5s 339ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.7994 - val_accuracy: 0.7314\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 5s 325ms/step - loss: 0.0137 - accuracy: 0.9965 - val_loss: 0.7753 - val_accuracy: 0.7333\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 336ms/step - loss: 0.8308 - accuracy: 0.8163 - val_loss: 0.5129 - val_accuracy: 0.8592\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 6s 233ms/step - loss: 0.4479 - accuracy: 0.8615 - val_loss: 0.4277 - val_accuracy: 0.8643\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 9s 330ms/step - loss: 0.4159 - accuracy: 0.8659 - val_loss: 0.4135 - val_accuracy: 0.8649\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 9s 346ms/step - loss: 0.4073 - accuracy: 0.8658 - val_loss: 0.4084 - val_accuracy: 0.8647\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 8s 326ms/step - loss: 0.4029 - accuracy: 0.8657 - val_loss: 0.4053 - val_accuracy: 0.8643\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 10s 358ms/step - loss: 0.3422 - accuracy: 0.8581 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 7s 274ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.3284e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 7s 248ms/step - loss: 3.8807e-04 - accuracy: 1.0000 - val_loss: 1.1994e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 9s 330ms/step - loss: 1.7278e-04 - accuracy: 1.0000 - val_loss: 6.4806e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 10s 377ms/step - loss: 1.0078e-04 - accuracy: 1.0000 - val_loss: 4.0374e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 24s 342ms/step - loss: 1.0503 - accuracy: 0.8036 - val_loss: 0.3417 - val_accuracy: 0.8286\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 23s 328ms/step - loss: 0.0309 - accuracy: 0.9929 - val_loss: 0.2337 - val_accuracy: 0.8482\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 24s 340ms/step - loss: 0.0217 - accuracy: 0.9936 - val_loss: 0.2001 - val_accuracy: 0.8708\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 22s 320ms/step - loss: 0.0192 - accuracy: 0.9941 - val_loss: 0.1757 - val_accuracy: 0.8915\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 17s 248ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.1893 - val_accuracy: 0.8863\n",
      "4279/4279 [==============================] - 21s 5ms/step - loss: 0.0968 - accuracy: 0.9889\n",
      "1721/1721 [==============================] - 16s 9ms/step - loss: 0.1369 - accuracy: 0.9630\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 5s 340ms/step - loss: 0.0206 - accuracy: 0.9932 - val_loss: 0.7193 - val_accuracy: 0.5644\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 5s 335ms/step - loss: 0.0189 - accuracy: 0.9937 - val_loss: 0.8442 - val_accuracy: 0.5371\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 5s 316ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 1.0348 - val_accuracy: 0.4892\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 5s 324ms/step - loss: 0.0175 - accuracy: 0.9941 - val_loss: 0.8742 - val_accuracy: 0.5659\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 5s 311ms/step - loss: 0.0171 - accuracy: 0.9944 - val_loss: 0.8505 - val_accuracy: 0.5937\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 5s 354ms/step - loss: 0.0138 - accuracy: 0.9962 - val_loss: 0.7529 - val_accuracy: 0.7462\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 4s 258ms/step - loss: 0.0130 - accuracy: 0.9970 - val_loss: 0.8292 - val_accuracy: 0.7446\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 3s 243ms/step - loss: 0.0124 - accuracy: 0.9967 - val_loss: 0.7802 - val_accuracy: 0.7532\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 3s 215ms/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.8835 - val_accuracy: 0.7463\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 4s 258ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 0.8176 - val_accuracy: 0.7529\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 9s 353ms/step - loss: 0.8833 - accuracy: 0.8125 - val_loss: 0.5505 - val_accuracy: 0.8479\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 8s 316ms/step - loss: 0.4630 - accuracy: 0.8575 - val_loss: 0.4302 - val_accuracy: 0.8629\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 9s 328ms/step - loss: 0.4121 - accuracy: 0.8654 - val_loss: 0.4107 - val_accuracy: 0.8639\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 8s 319ms/step - loss: 0.4019 - accuracy: 0.8657 - val_loss: 0.4051 - val_accuracy: 0.8640\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 8s 312ms/step - loss: 0.3982 - accuracy: 0.8657 - val_loss: 0.4031 - val_accuracy: 0.8640\n",
      "Epoch 1/5\n",
      "27/27 [==============================] - 9s 349ms/step - loss: 0.3258 - accuracy: 0.8552 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "27/27 [==============================] - 9s 336ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.8281e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "27/27 [==============================] - 9s 324ms/step - loss: 3.1193e-04 - accuracy: 1.0000 - val_loss: 8.7859e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "27/27 [==============================] - 9s 340ms/step - loss: 1.0835e-04 - accuracy: 1.0000 - val_loss: 3.1469e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "27/27 [==============================] - 9s 328ms/step - loss: 4.1622e-05 - accuracy: 1.0000 - val_loss: 1.3216e-05 - val_accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "70/70 [==============================] - 25s 359ms/step - loss: 1.0030 - accuracy: 0.8176 - val_loss: 0.1944 - val_accuracy: 0.8873\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 25s 362ms/step - loss: 0.0226 - accuracy: 0.9937 - val_loss: 0.1861 - val_accuracy: 0.8726\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 22s 316ms/step - loss: 0.0187 - accuracy: 0.9943 - val_loss: 0.1984 - val_accuracy: 0.8737\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 17s 244ms/step - loss: 0.0175 - accuracy: 0.9946 - val_loss: 0.1735 - val_accuracy: 0.8942\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 18s 258ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.1823 - val_accuracy: 0.8911\n",
      "4279/4279 [==============================] - 30s 7ms/step - loss: 0.1229 - accuracy: 0.9891\n",
      "1721/1721 [==============================] - 12s 7ms/step - loss: 0.1541 - accuracy: 0.9476\n"
     ]
    }
   ],
   "source": [
    "# Values saved each iteration \n",
    "loss_it = []\n",
    "accuracy_it = []\n",
    "f1_it = []\n",
    "precision_it = []\n",
    "recall_it = []\n",
    "\n",
    "for i in range(global_updates): \n",
    "    gradients_list = []\n",
    "    for node in range(num_nodes): \n",
    "        cp = global_model # create a copy of the global model\n",
    "        if node == 0:\n",
    "            x, y = x1, y1\n",
    "        elif node == 1:\n",
    "            x, y = x2, y2\n",
    "        elif node == 2:\n",
    "            x, y = x3, y3\n",
    "        elif node == 3: \n",
    "            x, y = x4, y4\n",
    "        else: \n",
    "            x, y = x5, y5\n",
    "        local_model, local_loss, local_acc, local_val_loss, local_val_acc = train_local_model(cp, node, x, y)\n",
    "        with tf.GradientTape() as tape: \n",
    "            predictions = local_model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, predictions))\n",
    "        gradients = tape.gradient(loss, local_model.trainable_variables)\n",
    "        gradients_list.append(gradients)\n",
    "\n",
    "    avg_grad = aggregate(gradients_list)\n",
    "    optimizer.apply_gradients(zip(avg_grad, global_model.trainable_variables)) # apply gradients to global model\n",
    "    loss_basic, accuracy_basic, f1_basic, precision_basic, recall_basic = evaluation(global_model, xbasic, ybasic) \n",
    "    loss_plus, accuracy_plus, f1_plus, precision_plus, recall_plus = evaluation(global_model, xplus, yplus)\n",
    "\n",
    "    loss_it.append([loss_basic, loss_plus])\n",
    "    accuracy_it.append([accuracy_basic, accuracy_plus])\n",
    "    f1_it.append([f1_basic, f1_plus])\n",
    "    precision_it.append([precision_basic, precision_plus])\n",
    "    recall_it.append([recall_basic, recall_plus])\n",
    "\n",
    "\n",
    "global_model.save('C:/Users/UX430/Documents/thesis/code/models/idcorr255C3geo.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for iterations:  [[0.08544706553220749, 0.12328588217496872], [0.09680859744548798, 0.13693860173225403], [0.12291232496500015, 0.15408408641815186]]\n",
      "Accuracy for iterations:  [[0.9878538846969604, 0.9722262620925903], [0.9889128804206848, 0.9629804491996765], [0.9890589714050293, 0.9475768208503723]]\n",
      "F1 for iterations:  [[0.9878578666501733, 0.9722010170737153], [0.988916709205785, 0.9628907034001225], [0.9890627905095888, 0.9472986746263102]]\n",
      "Precision for iterations:  [[0.9879434565329552, 0.9722715522619876], [0.9890099785924518, 0.9633804123844554], [0.9891592171717783, 0.949208839513966]]\n",
      "Recall for iterations:  [[0.9878538666043414, 0.9722262588098525], [0.9889129101054661, 0.9629804548426942], [0.9890589850711385, 0.9475768364455424]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for iterations: \", loss_it)\n",
    "print(\"Accuracy for iterations: \", accuracy_it)\n",
    "print(\"F1 for iterations: \", f1_it)\n",
    "print(\"Precision for iterations: \", precision_it)\n",
    "print(\"Recall for iterations: \", recall_it)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
